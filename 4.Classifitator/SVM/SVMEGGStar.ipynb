{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Analisis:\\n- All the data (list = patient with all values)\\n- BandPower = patient = 12 brain reagions = 5 bands = 1 value\\n\\n\\n- Lavels structure all patiens with one value = list (no shape)'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'''Analisis:\n",
    "- All the data (list = patient with all values)\n",
    "- BandPower = patient = 12 brain reagions = 5 bands = 1 value\n",
    "\n",
    "\n",
    "- Lavels structure all patiens with one value = list (no shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple regression is like linear regression, but with more than one independent value, meaning that we try to predict a value based on two or more variables.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/Feature_array_EC_norm.p\", \"rb\") as fp:   # Unpickling\n",
    "    Feature_array_EC_norm = pickle.load(fp)\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/Feature_array_EO_norm.p\", \"rb\") as fp:   # Unpickling\n",
    "    Feature_array_EO_norm = pickle.load(fp)\n",
    "\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/Sub_idx_EC\", \"rb\") as fp:   # Unpickling\n",
    "    Sub_idx_EC = pickle.load(fp)\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/Sub_idx_EO\", \"rb\") as fp:   # Unpickling\n",
    "    Sub_idx_EO = pickle.load(fp)\n",
    "\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/nameseo.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Old_EO = pickle.load(fp)\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/5.EEGAllChanels/Features/namesec.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Old_EC = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data to analise\n",
    "#Open the file in universal line ending mode \n",
    "with open('/Users/laianavarroolivella/Proyectos/EEG/Files_EEG/TEIQue-SF.csv', 'rU') as infile:\n",
    "  # read the file as a dictionary for each row ({header : value})\n",
    "  data = {}\n",
    "  reader = csv.DictReader(infile)\n",
    "  for row in reader:\n",
    "    for header, value in row.items():\n",
    "      try:\n",
    "        data[header].append(value)\n",
    "      except KeyError:\n",
    "        data[header] = [value]\n",
    "\n",
    "# extract the variables you want\n",
    "names = data['ID']\n",
    "TeiQueSF_emotionality = data['TeiQueSF_emotionality']\n",
    "TeiQueSF_wellBeing = data['TeiQueSF_well_being']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCorr= []\n",
    "for i in Sub_idx_EC:\n",
    "    hename = Old_EC[int(i)]   #Select the name of the patient\n",
    "    hename = str(hename[:-7])  #Select only the number witout the extension \n",
    "    if hename in names:    #If this is in the testNames:\n",
    "        indices = [i for i, s in enumerate(names) if hename in s] #Get the position of the testNames\n",
    "        x = (float(TeiQueSF_wellBeing[int(indices[0])])) #Get the value of the patient in the test selected\n",
    "        xCorr.append(x) #Add it in to the xCorr\n",
    "    else:\n",
    "        print(\"No esta\"+hename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "X=np.array(Feature_array_EC_norm)\n",
    "print(type(X))\n",
    "print(type(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Lavels\n",
    "Y = np.array(xCorr)\n",
    "print(type(Y))\n",
    "print(type(Y[0]))'''\n",
    "#Lavels\n",
    "Lavels2 = []\n",
    "for i  in xCorr:\n",
    "    if i>4.0:\n",
    "        Lavels2.append(int(0))\n",
    "    if i<=4.0:\n",
    "        Lavels2.append(int(1))\n",
    "\n",
    "Y = np.array(Lavels2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(141, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(141,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(187,x)\n",
    "\n",
    "#sub1 - num epoch - 42 features (band x brainR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=None)\n",
    "#Normalize data X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(112, 3)\n(29, 3)\n\n\n(112,)\n(29,)\n\n\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print('\\n')\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.0478840682921815"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.0915911 , -0.16066002, -0.20515782])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30706647732341846"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1600505552251486\n0.0672838759664421\n0.2593913567689604\n"
     ]
    }
   ],
   "source": [
    "# MAE output is non-negative floating point. The best value is 0.0.\n",
    "print(metrics.mean_absolute_error(y_test, y_pred))\n",
    "# A non-negative floating point value (the best value is 0.0), or an array of floating point values, one for each individual target.\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.0478840682921815\n"
     ]
    }
   ],
   "source": [
    "#The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearSVC(max_iter=10000, multi_class='crammer_singer', tol=1e-05)\nPredictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n\nAccuracy:  0.8620689655172413\nEl q ha de ser:  [0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\nRoc:  0.5\nRecall:  0.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "    \n",
    "# Create an object, or instance, of the class.\n",
    "clf = LinearSVC(random_state=0, tol=1e-4)\n",
    "# Train it\n",
    "# Adjust the parameters so it can predict the correct class as accurately.\n",
    "clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.00001,\n",
    "                C=1.0, multi_class='crammer_singer', fit_intercept=True,\n",
    "                intercept_scaling=1, class_weight=None, verbose=0,\n",
    "                random_state=None, max_iter=10000)\n",
    "#fitting (learning) the parameters of a model in sklearn is fit(X, y).\n",
    "print(clf.fit(X_train, y_train))\n",
    "clf.coef_\n",
    "clf.intercept_\n",
    "clf.score(X_train, y_train)\n",
    "#predict the class of the test data\n",
    "#sklearn is predict(X)\n",
    "prediction = (clf.predict(X_test))\n",
    "print('Predictet: {}\\n'.format(prediction) )\n",
    "# Then, compute the classification accuracy obtained.\n",
    "print('Accuracy: ', accuracy_score(y_test, prediction))\n",
    "print('El q ha de ser: ',y_test)\n",
    "\n",
    "print('Roc: ',roc_auc_score(y_test, prediction))\n",
    "\n",
    "print('Recall: ',recall_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}