{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Analisis:\\n- All the data (list = patient with all values)\\n- BandPower = patient = 12 brain reagions = 5 bands = 1 value\\n\\n\\n- Lavels structure all patiens with one value = list (no shape)'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'''Analisis:\n",
    "- All the data (list = patient with all values)\n",
    "- BandPower = patient = 12 brain reagions = 5 bands = 1 value\n",
    "\n",
    "\n",
    "- Lavels structure all patiens with one value = list (no shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple regression is like linear regression, but with more than one independent value, meaning that we try to predict a value based on two or more variables.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/2.BanPOwerEpoch12Chanels/list_final_EO.txt\", \"rb\") as fp:   # Unpickling\n",
    "    withEpoch = pickle.load(fp)\n",
    "\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/1.create12ChanelsXPatient/sorted_list_ECsave.txt\", \"rb\") as fp:   # Unpickling\n",
    "    sorted_list_EC_up = pickle.load(fp)\n",
    "\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/1.create12ChanelsXPatient/sorted_list_EO_save.txt\", \"rb\") as fp:   # Unpickling\n",
    "    sorted_list_EO_up = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data to analise\n",
    "#Open the file in universal line ending mode \n",
    "with open('/Users/laianavarroolivella/Proyectos/EEG/Files_EEG/TEIQue-SF.csv', 'rU') as infile:\n",
    "  # read the file as a dictionary for each row ({header : value})\n",
    "  data = {}\n",
    "  reader = csv.DictReader(infile)\n",
    "  for row in reader:\n",
    "    for header, value in row.items():\n",
    "      try:\n",
    "        data[header].append(value)\n",
    "      except KeyError:\n",
    "        data[header] = [value]\n",
    "\n",
    "# extract the variables you want\n",
    "names = data['ID']\n",
    "TeiQueSF_emotionality = data['TeiQueSF_emotionality']\n",
    "TeiQueSF_wellBeing = data['TeiQueSF_well_being']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCorr = []\n",
    "for e in range(0,len(sorted_list_EO_up)):       #For each frequency band:\n",
    "    hename = sorted_list_EO_up[e]   #Select the name of the patient\n",
    "    hename = str(hename[:-7])  #Select only the number witout the extension \n",
    "    if hename in names:    #If this is in the testNames:\n",
    "        indices = [i for i, s in enumerate(names) if hename in s] #Get the position of the testNames\n",
    "        x = (float(TeiQueSF_wellBeing[int(indices[0])])) #Get the value of the patient in the test selected\n",
    "        xCorr.append(x) #Add it in to the xCorr\n",
    "    else:\n",
    "        print(\"No esta\"+hename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12, 5, 187)\n(187, 5, 12)\n(187, 60)\n"
     ]
    }
   ],
   "source": [
    "#Epoch (samples data point) all incluede for each subject <- + band + brain region (concatenated)\n",
    "\n",
    "#All Epochs ! Majoriti points <- find a ave\n",
    "a = np.array(withEpoch)\n",
    "print(a.shape)\n",
    "b = a.T\n",
    "print(b.shape)\n",
    "c = b.reshape(187,60)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Lavels\n",
    "Y = np.array(xCorr)\n",
    "print(type(Y))\n",
    "print(type(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(c, Y, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training = normalise! - mean and standar desv.\n",
    "# Test should be the same\n",
    "New_Normalized = []\n",
    "normalizedXtrain = preprocessing.normalize(X_train)\n",
    "#normalizedXtest = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(149, 5, 12)\n(38, 5, 12)\n\n\n(149,)\n(38,)\n\n\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print('\\n')\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3127504605171769"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.08027846e+00,  1.08496097e+01, -9.02668152e+00,  1.64281838e+00,\n",
       "        2.80228414e-01, -1.22665430e+01,  1.64273904e+01, -1.42900240e+00,\n",
       "        2.07571409e+01, -2.27608770e+00, -1.57465432e+01, -6.93343454e+00,\n",
       "        2.79467625e+00, -1.00744839e+00,  1.01104620e+00,  4.51907384e+00,\n",
       "       -7.55761592e-02, -5.55501400e+00,  1.67277785e-01,  2.95795698e+00,\n",
       "        4.45028130e+00,  6.98873747e-01, -9.45033703e-01, -6.25981344e+00,\n",
       "        1.36530192e+00,  5.86478370e+00, -2.33863922e+00, -9.95258615e+00,\n",
       "       -5.41398110e+00,  4.06465111e+00, -1.01737860e+00,  9.74207381e+00,\n",
       "        4.39093632e+00,  8.29430732e+00, -1.30485333e+01, -3.35019030e+00,\n",
       "       -1.11133018e+00, -2.18083328e+00,  1.96977214e+00,  2.08743512e+01,\n",
       "        1.65190479e+01,  4.43653532e+01,  3.82185286e+01, -6.34156600e+01,\n",
       "        1.42405736e+02, -2.79848331e+00, -1.65053534e+02, -2.08241317e+01,\n",
       "       -1.47102736e+01,  8.44823234e+00, -2.11504018e+01,  3.89103777e+00,\n",
       "       -1.24289503e+00, -9.95056710e+01, -1.87134944e+02,  2.26301003e+02,\n",
       "       -4.68754316e+02,  8.54072071e+00,  6.46285951e+02, -1.36064708e+01])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.377772671619355"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.550674114344988\n12.494175008863406\n3.5347100317937548\n"
     ]
    }
   ],
   "source": [
    "# MAE output is non-negative floating point. The best value is 0.0.\n",
    "print(metrics.mean_absolute_error(y_test, y_pred))\n",
    "# A non-negative floating point value (the best value is 0.0), or an array of floating point values, one for each individual target.\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  5.10908076,   5.18832987,   5.94051614,   5.97274679,\n",
       "         5.66529845,   5.45863101,   5.12895805,   6.07526274,\n",
       "         6.03976559,   5.50735286,   5.87573254,   5.65128134,\n",
       "       -16.76765533,   5.91555935,   5.89089311,   4.99320052,\n",
       "         5.1644762 ,   6.73041354,   5.77927634,   5.57614557,\n",
       "         5.26582294,   6.35606118,   5.69230901,   3.54328787,\n",
       "         7.26188704,   5.52159783,   5.08854701,   5.04187601,\n",
       "         4.66894025,   5.99892787,   4.58568301,   5.56312186,\n",
       "         5.24754648,   5.16580446,   3.79739861,   5.26842165,\n",
       "         5.88479009,   4.57519832])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6.5       , 5.66666667, 6.33333333, 6.66666667, 5.83333333,\n",
       "       5.83333333, 5.83333333, 4.        , 4.33333333, 6.83333333,\n",
       "       4.66666667, 4.5       , 3.83333333, 4.33333333, 6.83333333,\n",
       "       4.66666667, 5.83333333, 6.5       , 5.33333333, 6.83333333,\n",
       "       3.        , 5.33333333, 6.5       , 5.        , 6.66666667,\n",
       "       6.16666667, 6.33333333, 6.16666667, 6.16666667, 6.5       ,\n",
       "       6.66666667, 4.5       , 6.33333333, 6.5       , 4.5       ,\n",
       "       6.66666667, 6.5       , 6.33333333])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-11.373260566531844\n"
     ]
    }
   ],
   "source": [
    "#The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "print(regr.score(X_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}