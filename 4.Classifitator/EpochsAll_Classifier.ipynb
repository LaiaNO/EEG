{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Analisis:\\n- All the data (list = patient with all values)\\n- BandPower = patient = 12 brain reagions = 5 bands = 1 value\\n\\n\\n- Lavels structure all patiens with one value = list (no shape)'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "'''Analisis:\n",
    "- All the data (list = patient with all values)\n",
    "- BandPower = patient = 12 brain reagions = 5 bands = 1 value\n",
    "\n",
    "\n",
    "- Lavels structure all patiens with one value = list (no shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple regression is like linear regression, but with more than one independent value, meaning that we try to predict a value based on two or more variables.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/4.Classifitator/Regression/RearengeEpochsForregetion/list_final_EO.txt\", \"rb\") as fp:   \n",
    "    withEpoch = pickle.load(fp)\n",
    "with open(\"/Users/laianavarroolivella/Proyectos/EEG/1.dataToBrainReagions/sorted_list_EC.txt\", \"rb\") as fp:   # Unpickling\n",
    "    sorted_list_EC_up = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data to analise\n",
    "#Open the file in universal line ending mode \n",
    "with open('/Users/laianavarroolivella/Proyectos/EEG/Files_EEG/TEIQue-SF.csv', 'rU') as infile:\n",
    "  # read the file as a dictionary for each row ({header : value})\n",
    "  data = {}\n",
    "  reader = csv.DictReader(infile)\n",
    "  for row in reader:\n",
    "    for header, value in row.items():\n",
    "      try:\n",
    "        data[header].append(value)\n",
    "      except KeyError:\n",
    "        data[header] = [value]\n",
    "\n",
    "# extract the variables you want\n",
    "names = data['ID']\n",
    "TeiQueSF_emotionality = data['TeiQueSF_emotionality']\n",
    "TeiQueSF_wellBeing = data['TeiQueSF_well_being']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del withEpoch[151]\n",
    "del withEpoch[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "longimin = 600\n",
    "for i in withEpoch:\n",
    "    if len(i)<longimin:\n",
    "        longimin=len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = []\n",
    "for i in withEpoch:\n",
    "    Data.append(i[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sorted_list_EO_up[151]\n",
    "del sorted_list_EO_up[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCorr = []\n",
    "for e in range(0,len(sorted_list_EO_up)):       #For each frequency band:\n",
    "    hename = sorted_list_EO_up[e]   #Select the name of the patient\n",
    "    hename = str(hename[:-7])  #Select only the number witout the extension \n",
    "    if hename in names:    #If this is in the testNames:\n",
    "        indices = [i for i, s in enumerate(names) if hename in s] #Get the position of the testNames\n",
    "        x = (float(TeiQueSF_wellBeing[int(indices[0])])) #Get the value of the patient in the test selected\n",
    "        xCorr.append(x) #Add it in to the xCorr\n",
    "    else:\n",
    "        print(\"No esta\"+hename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizedData = []\n",
    "for i in Data:\n",
    "    x=[]\n",
    "    normalized_arr = preprocessing.normalize([i])\n",
    "    x.append(normalized_arr)\n",
    "    normalizedData.append(normalized_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n(183, 400)\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "X=np.array(normalizedData)\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lavels\n",
    "Lavels2 = []\n",
    "for i  in xCorr:\n",
    "    if i>5.5:\n",
    "        Lavels2.append(int(0))\n",
    "    if i<=5.5:\n",
    "        Lavels2.append(int(1))\n",
    "\n",
    "Y = np.array(xCorr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "****************************************************\n",
      "0.1\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.39089217 5.82088632 5.95646584 5.76219314 4.00005676 4.71720278\n",
      " 5.97442617 6.3806907  5.41823708 5.9560131  6.7784927  5.63983258\n",
      " 6.40440889 5.31378802 4.45767806 5.7263009  4.67860929 6.25914216\n",
      " 5.65688435]\n",
      "\n",
      "What it should be:  [5.66666667 5.83333333 4.5        5.         6.33333333 5.5\n",
      " 4.66666667 5.33333333 6.5        5.33333333 5.83333333 6.16666667\n",
      " 5.66666667 6.33333333 6.66666667 5.33333333 4.5        6.83333333\n",
      " 6.83333333]\n",
      "Correlation:  [[ 1.         -0.16123338]\n",
      " [-0.16123338  1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -1.22\n",
      "R2 score = -1.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [2.29454794 6.01502927 5.05467327 5.50928202 5.42224063 6.2861315\n",
      " 6.76614832 5.02636674 6.29408935 5.65216154 5.48464219 6.56363854\n",
      " 4.71817497 5.70736301 5.22779097 6.14652144 5.6217935  3.80577969\n",
      " 6.39137308]\n",
      "\n",
      "What it should be:  [5.5        6.66666667 5.83333333 6.         6.         4.66666667\n",
      " 5.66666667 6.5        5.33333333 5.83333333 6.5        6.16666667\n",
      " 6.5        5.33333333 4.83333333 6.5        6.         6.33333333\n",
      " 6.66666667]\n",
      "Correlation:  [[1.         0.00336214]\n",
      " [0.00336214 1.        ]]\n",
      "Mean absolute error = 0.98\n",
      "Mean squared error = 1.59\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -3.08\n",
      "R2 score = -3.72\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.52586506 6.02907031 4.65501009 5.27248524 5.75425118 4.80880944\n",
      " 5.09571776 5.60397509 5.71335642 5.46897386 5.8152887  5.84868691\n",
      " 5.42957367 4.95809724 4.67260006 6.10933748 6.28803745 5.71624113\n",
      " 6.32184978]\n",
      "\n",
      "What it should be:  [4.5        6.83333333 6.         6.5        6.33333333 4.66666667\n",
      " 6.         6.5        1.83333333 6.33333333 4.83333333 3.\n",
      " 6.16666667 5.66666667 3.33333333 6.83333333 5.16666667 6.33333333\n",
      " 6.66666667]\n",
      "Correlation:  [[1.        0.2189546]\n",
      " [0.2189546 1.       ]]\n",
      "Mean absolute error = 1.06\n",
      "Mean squared error = 1.89\n",
      "Median absolute error = 0.86\n",
      "Explain variance score = 0.02\n",
      "R2 score = 0.02\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.68193933 4.83892813 4.83691346 5.00259126 5.28016315 4.35582794\n",
      " 5.25501113 5.86618143 5.75000697 3.7329832  5.74393239 4.92939236\n",
      " 7.11675537 5.73685745 5.11048536 4.74919803 6.36718461 5.50569349\n",
      " 3.89582111]\n",
      "\n",
      "What it should be:  [5.         6.         6.16666667 5.33333333 4.83333333 4.66666667\n",
      " 5.16666667 6.         6.83333333 5.33333333 5.66666667 6.5\n",
      " 6.5        5.83333333 6.         5.5        4.66666667 5.5\n",
      " 4.        ]\n",
      "Correlation:  [[1.         0.31237825]\n",
      " [0.31237825 1.        ]]\n",
      "Mean absolute error = 0.74\n",
      "Mean squared error = 0.91\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.68\n",
      "R2 score = -0.8\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.92724759 3.06124137 4.97906727 6.68421986 5.31672387 5.23709167\n",
      " 5.98898757 6.12071111 5.13347443 5.52556467 5.95554846 6.40873751\n",
      " 4.1611062  6.09488395 4.60223197 5.23710143 4.19497941 5.22323947\n",
      " 6.18754821]\n",
      "\n",
      "What it should be:  [4.83333333 4.5        5.16666667 5.33333333 6.         5.66666667\n",
      " 5.83333333 7.         5.5        6.         6.5        6.\n",
      " 6.         6.16666667 4.83333333 5.33333333 5.83333333 6.5\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.44949949]\n",
      " [0.44949949 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.9\n",
      "Median absolute error = 0.54\n",
      "Explain variance score = -0.72\n",
      "R2 score = -1.09\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.88524895 5.58463429 6.32786226 5.48816443 5.68818845 6.00381151\n",
      " 7.06427784 4.87709792 5.45927015 6.43959968 3.57431552 6.44591771\n",
      " 4.82723747 5.07475333 4.71650282 5.97918827 6.31052743 6.68186814\n",
      " 4.4641856 ]\n",
      "\n",
      "What it should be:  [5.66666667 6.16666667 4.66666667 6.16666667 6.66666667 5.16666667\n",
      " 5.83333333 6.66666667 5.33333333 6.16666667 4.5        6.5\n",
      " 5.83333333 3.66666667 4.83333333 5.5        4.66666667 6.16666667\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.34445967]\n",
      " [0.34445967 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 0.93\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.38\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.05388002 5.53059551 5.45873114 4.60746581 6.14770742 6.34478646\n",
      " 5.67545347 4.98555803 5.46348292 5.04952367 5.34616448 6.03079689\n",
      " 5.56965232 5.46415998 4.8173341  6.44684248 3.86494946 5.00525419\n",
      " 6.13533286]\n",
      "\n",
      "What it should be:  [7.         6.16666667 5.83333333 5.5        6.5        5.33333333\n",
      " 3.         4.5        4.5        6.16666667 6.5        5.66666667\n",
      " 5.83333333 4.83333333 6.         4.66666667 6.33333333 6.33333333\n",
      " 5.66666667]\n",
      "Correlation:  [[ 1.         -0.01653052]\n",
      " [-0.01653052  1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.4\n",
      "Median absolute error = 0.89\n",
      "Explain variance score = -0.63\n",
      "R2 score = -0.63\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.86306397 5.95578329 5.64600453 5.70098923 5.16753571 3.92992084\n",
      " 7.39527457 5.99675086 4.95910405 5.27633378 4.99030051 5.12305318\n",
      " 6.61727013 5.29722973 4.00483446 7.10195243 6.7419963  6.08405854\n",
      " 5.35091946]\n",
      "\n",
      "What it should be:  [5.66666667 6.5        5.33333333 6.16666667 4.83333333 6.33333333\n",
      " 6.16666667 5.16666667 6.16666667 4.16666667 5.5        5.66666667\n",
      " 4.66666667 5.         5.33333333 6.5        4.         4.5\n",
      " 4.83333333]\n",
      "Correlation:  [[ 1.         -0.01919221]\n",
      " [-0.01919221  1.        ]]\n",
      "Mean absolute error = 1.04\n",
      "Mean squared error = 1.56\n",
      "Median absolute error = 0.83\n",
      "Explain variance score = -1.57\n",
      "R2 score = -1.72\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.33181957 5.07023494 5.98170572 5.47663461 5.77945953 4.07405899\n",
      " 4.81183674 6.64461712 4.7555845  5.19134153 7.29020057 6.03059392\n",
      " 6.53754087 5.06452276 7.22570321 5.70113127 6.15048975 6.8690381\n",
      " 4.85143549]\n",
      "\n",
      "What it should be:  [5.33333333 6.16666667 4.         6.33333333 6.16666667 6.\n",
      " 6.5        6.66666667 5.16666667 6.5        7.         5.83333333\n",
      " 6.83333333 6.33333333 5.16666667 6.5        4.83333333 5.\n",
      " 5.33333333]\n",
      "Correlation:  [[ 1.        -0.0478429]\n",
      " [-0.0478429  1.       ]]\n",
      "Mean absolute error = 1.01\n",
      "Mean squared error = 1.45\n",
      "Median absolute error = 1.0\n",
      "Explain variance score = -1.38\n",
      "R2 score = -1.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.64639197 5.33281247 5.11129748 5.42360651 5.29379782 4.03980925\n",
      " 6.7054732  5.54980532 6.01867043 5.04594727 6.6384995  5.98819039\n",
      " 5.09729197 5.16631035 4.77807239 4.77761793 4.70828759 5.62943478\n",
      " 6.72427614]\n",
      "\n",
      "What it should be:  [6.5        6.5        6.16666667 5.5        6.16666667 4.\n",
      " 6.33333333 5.16666667 6.         5.33333333 6.         5.83333333\n",
      " 6.5        5.         6.33333333 4.66666667 5.16666667 6.16666667\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.43371816]\n",
      " [0.43371816 1.        ]]\n",
      "Mean absolute error = 0.59\n",
      "Mean squared error = 0.63\n",
      "Median absolute error = 0.38\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.29\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.53353319 6.62336188 5.28519561 6.11481248 6.86100579 6.13353977\n",
      " 4.90001309 5.6672868  5.20473887 5.75909653 5.96598496 4.01690333\n",
      " 3.70787653 6.94919832 4.26502299 6.06125151 5.52360929 5.40120513\n",
      " 4.82589298]\n",
      "\n",
      "What it should be:  [6.66666667 5.         6.5        5.66666667 4.66666667 5.33333333\n",
      " 5.33333333 5.33333333 3.33333333 5.33333333 5.83333333 5.16666667\n",
      " 6.33333333 5.16666667 5.5        6.         6.16666667 4.\n",
      " 6.83333333]\n",
      "Correlation:  [[ 1.         -0.12256115]\n",
      " [-0.12256115  1.        ]]\n",
      "Mean absolute error = 1.08\n",
      "Mean squared error = 1.74\n",
      "Median absolute error = 1.15\n",
      "Explain variance score = -1.38\n",
      "R2 score = -1.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.05195654 4.15831779 4.4373347  5.85416791 6.36947733 6.33042475\n",
      " 4.71606762 4.38961405 6.03226646 6.17971713 5.43251373 6.91471799\n",
      " 5.26405715 5.24622521 5.85150078 5.66206836 6.08223006 6.57092619\n",
      " 6.14477133]\n",
      "\n",
      "What it should be:  [6.33333333 4.83333333 7.         5.83333333 4.5        6.\n",
      " 5.83333333 6.83333333 7.         4.66666667 6.5        6.83333333\n",
      " 6.66666667 3.83333333 6.5        5.5        4.         4.33333333\n",
      " 5.33333333]\n",
      "Correlation:  [[ 1.         -0.12467955]\n",
      " [-0.12467955  1.        ]]\n",
      "Mean absolute error = 1.16\n",
      "Mean squared error = 1.96\n",
      "Median absolute error = 1.07\n",
      "Explain variance score = -0.82\n",
      "R2 score = -0.82\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.9066773  6.13206098 4.94561697 3.83369699 5.16939319 5.86108903\n",
      " 5.21909127 6.39091855 6.27755703 5.84669521 5.37606275 6.19594097\n",
      " 4.59464016 5.18557874 5.91984515 7.91768236 5.56590267 7.54269545\n",
      " 4.43084809]\n",
      "\n",
      "What it should be:  [6.33333333 6.         5.33333333 4.83333333 6.         4.16666667\n",
      " 6.16666667 6.83333333 5.16666667 6.16666667 6.         6.83333333\n",
      " 3.66666667 5.66666667 4.66666667 7.         5.33333333 5.16666667\n",
      " 4.        ]\n",
      "Correlation:  [[1.         0.38153593]\n",
      " [0.38153593 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.83\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.07360183 5.96357456 5.24248276 5.31337681 5.43050192 5.82603645\n",
      " 5.27557164 6.2470777  7.20656093 5.88280155 4.69761175 6.83821716\n",
      " 5.18321871 5.43327968 4.35739078 5.71030408 5.47481341 5.98934241\n",
      " 5.69514119]\n",
      "\n",
      "What it should be:  [6.5        6.         3.66666667 5.66666667 5.83333333 6.\n",
      " 6.16666667 6.         5.16666667 4.83333333 6.83333333 6.\n",
      " 3.5        6.16666667 6.         6.33333333 6.16666667 6.66666667\n",
      " 4.66666667]\n",
      "Correlation:  [[ 1.         -0.04291453]\n",
      " [-0.04291453  1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.84\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.6\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.38238056 5.58804957 4.87489862 5.92782081 5.13808544 5.57346391\n",
      " 5.95104887 7.04275075 4.95000671 5.110342   5.29739702 4.12640374\n",
      " 6.03744695 5.94593245 4.6538698  5.76378013 5.67903208 4.7963611\n",
      " 6.35671665]\n",
      "\n",
      "What it should be:  [6.5        4.5        4.5        5.33333333 4.66666667 5.83333333\n",
      " 4.16666667 6.16666667 5.83333333 6.5        6.5        4.66666667\n",
      " 6.         5.33333333 6.83333333 5.83333333 3.83333333 6.16666667\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.14320447]\n",
      " [0.14320447 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.79339485 5.2019816  5.71713539 4.85785194 4.08512039 5.55455354\n",
      " 3.81738287 5.13606088 5.30526121 5.68087146 5.57859496 4.99282785\n",
      " 5.47586485 4.53352532 5.88048022 6.31521717 5.13549387 5.58805321\n",
      " 4.97284279]\n",
      "\n",
      "What it should be:  [6.5        4.         6.16666667 5.83333333 5.         5.33333333\n",
      " 6.33333333 6.16666667 5.5        5.         5.         6.16666667\n",
      " 3.66666667 6.5        6.16666667 6.16666667 6.33333333 5.\n",
      " 4.83333333]\n",
      "Correlation:  [[ 1.         -0.06052004]\n",
      " [-0.06052004  1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.63\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.59946374 4.39901869 5.60468547 6.81014901 6.36499381 3.02426753\n",
      " 5.41325808 5.97467056 4.54755597 3.98279614 6.73382661 4.98384272\n",
      " 4.18335421 6.10191193 7.29831035 5.00802766 6.26399705 5.51708209\n",
      " 6.64232117]\n",
      "\n",
      "What it should be:  [4.5        7.         4.66666667 5.16666667 6.33333333 5.5\n",
      " 5.33333333 6.83333333 6.83333333 5.16666667 5.66666667 4.33333333\n",
      " 6.33333333 5.66666667 6.33333333 4.5        5.33333333 5.83333333\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.03539456]\n",
      " [0.03539456 1.        ]]\n",
      "Mean absolute error = 1.1\n",
      "Mean squared error = 1.79\n",
      "Median absolute error = 0.94\n",
      "Explain variance score = -1.75\n",
      "R2 score = -1.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.60388831 5.98288503 6.82920326 7.6901788  6.26960797 6.77253312\n",
      " 4.74484175 4.45258701 4.81447577 5.27014403 6.4715812  5.20370639\n",
      " 6.56557431 5.71964586 6.43605173 5.50691938 4.83506413 4.65012345\n",
      " 5.2483176 ]\n",
      "\n",
      "What it should be:  [6.5        6.66666667 5.66666667 6.16666667 6.16666667 5.66666667\n",
      " 6.         4.66666667 6.         6.33333333 4.83333333 5.33333333\n",
      " 7.         4.66666667 6.5        4.66666667 5.5        4.\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.39988278]\n",
      " [0.39988278 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.84\n",
      "Median absolute error = 0.84\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.74338333 6.17472751 5.6693778  6.04623333 4.84195403 6.91938109\n",
      " 7.42998334 4.22004253 5.78294756 6.87703703 6.86984174 5.64100665\n",
      " 5.86863881 5.59603799 5.96841863 5.70350731 5.99067268 6.13519038\n",
      " 3.87669019]\n",
      "\n",
      "What it should be:  [6.66666667 4.66666667 5.83333333 6.         5.         6.16666667\n",
      " 6.         6.16666667 5.33333333 5.33333333 4.83333333 5.83333333\n",
      " 3.5        4.66666667 6.16666667 4.5        6.83333333 5.66666667\n",
      " 5.5       ]\n",
      "Correlation:  [[ 1.        -0.0641526]\n",
      " [-0.0641526  1.       ]]\n",
      "Mean absolute error = 1.04\n",
      "Mean squared error = 1.62\n",
      "Median absolute error = 0.93\n",
      "Explain variance score = -1.35\n",
      "R2 score = -1.49\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.75866384 4.93209311 4.27796842 6.18428935 4.88956886 5.68776246\n",
      " 5.7424346  4.41327044 6.02094624 5.75403477 5.18322869 4.84203903\n",
      " 6.28670032 5.24704086 5.49977655 5.09619489 6.04599114 5.85433436\n",
      " 5.70330437]\n",
      "\n",
      "What it should be:  [4.5        5.33333333 4.66666667 6.66666667 5.5        5.66666667\n",
      " 5.5        4.83333333 6.5        6.         5.66666667 6.16666667\n",
      " 5.33333333 4.5        6.66666667 4.33333333 4.66666667 5.66666667\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.47159787]\n",
      " [0.47159787 1.        ]]\n",
      "Mean absolute error = 0.62\n",
      "Mean squared error = 0.55\n",
      "Median absolute error = 0.48\n",
      "Explain variance score = 0.15\n",
      "R2 score = 0.12\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.80837422 6.45222873 5.09939829 6.21825939 5.03295262 6.19921511\n",
      " 5.93859131 6.90372051 5.68896083 4.32842119 4.91103126 7.1159352\n",
      " 5.02044714 6.5197495  6.09763569 5.27730166 4.54570789 8.13158039\n",
      " 5.42619145]\n",
      "\n",
      "What it should be:  [5.33333333 5.66666667 3.5        4.33333333 6.         7.\n",
      " 5.16666667 6.16666667 4.66666667 5.66666667 7.         5.83333333\n",
      " 4.         6.5        5.66666667 5.33333333 6.83333333 6.16666667\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.18513605]\n",
      " [0.18513605 1.        ]]\n",
      "Mean absolute error = 1.12\n",
      "Mean squared error = 1.66\n",
      "Median absolute error = 1.02\n",
      "Explain variance score = -0.75\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.84798366 5.0714668  6.25086749 5.75920578 5.84008471 6.72020643\n",
      " 4.98745431 5.36689603 6.74163306 6.56829712 7.94289951 4.85845206\n",
      " 4.83078891 5.26988309 5.27801172 7.10609704 6.08032715 6.82382405\n",
      " 5.73599554]\n",
      "\n",
      "What it should be:  [4.5        6.16666667 6.5        4.5        6.5        5.66666667\n",
      " 6.5        5.5        5.33333333 4.83333333 6.33333333 4.33333333\n",
      " 4.33333333 5.33333333 6.16666667 6.         3.         5.\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.19567693]\n",
      " [0.19567693 1.        ]]\n",
      "Mean absolute error = 1.02\n",
      "Mean squared error = 1.57\n",
      "Median absolute error = 1.05\n",
      "Explain variance score = -0.5\n",
      "R2 score = -0.79\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.30313247 4.41259586 4.94645236 5.60953868 6.47372808 5.34854305\n",
      " 5.50749699 7.55453595 4.3042887  6.15045725 6.01780564 4.54779498\n",
      " 6.86823401 5.69083165 4.87720815 5.02651273 5.81510572 5.95778617\n",
      " 4.36740126]\n",
      "\n",
      "What it should be:  [6.         5.33333333 4.83333333 6.16666667 5.16666667 1.83333333\n",
      " 6.5        7.         6.83333333 6.16666667 5.66666667 6.16666667\n",
      " 6.66666667 5.83333333 6.         5.16666667 6.16666667 6.83333333\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.21918275]\n",
      " [0.21918275 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.61\n",
      "Median absolute error = 0.56\n",
      "Explain variance score = -0.28\n",
      "R2 score = -0.32\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.45931788 4.92485268 5.88977659 4.4002016  5.80208007 6.19813707\n",
      " 5.19166505 3.21424668 6.1080023  5.25149922 5.15067102 7.62989056\n",
      " 4.19693192 5.76978004 5.99307627 7.19274878 6.66561885 5.2129138\n",
      " 5.70006842]\n",
      "\n",
      "What it should be:  [5.16666667 6.83333333 4.66666667 4.66666667 6.66666667 6.33333333\n",
      " 6.83333333 4.5        6.         6.         5.16666667 6.16666667\n",
      " 5.83333333 6.33333333 6.         6.83333333 5.66666667 5.66666667\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.46572523]\n",
      " [0.46572523 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.61\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.82189131 5.03886909 5.38851209 7.16981284 5.66567278 5.40544343\n",
      " 4.69061451 4.02603205 6.99546771 6.00832295 6.12705647 3.85689436\n",
      " 6.02150137 5.23234788 5.63407421 4.3730318  5.11191425 7.11022343\n",
      " 6.39153214]\n",
      "\n",
      "What it should be:  [6.16666667 5.83333333 6.16666667 5.16666667 3.         5.5\n",
      " 4.         5.33333333 6.66666667 5.33333333 5.33333333 3.33333333\n",
      " 6.66666667 6.5        7.         5.33333333 7.         5.16666667\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.25009907]\n",
      " [0.25009907 1.        ]]\n",
      "Mean absolute error = 1.08\n",
      "Mean squared error = 1.59\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.27969915 4.0952012  5.57845698 5.84531933 5.80956322 5.83525338\n",
      " 5.96544966 7.48476844 4.89172944 4.85279701 6.17255371 5.91903438\n",
      " 6.5121552  6.33312423 8.03515185 5.14891039 6.58747241 5.02499185\n",
      " 5.79645844]\n",
      "\n",
      "What it should be:  [5.33333333 5.16666667 4.5        6.16666667 4.66666667 5.83333333\n",
      " 6.83333333 7.         6.5        3.66666667 6.16666667 5.\n",
      " 5.83333333 6.16666667 6.5        6.83333333 6.         5.5\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.44161358]\n",
      " [0.44161358 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.51785973 5.29649421 4.97313224 5.30206221 5.56861412 5.38741162\n",
      " 6.03952175 4.85195108 6.01595841 5.1709035  5.9331545  5.29625169\n",
      " 4.69197696 5.33114674 5.67297497 6.23780283 5.04932891 2.8734408\n",
      " 5.88489145]\n",
      "\n",
      "What it should be:  [5.5        4.         6.16666667 6.83333333 5.83333333 5.33333333\n",
      " 5.16666667 5.83333333 6.66666667 6.5        5.         5.83333333\n",
      " 6.83333333 4.33333333 6.16666667 4.33333333 3.5        5.5\n",
      " 5.66666667]\n",
      "Correlation:  [[ 1.         -0.09906776]\n",
      " [-0.09906776  1.        ]]\n",
      "Mean absolute error = 1.03\n",
      "Mean squared error = 1.55\n",
      "Median absolute error = 0.98\n",
      "Explain variance score = -0.73\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.36061331 5.15028806 6.22745845 5.47796936 5.9312442  5.633842\n",
      " 6.35425097 5.66706038 5.88377058 4.38208226 5.02970033 6.32813913\n",
      " 5.12387136 5.53033176 6.50184055 6.62994415 5.15313672 6.46917362\n",
      " 7.58444888]\n",
      "\n",
      "What it should be:  [5.33333333 6.33333333 5.         4.33333333 5.         4.16666667\n",
      " 4.83333333 5.83333333 5.66666667 4.66666667 4.33333333 6.16666667\n",
      " 3.66666667 6.16666667 6.5        4.66666667 4.         6.83333333\n",
      " 5.16666667]\n",
      "Correlation:  [[1.         0.26012118]\n",
      " [0.26012118 1.        ]]\n",
      "Mean absolute error = 1.0\n",
      "Mean squared error = 1.46\n",
      "Median absolute error = 1.14\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.82\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.10322297 7.4633702  6.13344185 5.37169094 6.18956999 7.77945079\n",
      " 6.15619548 4.84039018 4.59219068 7.44470044 4.37988256 6.69006604\n",
      " 3.89931483 5.91016938 6.63516412 6.39697972 5.88564122 4.69908763\n",
      " 5.91046562]\n",
      "\n",
      "What it should be:  [3.83333333 6.16666667 6.         6.33333333 4.83333333 6.5\n",
      " 6.66666667 6.5        4.66666667 7.         5.33333333 5.83333333\n",
      " 5.33333333 6.33333333 6.5        7.         4.66666667 6.\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.47579441]\n",
      " [0.47579441 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.01\n",
      "Median absolute error = 0.95\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.32\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.58657798 7.27911215 5.20914838 5.92415798 5.94916863 6.16799274\n",
      " 5.36392798 5.3410754  5.2797258  7.35934574 6.15305242 4.22921992\n",
      " 6.80496207 4.82265431 5.41502071 6.51041352 7.28204326 5.6094247\n",
      " 4.57996031]\n",
      "\n",
      "What it should be:  [4.83333333 6.5        6.16666667 6.66666667 6.5        6.5\n",
      " 6.5        7.         6.83333333 5.83333333 6.66666667 5.33333333\n",
      " 6.         3.33333333 3.66666667 6.33333333 6.         5.83333333\n",
      " 4.83333333]\n",
      "Correlation:  [[1.         0.42366821]\n",
      " [0.42366821 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.07\n",
      "R2 score = -0.07\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.7215616  6.66434708 5.58467324 6.45507973 6.05823064 5.79922805\n",
      " 5.83684858 5.22751941 5.82352572 4.77906711 5.75263561 6.1597853\n",
      " 7.66124047 7.61926099 4.73932011 3.68734732 7.54125297 5.81666845\n",
      " 6.90911738]\n",
      "\n",
      "What it should be:  [5.16666667 5.83333333 5.5        6.83333333 5.33333333 5.33333333\n",
      " 5.66666667 5.16666667 6.33333333 3.33333333 4.83333333 6.\n",
      " 6.16666667 5.16666667 6.         4.83333333 7.         6.\n",
      " 4.        ]\n",
      "Correlation:  [[1.         0.38245367]\n",
      " [0.38245367 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.32\n",
      "Median absolute error = 0.55\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.76\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.62907953 7.81039242 4.01944527 5.59606278 5.53028942 7.9925112\n",
      " 6.1066148  5.00610925 6.33304327 5.42303621 4.62378332 5.99411428\n",
      " 6.69225787 5.93641603 6.92928976 6.41473705 6.19009273 5.89609927\n",
      " 6.58656756]\n",
      "\n",
      "What it should be:  [5.33333333 6.66666667 6.         6.16666667 6.66666667 5.16666667\n",
      " 6.83333333 4.83333333 5.16666667 6.         4.5        5.33333333\n",
      " 6.16666667 6.83333333 5.33333333 5.83333333 6.         4.5\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.18436307]\n",
      " [0.18436307 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -1.17\n",
      "R2 score = -1.29\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.71786141 6.38765052 5.41576296 5.27180529 6.00448153 6.10980844\n",
      " 5.37784265 6.55634577 4.93370152 6.21347368 5.61704022 5.46079698\n",
      " 5.64456218 5.42326868 5.84632874 6.11347618 5.55724062 5.66289723\n",
      " 6.75730302]\n",
      "\n",
      "What it should be:  [5.5        6.         5.83333333 4.83333333 7.         6.83333333\n",
      " 6.33333333 5.16666667 6.66666667 5.83333333 1.83333333 5.83333333\n",
      " 6.16666667 6.83333333 5.         5.83333333 5.83333333 5.33333333\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.12263316]\n",
      " [0.12263316 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.44\n",
      "Explain variance score = -0.07\n",
      "R2 score = -0.07\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.23953635 6.41483505 6.16356814 5.53054937 6.33090097 6.06228603\n",
      " 5.19707757 6.09436912 2.27761381 6.34514101 5.43975381 5.09282999\n",
      " 6.07088814 5.60004029 4.98018719 4.23721212 5.81525484 5.36931671\n",
      " 7.16490577]\n",
      "\n",
      "What it should be:  [6.83333333 6.16666667 6.83333333 6.16666667 6.5        6.33333333\n",
      " 4.66666667 5.66666667 5.5        5.33333333 6.33333333 5.\n",
      " 6.33333333 6.16666667 3.66666667 5.33333333 6.83333333 5.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.28382239]\n",
      " [0.28382239 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.27\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.86\n",
      "R2 score = -0.99\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.21203053 5.32977353 4.67635884 5.9295961  5.63060678 6.13767101\n",
      " 6.05255825 6.16827432 5.43226416 5.26927583 6.14722134 5.76502323\n",
      " 3.37539603 6.32246277 4.59863764 5.7812759  5.11571294 6.39894659\n",
      " 3.16932703]\n",
      "\n",
      "What it should be:  [4.5        5.66666667 6.83333333 4.         6.5        5.5\n",
      " 6.33333333 5.16666667 6.         4.83333333 6.16666667 6.66666667\n",
      " 6.16666667 4.         4.83333333 4.83333333 4.66666667 5.83333333\n",
      " 5.16666667]\n",
      "Correlation:  [[ 1.         -0.08213422]\n",
      " [-0.08213422  1.        ]]\n",
      "Mean absolute error = 1.01\n",
      "Mean squared error = 1.64\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -1.25\n",
      "R2 score = -1.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.79293686 6.76594352 5.78996955 4.83146158 6.09349816 5.9997275\n",
      " 4.34199994 4.79179295 5.04039615 6.67150256 5.1775923  5.14333625\n",
      " 5.62395443 5.55003656 6.38326377 6.20656292 5.43249606 6.06050164\n",
      " 6.50465649]\n",
      "\n",
      "What it should be:  [4.66666667 5.83333333 4.5        3.5        6.16666667 5.\n",
      " 6.         6.83333333 4.5        6.5        6.5        4.33333333\n",
      " 6.66666667 6.         5.5        5.66666667 6.66666667 6.66666667\n",
      " 4.33333333]\n",
      "Correlation:  [[1.         0.08050302]\n",
      " [0.08050302 1.        ]]\n",
      "Mean absolute error = 1.01\n",
      "Mean squared error = 1.33\n",
      "Median absolute error = 1.0\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.5240759  4.72903181 7.29402629 5.97947887 6.24445039 4.44348377\n",
      " 5.73011336 6.0250521  6.5492542  5.04131086 6.04209354 6.25075272\n",
      " 4.84731618 4.70700056 5.53821215 3.83360126 4.60551993 4.67861497\n",
      " 6.18930333]\n",
      "\n",
      "What it should be:  [5.16666667 6.33333333 6.66666667 6.33333333 5.66666667 3.66666667\n",
      " 6.5        5.16666667 6.83333333 5.16666667 6.5        5.83333333\n",
      " 5.         4.33333333 5.33333333 6.33333333 6.         6.66666667\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.40650725]\n",
      " [0.40650725 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.03723037 7.13464514 6.81645561 5.66204581 5.31692331 5.95642538\n",
      " 6.11057315 5.87325732 3.43925556 5.94061704 4.7265294  6.79093419\n",
      " 7.02704997 4.83173246 4.00383512 6.72617049 6.09990847 5.88584524\n",
      " 5.84419639]\n",
      "\n",
      "What it should be:  [4.83333333 6.         5.33333333 6.16666667 6.         5.16666667\n",
      " 5.33333333 6.16666667 6.33333333 6.33333333 6.33333333 4.66666667\n",
      " 5.         5.66666667 5.16666667 6.83333333 6.83333333 5.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[ 1.         -0.10423831]\n",
      " [-0.10423831  1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.48\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -2.69\n",
      "R2 score = -2.69\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.74192713 5.39934743 5.25616842 5.1335972  5.75302873 4.15503294\n",
      " 6.52444284 5.39453687 4.32641933 6.06026679 5.36420735 6.68048601\n",
      " 4.70812099 5.51402075 4.12104733 6.55696521 5.70922238 4.43516585\n",
      " 6.87805768]\n",
      "\n",
      "What it should be:  [5.16666667 6.33333333 6.66666667 6.5        6.         4.66666667\n",
      " 5.5        6.5        6.         6.5        5.16666667 6.16666667\n",
      " 3.66666667 5.83333333 7.         4.33333333 6.66666667 6.\n",
      " 5.66666667]\n",
      "Correlation:  [[ 1.         -0.03949139]\n",
      " [-0.03949139  1.        ]]\n",
      "Mean absolute error = 1.06\n",
      "Mean squared error = 1.59\n",
      "Median absolute error = 1.02\n",
      "Explain variance score = -1.01\n",
      "R2 score = -1.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.77422954 7.34513178 6.24765185 5.1068728  5.13326831 6.32115894\n",
      " 5.38655097 1.26868794 5.11355985 6.06695725 5.92009095 4.38089103\n",
      " 6.35963198 4.38911696 4.56026428 6.22165424 4.61441974 4.97785747\n",
      " 4.06795691]\n",
      "\n",
      "What it should be:  [6.5        6.         5.66666667 5.33333333 5.16666667 5.66666667\n",
      " 5.16666667 5.5        5.5        5.66666667 6.16666667 6.33333333\n",
      " 4.66666667 6.33333333 6.16666667 6.16666667 5.83333333 4.83333333\n",
      " 4.83333333]\n",
      "Correlation:  [[1.         0.15183096]\n",
      " [0.15183096 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.9\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -5.04\n",
      "R2 score = -5.54\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.54159684 5.053969   5.72648468 4.73722607 4.83115085 4.69230999\n",
      " 6.23393116 6.0070218  5.17800986 5.92541863 5.95240483 5.04707417\n",
      " 6.61645484 5.27353293 5.33654349 6.27320887 6.72087526 5.12525597\n",
      " 5.13859497]\n",
      "\n",
      "What it should be:  [4.83333333 6.5        3.         4.33333333 6.5        4.\n",
      " 6.33333333 4.66666667 6.5        4.5        6.83333333 6.\n",
      " 5.66666667 5.66666667 6.         5.33333333 5.83333333 6.5\n",
      " 6.33333333]\n",
      "Correlation:  [[ 1.         -0.01353237]\n",
      " [-0.01353237  1.        ]]\n",
      "Mean absolute error = 1.06\n",
      "Mean squared error = 1.43\n",
      "Median absolute error = 0.95\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.04239836 6.33676571 3.75658494 5.00887021 6.31126346 5.84026675\n",
      " 6.16001145 5.7172554  6.69129225 6.35139459 7.43297691 5.95042473\n",
      " 3.99923106 5.97970428 6.14368733 3.71358548 6.84700315 5.22445271\n",
      " 4.66728008]\n",
      "\n",
      "What it should be:  [5.33333333 5.33333333 4.         6.5        6.16666667 5.83333333\n",
      " 6.16666667 5.16666667 6.66666667 6.5        7.         4.83333333\n",
      " 6.33333333 4.33333333 6.33333333 6.33333333 6.66666667 5.5\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.31520251]\n",
      " [0.31520251 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.43\n",
      "Explain variance score = -0.8\n",
      "R2 score = -0.83\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.6655023  5.16916979 2.27923598 6.55441117 6.39304462 5.09587312\n",
      " 4.97375281 5.18989352 6.0426797  5.87584278 7.00988693 6.78285947\n",
      " 4.93473774 5.21619558 6.60676345 4.64141689 4.33360881 6.93151354\n",
      " 7.12103171]\n",
      "\n",
      "What it should be:  [5.66666667 6.         5.5        5.83333333 4.66666667 5.33333333\n",
      " 6.16666667 6.16666667 6.83333333 4.83333333 5.16666667 6.83333333\n",
      " 5.66666667 5.33333333 5.66666667 6.         5.5        5.16666667\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.12481091]\n",
      " [0.12481091 1.        ]]\n",
      "Mean absolute error = 0.99\n",
      "Mean squared error = 1.57\n",
      "Median absolute error = 0.94\n",
      "Explain variance score = -2.9\n",
      "R2 score = -2.94\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.25494997 5.00872245 5.64995077 6.12529345 5.60424021 5.01478824\n",
      " 6.53576601 5.08706592 3.54130328 6.29156088 5.84474713 6.06735007\n",
      " 5.27457527 5.14666479 5.40615692 4.74508055 4.43885292 5.92514597\n",
      " 5.40973447]\n",
      "\n",
      "What it should be:  [6.5        3.66666667 5.33333333 5.66666667 6.66666667 5.16666667\n",
      " 5.83333333 3.83333333 6.33333333 7.         6.5        5.66666667\n",
      " 6.16666667 5.5        5.33333333 6.5        6.         5.16666667\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.08222346]\n",
      " [0.08222346 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.51\n",
      "R2 score = -0.65\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.83571523 5.89516209 6.31502533 5.0238489  3.20990138 5.31584971\n",
      " 5.50169383 5.52426911 5.86242312 5.51591035 5.92140355 4.27079442\n",
      " 4.89069744 5.9112707  5.58277237 6.76918281 5.39372983 7.00339189\n",
      " 5.9527603 ]\n",
      "\n",
      "What it should be:  [6.16666667 7.         4.66666667 4.5        5.33333333 4.\n",
      " 6.5        6.83333333 6.16666667 6.33333333 4.66666667 5.83333333\n",
      " 6.5        6.33333333 5.66666667 6.5        5.16666667 6.33333333\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.19837161]\n",
      " [0.19837161 1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 1.0\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.62\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.83826797 6.09820548 4.27230045 5.00354443 4.63354301 5.06105031\n",
      " 6.15038991 6.19217018 4.27952746 5.52261882 6.77333923 5.05832531\n",
      " 6.104225   6.44201455 6.1417229  6.25543156 4.89051715 5.47569564\n",
      " 4.8044557 ]\n",
      "\n",
      "What it should be:  [5.5        6.33333333 4.83333333 6.16666667 5.33333333 5.5\n",
      " 5.16666667 5.83333333 6.         5.33333333 6.5        6.16666667\n",
      " 5.         6.         5.83333333 4.66666667 6.5        5.66666667\n",
      " 5.33333333]\n",
      "Correlation:  [[1.        0.0908558]\n",
      " [0.0908558 1.       ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.78\n",
      "Median absolute error = 0.53\n",
      "Explain variance score = -1.69\n",
      "R2 score = -1.76\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.10162682 5.61410223 4.82627487 5.88464002 4.8020479  5.2612177\n",
      " 5.53609328 6.98594383 5.16606317 5.35011546 3.93039216 6.62637645\n",
      " 4.1420807  4.75486357 6.23041568 5.16485911 4.68632864 4.86020882\n",
      " 5.75778104]\n",
      "\n",
      "What it should be:  [5.33333333 6.33333333 3.66666667 5.83333333 4.33333333 5.\n",
      " 5.66666667 6.         6.16666667 4.5        5.16666667 5.16666667\n",
      " 6.         6.5        6.         5.66666667 7.         6.83333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.04223483]\n",
      " [0.04223483 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.33\n",
      "Median absolute error = 0.85\n",
      "Explain variance score = -0.77\n",
      "R2 score = -0.9\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.62253847 7.82926241 4.62861179 4.71597574 5.5445414  5.3257373\n",
      " 7.3843337  6.14152846 5.42593559 5.5923383  5.58635715 5.51264777\n",
      " 7.03185091 5.15344712 5.70184673 5.82174013 7.21460538 7.12962799\n",
      " 5.36889741]\n",
      "\n",
      "What it should be:  [5.66666667 5.16666667 4.33333333 5.5        5.83333333 4.5\n",
      " 5.33333333 6.66666667 6.33333333 6.33333333 4.66666667 4.5\n",
      " 5.83333333 5.5        4.66666667 6.66666667 5.16666667 5.83333333\n",
      " 3.66666667]\n",
      "Correlation:  [[1.         0.21616931]\n",
      " [0.21616931 1.        ]]\n",
      "Mean absolute error = 1.08\n",
      "Mean squared error = 1.54\n",
      "Median absolute error = 0.92\n",
      "Explain variance score = -0.78\n",
      "R2 score = -1.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.22447429 7.66272495 5.51568413 5.19699668 5.57182909 5.12252309\n",
      " 5.49273656 5.89789674 6.40797822 6.45906284 6.13313778 4.82981195\n",
      " 4.17861313 6.50812627 5.99524313 5.53668344 5.49020676 6.37950351\n",
      " 5.80537041]\n",
      "\n",
      "What it should be:  [5.33333333 6.33333333 6.66666667 6.83333333 6.16666667 6.33333333\n",
      " 6.16666667 5.16666667 6.66666667 5.83333333 6.83333333 5.83333333\n",
      " 3.33333333 6.         5.66666667 6.33333333 6.83333333 4.33333333\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.17007781]\n",
      " [0.17007781 1.        ]]\n",
      "Mean absolute error = 0.98\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.85\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.5\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.75304193 5.11221031 7.01326969 3.98257709 2.54668092 6.47185751\n",
      " 5.006053   3.25006231 6.5631592  6.50688378 5.63616884 6.00265338\n",
      " 6.39063225 7.64526718 5.21783129 7.11163021 6.87286064 4.74649556\n",
      " 6.86699928]\n",
      "\n",
      "What it should be:  [6.33333333 6.5        6.5        4.5        4.5        6.16666667\n",
      " 6.33333333 4.66666667 7.         5.66666667 4.5        5.33333333\n",
      " 6.66666667 6.66666667 5.33333333 5.83333333 6.33333333 6.83333333\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.52734339]\n",
      " [0.52734339 1.        ]]\n",
      "Mean absolute error = 1.03\n",
      "Mean squared error = 1.48\n",
      "Median absolute error = 0.98\n",
      "Explain variance score = -1.12\n",
      "R2 score = -1.21\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.2\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.31374981 5.24822036 3.71408584 6.3486939  5.43132376 4.60724161\n",
      " 5.85156218 6.16710214 5.21443998 4.89952505 5.94996533 6.23234293\n",
      " 5.08271214 4.81643804 5.02329272 4.05710946 6.30261155 5.47165894\n",
      " 4.52045767 6.35140613 6.70852451 4.72333862 6.31193619 4.66274872\n",
      " 4.15189842 6.22234555 6.89040128 3.03803011 5.67890421 4.05149092\n",
      " 4.72393971 5.821324   5.58254978 5.24453303 4.45042066 6.2453143\n",
      " 6.92864869]\n",
      "\n",
      "What it should be:  [6.83333333 5.83333333 4.83333333 5.66666667 6.16666667 5.5\n",
      " 5.83333333 5.83333333 6.16666667 6.66666667 6.16666667 5.16666667\n",
      " 5.5        6.16666667 6.5        6.33333333 6.         4.16666667\n",
      " 3.33333333 5.33333333 4.83333333 6.16666667 5.33333333 5.66666667\n",
      " 7.         5.33333333 6.33333333 4.5        6.16666667 5.33333333\n",
      " 4.5        5.33333333 5.33333333 4.33333333 5.83333333 6.5\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.09712238]\n",
      " [0.09712238 1.        ]]\n",
      "Mean absolute error = 1.01\n",
      "Mean squared error = 1.45\n",
      "Median absolute error = 0.95\n",
      "Explain variance score = -1.19\n",
      "R2 score = -1.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.42284096 5.60991075 3.61877398 6.05315467 5.60903843 6.21377157\n",
      " 5.05675936 4.71006764 5.29012872 4.8627736  5.81483914 6.2518118\n",
      " 4.41105119 6.07539966 5.65391626 6.1104227  4.89161066 5.38369931\n",
      " 6.42203578 4.48459869 4.56522616 6.71875312 4.60088333 5.88256776\n",
      " 4.43071161 4.80098159 8.11672631 3.802553   6.33553801 6.02432737\n",
      " 4.48156676 4.5053534  5.14083074 6.65518891 3.3994904  4.27755515\n",
      " 4.38896888]\n",
      "\n",
      "What it should be:  [6.33333333 6.16666667 5.33333333 5.33333333 5.83333333 5.83333333\n",
      " 5.66666667 6.33333333 5.5        6.16666667 6.66666667 6.16666667\n",
      " 5.5        6.5        4.16666667 6.83333333 5.83333333 6.66666667\n",
      " 5.33333333 6.83333333 4.83333333 5.83333333 4.83333333 6.\n",
      " 5.16666667 5.5        7.         7.         4.66666667 5.83333333\n",
      " 6.5        5.         5.16666667 5.16666667 6.33333333 3.66666667\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.15780162]\n",
      " [0.15780162 1.        ]]\n",
      "Mean absolute error = 0.97\n",
      "Mean squared error = 1.53\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -1.26\n",
      "R2 score = -1.58\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.96939086 5.94530012 5.24622471 5.13611727 5.25490083 4.74619576\n",
      " 6.43332674 3.71895724 3.71780817 5.78073773 4.93879036 5.97404226\n",
      " 5.95452026 4.92131841 5.86651396 3.67069662 4.779589   4.83477327\n",
      " 4.8466345  5.06205563 5.62209466 4.92850755 7.26592194 5.86112239\n",
      " 5.34186673 6.52524337 5.80313638 4.75396459 5.1185157  5.52629754\n",
      " 5.32876971 6.96121685 5.99501723 5.53278944 4.62208202 5.23496458\n",
      " 4.74345494]\n",
      "\n",
      "What it should be:  [4.66666667 5.66666667 6.         6.16666667 5.         5.5\n",
      " 5.5        5.5        4.83333333 6.         5.66666667 6.33333333\n",
      " 4.83333333 6.5        4.16666667 6.33333333 6.         4.\n",
      " 5.33333333 4.83333333 6.33333333 3.66666667 7.         5.66666667\n",
      " 6.66666667 6.83333333 7.         7.         6.5        5.83333333\n",
      " 6.5        5.83333333 5.66666667 6.16666667 5.5        6.16666667\n",
      " 3.66666667]\n",
      "Correlation:  [[1.         0.30001314]\n",
      " [0.30001314 1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.88\n",
      "Explain variance score = -0.29\n",
      "R2 score = -0.5\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.76509048 5.97100353 6.1500531  5.15591223 6.05628346 4.93251505\n",
      " 5.3598203  5.15551584 6.24026764 4.68728058 7.92398569 6.37702845\n",
      " 5.3780191  6.33410992 5.24223657 5.94643082 5.08042624 6.01728889\n",
      " 5.68768406 4.30128952 5.34035098 4.75422583 6.53696074 5.44316418\n",
      " 5.23066396 6.56748209 5.04088794 5.44909606 6.87288644 6.60099194\n",
      " 6.1336567  6.80442722 6.35360943 6.6395053  4.99306659 4.57532629\n",
      " 5.15063877]\n",
      "\n",
      "What it should be:  [5.16666667 6.16666667 6.5        3.5        5.66666667 6.66666667\n",
      " 6.66666667 6.33333333 6.16666667 6.83333333 6.5        6.66666667\n",
      " 6.5        5.83333333 4.5        5.66666667 5.33333333 5.16666667\n",
      " 5.83333333 6.66666667 6.33333333 6.16666667 5.66666667 6.5\n",
      " 4.66666667 5.16666667 6.5        5.66666667 6.5        5.16666667\n",
      " 5.66666667 6.33333333 4.66666667 5.33333333 5.         4.83333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.        0.0807525]\n",
      " [0.0807525 1.       ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -1.01\n",
      "R2 score = -1.03\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.43612441 4.12687396 4.68763516 5.09672297 6.51601951 6.44434045\n",
      " 4.49097776 4.81772214 4.70870048 5.54924811 4.59469393 4.91583596\n",
      " 4.30509989 6.08400549 6.5544528  6.22059088 5.12635432 5.73633338\n",
      " 6.56676632 6.41480271 6.01519306 5.85688351 6.72289095 3.7329311\n",
      " 6.22392541 6.94351738 6.16496905 5.20504695 4.78413369 4.53139166\n",
      " 6.65511886 4.5388195  6.3140949  4.81187347 4.62656932 6.2023431\n",
      " 5.06612636]\n",
      "\n",
      "What it should be:  [5.66666667 7.         5.16666667 6.5        6.         4.\n",
      " 3.66666667 4.83333333 4.83333333 6.33333333 6.83333333 3.66666667\n",
      " 4.         6.16666667 6.5        6.66666667 5.         6.5\n",
      " 6.66666667 5.66666667 5.83333333 6.83333333 7.         6.\n",
      " 5.83333333 6.33333333 5.         6.5        6.5        5.5\n",
      " 5.33333333 5.83333333 5.66666667 5.66666667 6.83333333 6.\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.19804048]\n",
      " [0.19804048 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.56\n",
      "R2 score = -0.66\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.03935526 3.25199154 7.13129701 4.20471424 6.06498947 6.41817651\n",
      " 4.95744444 5.63677694 5.7119755  7.12968544 6.22178274 5.31778802\n",
      " 6.61864196 5.29515011 5.77337709 4.30499279 6.65437705 4.33345306\n",
      " 5.18818101 6.44678145 5.20561366 6.11097912 5.10459705 5.0024528\n",
      " 5.78604382 5.57384784 6.07887989 6.4984981  5.17273518 4.29499078\n",
      " 5.6143733  6.47786781 5.64748127 3.4457155  5.78674233 6.59873754\n",
      " 4.54885247]\n",
      "\n",
      "What it should be:  [6.5        6.33333333 6.33333333 7.         6.16666667 5.33333333\n",
      " 5.83333333 5.66666667 5.83333333 6.66666667 6.83333333 5.83333333\n",
      " 6.5        5.83333333 6.66666667 5.66666667 5.16666667 4.83333333\n",
      " 5.16666667 6.66666667 5.33333333 6.33333333 3.66666667 6.83333333\n",
      " 6.         7.         5.33333333 6.         5.5        5.5\n",
      " 6.33333333 6.         6.16666667 4.5        6.5        5.33333333\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.20463981]\n",
      " [0.20463981 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.29\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -1.11\n",
      "R2 score = -1.43\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.0189589  7.07362018 6.25280446 5.43210046 5.71481275 4.84985332\n",
      " 6.35736562 7.18948398 7.14707326 5.67265554 5.37933263 5.92650052\n",
      " 5.18391899 6.21157166 4.37124486 5.33440171 4.32775561 4.33164986\n",
      " 4.17559201 4.66258124 5.71200639 4.75540245 6.90494672 5.136198\n",
      " 5.56128516 4.26472549 6.10131145 3.7992376  5.08084831 5.39017949\n",
      " 6.12499235 5.91382407 5.17143755 5.27291682 5.24986922 5.47089783\n",
      " 6.05129531]\n",
      "\n",
      "What it should be:  [6.16666667 6.         5.16666667 4.66666667 3.66666667 6.\n",
      " 6.83333333 5.33333333 6.         4.66666667 5.16666667 5.83333333\n",
      " 6.5        4.         4.         6.16666667 5.16666667 5.83333333\n",
      " 5.83333333 4.66666667 4.16666667 4.83333333 6.83333333 6.\n",
      " 6.83333333 6.66666667 6.5        4.         7.         6.16666667\n",
      " 5.5        7.         5.83333333 6.33333333 6.         6.83333333\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.19933445]\n",
      " [0.19933445 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.86\n",
      "Explain variance score = -0.45\n",
      "R2 score = -0.48\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.65057133 5.46352508 5.89722987 4.39582736 5.84201407 5.40246611\n",
      " 5.39312517 5.97253813 6.26101392 6.12443728 5.81640934 6.26098062\n",
      " 5.90107459 5.9832982  6.17572958 6.37838857 2.78546336 5.17127665\n",
      " 4.51958116 6.65633485 4.80025167 6.51634247 5.5548998  5.51584869\n",
      " 5.8129297  5.63587061 5.65945481 7.57169497 5.2623941  4.34770248\n",
      " 4.92806963 4.98130026 4.88881492 5.20556307 6.50460107 6.13781172\n",
      " 6.28750327]\n",
      "\n",
      "What it should be:  [5.16666667 6.5        5.5        5.         5.66666667 6.66666667\n",
      " 7.         6.         6.5        3.5        6.         4.5\n",
      " 6.66666667 6.         4.66666667 5.5        5.5        6.16666667\n",
      " 6.83333333 6.66666667 5.66666667 3.         3.66666667 6.33333333\n",
      " 4.         6.83333333 5.66666667 6.33333333 6.66666667 6.33333333\n",
      " 4.83333333 4.33333333 6.16666667 3.66666667 4.16666667 5.16666667\n",
      " 6.5       ]\n",
      "Correlation:  [[ 1.         -0.10178596]\n",
      " [-0.10178596  1.        ]]\n",
      "Mean absolute error = 1.15\n",
      "Mean squared error = 2.05\n",
      "Median absolute error = 1.04\n",
      "Explain variance score = -0.76\n",
      "R2 score = -0.77\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.25277557 5.40366786 5.51997688 5.97058968 7.20258863 5.85553851\n",
      " 5.37451027 5.63787025 3.86954807 5.49643256 7.15148019 5.59237907\n",
      " 5.39891221 4.51340705 4.99526881 5.96960273 5.14767666 5.32444316\n",
      " 4.43341613 4.66854661 6.09017417 4.97626376 6.05085103 5.32331182\n",
      " 4.79583281 5.83899029 4.75392774 4.30908219 6.42358857 6.36151828\n",
      " 5.11802796 5.68228928 6.26072234 5.14435508 4.07331347 7.21280224\n",
      " 6.46977207]\n",
      "\n",
      "What it should be:  [6.83333333 6.         4.33333333 5.66666667 6.33333333 5.33333333\n",
      " 4.66666667 4.         5.16666667 5.5        6.         6.5\n",
      " 5.66666667 4.         5.83333333 5.16666667 5.16666667 4.83333333\n",
      " 3.66666667 6.33333333 5.33333333 4.83333333 5.33333333 5.83333333\n",
      " 5.83333333 6.33333333 5.66666667 7.         6.33333333 5.83333333\n",
      " 5.5        4.5        6.66666667 6.16666667 5.33333333 7.\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.26288845]\n",
      " [0.26288845 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.51\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.33994273 5.25966628 6.3484265  6.10592236 4.15196822 4.99982478\n",
      " 5.16538343 5.33441646 4.71690819 6.09092499 6.13674699 4.79288022\n",
      " 5.02178344 4.72144786 6.26511299 5.74691518 6.80789514 5.32582499\n",
      " 3.83940123 5.21656473 6.26412682 6.8053836  5.713583   4.80068\n",
      " 5.23758026 5.35760477 4.59408358 6.00910621 7.5140821  5.82916674\n",
      " 5.95333495 4.58451917 5.18294531 6.47967682 4.47023711 5.46270822\n",
      " 5.09576347]\n",
      "\n",
      "What it should be:  [7.         5.83333333 6.16666667 6.16666667 5.16666667 4.66666667\n",
      " 5.83333333 3.5        6.16666667 5.66666667 6.83333333 5.83333333\n",
      " 5.5        3.         6.5        6.16666667 5.16666667 6.83333333\n",
      " 6.33333333 6.         5.66666667 7.         5.83333333 6.33333333\n",
      " 5.         5.         4.83333333 5.33333333 6.66666667 6.\n",
      " 4.16666667 5.5        5.66666667 6.83333333 6.66666667 6.5\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.23960511]\n",
      " [0.23960511 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.43\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.30127429 4.69161607 5.22901716 5.91074331 6.22400205 6.49981663\n",
      " 5.91766108 7.03713632 4.76011481 4.99729195 7.49416447 6.12308068\n",
      " 5.20647534 3.80447369 5.33955607 5.67753683 5.42289539 5.20566722\n",
      " 5.59762605 5.13334218 3.93233592 6.06324177 1.45173656 5.0010583\n",
      " 4.92035713 5.31051093 4.72029885 5.95637402 3.97063237 5.99270285\n",
      " 6.19525028 4.49618539 6.00437949 5.92327356 4.88407158 4.73897549\n",
      " 4.84345803]\n",
      "\n",
      "What it should be:  [6.5        5.5        6.         6.66666667 5.33333333 6.16666667\n",
      " 6.16666667 6.16666667 4.33333333 5.33333333 6.16666667 4.66666667\n",
      " 6.33333333 4.66666667 4.16666667 6.33333333 4.5        5.66666667\n",
      " 5.5        5.33333333 5.33333333 6.         5.5        4.66666667\n",
      " 6.5        6.16666667 5.5        4.83333333 4.         6.66666667\n",
      " 6.83333333 6.16666667 6.         4.         6.16666667 6.16666667\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.22681347]\n",
      " [0.22681347 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.44\n",
      "Median absolute error = 0.86\n",
      "Explain variance score = -1.11\n",
      "R2 score = -1.3\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.35999746 5.76889234 6.35848799 5.50775084 4.80468045 4.7323938\n",
      " 5.67864241 4.4763523  5.96305061 5.64574038 6.02401952 5.63036676\n",
      " 6.15493484 6.0560762  3.9993842  7.69055388 5.80509202 3.21000105\n",
      " 6.39013614 4.17256505 5.84791932 6.90579051 5.82118361 4.74471574\n",
      " 4.95556215 5.56080206 5.34537024 5.47072433 4.09136931 7.17882338\n",
      " 4.53874921 2.06060692 5.14335497 5.29796005 6.19717189 6.08584001\n",
      " 7.22678354]\n",
      "\n",
      "What it should be:  [4.66666667 6.16666667 6.         6.66666667 5.5        4.66666667\n",
      " 4.16666667 4.5        5.83333333 5.16666667 5.         4.5\n",
      " 5.16666667 5.33333333 4.         6.5        6.5        4.83333333\n",
      " 4.66666667 6.5        6.16666667 6.66666667 5.83333333 7.\n",
      " 5.5        5.5        6.5        4.5        5.33333333 5.16666667\n",
      " 6.83333333 5.5        5.5        6.16666667 5.83333333 6.\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.21350368]\n",
      " [0.21350368 1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.49\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -1.35\n",
      "R2 score = -1.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.88696659 5.46644145 5.89380486 6.46679956 5.57536536 5.22958915\n",
      " 5.6682353  3.78432241 6.72465483 4.40543667 4.52233092 5.06456485\n",
      " 6.92655442 5.80342492 5.21427033 5.57084893 5.11042613 7.56561689\n",
      " 5.69693455 5.65860954 5.92348631 4.2298523  4.63172223 5.36333105\n",
      " 6.85030583 5.89324036 5.1240661  1.61557386 5.15869227 5.1763441\n",
      " 5.45362455 5.63647836 5.17032223 6.74130674 4.62376695 5.49996714\n",
      " 4.77166588]\n",
      "\n",
      "What it should be:  [6.         6.66666667 5.5        4.83333333 6.33333333 5.5\n",
      " 4.5        4.66666667 5.66666667 6.33333333 6.16666667 4.83333333\n",
      " 5.83333333 5.66666667 4.         6.16666667 6.         6.16666667\n",
      " 6.5        5.83333333 6.16666667 4.5        5.5        3.5\n",
      " 6.5        6.         6.66666667 5.5        6.83333333 5.33333333\n",
      " 4.66666667 5.83333333 3.66666667 4.66666667 4.33333333 5.5\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.14589663]\n",
      " [0.14589663 1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.51\n",
      "Median absolute error = 0.88\n",
      "Explain variance score = -1.04\n",
      "R2 score = -1.07\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.16770835 7.6748381  6.3839492  5.39624647 5.87644215 5.38587222\n",
      " 6.16756856 4.96158922 5.1090075  4.19055213 5.11824176 6.01720789\n",
      " 5.81558909 5.45199104 4.99373768 6.11438427 6.64349579 5.15820295\n",
      " 5.40240769 6.01076334 5.8719344  5.32408712 5.38340265 5.34453322\n",
      " 5.41786103 7.6465238  4.88573028 3.96666456 5.20044121 5.70670433\n",
      " 7.16122334 3.66297544 5.73711383 6.11090157 5.98101352 4.33897929\n",
      " 6.92615543]\n",
      "\n",
      "What it should be:  [6.33333333 6.66666667 4.83333333 6.         5.33333333 6.16666667\n",
      " 5.33333333 6.66666667 4.33333333 5.5        7.         7.\n",
      " 4.66666667 5.33333333 6.83333333 6.16666667 6.33333333 6.5\n",
      " 6.66666667 5.5        6.66666667 6.16666667 5.16666667 6.33333333\n",
      " 6.33333333 5.83333333 5.16666667 5.16666667 5.66666667 5.5\n",
      " 6.33333333 4.83333333 6.83333333 6.16666667 5.66666667 4.83333333\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.30793636]\n",
      " [0.30793636 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.83\n",
      "Explain variance score = -0.72\n",
      "R2 score = -0.89\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.40293929 5.27644016 4.63350212 4.84562367 5.65229482 6.90799296\n",
      " 3.63675985 5.95194487 4.44021197 6.77001944 5.69538144 5.25065417\n",
      " 5.64945826 5.99654398 3.95554295 5.0196003  5.414516   5.51458953\n",
      " 4.69713662 5.02710851 6.08650605 6.64552473 4.18554352 7.64108962\n",
      " 5.10669406 4.77187598 6.25589869 6.22445938 5.10659374 5.9683796\n",
      " 5.57139024 5.88042538 5.10126461 4.95804344 6.00518667 4.49227588\n",
      " 4.72763954]\n",
      "\n",
      "What it should be:  [6.33333333 5.         5.83333333 3.66666667 6.5        5.83333333\n",
      " 6.33333333 5.66666667 5.33333333 6.5        6.83333333 5.\n",
      " 5.33333333 5.33333333 6.33333333 3.66666667 4.83333333 5.66666667\n",
      " 5.5        3.33333333 4.66666667 6.5        4.5        5.83333333\n",
      " 6.16666667 4.5        6.         6.66666667 6.66666667 6.83333333\n",
      " 6.5        6.83333333 3.83333333 5.5        4.33333333 6.\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.24946875]\n",
      " [0.24946875 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.25\n",
      "Median absolute error = 0.89\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.96568898 4.18342498 5.37576616 6.18288203 5.95288793 5.52678364\n",
      " 5.90763112 5.97760813 5.10725344 4.73602642 6.31432298 4.40199348\n",
      " 5.60030522 6.204491   4.95008116 6.88876318 6.226282   5.60592531\n",
      " 5.78540514 6.45765244 4.85443663 5.68310564 5.59775151 5.63370809\n",
      " 4.41398709 5.8208005  5.95743692 5.77665655 5.62728587 2.98505034\n",
      " 5.54973522 5.88801023 6.33781099 5.05826939 4.6385487  6.01024986\n",
      " 7.2320905 ]\n",
      "\n",
      "What it should be:  [5.83333333 6.33333333 5.66666667 5.5        5.33333333 5.83333333\n",
      " 4.5        5.66666667 5.33333333 4.33333333 5.33333333 4.5\n",
      " 5.16666667 5.66666667 3.83333333 6.16666667 6.         5.16666667\n",
      " 6.83333333 6.16666667 6.16666667 6.83333333 6.         5.66666667\n",
      " 5.5        5.83333333 6.5        4.66666667 7.         4.5\n",
      " 5.         5.         6.66666667 6.5        4.83333333 6.5\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.38519429]\n",
      " [0.38519429 1.        ]]\n",
      "Mean absolute error = 0.72\n",
      "Mean squared error = 0.76\n",
      "Median absolute error = 0.55\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.08701477 5.87365189 5.95530384 4.77394096 4.35998575 5.13127434\n",
      " 4.95251857 5.15815648 5.89759929 6.21035052 4.92159119 4.55838443\n",
      " 5.53731664 6.09815211 5.53587056 5.6712755  5.86327579 5.09018918\n",
      " 6.37267753 5.99361606 4.84749603 6.07008722 6.6321901  5.58789777\n",
      " 6.28303029 6.13166823 7.17629262 5.96496178 5.00178069 6.1113188\n",
      " 5.19246842 6.18835241 6.27834875 5.2984068  5.33285699 5.38614338\n",
      " 3.67491208]\n",
      "\n",
      "What it should be:  [4.33333333 6.16666667 4.66666667 4.66666667 3.66666667 4.66666667\n",
      " 4.66666667 6.16666667 5.83333333 6.83333333 6.33333333 5.33333333\n",
      " 5.5        6.         4.83333333 4.5        5.5        3.66666667\n",
      " 5.66666667 5.16666667 5.16666667 7.         5.83333333 1.83333333\n",
      " 5.33333333 6.16666667 5.83333333 5.83333333 5.83333333 4.66666667\n",
      " 6.16666667 6.33333333 6.33333333 6.5        4.33333333 6.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.30816954]\n",
      " [0.30816954 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.04\n",
      "R2 score = -0.07\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.16113039 5.15690181 5.85928211 5.56080764 4.84984472 6.03441051\n",
      " 5.14917021 6.52066596 5.85343574 4.96655651 5.72106313 5.58193984\n",
      " 3.44599271 5.98930468 5.27967781 5.78514086 7.19891597 4.14732429\n",
      " 7.09534484 5.98912664 6.05050639 5.62535902 6.52854523 5.52663706\n",
      " 6.73363697 5.13459815 5.41304726 6.32155711 5.71726042 5.67001719\n",
      " 5.60715586 6.82329462 6.08762817 5.0764697  6.06163292 6.65240387\n",
      " 6.41423327]\n",
      "\n",
      "What it should be:  [6.16666667 5.33333333 4.         6.66666667 4.66666667 5.16666667\n",
      " 5.16666667 6.5        5.33333333 5.         5.16666667 5.16666667\n",
      " 4.         7.         3.33333333 5.33333333 5.         6.33333333\n",
      " 6.66666667 6.16666667 4.66666667 6.83333333 6.         6.5\n",
      " 5.83333333 5.33333333 3.         6.         6.16666667 6.\n",
      " 4.5        5.66666667 5.33333333 6.         6.83333333 5.66666667\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.32163288]\n",
      " [0.32163288 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.12\n",
      "R2 score = -0.2\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [2.3634266  7.56476326 4.56081224 5.69022281 4.50725636 4.66934885\n",
      " 5.26454789 5.84975504 5.001528   5.78989518 5.78153227 5.44416808\n",
      " 6.52287147 6.4493184  5.35340856 6.03176078 4.08233814 4.98282371\n",
      " 5.83126938 4.90139378 6.08758454 4.75991003 5.23075992 4.97371277\n",
      " 5.7396764  4.61094272 6.14401065 6.2968798  5.0054248  6.03306228\n",
      " 5.50160413 4.78710517 5.57314282 5.24278956 5.67704299 6.27065574\n",
      " 5.74414643]\n",
      "\n",
      "What it should be:  [5.5        6.5        4.         6.83333333 6.33333333 5.83333333\n",
      " 4.5        7.         5.66666667 4.         6.16666667 5.66666667\n",
      " 6.16666667 5.83333333 6.83333333 6.16666667 6.33333333 3.66666667\n",
      " 4.33333333 5.33333333 4.66666667 7.         5.83333333 6.5\n",
      " 6.16666667 6.16666667 5.16666667 6.5        4.83333333 6.83333333\n",
      " 5.         6.         6.16666667 5.66666667 5.33333333 7.\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.15913625]\n",
      " [0.15913625 1.        ]]\n",
      "Mean absolute error = 0.98\n",
      "Mean squared error = 1.41\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.62\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.89774239 5.87927494 4.91718345 6.03801731 6.6508103  6.37751125\n",
      " 5.89305904 5.55561764 5.20170039 5.7835899  5.29653993 7.60427179\n",
      " 6.37602021 4.54107795 5.01319387 5.05880285 4.05248958 6.03160277\n",
      " 6.74919852 4.28207808 6.48295494 6.49575144 4.90493318 5.43530992\n",
      " 5.93235797 5.92347866 5.4289428  7.18163989 5.53937069 4.50497659\n",
      " 6.43285711 6.98074223 6.07759548 6.19531951 5.73855723 5.83134944\n",
      " 5.53657765]\n",
      "\n",
      "What it should be:  [6.83333333 5.66666667 5.5        5.33333333 6.83333333 6.83333333\n",
      " 5.83333333 5.66666667 6.16666667 5.33333333 6.16666667 7.\n",
      " 6.5        6.33333333 5.16666667 6.16666667 4.83333333 5.33333333\n",
      " 6.5        3.66666667 5.66666667 6.83333333 6.83333333 4.33333333\n",
      " 4.16666667 5.33333333 3.83333333 5.16666667 6.16666667 4.83333333\n",
      " 4.66666667 5.         5.83333333 5.66666667 6.         5.5\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.32562037]\n",
      " [0.32562037 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.92\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.26\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.54001417 4.919924   5.3952064  5.24017369 6.1016627  5.91806012\n",
      " 5.95471381 4.0450318  6.17449992 6.02143555 5.88056869 4.93565608\n",
      " 4.83976845 4.51179342 6.59361307 5.38850483 5.15848728 5.37063908\n",
      " 6.38328141 5.11611648 5.18574411 5.33911086 5.53936967 5.68036585\n",
      " 6.06704456 5.3755042  4.77687256 6.20282682 6.0501871  6.02866815\n",
      " 5.85138247 4.92614409 7.12730368 4.90664326 6.46614275 6.54763317\n",
      " 3.59155505]\n",
      "\n",
      "What it should be:  [5.         6.5        5.33333333 4.33333333 5.5        6.66666667\n",
      " 6.5        4.66666667 6.33333333 6.16666667 5.66666667 6.\n",
      " 6.         4.33333333 5.16666667 4.         4.5        6.33333333\n",
      " 5.66666667 4.83333333 4.83333333 5.5        6.5        5.5\n",
      " 6.16666667 6.16666667 4.83333333 5.66666667 6.         3.66666667\n",
      " 6.16666667 5.66666667 6.         6.16666667 6.83333333 6.5\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.21684152]\n",
      " [0.21684152 1.        ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.45\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.91623979 5.34523579 4.97978278 4.29412966 5.03338115 5.99992653\n",
      " 4.61901075 6.15986296 5.45054864 5.45453255 5.29840231 5.55881279\n",
      " 5.64218571 5.20379018 6.35521257 5.90430699 4.72283037 5.88221645\n",
      " 5.51993273 6.21323832 5.10966701 6.10344445 6.35025625 6.89580078\n",
      " 5.78441929 5.92849178 6.07271664 5.576031   5.81539168 6.2903282\n",
      " 4.81982713 6.49764024 6.32303308 6.42936663 4.84055416 5.60598061\n",
      " 5.17080851]\n",
      "\n",
      "What it should be:  [5.83333333 5.         6.33333333 6.33333333 4.         5.33333333\n",
      " 3.66666667 4.83333333 5.33333333 3.33333333 5.5        5.33333333\n",
      " 6.66666667 6.83333333 4.5        5.33333333 6.16666667 5.66666667\n",
      " 5.         4.5        5.33333333 5.83333333 4.66666667 4.66666667\n",
      " 4.5        4.         5.83333333 6.66666667 3.66666667 6.\n",
      " 6.33333333 4.         3.         5.66666667 6.         5.83333333\n",
      " 6.83333333]\n",
      "Correlation:  [[ 1.         -0.33385334]\n",
      " [-0.33385334  1.        ]]\n",
      "Mean absolute error = 1.13\n",
      "Mean squared error = 1.93\n",
      "Median absolute error = 1.09\n",
      "Explain variance score = -0.75\n",
      "R2 score = -0.9\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.9201494  5.30239671 5.63409796 5.6460762  5.00697962 5.21098767\n",
      " 6.55650411 5.56915961 4.68862132 4.71061771 5.90847827 4.63968438\n",
      " 5.11839444 6.32428708 6.15859762 3.7076275  4.43931815 5.68263598\n",
      " 5.34042056 5.27962512 5.3535757  5.77422575 6.19240725 5.72394853\n",
      " 5.14224429 5.3496528  2.44659109 6.12117273 6.1302144  6.14492327\n",
      " 5.11119233 4.33469126 5.44027069 5.99557932 6.44884646 5.63650682\n",
      " 5.3714783 ]\n",
      "\n",
      "What it should be:  [6.83333333 6.16666667 6.         5.33333333 5.66666667 6.16666667\n",
      " 6.5        6.16666667 6.16666667 4.83333333 4.5        6.5\n",
      " 6.66666667 6.5        6.83333333 6.33333333 6.         5.33333333\n",
      " 5.66666667 5.         6.         5.83333333 5.83333333 4.83333333\n",
      " 5.83333333 4.33333333 4.83333333 6.33333333 6.83333333 5.5\n",
      " 6.5        6.83333333 3.33333333 4.5        7.         5.83333333\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.13176768]\n",
      " [0.13176768 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.31\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.64\n",
      "R2 score = -0.87\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.61727351 6.18323173 2.37802018 4.8121872  5.79368273 5.42584026\n",
      " 4.98622989 5.81757568 7.59364359 6.34527371 5.14342724 6.91326655\n",
      " 7.62926514 6.11475771 6.09796214 2.41081233 5.6993655  6.84224775\n",
      " 5.75013055 6.1717041  4.82434559 4.8765465  5.56104695 5.19433001\n",
      " 3.90958059 6.01548089 5.85340189 7.25680253 6.17848401 6.38280783\n",
      " 4.98720853 6.46742624 6.28555023 5.64853822 6.65418922 5.67674202\n",
      " 4.69125985]\n",
      "\n",
      "What it should be:  [6.5        5.66666667 5.5        3.66666667 6.33333333 5.66666667\n",
      " 6.5        5.5        6.5        6.83333333 5.33333333 5.83333333\n",
      " 7.         5.83333333 5.83333333 4.83333333 5.33333333 7.\n",
      " 5.66666667 6.66666667 6.         5.33333333 6.16666667 5.5\n",
      " 3.66666667 5.33333333 5.66666667 5.33333333 6.66666667 6.5\n",
      " 3.83333333 5.33333333 6.83333333 5.16666667 6.5        6.16666667\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.50597097]\n",
      " [0.50597097 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 1.04\n",
      "Median absolute error = 0.49\n",
      "Explain variance score = -0.48\n",
      "R2 score = -0.5\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.89349831 7.12628413 5.80912916 3.55999797 5.7833357  5.6599913\n",
      " 5.51989398 5.76210872 4.43128592 5.66453899 5.11635859 6.64924052\n",
      " 5.91649013 6.03297971 4.82614353 6.60810922 5.12355656 4.05042365\n",
      " 6.72472496 5.63520885 4.98517931 6.31506445 6.07212988 5.57297938\n",
      " 6.21408909 4.0073619  5.46609338 5.1583022  6.56905739 4.53712458\n",
      " 5.21410438 5.42526837 5.34275317 5.21293268 5.16474024 5.44582895\n",
      " 5.62816294]\n",
      "\n",
      "What it should be:  [5.         7.         5.66666667 6.16666667 5.33333333 6.33333333\n",
      " 1.83333333 6.83333333 6.83333333 6.         5.         6.33333333\n",
      " 4.         6.         5.         6.5        5.16666667 4.83333333\n",
      " 6.83333333 6.16666667 4.83333333 6.66666667 6.5        5.5\n",
      " 6.16666667 6.33333333 4.5        6.16666667 5.83333333 6.5\n",
      " 6.16666667 5.33333333 5.5        5.         6.33333333 5.66666667\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.21644518]\n",
      " [0.21644518 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 1.31\n",
      "Median absolute error = 0.35\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.90837963 6.33805991 5.57118677 6.48577386 5.98943781 6.52697981\n",
      " 4.74250518 5.29808423 5.6168104  7.32019904 5.48051576 6.58311771\n",
      " 5.53136156 5.2939844  5.58063513 6.65065286 4.79034553 6.30318965\n",
      " 5.30886868 4.36065224 5.59239632 4.53325902 4.47003694 5.16570423\n",
      " 5.9516702  4.7486484  6.35307538 6.35689813 6.39437677 4.96109787\n",
      " 4.51640578 6.82934654 6.20636323 4.68545779 5.43080871 6.05518613\n",
      " 4.83950041]\n",
      "\n",
      "What it should be:  [6.         5.33333333 6.66666667 6.33333333 6.83333333 5.\n",
      " 5.83333333 6.16666667 5.66666667 6.5        4.5        6.16666667\n",
      " 6.33333333 5.5        6.33333333 3.         4.33333333 5.66666667\n",
      " 5.33333333 5.5        6.5        5.83333333 4.83333333 5.5\n",
      " 6.5        6.         5.16666667 5.83333333 6.         4.33333333\n",
      " 4.83333333 6.16666667 4.16666667 6.16666667 6.16666667 6.16666667\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.13757578]\n",
      " [0.13757578 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.61\n",
      "R2 score = -0.61\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.68569941 5.94176642 4.7893641  6.91003045 6.99187804 4.98017568\n",
      " 5.52941571 5.32065957 6.27611904 5.70591597 5.86232676 5.67303265\n",
      " 4.18170168 3.89588671 5.2531801  4.55927328 6.1673708  5.75973672\n",
      " 4.62656775 6.14514874 5.39860273 4.79341485 5.45675296 6.3376677\n",
      " 6.07927425 4.2599656  6.37640096 3.52353751 5.08807645 6.14136846\n",
      " 6.29522781 5.0931473  5.07506015 5.45404607 5.52802595 5.2432617\n",
      " 6.12927407]\n",
      "\n",
      "What it should be:  [5.66666667 6.66666667 6.5        6.33333333 6.5        6.\n",
      " 4.83333333 6.5        6.83333333 6.16666667 6.5        5.16666667\n",
      " 4.66666667 6.33333333 5.         5.16666667 5.83333333 6.16666667\n",
      " 6.83333333 6.16666667 4.83333333 4.         5.         6.83333333\n",
      " 6.5        7.         6.         5.33333333 4.5        6.\n",
      " 6.5        5.16666667 3.66666667 5.33333333 4.16666667 6.5\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.30714258]\n",
      " [0.30714258 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.57\n",
      "Explain variance score = -0.28\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.37996357 2.71483427 2.6293255  5.0877927  5.21652227 5.60639061\n",
      " 6.26606232 5.75723892 5.48754466 4.82519582 5.00192531 4.52255507\n",
      " 4.48980538 6.31991184 4.8266021  4.97839819 5.76139736 4.16593645\n",
      " 6.03321846 7.39075443 5.67590987 5.454446   5.102166   5.25185601\n",
      " 5.12390036 4.69007169 6.09906746 5.04563552 5.74517717 6.51536578\n",
      " 4.73518492 4.8945855  4.99072579 5.21165697 6.74519707 4.86845952\n",
      " 6.14652711]\n",
      "\n",
      "What it should be:  [4.66666667 5.5        4.83333333 5.33333333 6.16666667 6.33333333\n",
      " 6.16666667 5.16666667 4.83333333 5.5        4.66666667 6.33333333\n",
      " 6.         5.66666667 5.83333333 5.83333333 5.66666667 5.33333333\n",
      " 5.33333333 6.5        5.83333333 6.         5.5        3.\n",
      " 6.         6.5        4.66666667 6.33333333 6.16666667 6.83333333\n",
      " 5.         5.66666667 6.5        4.33333333 6.16666667 4.5\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.26213102]\n",
      " [0.26213102 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.83\n",
      "R2 score = -1.03\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.00275669 5.53659405 4.82253756 5.92745424 5.15637647 5.48042512\n",
      " 5.48462972 7.51043192 6.50440716 6.73577355 4.93288903 6.42462432\n",
      " 6.49877922 5.29699852 6.65482087 6.59463727 7.01270455 4.6772321\n",
      " 6.51135559 3.71572024 6.7577596  6.39660724 6.13467016 5.57239572\n",
      " 5.95547801 5.04088697 5.82959777 5.29152162 6.80144421 5.64081645\n",
      " 6.19931874 5.92045061 6.01669301 6.78130364 5.51668205 6.09570319\n",
      " 4.62011054]\n",
      "\n",
      "What it should be:  [5.33333333 7.         5.83333333 6.66666667 7.         5.66666667\n",
      " 5.5        6.5        6.5        6.16666667 5.66666667 6.5\n",
      " 6.16666667 6.5        5.83333333 5.66666667 7.         4.33333333\n",
      " 6.83333333 4.5        6.         5.83333333 6.33333333 3.\n",
      " 5.66666667 5.16666667 6.5        6.         6.66666667 3.66666667\n",
      " 6.         4.         5.66666667 5.83333333 6.5        6.83333333\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.37535845]\n",
      " [0.37535845 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.09\n",
      "R2 score = -0.09\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.86905235 5.77527556 5.57093289 5.35168344 3.91488957 5.75384514\n",
      " 5.04727018 4.70588947 5.8773585  5.50317214 5.13930958 6.46567252\n",
      " 5.97204549 4.03202168 6.64918671 5.95094778 6.06532043 5.80005228\n",
      " 3.83335449 5.93551531 6.27094611 6.75162377 3.57823314 5.82768448\n",
      " 5.8435918  5.15638809 7.06891871 5.69874828 6.03437609 5.601606\n",
      " 7.5621756  3.87827262 5.99258403 4.84230221 4.87190492 6.60850976\n",
      " 5.35392859]\n",
      "\n",
      "What it should be:  [4.5        6.16666667 5.33333333 6.83333333 4.33333333 6.\n",
      " 5.83333333 5.5        6.66666667 6.         5.5        6.\n",
      " 6.         6.16666667 4.66666667 4.5        6.33333333 6.66666667\n",
      " 4.         6.83333333 5.33333333 5.16666667 6.33333333 6.83333333\n",
      " 6.83333333 6.5        5.16666667 4.83333333 6.5        5.33333333\n",
      " 5.83333333 4.83333333 6.5        4.66666667 6.16666667 7.\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.20614896]\n",
      " [0.20614896 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.77\n",
      "R2 score = -0.83\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.65326894 5.08399927 5.84278507 6.67678066 7.30628709 4.59877031\n",
      " 4.13299011 4.57052311 5.53446449 5.0906208  7.72527601 4.86708541\n",
      " 6.02433063 4.07082786 5.51178447 6.72907281 5.17315117 4.40951405\n",
      " 7.35437425 5.23973619 4.21243168 5.67928007 5.01260863 4.93539869\n",
      " 5.94368696 5.72514664 6.25096302 6.01502868 5.96956465 4.50130377\n",
      " 5.29183043 4.82116678 4.99027378 6.4873613  4.55768656 6.32086281\n",
      " 5.916646  ]\n",
      "\n",
      "What it should be:  [4.         4.5        5.16666667 5.33333333 5.83333333 5.83333333\n",
      " 6.33333333 5.33333333 6.5        4.33333333 6.         6.\n",
      " 4.66666667 4.         3.5        7.         4.         4.66666667\n",
      " 6.5        7.         6.         5.33333333 5.5        7.\n",
      " 6.83333333 6.         6.         6.5        4.83333333 5.5\n",
      " 5.83333333 6.16666667 4.83333333 6.83333333 3.66666667 5.66666667\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.24741411]\n",
      " [0.24741411 1.        ]]\n",
      "Mean absolute error = 0.97\n",
      "Mean squared error = 1.37\n",
      "Median absolute error = 0.89\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.62096264 5.78942635 5.29933509 5.43892456 4.30758417 4.9833637\n",
      " 6.65582099 5.86731767 5.27727075 5.37111394 5.15737464 6.03917061\n",
      " 5.82530082 5.27633882 5.49521885 5.35263249 5.77922112 4.95121946\n",
      " 5.00940724 7.19895792 6.81644315 5.54944713 2.76673955 5.04837564\n",
      " 6.54486486 6.2622057  5.71943836 6.25227227 5.82861335 5.86495088\n",
      " 4.68418669 4.60597767 5.39298314 5.49353507 4.37063403 5.53271608\n",
      " 6.7407354 ]\n",
      "\n",
      "What it should be:  [5.16666667 3.         3.33333333 4.83333333 4.5        5.\n",
      " 5.83333333 4.5        6.66666667 6.33333333 1.83333333 5.33333333\n",
      " 4.         4.83333333 6.66666667 5.83333333 6.         6.33333333\n",
      " 6.83333333 5.83333333 6.33333333 4.66666667 5.33333333 4.5\n",
      " 6.83333333 5.16666667 5.33333333 4.66666667 5.5        4.83333333\n",
      " 4.83333333 3.66666667 4.83333333 5.83333333 6.66666667 4.66666667\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.17284224]\n",
      " [0.17284224 1.        ]]\n",
      "Mean absolute error = 1.02\n",
      "Mean squared error = 1.67\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.63299433 4.66701072 5.92312294 7.04475533 3.99148931 6.37957658\n",
      " 5.96796089 5.48302106 5.55674873 4.01604289 5.50493584 4.95109899\n",
      " 5.46739974 4.72450238 5.90147552 6.28918067 5.81453563 5.76465947\n",
      " 5.50726607 4.56745613 5.33373828 5.06055558 6.3904189  5.3311779\n",
      " 3.82295001 4.54950407 6.21742005 5.06027622 5.42755123 5.70547111\n",
      " 5.35841424 7.40086038 3.84840169 5.75553689 7.40992456 5.11989353\n",
      " 5.9708884 ]\n",
      "\n",
      "What it should be:  [5.5        6.16666667 5.16666667 5.33333333 6.33333333 4.\n",
      " 6.16666667 5.16666667 6.83333333 5.         5.66666667 5.66666667\n",
      " 4.5        4.5        4.83333333 5.33333333 7.         6.83333333\n",
      " 1.83333333 6.16666667 5.16666667 5.5        6.83333333 6.5\n",
      " 4.33333333 6.5        5.33333333 6.83333333 5.33333333 5.16666667\n",
      " 6.33333333 6.5        5.5        5.66666667 6.16666667 5.16666667\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.10425863]\n",
      " [0.10425863 1.        ]]\n",
      "Mean absolute error = 1.0\n",
      "Mean squared error = 1.59\n",
      "Median absolute error = 0.96\n",
      "Explain variance score = -0.56\n",
      "R2 score = -0.57\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.47844904 7.25254546 5.7278974  5.98325197 5.00552851 5.53113928\n",
      " 5.28645776 6.67556453 5.74526028 6.34725334 5.4817837  6.52261697\n",
      " 4.67953467 7.57734836 6.87170229 5.04133228 3.42822308 5.17960547\n",
      " 6.33426836 5.29330608 5.35785626 5.0746203  5.22049803 5.56914988\n",
      " 4.603042   4.96959189 6.23466927 3.76233529 2.38404139 7.0536215\n",
      " 4.57494107 4.98396873 5.15538167 5.97737964 7.51833436 5.90273134\n",
      " 5.94763849]\n",
      "\n",
      "What it should be:  [5.66666667 6.5        5.83333333 6.83333333 5.16666667 6.66666667\n",
      " 6.         5.33333333 5.16666667 5.83333333 6.5        5.66666667\n",
      " 4.         6.66666667 4.66666667 5.16666667 4.5        6.\n",
      " 6.16666667 4.         4.83333333 6.         5.5        6.5\n",
      " 3.83333333 3.33333333 5.33333333 6.33333333 5.5        6.16666667\n",
      " 5.83333333 5.16666667 5.33333333 5.16666667 5.83333333 5.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.32855744]\n",
      " [0.32855744 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -0.81\n",
      "R2 score = -0.82\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.2222328  5.02088384 6.88989612 5.29176553 6.6636199  5.30809802\n",
      " 5.65946283 5.18474538 4.5397956  6.18859261 5.70179806 6.4455766\n",
      " 5.59331244 4.94101798 5.95532146 5.13951249 5.28012217 6.81452593\n",
      " 5.90283695 5.14848651 5.44407338 5.76291815 4.08763735 3.56215788\n",
      " 6.2951175  4.90989592 5.8941692  4.68828277 5.79561429 5.38219634\n",
      " 5.03780165 3.97974647 5.3727991  5.50033879 5.48336904 5.76013402\n",
      " 5.92507163]\n",
      "\n",
      "What it should be:  [6.5        6.         7.         4.         6.         6.16666667\n",
      " 6.16666667 5.83333333 5.16666667 4.66666667 6.5        6.66666667\n",
      " 6.         6.66666667 5.16666667 5.66666667 6.83333333 6.33333333\n",
      " 5.83333333 6.66666667 7.         5.33333333 6.33333333 4.66666667\n",
      " 6.         6.66666667 5.33333333 5.5        7.         5.5\n",
      " 5.33333333 6.5        6.33333333 5.16666667 6.83333333 5.66666667\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.12860398]\n",
      " [0.12860398 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.71\n",
      "R2 score = -1.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.72054474 7.82084617 5.26218387 5.44962903 5.24563409 5.80547272\n",
      " 5.45615494 3.58007336 6.06256453 5.04722253 6.12345815 6.18142815\n",
      " 6.34814131 6.1003703  5.39862909 4.79065894 5.56718977 4.37753267\n",
      " 4.43491867 5.7962899  5.93154492 5.26005721 5.59582301 5.82549688\n",
      " 5.71338192 3.83100691 4.65645767 4.81257082 4.96549276 6.91438865\n",
      " 5.47402777 5.64106644 4.34957813 4.06907318 6.840397   5.08592544\n",
      " 6.53002837]\n",
      "\n",
      "What it should be:  [6.33333333 6.5        6.66666667 5.         6.         6.83333333\n",
      " 4.5        4.66666667 6.16666667 6.33333333 5.83333333 6.\n",
      " 5.33333333 6.16666667 6.         4.66666667 5.5        6.83333333\n",
      " 6.16666667 6.16666667 5.83333333 6.33333333 5.33333333 6.5\n",
      " 6.33333333 5.16666667 6.16666667 5.16666667 6.         6.83333333\n",
      " 5.66666667 6.16666667 6.5        5.33333333 5.83333333 6.66666667\n",
      " 5.        ]\n",
      "Correlation:  [[1.        0.2218967]\n",
      " [0.2218967 1.       ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.96\n",
      "Explain variance score = -1.28\n",
      "R2 score = -1.83\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.91836258 5.92898812 6.36175532 6.90077212 6.73644445 4.92305611\n",
      " 5.80730174 5.29108119 4.9413674  4.89575816 5.06489707 6.21969729\n",
      " 6.56739255 4.5867548  6.27131068 6.50478804 6.2409742  4.68399706\n",
      " 5.05402422 7.0928471  6.13780296 6.03949304 5.49991417 5.12563487\n",
      " 5.83886195 2.01885378 6.46884873 5.3426827  4.57895911 6.21157617\n",
      " 5.64824301 7.18208116 5.78157478 4.664299   5.19580465 5.03598066\n",
      " 6.25369212]\n",
      "\n",
      "What it should be:  [5.5        5.33333333 6.83333333 5.33333333 5.66666667 6.\n",
      " 6.33333333 4.         6.16666667 6.5        6.         6.5\n",
      " 6.33333333 6.83333333 6.         3.         5.16666667 3.66666667\n",
      " 3.5        6.5        5.16666667 5.33333333 4.83333333 5.33333333\n",
      " 5.5        5.5        5.66666667 5.33333333 5.33333333 5.66666667\n",
      " 5.16666667 6.         4.5        5.33333333 5.83333333 4.\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.11316362]\n",
      " [0.11316362 1.        ]]\n",
      "Mean absolute error = 0.99\n",
      "Mean squared error = 1.55\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.89\n",
      "R2 score = -0.94\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.06443779 4.74066294 6.27507777 4.59812607 6.30931095 5.08473532\n",
      " 6.55677453 4.40877105 5.22347634 6.57505689 5.70957093 6.8326969\n",
      " 6.01693363 5.6816461  3.8164849  5.77438252 5.6586841  6.42686679\n",
      " 5.63792852 6.08591484 5.76765951 4.55133    7.20149938 4.10199207\n",
      " 6.28319878 4.78238251 5.10426017 5.22132155 5.31585806 7.20331633\n",
      " 7.54339244 5.36878435 5.96785105 5.44550651 6.64348135 4.67629881\n",
      " 6.7871859 ]\n",
      "\n",
      "What it should be:  [4.5        4.5        5.66666667 5.5        6.5        5.\n",
      " 6.16666667 6.         6.5        7.         6.33333333 5.66666667\n",
      " 6.5        6.         3.33333333 6.16666667 7.         6.16666667\n",
      " 6.83333333 5.33333333 5.33333333 6.16666667 6.33333333 4.83333333\n",
      " 6.5        6.66666667 6.         6.16666667 6.         6.\n",
      " 5.83333333 6.33333333 5.33333333 3.83333333 6.83333333 6.66666667\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.33519913]\n",
      " [0.33519913 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.43\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.21780958 4.76276076 5.59602979 6.79420341 4.59531029 7.10927752\n",
      " 5.82910505 6.03665206 6.14801586 7.10277506 6.09717952 6.73878948\n",
      " 6.01159892 5.51527279 5.04419069 5.81159679 6.53121647 5.23397288\n",
      " 2.85546832 5.10028802 6.03054058 4.94725377 4.97332764 6.2631162\n",
      " 4.53426357 5.12280876 5.68238301 3.83264311 4.16294226 6.21621317\n",
      " 5.40801387 5.43443557 4.93775872 5.20408734 5.71151273 5.85130305\n",
      " 5.8834772 ]\n",
      "\n",
      "What it should be:  [5.         5.5        6.5        5.16666667 6.16666667 7.\n",
      " 6.         5.         6.66666667 5.66666667 7.         4.66666667\n",
      " 5.33333333 4.66666667 4.66666667 6.16666667 6.33333333 5.66666667\n",
      " 5.5        4.         5.83333333 5.33333333 6.66666667 5.66666667\n",
      " 4.33333333 6.83333333 4.33333333 4.         4.66666667 3.\n",
      " 7.         6.5        5.5        5.16666667 5.83333333 6.16666667\n",
      " 6.66666667]\n",
      "Correlation:  [[1.         0.22302975]\n",
      " [0.22302975 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.31\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.42\n",
      "R2 score = -0.43\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.02219145 6.18937424 4.58611372 4.196198   5.34142598 4.23167047\n",
      " 6.20390824 6.48769284 7.09318355 5.28792887 4.0268572  5.70116187\n",
      " 6.64650089 5.75983418 6.1877666  5.98281919 5.48022383 5.45152337\n",
      " 7.57941278 6.82213362 8.1563805  6.3927239  5.68625042 5.67505599\n",
      " 5.76339674 5.38970817 5.22890565 4.57277378 5.8677592  5.87689018\n",
      " 5.86352841 5.07845948 4.90790134 6.35570001 5.07739193 6.23766737\n",
      " 4.97055251]\n",
      "\n",
      "What it should be:  [6.33333333 6.         6.66666667 7.         5.66666667 4.83333333\n",
      " 6.         5.33333333 5.66666667 5.66666667 4.83333333 4.\n",
      " 6.16666667 7.         5.66666667 5.16666667 5.33333333 4.66666667\n",
      " 6.33333333 6.66666667 6.66666667 5.16666667 6.5        6.\n",
      " 6.16666667 5.5        6.66666667 4.         4.66666667 5.83333333\n",
      " 4.5        6.16666667 6.         6.16666667 6.33333333 5.\n",
      " 4.33333333]\n",
      "Correlation:  [[1.         0.22870272]\n",
      " [0.22870272 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.69\n",
      "R2 score = -0.69\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.98083073 6.32581008 5.17917875 6.40987757 5.98327708 5.09978159\n",
      " 5.62454201 5.99606299 4.62842542 5.76273853 5.40710196 6.19784201\n",
      " 4.23834116 6.25232027 4.80546061 5.49273727 5.78228769 6.31907394\n",
      " 6.37364736 4.99901505 5.00697336 7.07495958 7.30962593 6.33548054\n",
      " 6.31563707 5.00726263 5.45990526 6.52016136 4.69067149 6.18569145\n",
      " 5.83183649 4.920253   5.22177172 6.06905388 6.03004616 5.72793195\n",
      " 6.54876258]\n",
      "\n",
      "What it should be:  [6.5        6.16666667 5.         6.83333333 6.16666667 5.5\n",
      " 5.33333333 6.         6.         7.         6.5        5.33333333\n",
      " 6.83333333 6.5        4.83333333 5.         5.5        6.83333333\n",
      " 6.66666667 6.16666667 5.33333333 6.33333333 5.16666667 5.33333333\n",
      " 4.66666667 5.5        4.5        4.83333333 5.5        6.5\n",
      " 6.33333333 6.         3.66666667 5.83333333 6.         6.16666667\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.16469349]\n",
      " [0.16469349 1.        ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.91\n",
      "Median absolute error = 0.49\n",
      "Explain variance score = -0.6\n",
      "R2 score = -0.6\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.01648071 6.20909979 6.07100682 5.19396983 5.98481835 4.97648007\n",
      " 6.75785719 5.12128436 5.19494208 6.46999123 4.87947656 5.30663494\n",
      " 5.42590049 5.83754236 5.6533156  5.44866867 7.00493425 5.79625538\n",
      " 5.60741903 7.09539598 5.2614916  6.33667769 5.03861011 5.27123086\n",
      " 5.80321922 4.30547261 5.59061109 4.75682528 5.66736778 6.971654\n",
      " 5.26598948 5.24456473 6.79771859 6.3089528  6.15180797 5.02366361\n",
      " 5.07526269]\n",
      "\n",
      "What it should be:  [5.         5.5        5.33333333 4.         6.16666667 4.\n",
      " 7.         6.33333333 4.5        6.66666667 5.16666667 4.5\n",
      " 6.5        6.5        5.         6.         6.16666667 5.5\n",
      " 5.83333333 4.33333333 5.33333333 4.16666667 6.         5.5\n",
      " 5.66666667 4.83333333 6.66666667 6.83333333 5.83333333 6.83333333\n",
      " 3.66666667 6.16666667 4.66666667 6.         5.16666667 6.83333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.13423013]\n",
      " [0.13423013 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.8359167  5.35722977 4.0582679  7.31329847 5.44795056 6.36217304\n",
      " 4.90605462 5.58714322 5.77584753 5.11011427 5.88379611 5.52366892\n",
      " 5.97279922 5.29967998 7.41661769 4.89629937 4.98891566 6.01855317\n",
      " 5.72036253 4.87680117 5.07854689 4.32862496 4.75781353 7.25068566\n",
      " 6.15391842 6.00016281 6.87070536 6.20585406 4.58239251 4.51561283\n",
      " 5.09523578 5.19370872 4.36311305 4.97737045 4.78401212 5.28543831\n",
      " 8.41148708]\n",
      "\n",
      "What it should be:  [4.5        6.33333333 5.         5.83333333 3.         5.83333333\n",
      " 6.16666667 6.5        4.         4.33333333 7.         6.\n",
      " 5.83333333 5.16666667 5.16666667 7.         5.83333333 6.\n",
      " 5.16666667 6.16666667 5.33333333 5.83333333 4.83333333 5.83333333\n",
      " 4.5        4.83333333 7.         6.5        5.33333333 4.83333333\n",
      " 3.66666667 5.66666667 5.83333333 5.66666667 3.66666667 5.\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.23883165]\n",
      " [0.23883165 1.        ]]\n",
      "Mean absolute error = 0.98\n",
      "Mean squared error = 1.38\n",
      "Median absolute error = 0.94\n",
      "Explain variance score = -0.51\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.78344745 5.10944824 5.07790234 6.0396255  5.41581366 7.1764726\n",
      " 5.71643009 7.54089659 5.6171606  5.29567825 5.53200981 6.11065404\n",
      " 5.09728017 6.80707493 6.18418953 4.34904949 6.4739062  5.52747541\n",
      " 4.41407187 5.82033752 5.6178434  5.81170257 4.89813437 5.26939907\n",
      " 4.93870857 5.46453672 5.75210672 3.56276756 6.17890304 5.43268865\n",
      " 5.23318837 5.37920612 6.37762768 6.0766219  5.54613491 6.26593288\n",
      " 4.85870239]\n",
      "\n",
      "What it should be:  [5.83333333 3.         5.33333333 5.66666667 6.5        5.16666667\n",
      " 1.83333333 6.5        3.66666667 3.66666667 6.16666667 4.66666667\n",
      " 5.33333333 5.33333333 7.         4.5        6.5        6.\n",
      " 5.         6.5        6.16666667 6.5        5.33333333 6.16666667\n",
      " 6.66666667 4.83333333 6.66666667 5.5        6.16666667 6.5\n",
      " 6.         6.33333333 6.16666667 6.83333333 4.5        6.16666667\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.21436541]\n",
      " [0.21436541 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.47\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.17\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.16609947 5.92607787 5.71575666 7.55277517 7.48746214 4.6616687\n",
      " 7.07679189 4.46451478 4.98313554 5.62857541 5.95620244 5.92131057\n",
      " 4.74320852 6.4342993  6.1104333  5.17708125 5.95005132 5.63521374\n",
      " 6.58107396 6.57892547 5.67988626 5.38934531 4.39046329 4.50583949\n",
      " 6.08567115 5.76804201 4.92666614 5.20971655 5.75959058 5.45482219\n",
      " 6.04134953 6.27563847 5.10298396 5.17475796 5.41420298 5.8078762\n",
      " 3.18426749]\n",
      "\n",
      "What it should be:  [5.66666667 6.16666667 5.83333333 5.16666667 5.83333333 3.33333333\n",
      " 5.83333333 5.5        5.16666667 6.5        5.33333333 6.\n",
      " 3.66666667 5.83333333 5.33333333 1.83333333 6.83333333 4.66666667\n",
      " 6.16666667 6.33333333 5.33333333 5.5        6.5        4.\n",
      " 6.16666667 5.16666667 4.5        6.16666667 6.16666667 7.\n",
      " 6.         5.33333333 5.         5.83333333 6.16666667 6.16666667\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.29822114]\n",
      " [0.29822114 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.24\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.13437505 4.22754824 4.5282116  5.77913819 5.50438101 5.89247467\n",
      " 5.01918699 4.82837205 6.43891872 7.46049422 5.28177913 5.35344411\n",
      " 6.30396816 5.85860711 5.51813177 6.9568247  5.78720787 5.51100843\n",
      " 5.52839763 4.3562209  7.02019495 3.93791268 5.41276422 5.6017978\n",
      " 4.1078222  5.90994833 6.22759828 6.68298193 5.91892131 6.83681086\n",
      " 6.02203298 6.08856029 5.41021736 6.67581129 5.72447731 6.31184957\n",
      " 4.40587048]\n",
      "\n",
      "What it should be:  [6.66666667 4.83333333 4.66666667 5.33333333 3.         6.83333333\n",
      " 5.5        6.66666667 5.33333333 5.66666667 6.33333333 4.83333333\n",
      " 5.66666667 6.16666667 4.5        6.66666667 6.         4.66666667\n",
      " 6.66666667 6.33333333 6.16666667 5.5        4.66666667 5.33333333\n",
      " 4.         6.33333333 6.5        6.         5.83333333 5.66666667\n",
      " 5.33333333 6.16666667 6.33333333 6.66666667 5.         6.83333333\n",
      " 4.33333333]\n",
      "Correlation:  [[1.         0.37240296]\n",
      " [0.37240296 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.75817018 6.16838549 5.57751925 5.56946584 3.55820307 5.70752568\n",
      " 6.1000338  6.04236618 5.31378071 5.88949241 7.47210129 6.28031863\n",
      " 5.01393564 5.50616603 5.01360971 5.21040889 4.95560745 6.83852686\n",
      " 7.16747899 5.21483834 4.96405471 6.15748446 5.43776527 5.28125617\n",
      " 5.54818774 6.84125817 5.67468751 6.34837034 6.03861347 5.28859232\n",
      " 7.28680307 5.73556326 6.80402297 4.56790249 6.39416018 5.01360284\n",
      " 3.49942975]\n",
      "\n",
      "What it should be:  [4.83333333 6.66666667 5.16666667 5.83333333 4.5        5.5\n",
      " 5.33333333 6.83333333 5.16666667 5.66666667 7.         6.66666667\n",
      " 3.66666667 5.33333333 6.5        5.83333333 6.83333333 5.83333333\n",
      " 5.66666667 4.66666667 5.33333333 6.16666667 4.         4.5\n",
      " 5.33333333 6.5        6.83333333 6.5        5.83333333 6.66666667\n",
      " 6.16666667 6.33333333 5.66666667 4.5        6.16666667 3.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.51266322]\n",
      " [0.51266322 1.        ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.8\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.02\n",
      "R2 score = -0.02\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.46257047 4.89755213 4.40419956 7.42405191 5.20987468 5.96978821\n",
      " 4.38646757 4.87887194 5.24028214 6.36717843 6.56003463 6.1044633\n",
      " 5.6096921  4.38699135 6.90485409 5.07276096 5.44709452 5.05346695\n",
      " 5.06849595 4.47811563 5.7341277  3.5604197  6.04800772 5.44849121\n",
      " 4.90679424 5.08695377 5.89014756 5.47369113 5.65315171 5.57823185\n",
      " 4.72653533 4.96837168 5.57013784 4.04522822 5.85442512 6.05962311\n",
      " 5.64687698]\n",
      "\n",
      "What it should be:  [6.5        5.33333333 4.83333333 6.5        6.16666667 5.66666667\n",
      " 6.5        4.83333333 6.66666667 6.83333333 6.5        5.66666667\n",
      " 6.83333333 5.5        7.         5.5        6.5        6.\n",
      " 6.16666667 5.83333333 4.5        5.16666667 5.66666667 5.66666667\n",
      " 5.5        6.16666667 5.83333333 3.83333333 6.33333333 4.66666667\n",
      " 4.33333333 4.66666667 5.         6.33333333 5.83333333 6.33333333\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.37180136]\n",
      " [0.37180136 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.9\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.29\n",
      "R2 score = -0.51\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.72454003 6.8673434  5.37442309 7.08973139 4.7843912  4.62278147\n",
      " 5.70111879 4.69095189 4.80411995 4.92378732 7.06726795 6.18914617\n",
      " 5.16066294 5.66180683 4.88072735 6.86312402 7.39633652 6.66423388\n",
      " 6.02560414 5.43267214 6.23849627 5.2784139  6.98783053 6.04859517\n",
      " 7.01975439 5.2101227  3.72924671 4.42166604 6.41739752 4.77225213\n",
      " 5.91826745 4.87211109 5.67596891 5.07709678 5.61891317 6.75474086\n",
      " 5.03759407]\n",
      "\n",
      "What it should be:  [5.33333333 6.16666667 6.5        7.         4.         5.83333333\n",
      " 6.5        6.16666667 6.         6.83333333 5.83333333 6.\n",
      " 5.16666667 5.66666667 6.66666667 5.16666667 6.33333333 6.33333333\n",
      " 6.         3.         6.33333333 6.66666667 6.         4.33333333\n",
      " 6.16666667 4.66666667 4.83333333 5.83333333 6.33333333 4.83333333\n",
      " 5.66666667 5.33333333 5.16666667 6.         3.5        5.33333333\n",
      " 3.33333333]\n",
      "Correlation:  [[1.         0.26130739]\n",
      " [0.26130739 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.33\n",
      "Median absolute error = 0.99\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.42\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.94379328 6.60568396 6.44751436 5.43326024 4.44130071 5.634689\n",
      " 5.41966554 5.64119075 4.57242343 5.17548848 4.86554598 7.14563302\n",
      " 5.61031095 5.79701455 6.48020388 4.79902842 5.12699876 5.02045694\n",
      " 5.66790348 6.34485722 4.24622253 4.95391194 5.24239015 6.74325411\n",
      " 5.50700162 4.52605526 5.14268377 5.23418821 5.23321551 5.83693962\n",
      " 6.69493787 6.28775604 5.1791549  5.26993277 5.6386696  6.33983095\n",
      " 5.99556744]\n",
      "\n",
      "What it should be:  [6.83333333 6.         6.5        5.5        4.83333333 1.83333333\n",
      " 4.83333333 7.         6.66666667 4.66666667 6.66666667 6.33333333\n",
      " 4.         4.83333333 6.         5.5        4.83333333 5.33333333\n",
      " 6.16666667 5.83333333 5.5        6.33333333 5.16666667 6.16666667\n",
      " 4.83333333 5.83333333 6.         6.5        6.         6.16666667\n",
      " 6.33333333 4.33333333 5.5        4.83333333 3.66666667 6.33333333\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.17988864]\n",
      " [0.17988864 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.26\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.3\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.43199937 5.19373376 6.72467695 4.23638358 6.53901818 5.91424643\n",
      " 5.83764703 5.3975904  4.48572088 4.91988631 5.26919221 4.24865604\n",
      " 5.48060495 5.05239515 4.95255728 4.74701755 5.33730717 5.55343305\n",
      " 4.2192596  5.38924967 5.81914795 5.46022554 4.2850703  5.71532953\n",
      " 6.01817937 5.72022146 4.59560608 6.05552821 6.25477667 5.63557122\n",
      " 5.71025886 6.05783058 6.28234221 5.31815224 4.2892104  5.89889825\n",
      " 5.55682087 6.39756323 6.35369469 5.69369525 5.50445432 5.83158762\n",
      " 5.62087257 4.80172106 5.9362526  5.00858972 6.14503917 5.99486126\n",
      " 5.97971155 5.70646814 5.54539595 4.95527247 4.41211027 5.12621509\n",
      " 5.99901673]\n",
      "\n",
      "What it should be:  [5.16666667 4.         7.         4.33333333 6.83333333 1.83333333\n",
      " 4.83333333 5.83333333 4.83333333 5.16666667 5.83333333 6.\n",
      " 4.5        4.5        4.83333333 3.66666667 5.83333333 5.5\n",
      " 6.33333333 5.5        5.66666667 6.         6.83333333 5.33333333\n",
      " 4.         6.16666667 6.         6.83333333 6.         6.16666667\n",
      " 6.5        5.83333333 4.66666667 5.33333333 5.16666667 6.66666667\n",
      " 4.66666667 5.33333333 5.33333333 6.16666667 6.33333333 7.\n",
      " 3.83333333 7.         5.83333333 5.         6.83333333 6.5\n",
      " 6.33333333 6.16666667 6.66666667 6.5        5.83333333 6.5\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.13573464]\n",
      " [0.13573464 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.21\n",
      "R2 score = -0.24\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.96546008 5.37812671 5.67441812 4.86978801 4.98856834 5.28242338\n",
      " 5.17493472 3.05119718 6.18449258 4.40888252 4.7593252  5.90021297\n",
      " 5.43013277 5.36570369 5.48635363 6.13974389 5.9061964  5.58153462\n",
      " 5.25282288 5.29450727 6.87938586 5.23338578 5.39670287 7.54227209\n",
      " 6.43340526 5.97302452 5.09597421 5.69232082 5.20012485 6.65565068\n",
      " 5.53252953 5.31187077 6.66930461 6.19425461 5.78867248 4.77061148\n",
      " 6.93479698 5.64975373 4.49621797 5.68736941 6.45121791 4.86981811\n",
      " 6.22098729 6.14955179 6.28502788 2.32912864 5.36664719 6.96167115\n",
      " 5.71209065 5.91301819 4.73991472 6.97419292 5.36288634 7.27633545\n",
      " 6.88539734]\n",
      "\n",
      "What it should be:  [6.83333333 4.5        6.16666667 6.5        4.83333333 6.83333333\n",
      " 4.66666667 4.83333333 6.33333333 5.16666667 6.16666667 6.\n",
      " 5.5        6.16666667 5.         6.         6.         4.5\n",
      " 5.66666667 6.33333333 5.66666667 3.33333333 6.5        6.5\n",
      " 6.33333333 5.16666667 6.         4.         6.66666667 5.16666667\n",
      " 6.5        5.5        6.66666667 6.83333333 7.         6.33333333\n",
      " 5.66666667 4.         4.83333333 7.         5.5        3.\n",
      " 6.16666667 6.5        5.33333333 5.5        6.5        6.\n",
      " 5.66666667 4.83333333 6.         6.5        5.33333333 7.\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.30837703]\n",
      " [0.30837703 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.9\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.16123485 6.00550646 6.20582215 5.63608672 6.24074589 5.55923989\n",
      " 5.3298754  6.5963331  6.04073552 5.9657591  4.70407891 7.92706537\n",
      " 5.46403999 5.57664264 6.08392572 5.30453978 5.79880384 6.52104849\n",
      " 6.07189099 4.86171038 6.37429559 6.54223662 6.07998837 4.47111851\n",
      " 5.68203893 5.90925456 4.96050798 4.57898095 5.32615184 5.92777489\n",
      " 6.52446695 5.5923818  5.23765752 4.46258134 5.36795187 6.44078768\n",
      " 5.54181198 6.37956121 5.33998493 5.46570453 5.99193993 5.65723931\n",
      " 6.01092767 5.18861211 5.10517951 5.78127847 6.83381735 6.15485559\n",
      " 6.32503373 3.83630262 6.13774596 6.35844604 5.81402401 6.40144906\n",
      " 5.80259881]\n",
      "\n",
      "What it should be:  [4.66666667 5.5        4.66666667 6.         6.66666667 5.83333333\n",
      " 7.         6.66666667 6.83333333 5.16666667 5.83333333 6.16666667\n",
      " 6.33333333 6.66666667 6.83333333 4.83333333 1.83333333 5.83333333\n",
      " 4.83333333 6.66666667 4.         5.66666667 6.16666667 4.83333333\n",
      " 6.5        5.66666667 6.83333333 6.5        5.66666667 4.5\n",
      " 6.16666667 5.83333333 5.33333333 3.5        3.66666667 4.16666667\n",
      " 5.33333333 5.16666667 5.66666667 5.66666667 6.83333333 6.\n",
      " 6.16666667 5.5        7.         3.         6.33333333 5.16666667\n",
      " 6.5        5.         5.5        4.33333333 4.5        5.5\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.06869906]\n",
      " [0.06869906 1.        ]]\n",
      "Mean absolute error = 0.97\n",
      "Mean squared error = 1.55\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.35318155 6.13767989 5.26191658 6.5716523  5.29047292 5.68302015\n",
      " 5.14872314 5.74906501 5.27047023 6.23192413 6.54259065 6.65079984\n",
      " 6.12812433 4.87249264 6.63252451 5.47195269 6.81218821 5.61158505\n",
      " 6.24027815 5.18129243 6.53318711 5.27185972 6.4232928  5.10984138\n",
      " 7.39650727 5.77700163 7.63528149 5.62626267 5.27216053 4.58147883\n",
      " 6.01833313 5.50762534 6.81470798 6.90102745 5.3311103  6.00895652\n",
      " 6.95550681 6.22954798 6.63525733 6.15232779 5.9354919  4.06639503\n",
      " 4.94727258 5.45822713 5.04060159 6.29779409 5.10092587 5.82214237\n",
      " 5.42623758 5.91080132 3.24385302 5.64650526 6.08757758 5.84911587\n",
      " 5.67136947]\n",
      "\n",
      "What it should be:  [3.83333333 6.66666667 6.16666667 3.66666667 5.33333333 5.33333333\n",
      " 6.5        6.83333333 6.16666667 6.16666667 6.16666667 4.66666667\n",
      " 5.33333333 5.83333333 4.66666667 6.33333333 6.16666667 6.\n",
      " 5.83333333 4.83333333 6.         7.         4.83333333 6.33333333\n",
      " 5.66666667 5.83333333 3.         6.66666667 5.5        6.66666667\n",
      " 5.33333333 6.16666667 7.         5.66666667 5.33333333 5.16666667\n",
      " 5.83333333 6.33333333 4.5        6.83333333 4.5        5.33333333\n",
      " 5.83333333 6.33333333 3.33333333 5.33333333 5.83333333 4.66666667\n",
      " 5.66666667 3.66666667 5.5        4.         6.         6.66666667\n",
      " 6.16666667]\n",
      "Correlation:  [[ 1.        -0.1548729]\n",
      " [-0.1548729  1.       ]]\n",
      "Mean absolute error = 1.05\n",
      "Mean squared error = 1.79\n",
      "Median absolute error = 0.89\n",
      "Explain variance score = -0.93\n",
      "R2 score = -0.99\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.44521789 4.77791501 5.1642356  6.94584088 5.17790404 5.80692684\n",
      " 5.43198206 5.6418758  6.09394243 4.09141954 6.16565637 4.09463453\n",
      " 5.86430218 5.58923831 2.82296549 6.23045286 5.57618177 6.3530995\n",
      " 6.44770007 5.40908612 5.40552284 6.01761214 6.33912647 5.948478\n",
      " 6.32757973 4.45868239 5.14973694 6.72510462 5.88481626 6.41119294\n",
      " 6.16293166 5.58167257 4.52528512 6.20454942 5.60070395 5.44548846\n",
      " 5.49491638 6.7877139  6.46405893 7.32165248 5.60331748 6.84781109\n",
      " 5.12422568 6.41688561 5.49521652 5.37982832 5.5978847  5.4285295\n",
      " 5.26009678 6.83552947 4.43595905 6.41906125 3.77893505 5.52773283\n",
      " 5.31313067]\n",
      "\n",
      "What it should be:  [5.16666667 3.66666667 5.83333333 5.83333333 4.83333333 6.16666667\n",
      " 6.         4.33333333 6.5        4.         6.83333333 4.83333333\n",
      " 5.         5.         5.5        5.33333333 6.5        7.\n",
      " 5.33333333 5.83333333 4.66666667 5.16666667 4.83333333 5.33333333\n",
      " 6.16666667 5.5        6.16666667 6.16666667 6.33333333 6.5\n",
      " 6.16666667 4.5        6.5        6.66666667 3.         6.83333333\n",
      " 7.         6.83333333 6.5        5.83333333 6.66666667 5.16666667\n",
      " 3.66666667 6.         5.16666667 3.83333333 3.5        5.33333333\n",
      " 5.66666667 5.83333333 7.         5.33333333 5.33333333 6.33333333\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.25570007]\n",
      " [0.25570007 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.25\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.47889591 6.81794432 6.16719149 5.59165829 6.39671116 5.09372563\n",
      " 5.80187888 6.10196117 4.80848537 5.78381673 7.22382969 5.60873931\n",
      " 5.17972531 6.96387193 6.04437563 5.57434144 7.84746376 5.87574072\n",
      " 5.69520776 7.09039314 5.27838094 5.70561078 6.20138291 5.2893677\n",
      " 5.95147727 5.73133248 4.8054965  4.98815849 6.99667474 6.75750288\n",
      " 6.35940696 5.17677091 4.46834033 6.28343031 5.40455948 5.69926237\n",
      " 4.45342116 5.22187886 4.98665772 6.16630576 5.10568447 5.46363307\n",
      " 6.76237948 5.25745751 6.33677985 5.67261744 4.99153997 5.40984586\n",
      " 3.4521909  6.38795957 6.1883499  6.57634229 5.97729814 5.97159872\n",
      " 5.74977358]\n",
      "\n",
      "What it should be:  [5.66666667 5.33333333 4.         6.83333333 5.83333333 4.33333333\n",
      " 6.66666667 4.         4.83333333 6.16666667 7.         5.66666667\n",
      " 5.         6.         5.66666667 4.5        6.5        3.33333333\n",
      " 5.5        6.         4.66666667 5.83333333 6.16666667 6.16666667\n",
      " 6.83333333 5.16666667 5.5        6.16666667 5.16666667 4.66666667\n",
      " 6.83333333 6.         4.5        6.33333333 4.33333333 5.33333333\n",
      " 3.66666667 6.33333333 3.66666667 4.66666667 6.16666667 6.\n",
      " 5.16666667 6.83333333 4.5        4.83333333 6.33333333 6.5\n",
      " 5.33333333 6.66666667 7.         5.83333333 5.33333333 6.16666667\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.23632794]\n",
      " [0.23632794 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.4715138  5.11151528 5.25380493 5.59436034 6.52801318 5.34839197\n",
      " 6.59315834 5.9210246  6.83012056 5.44988735 6.05661604 5.18552444\n",
      " 5.34609431 6.74969463 5.62104665 5.2512171  6.28901697 6.34453194\n",
      " 7.01747796 5.68645996 5.02795714 5.07039596 6.16679011 5.72662997\n",
      " 5.46025948 6.55905816 4.75157034 5.75969899 5.49622344 5.76474571\n",
      " 5.75366477 5.86986495 5.50804769 4.87132634 6.38028673 4.54668158\n",
      " 7.19896836 7.23610546 5.97808643 5.18757377 5.78613165 6.29372137\n",
      " 4.98272328 6.02287007 5.21826961 5.37691176 5.48727161 5.89403942\n",
      " 6.09796757 5.12434048 5.47481341 7.5002355  5.74507887 5.6263174\n",
      " 6.79155691]\n",
      "\n",
      "What it should be:  [4.         6.66666667 5.33333333 7.         6.83333333 6.33333333\n",
      " 4.         4.66666667 6.16666667 1.83333333 7.         6.16666667\n",
      " 7.         4.66666667 5.16666667 6.33333333 4.         4.33333333\n",
      " 5.33333333 5.5        4.66666667 6.16666667 6.16666667 5.83333333\n",
      " 6.16666667 5.33333333 6.5        5.         5.         5.33333333\n",
      " 5.         6.83333333 5.66666667 5.33333333 5.66666667 4.\n",
      " 6.16666667 5.33333333 5.66666667 6.5        3.33333333 6.33333333\n",
      " 6.16666667 3.66666667 4.33333333 6.         4.83333333 5.83333333\n",
      " 6.66666667 5.16666667 6.         4.83333333 5.5        6.5\n",
      " 5.33333333]\n",
      "Correlation:  [[ 1.         -0.01637934]\n",
      " [-0.01637934  1.        ]]\n",
      "Mean absolute error = 1.02\n",
      "Mean squared error = 1.67\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -0.45\n",
      "R2 score = -0.54\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.56051662 4.17218057 6.25249966 5.12377349 6.94597544 6.48395519\n",
      " 4.02962849 5.39041526 6.3843607  5.92248342 5.20493935 6.37275931\n",
      " 5.30200663 5.1496225  5.3393848  5.92798287 5.89011002 4.86306683\n",
      " 5.84682332 5.63770689 6.25113507 5.1174469  6.78099997 5.48678226\n",
      " 3.80262295 6.46237935 6.20989419 6.19037822 6.661722   5.56134148\n",
      " 6.3455589  5.98978383 5.42339393 5.7168725  5.84010204 5.49342817\n",
      " 5.73136866 6.44306274 6.07254214 5.45194549 5.69754757 5.62482475\n",
      " 6.43882508 5.24213156 5.82150698 4.88365801 6.70544498 6.18181011\n",
      " 5.46031811 5.59752721 5.64481463 4.37605694 5.99224111 5.22888649\n",
      " 4.91236832]\n",
      "\n",
      "What it should be:  [6.5        4.         5.16666667 6.33333333 6.         6.83333333\n",
      " 5.         6.16666667 5.66666667 6.33333333 4.         4.66666667\n",
      " 5.         4.66666667 6.         6.33333333 6.83333333 4.5\n",
      " 5.66666667 6.66666667 5.83333333 6.66666667 7.         6.33333333\n",
      " 5.33333333 5.33333333 5.83333333 4.83333333 6.66666667 1.83333333\n",
      " 4.66666667 5.5        6.         6.16666667 6.16666667 5.16666667\n",
      " 3.         6.66666667 6.16666667 6.66666667 4.5        3.66666667\n",
      " 7.         3.33333333 6.83333333 5.83333333 6.16666667 5.16666667\n",
      " 6.16666667 4.83333333 6.5        6.5        6.66666667 5.66666667\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.26003387]\n",
      " [0.26003387 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.26\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.06\n",
      "R2 score = -0.07\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.88271364 6.32363757 6.13770997 5.35123799 6.4298367  6.17352579\n",
      " 7.59919468 5.54982104 5.71208605 5.90038314 6.81695407 5.79167081\n",
      " 5.11446546 6.57846651 6.56885244 6.28737738 5.77012683 5.76672806\n",
      " 4.81955018 4.97925771 4.81117039 4.5698263  5.26916412 6.32531039\n",
      " 6.42787076 4.61831924 5.96719795 5.82940507 7.8846784  5.52763635\n",
      " 4.62788943 6.01512987 6.72029811 3.49274141 5.88704661 6.71806822\n",
      " 4.92413394 5.67390117 5.68057043 5.43311916 5.37895512 6.21637822\n",
      " 5.28823122 4.69251593 4.53581254 4.90735113 5.36071565 7.67343575\n",
      " 7.17271073 3.81956151 5.52439691 6.50926471 5.0551453  6.67350746\n",
      " 5.18403364]\n",
      "\n",
      "What it should be:  [3.66666667 5.66666667 6.         5.66666667 5.         5.66666667\n",
      " 6.33333333 6.16666667 6.33333333 4.33333333 5.83333333 6.5\n",
      " 6.66666667 4.66666667 6.5        6.33333333 6.5        6.83333333\n",
      " 5.16666667 6.66666667 5.33333333 5.         6.16666667 5.66666667\n",
      " 6.16666667 6.33333333 4.83333333 6.16666667 5.83333333 4.66666667\n",
      " 6.         5.16666667 6.83333333 4.66666667 5.66666667 6.\n",
      " 5.83333333 5.83333333 5.83333333 5.33333333 5.5        6.16666667\n",
      " 6.5        3.83333333 4.66666667 4.33333333 5.5        7.\n",
      " 5.83333333 5.33333333 5.16666667 5.         5.33333333 6.83333333\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.36760596]\n",
      " [0.36760596 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.89\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.49\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.18418619 5.01409508 4.31022356 5.45015918 4.97361415 5.41677985\n",
      " 6.35761742 7.06596654 1.99754026 6.21212091 5.73540438 6.1047972\n",
      " 5.13014332 4.32513158 5.86072957 5.89002813 6.50324173 4.9576842\n",
      " 6.38885784 5.03275156 5.95476462 5.31779374 3.95516958 4.81835815\n",
      " 4.82925732 5.29901182 6.19165453 5.04494818 5.34732272 5.38846903\n",
      " 4.3829349  4.99485174 6.18674781 4.98540233 5.10400475 6.09189557\n",
      " 6.39528472 5.61208623 5.37431963 5.460704   5.24353439 5.62156175\n",
      " 6.67470042 4.67829423 4.98102835 3.88989833 5.55579408 5.32637385\n",
      " 6.07904682 4.79471579 5.67042839 5.20539248 6.51721503 5.83055577\n",
      " 5.96303943]\n",
      "\n",
      "What it should be:  [6.33333333 7.         4.83333333 6.33333333 4.83333333 5.33333333\n",
      " 4.33333333 6.83333333 5.5        5.16666667 6.16666667 7.\n",
      " 5.         6.16666667 5.33333333 4.5        6.83333333 6.\n",
      " 5.66666667 5.33333333 4.66666667 4.66666667 5.83333333 5.5\n",
      " 6.5        4.33333333 5.33333333 6.5        4.5        5.16666667\n",
      " 4.         6.5        6.33333333 5.66666667 6.83333333 5.83333333\n",
      " 5.83333333 5.5        6.         4.66666667 6.16666667 5.66666667\n",
      " 4.66666667 6.16666667 6.16666667 5.33333333 5.         3.33333333\n",
      " 5.33333333 4.5        5.66666667 5.83333333 6.5        6.16666667\n",
      " 4.83333333]\n",
      "Correlation:  [[1.         0.07411061]\n",
      " [0.07411061 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.28\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.85\n",
      "R2 score = -0.9\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.44105178 6.34351302 5.29356246 5.68227204 5.48242577 4.2026103\n",
      " 4.11738092 6.41881569 6.01332996 5.2816245  5.63847541 5.37777385\n",
      " 4.46408305 5.03663155 4.39832645 5.61149107 6.26253311 5.96838976\n",
      " 5.80335049 6.10788491 6.32572954 5.49195161 3.80876521 4.67998004\n",
      " 4.67043663 5.50384858 6.49367915 3.70807826 5.39473745 6.39804737\n",
      " 4.35854595 6.4591378  4.03778305 5.41300508 5.25929097 5.25518331\n",
      " 6.30293612 6.22508918 6.62763751 6.41836271 6.25308251 5.47433345\n",
      " 4.21575348 5.33578751 6.75874727 4.4811261  5.39681573 5.27616258\n",
      " 6.95101353 5.07160289 4.47717791 5.06883347 6.61174407 5.51152632\n",
      " 4.39712794]\n",
      "\n",
      "What it should be:  [4.83333333 5.66666667 6.16666667 7.         4.66666667 4.\n",
      " 4.83333333 7.         4.5        5.83333333 3.5        6.5\n",
      " 6.         4.83333333 6.         5.83333333 5.5        6.\n",
      " 6.33333333 6.83333333 6.33333333 6.66666667 4.83333333 4.5\n",
      " 6.16666667 4.33333333 4.66666667 5.16666667 6.66666667 6.16666667\n",
      " 6.5        5.83333333 6.         6.         5.33333333 5.33333333\n",
      " 6.16666667 6.83333333 5.66666667 6.33333333 6.5        6.\n",
      " 6.83333333 5.5        6.         4.5        5.66666667 6.83333333\n",
      " 6.5        6.5        4.33333333 4.33333333 5.16666667 5.5\n",
      " 5.66666667]\n",
      "Correlation:  [[1.         0.27283943]\n",
      " [0.27283943 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.41\n",
      "R2 score = -0.5\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.63652022 5.23905512 7.43138111 5.69552938 5.85680864 4.76899639\n",
      " 6.39712036 5.17906555 5.91386065 5.87793568 5.84729016 5.18749222\n",
      " 5.31273854 4.91123567 4.17322871 5.644319   5.49166061 4.65385556\n",
      " 5.95981869 4.74932263 4.76837423 6.79369792 4.51401367 5.65547302\n",
      " 5.49533321 4.9991825  5.9782864  4.52418462 4.60977365 5.54112138\n",
      " 5.84831641 5.77275818 5.92114973 5.50558975 3.76103921 5.3397052\n",
      " 4.96098163 5.87020152 6.34058971 5.15289454 5.06540465 5.85090631\n",
      " 6.24100963 6.55623717 5.59052278 5.07304717 4.45356557 4.73259328\n",
      " 5.08958323 4.18636013 4.94842933 5.22731821 5.40201854 6.1686976\n",
      " 6.88299176]\n",
      "\n",
      "What it should be:  [5.66666667 4.5        6.5        5.33333333 5.33333333 4.5\n",
      " 5.66666667 6.5        4.16666667 5.5        5.66666667 5.33333333\n",
      " 6.16666667 6.33333333 4.         5.33333333 6.33333333 5.83333333\n",
      " 5.5        6.5        4.83333333 7.         4.83333333 6.\n",
      " 5.         5.83333333 6.16666667 6.66666667 6.         5.16666667\n",
      " 4.33333333 6.83333333 7.         5.33333333 5.5        4.83333333\n",
      " 5.         6.         4.66666667 5.66666667 6.16666667 6.16666667\n",
      " 6.66666667 5.83333333 6.5        6.16666667 6.5        5.\n",
      " 1.83333333 5.83333333 4.         6.5        6.66666667 6.16666667\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.23471361]\n",
      " [0.23471361 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.60566238 6.29523249 5.72525722 6.46344898 5.9216848  4.66535562\n",
      " 4.89702256 5.64166942 7.03638269 5.2324038  4.22105131 4.94704796\n",
      " 5.30147848 6.39214351 6.07063653 6.41926923 4.9635135  5.09973383\n",
      " 5.38576703 5.91327625 6.679038   5.75887392 5.78910802 5.47851364\n",
      " 4.94206357 6.41242818 5.21936001 5.9749604  6.26188276 4.63527998\n",
      " 5.31673768 4.65889645 6.08294869 5.21894697 5.37360335 5.32029751\n",
      " 5.75472263 5.77277601 6.07741906 7.24025618 5.20128121 5.7949029\n",
      " 5.63914872 5.67726972 3.87553117 5.69279082 5.30569232 5.07249478\n",
      " 5.59984639 4.86281976 4.01956249 5.90715365 6.37705179 6.95226088\n",
      " 4.7736687 ]\n",
      "\n",
      "What it should be:  [6.         5.16666667 1.83333333 5.16666667 5.16666667 6.\n",
      " 6.16666667 5.16666667 6.66666667 6.66666667 5.         5.66666667\n",
      " 6.16666667 6.66666667 6.5        4.16666667 5.83333333 6.\n",
      " 4.33333333 6.33333333 6.33333333 5.33333333 6.         4.83333333\n",
      " 6.33333333 5.33333333 4.         6.5        4.83333333 5.5\n",
      " 6.66666667 5.83333333 5.66666667 5.33333333 6.16666667 5.33333333\n",
      " 6.5        6.16666667 7.         6.66666667 5.         5.66666667\n",
      " 5.83333333 6.16666667 4.         6.16666667 5.5        5.83333333\n",
      " 5.83333333 6.16666667 4.5        5.         6.5        6.33333333\n",
      " 3.        ]\n",
      "Correlation:  [[1.         0.27578029]\n",
      " [0.27578029 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [2.7037489  4.50039559 4.22662125 4.37052782 4.95758064 6.55440852\n",
      " 5.82420735 4.89813287 6.40599896 5.43079792 5.23320748 5.78687393\n",
      " 6.06435732 5.73512851 5.40812596 5.42415287 4.68110348 6.16163205\n",
      " 6.29285685 5.68603779 5.17350953 5.92759272 6.72336812 5.92244487\n",
      " 7.13986258 4.83141824 6.44068315 6.52592744 5.63286547 6.59645989\n",
      " 5.89360628 6.41851832 5.319665   6.18814594 5.19367938 4.83359047\n",
      " 6.31426556 5.24132059 5.17328035 6.37324832 6.27220336 5.54987384\n",
      " 5.60421598 5.75718334 4.20591418 4.95977448 5.57630235 6.7693824\n",
      " 6.05392409 6.57788118 6.80257099 6.76357538 5.17522406 5.42675329\n",
      " 5.63558844]\n",
      "\n",
      "What it should be:  [5.5        4.5        5.16666667 4.83333333 4.33333333 6.16666667\n",
      " 6.66666667 6.33333333 6.5        6.66666667 4.83333333 5.5\n",
      " 5.16666667 7.         5.         6.83333333 6.         6.5\n",
      " 5.33333333 6.83333333 6.5        5.33333333 4.         5.33333333\n",
      " 3.         5.33333333 5.         6.33333333 7.         6.\n",
      " 6.         6.66666667 5.83333333 6.         5.5        6.66666667\n",
      " 6.83333333 3.83333333 7.         5.66666667 6.16666667 6.\n",
      " 6.5        4.66666667 6.83333333 6.66666667 5.66666667 5.66666667\n",
      " 6.5        4.         6.16666667 7.         6.16666667 6.16666667\n",
      " 6.5       ]\n",
      "Correlation:  [[ 1.         -0.03187813]\n",
      " [-0.03187813  1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.58\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.84\n",
      "R2 score = -0.87\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.72662288 6.3703221  5.49359027 5.93774991 4.26667385 7.23174294\n",
      " 5.68010308 5.43883355 4.14113074 6.03027444 4.38776883 4.65691065\n",
      " 6.66259139 4.95064095 6.43435369 6.12889603 6.78616136 5.53846563\n",
      " 6.43067929 4.63476173 6.06621275 5.24685456 7.09543742 5.40857918\n",
      " 6.22855306 4.61779975 5.09421434 5.85190023 7.12251831 6.48972575\n",
      " 6.23487814 5.77846085 5.44912324 5.30074129 5.96990977 5.11599902\n",
      " 4.6907619  4.76970465 4.67087646 7.21820503 5.00034112 5.59103901\n",
      " 5.88381261 5.91511207 6.35783535 6.85466413 4.48950318 7.54024008\n",
      " 6.0435     4.84975986 4.88285038 7.34360451 6.86568845 4.83075499\n",
      " 5.90406507]\n",
      "\n",
      "What it should be:  [6.5        5.66666667 6.         6.83333333 4.83333333 6.5\n",
      " 6.33333333 5.83333333 4.         5.16666667 5.83333333 6.\n",
      " 6.16666667 6.5        5.33333333 5.66666667 6.83333333 5.5\n",
      " 6.83333333 5.16666667 5.5        6.33333333 5.33333333 4.\n",
      " 4.66666667 6.83333333 4.5        6.83333333 5.33333333 4.\n",
      " 5.33333333 6.16666667 6.66666667 4.66666667 5.83333333 3.33333333\n",
      " 6.         6.66666667 6.5        6.33333333 6.         6.33333333\n",
      " 5.5        4.83333333 4.66666667 4.5        4.         6.5\n",
      " 5.83333333 6.16666667 5.66666667 3.         5.33333333 5.33333333\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.02575832]\n",
      " [0.02575832 1.        ]]\n",
      "Mean absolute error = 1.04\n",
      "Mean squared error = 1.64\n",
      "Median absolute error = 0.9\n",
      "Explain variance score = -0.85\n",
      "R2 score = -0.88\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.93937985 5.68826443 5.8900861  5.39109151 4.68020362 5.20060728\n",
      " 5.77393268 5.91551701 5.85962265 6.47475807 4.91579658 5.4441323\n",
      " 6.05888718 4.17364426 5.59656797 4.39433615 6.57376415 6.05360944\n",
      " 6.44770893 5.75638277 6.17705541 5.02666197 5.58428467 6.23959357\n",
      " 3.99850981 6.51868433 6.26903497 6.60524235 5.73281312 3.92790848\n",
      " 5.77339875 4.77993205 5.97981825 4.90076406 5.35575338 5.5022298\n",
      " 4.8295804  4.54091897 4.95836335 5.48931174 5.09548446 4.80769619\n",
      " 5.02176222 5.26245672 5.36923735 5.2823289  5.52090209 5.31386751\n",
      " 5.52041028 6.76410795 4.11653067 6.13253685 4.6583609  5.6998623\n",
      " 6.34302061]\n",
      "\n",
      "What it should be:  [6.         5.83333333 6.16666667 5.83333333 6.16666667 6.16666667\n",
      " 4.66666667 5.66666667 5.5        5.33333333 4.83333333 5.\n",
      " 6.66666667 4.66666667 7.         4.33333333 4.         6.83333333\n",
      " 4.66666667 5.         5.66666667 6.83333333 4.16666667 6.\n",
      " 4.83333333 6.16666667 6.83333333 6.66666667 6.16666667 6.33333333\n",
      " 5.83333333 3.66666667 5.33333333 6.66666667 6.16666667 5.66666667\n",
      " 4.83333333 6.33333333 5.83333333 6.33333333 5.33333333 5.83333333\n",
      " 6.83333333 5.33333333 6.         5.5        4.5        6.\n",
      " 6.66666667 7.         6.16666667 5.33333333 6.33333333 4.66666667\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.10065051]\n",
      " [0.10065051 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.55\n",
      "R2 score = -0.63\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.68797293 7.20946303 4.88025393 4.68662355 6.66594865 6.16257253\n",
      " 7.02832623 5.13101371 5.80885929 4.98707409 5.85694648 5.62661215\n",
      " 5.42053101 7.08332215 5.35334776 6.41883832 5.6968753  5.74560538\n",
      " 6.26988216 4.72048605 5.44756646 6.00561065 6.57362309 4.2657376\n",
      " 5.41567234 5.3309576  5.68603004 5.8182095  5.57449199 5.5249854\n",
      " 3.82684058 6.19642148 6.40679437 6.13962621 5.56632846 5.89115501\n",
      " 6.24923966 7.25556677 6.6084903  5.10277911 4.52103878 6.27667616\n",
      " 5.62577485 4.79668575 4.79321812 3.49058697 5.31030675 4.12334923\n",
      " 5.67497956 4.48427506 4.67656862 4.84054142 6.17310338 6.76114107\n",
      " 6.19824681]\n",
      "\n",
      "What it should be:  [5.83333333 6.33333333 4.5        5.66666667 6.         6.\n",
      " 6.5        6.16666667 4.66666667 5.66666667 5.66666667 6.\n",
      " 6.16666667 7.         3.83333333 5.83333333 5.66666667 5.\n",
      " 4.66666667 7.         5.5        6.66666667 4.66666667 4.83333333\n",
      " 6.16666667 4.66666667 6.83333333 6.66666667 6.         6.83333333\n",
      " 4.         6.         5.         7.         6.33333333 5.16666667\n",
      " 4.83333333 5.83333333 6.83333333 4.83333333 6.83333333 5.33333333\n",
      " 5.         5.5        6.16666667 5.5        4.33333333 5.33333333\n",
      " 5.83333333 6.16666667 6.33333333 6.66666667 4.83333333 5.33333333\n",
      " 5.        ]\n",
      "Correlation:  [[1.         0.14790447]\n",
      " [0.14790447 1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.85\n",
      "Explain variance score = -0.79\n",
      "R2 score = -0.8\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.18650686 4.69531551 4.13148306 4.96076163 4.5194772  4.58485498\n",
      " 7.35557259 5.57548248 5.69085007 4.91489013 6.51106282 5.56596187\n",
      " 6.16630847 6.61747195 5.37333422 6.28136082 6.34799108 5.3087021\n",
      " 5.04146032 3.95349287 5.94563422 5.26253916 5.33768178 4.99079842\n",
      " 3.83481805 5.47952546 6.1020156  4.61431627 4.20623196 6.83307102\n",
      " 5.05099492 5.09266647 6.99491219 6.49148624 7.00343837 6.63093419\n",
      " 6.00212428 7.16638343 5.71628446 7.08290387 4.44543646 4.08639639\n",
      " 6.15600501 5.85519402 5.68976107 4.56627099 4.6596778  5.86291934\n",
      " 5.1201737  6.08465118 6.52979883 4.36229804 5.72164749 5.48710585\n",
      " 6.82957931]\n",
      "\n",
      "What it should be:  [6.33333333 6.66666667 5.16666667 4.83333333 5.5        4.66666667\n",
      " 5.83333333 7.         6.83333333 6.66666667 6.33333333 6.5\n",
      " 5.16666667 6.5        5.33333333 6.5        5.66666667 5.83333333\n",
      " 5.66666667 6.         6.16666667 4.66666667 6.83333333 4.\n",
      " 6.33333333 5.66666667 5.         5.66666667 5.5        5.83333333\n",
      " 5.33333333 3.66666667 5.83333333 6.66666667 6.5        6.5\n",
      " 6.66666667 5.16666667 7.         7.         3.66666667 5.83333333\n",
      " 6.         7.         6.66666667 6.83333333 5.33333333 4.5\n",
      " 5.66666667 5.83333333 5.33333333 6.16666667 3.66666667 3.5\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.22430678]\n",
      " [0.22430678 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.34\n",
      "Median absolute error = 0.98\n",
      "Explain variance score = -0.54\n",
      "R2 score = -0.58\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.80877722 6.20699633 4.84653114 5.90403991 6.76316508 5.86466652\n",
      " 6.85290316 5.54854833 6.27994812 5.39606209 6.01377467 6.95454479\n",
      " 6.52213774 5.52103399 6.3252461  5.15473126 6.44914883 5.89662731\n",
      " 6.0863031  4.77145219 5.35676521 5.46172928 7.13121022 6.03126828\n",
      " 5.53281917 5.947573   5.27294237 5.45329084 5.29599895 5.26335606\n",
      " 5.00064008 6.09767054 5.22687369 5.39063078 6.52918381 5.44390948\n",
      " 5.59998454 5.94600645 5.85463499 6.25725061 4.75240528 5.57168692\n",
      " 5.62357393 6.76764475 5.87672494 6.00289537 7.01463581 5.92144686\n",
      " 6.26411755 5.70043902 4.7640088  6.19226978 6.6666541  5.20299725\n",
      " 3.93059263]\n",
      "\n",
      "What it should be:  [7.         6.16666667 4.33333333 4.5        5.33333333 4.83333333\n",
      " 6.5        4.83333333 5.16666667 3.66666667 3.33333333 6.5\n",
      " 5.33333333 5.16666667 4.66666667 6.16666667 5.16666667 6.5\n",
      " 6.16666667 6.83333333 6.66666667 6.         6.66666667 5.5\n",
      " 5.83333333 6.33333333 5.33333333 5.83333333 4.33333333 6.16666667\n",
      " 5.66666667 6.16666667 5.5        4.         3.         6.83333333\n",
      " 5.16666667 6.83333333 6.33333333 6.16666667 4.         1.83333333\n",
      " 4.5        6.33333333 6.         5.33333333 6.33333333 4.66666667\n",
      " 5.16666667 5.66666667 4.66666667 6.         6.         3.66666667\n",
      " 5.33333333]\n",
      "Correlation:  [[1.        0.2243985]\n",
      " [0.2243985 1.       ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.41\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.09\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.9213327  4.82818729 5.34066558 5.70390862 5.44485203 4.63110583\n",
      " 3.50317821 6.32931639 6.88284651 6.93064493 4.35007189 4.04476038\n",
      " 5.10512508 5.00170179 4.45498832 5.23753135 5.4897455  6.18220021\n",
      " 5.86639715 5.12348507 4.92363958 4.45830956 5.11923181 4.38482082\n",
      " 5.59351943 6.66287149 7.33034122 6.62319132 4.10663843 5.46578917\n",
      " 4.45948505 5.37694669 5.56805124 6.05350311 2.93737528 7.08350782\n",
      " 5.37833815 4.5016493  6.00836925 7.22325382 6.36463307 4.46992316\n",
      " 5.56901156 4.84423273 5.75893821 6.10652454 6.90223675 5.61006443\n",
      " 5.76976724 7.91302561 6.22232031 6.12410919 5.75286076 5.0435606\n",
      " 4.86696077]\n",
      "\n",
      "What it should be:  [6.         3.83333333 5.5        5.33333333 4.66666667 6.16666667\n",
      " 4.83333333 5.66666667 6.83333333 5.33333333 6.16666667 3.33333333\n",
      " 5.16666667 5.33333333 5.33333333 6.         6.5        5.83333333\n",
      " 5.83333333 4.83333333 6.         4.83333333 5.         4.5\n",
      " 5.33333333 6.33333333 6.5        7.         6.33333333 5.16666667\n",
      " 5.83333333 5.83333333 6.33333333 6.16666667 4.5        7.\n",
      " 5.5        4.66666667 6.5        6.5        5.16666667 6.83333333\n",
      " 5.66666667 6.         5.33333333 5.33333333 6.         6.16666667\n",
      " 5.66666667 7.         6.33333333 6.33333333 6.5        5.5\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.52962998]\n",
      " [0.52962998 1.        ]]\n",
      "Mean absolute error = 0.69\n",
      "Mean squared error = 0.82\n",
      "Median absolute error = 0.49\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.3\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.0342572  6.08370745 5.95051822 6.02071634 6.15390436 5.34881212\n",
      " 4.36797618 7.0862415  5.17278376 6.08428118 4.63023471 3.61975626\n",
      " 5.18228362 6.49969579 5.66208772 6.32118088 6.55133186 4.9338686\n",
      " 4.6914797  5.80915252 5.58371227 5.95583631 5.66736467 4.74564793\n",
      " 4.69525245 5.42516809 5.64071517 5.62363769 4.99745166 4.19557403\n",
      " 6.28217136 4.52151526 6.28989483 4.56633303 5.03132565 5.87003868\n",
      " 5.93443366 6.1729528  4.73342431 7.30189336 5.76977866 3.01610178\n",
      " 5.72277388 5.10179044 6.13490734 4.80623208 6.27566875 6.39554795\n",
      " 4.76325697 7.76560157 3.70841462 5.63453877 6.3339804  5.97068698\n",
      " 5.71361117]\n",
      "\n",
      "What it should be:  [5.16666667 6.5        5.83333333 5.66666667 5.33333333 6.16666667\n",
      " 6.         6.33333333 6.33333333 6.66666667 6.         5.16666667\n",
      " 4.5        6.16666667 6.         5.33333333 5.         6.83333333\n",
      " 5.5        6.83333333 6.16666667 5.83333333 5.83333333 4.83333333\n",
      " 3.66666667 5.16666667 4.33333333 6.33333333 6.5        5.33333333\n",
      " 4.         5.83333333 5.66666667 4.         4.66666667 5.16666667\n",
      " 6.16666667 6.16666667 4.66666667 5.33333333 5.5        5.33333333\n",
      " 6.5        1.83333333 6.5        5.33333333 6.5        6.16666667\n",
      " 4.33333333 6.5        6.16666667 4.66666667 6.16666667 6.83333333\n",
      " 6.5       ]\n",
      "Correlation:  [[1.         0.26828849]\n",
      " [0.26828849 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.86250053 5.251615   6.37377934 6.5358996  6.19015578 5.44647695\n",
      " 6.18205089 4.94406163 6.64311571 5.37763008 6.59271823 5.84306517\n",
      " 5.44102278 6.5419399  5.66932686 5.88361336 4.89341082 5.76634988\n",
      " 5.48969137 4.99701088 5.38403943 5.78843939 6.93550589 5.54575756\n",
      " 6.46959929 6.12639996 5.14734808 5.09753305 6.03921438 5.58943273\n",
      " 5.38662488 6.53498927 6.55495302 5.63056309 6.20610395 6.98122913\n",
      " 6.29079424 5.70536958 6.30345103 4.54504804 6.02029898 5.71928906\n",
      " 6.64707769 6.24569509 5.86902799 5.93668774 3.41347931 5.80727335\n",
      " 5.29966427 6.60001435 4.77628663 6.31562382 6.38934805 5.70722987\n",
      " 5.86824154]\n",
      "\n",
      "What it should be:  [6.5        5.5        5.66666667 4.83333333 6.33333333 5.83333333\n",
      " 5.16666667 6.5        5.83333333 6.66666667 5.66666667 6.33333333\n",
      " 5.         6.5        6.16666667 5.16666667 5.33333333 4.66666667\n",
      " 1.83333333 6.         6.83333333 5.66666667 6.5        6.5\n",
      " 5.83333333 5.33333333 6.         3.66666667 6.16666667 7.\n",
      " 5.5        3.66666667 6.66666667 5.5        6.         5.33333333\n",
      " 6.33333333 5.33333333 4.66666667 4.5        4.83333333 6.5\n",
      " 5.66666667 5.83333333 4.33333333 6.5        5.5        5.66666667\n",
      " 4.5        6.5        4.83333333 6.83333333 4.66666667 4.\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.11648313]\n",
      " [0.11648313 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.27\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.43718634 5.31531536 6.06622617 4.91323795 6.13220804 6.02946874\n",
      " 4.72329074 6.14713262 5.49962679 4.98830538 4.27022427 5.79621033\n",
      " 5.44001403 6.24659569 5.89055314 6.74487085 1.79011709 6.15127484\n",
      " 4.89589676 5.54006516 6.3028836  6.59193388 4.77465854 6.94355494\n",
      " 5.35553283 5.91924002 7.15956988 5.70010104 4.39512924 4.74183679\n",
      " 6.54362192 6.636828   6.57277717 6.23920046 6.27835351 4.89872071\n",
      " 5.2546475  5.20513519 5.81007418 5.30117258 6.48030191 6.72741928\n",
      " 7.13482567 3.89211421 4.61501587 6.18882585 5.35692196 4.06728968\n",
      " 5.16767525 4.48848649 5.70338997 6.81837895 6.44079735 5.70031997\n",
      " 6.97750604]\n",
      "\n",
      "What it should be:  [6.         6.83333333 5.83333333 4.83333333 4.83333333 6.16666667\n",
      " 6.83333333 5.66666667 5.83333333 6.16666667 6.33333333 5.66666667\n",
      " 6.16666667 5.66666667 5.16666667 6.5        5.5        5.\n",
      " 5.83333333 5.5        5.33333333 5.83333333 4.         6.5\n",
      " 6.16666667 5.66666667 4.         6.16666667 4.66666667 3.66666667\n",
      " 6.         5.83333333 6.66666667 5.33333333 6.5        6.66666667\n",
      " 5.5        6.5        4.66666667 5.16666667 5.83333333 6.33333333\n",
      " 5.83333333 4.5        3.66666667 5.83333333 4.         6.16666667\n",
      " 5.33333333 6.5        4.66666667 6.16666667 7.         5.33333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.18553575]\n",
      " [0.18553575 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.34\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.99\n",
      "R2 score = -0.99\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.60121147 6.07819293 5.55969915 6.09091873 5.4817963  5.09769818\n",
      " 5.74383819 5.62649613 4.98379558 6.05093697 6.93030462 5.52248696\n",
      " 6.00947457 5.3308382  5.23172368 5.42395491 6.3768575  5.36310392\n",
      " 4.935696   7.1241081  4.78795462 4.51068771 5.95179962 5.54004593\n",
      " 7.1698379  5.73957559 5.81920359 5.86230433 4.91100044 6.44264625\n",
      " 5.28838947 4.94619456 4.81567336 5.55029479 5.03123837 4.54618248\n",
      " 5.50386098 6.37374685 6.27778864 5.51658591 6.39404178 4.5950456\n",
      " 4.90886251 6.89900662 4.66262794 5.89418608 5.43700719 6.05892006\n",
      " 6.35197272 4.08355799 5.80584314 6.26002356 6.16603029 7.01617198\n",
      " 5.04635916]\n",
      "\n",
      "What it should be:  [6.         5.         6.16666667 5.33333333 6.16666667 4.33333333\n",
      " 5.33333333 7.         5.5        5.66666667 7.         4.66666667\n",
      " 6.83333333 3.5        5.33333333 5.33333333 5.16666667 6.16666667\n",
      " 6.16666667 6.5        4.         5.83333333 6.83333333 6.16666667\n",
      " 6.16666667 6.66666667 5.         6.16666667 5.33333333 5.83333333\n",
      " 5.5        5.5        5.66666667 6.83333333 5.66666667 5.16666667\n",
      " 5.83333333 4.66666667 5.16666667 5.5        4.16666667 4.83333333\n",
      " 5.         6.33333333 3.66666667 6.33333333 6.16666667 5.33333333\n",
      " 5.16666667 6.33333333 3.66666667 6.         3.         6.16666667\n",
      " 6.66666667]\n",
      "Correlation:  [[1.         0.17683037]\n",
      " [0.17683037 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.29811259 5.51309483 4.68264107 5.20108422 4.86107685 6.95508837\n",
      " 6.48364253 5.29001677 5.85076648 4.43901024 5.06866402 4.69431517\n",
      " 3.65526604 7.09856667 5.79073675 7.11339371 6.48639602 6.85032021\n",
      " 5.89359962 5.71142101 5.62577134 6.67551531 5.82777328 5.80241562\n",
      " 5.56597664 5.76452188 6.37556033 5.96349286 4.4408286  6.24984543\n",
      " 4.64946096 6.30762182 6.39939356 5.48160242 6.11778106 8.01775141\n",
      " 5.60456094 5.16325309 5.2651156  5.23388842 5.86703322 5.74270234\n",
      " 5.14068606 4.34563344 6.49041077 6.101663   7.19353869 6.73105461\n",
      " 5.69522133 5.97968817 5.87945446 5.40646519 5.11985473 4.3463625\n",
      " 4.5611446 ]\n",
      "\n",
      "What it should be:  [5.16666667 4.33333333 4.         5.33333333 6.33333333 5.16666667\n",
      " 5.         6.5        6.5        6.         4.33333333 4.33333333\n",
      " 4.         4.         6.         6.33333333 6.83333333 6.5\n",
      " 5.83333333 5.         5.33333333 6.66666667 3.33333333 4.83333333\n",
      " 6.83333333 6.66666667 5.16666667 6.66666667 4.         6.\n",
      " 4.66666667 5.33333333 5.66666667 5.         4.66666667 6.5\n",
      " 5.5        6.16666667 4.66666667 6.16666667 5.16666667 6.\n",
      " 5.5        6.         4.         6.16666667 7.         6.83333333\n",
      " 5.83333333 6.33333333 4.83333333 6.16666667 5.33333333 6.83333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.25348599]\n",
      " [0.25348599 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.39403114 5.21049234 6.23085491 5.49202981 5.31815847 5.07437476\n",
      " 5.73222814 4.87913774 5.62728665 5.4091082  7.07887528 5.92131565\n",
      " 4.38142826 5.82142002 6.87285993 5.37199133 6.25468623 6.33901372\n",
      " 4.85404769 4.10394582 6.10258854 5.99758252 5.52837022 5.8236679\n",
      " 5.37535844 5.74309577 6.73696625 6.55199567 4.68409319 4.43514411\n",
      " 5.42699052 5.48279607 6.33743969 5.00405042 4.7173653  6.50513046\n",
      " 5.61137644 5.78288249 5.26845382 6.80989215 5.43156455 6.00091563\n",
      " 6.68408036 3.82046541 7.02384831 5.51402622 5.04220879 4.93834921\n",
      " 6.01039476 4.89446176 5.25851832 6.5115604  6.95547386 6.04978235\n",
      " 6.05614055]\n",
      "\n",
      "What it should be:  [4.33333333 4.         6.         6.16666667 5.5        3.66666667\n",
      " 3.5        5.33333333 6.5        5.33333333 5.16666667 6.\n",
      " 6.83333333 6.83333333 5.83333333 6.66666667 4.83333333 5.83333333\n",
      " 6.         5.33333333 5.66666667 4.66666667 3.66666667 5.33333333\n",
      " 6.83333333 6.16666667 6.33333333 6.         5.         6.5\n",
      " 6.         3.         6.5        4.66666667 6.33333333 5.66666667\n",
      " 4.5        5.66666667 5.         6.5        4.5        6.33333333\n",
      " 6.         7.         6.         5.83333333 5.5        6.16666667\n",
      " 6.66666667 5.66666667 6.66666667 5.16666667 6.66666667 6.83333333\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.06827716]\n",
      " [0.06827716 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.35\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.52\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.65968284 3.95031491 5.77810454 5.61441941 5.87185202 5.73509774\n",
      " 5.92857362 5.66151925 5.91143881 5.46086975 5.70873555 6.27379206\n",
      " 5.81953762 5.62468739 5.98785413 5.77259556 6.71437052 6.1417317\n",
      " 4.88565407 5.63784319 6.54701612 5.42330771 5.37851328 4.986768\n",
      " 5.32342974 5.70137318 6.15239283 6.49487037 5.65232422 4.41744023\n",
      " 6.09935122 6.71349479 6.95288498 4.63139666 5.938313   5.76418319\n",
      " 6.18690538 6.14405155 5.76145503 6.56569351 5.35307525 5.98356463\n",
      " 3.99233139 3.71891611 6.36631334 6.40661019 6.63911442 5.64296133\n",
      " 6.10700045 7.3704492  6.01790174 6.24842181 3.98983317 4.65995347\n",
      " 6.8433131 ]\n",
      "\n",
      "What it should be:  [6.16666667 5.16666667 5.83333333 6.83333333 5.66666667 3.\n",
      " 5.83333333 5.83333333 6.16666667 5.83333333 6.83333333 6.16666667\n",
      " 5.66666667 5.83333333 3.66666667 4.5        6.33333333 6.66666667\n",
      " 6.         5.         6.         4.66666667 4.5        5.16666667\n",
      " 6.         5.         6.16666667 5.66666667 6.16666667 6.66666667\n",
      " 5.33333333 5.83333333 5.66666667 4.33333333 5.5        6.33333333\n",
      " 4.66666667 4.83333333 6.16666667 6.16666667 5.33333333 4.5\n",
      " 5.5        4.         4.66666667 6.5        6.5        6.33333333\n",
      " 6.16666667 6.5        5.33333333 6.         4.         4.66666667\n",
      " 5.83333333]\n",
      "Correlation:  [[1.         0.36604984]\n",
      " [0.36604984 1.        ]]\n",
      "Mean absolute error = 0.7\n",
      "Mean squared error = 0.88\n",
      "Median absolute error = 0.55\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.23\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.96360475 6.05484275 5.96724987 5.45820805 5.51892888 5.97984966\n",
      " 4.38757493 4.68743887 6.4578203  5.03222634 4.93361541 6.04702525\n",
      " 6.9852054  6.80866021 5.26998708 6.98437616 4.34637922 5.43119729\n",
      " 6.92002109 5.52020275 6.10476107 6.95632929 5.96543477 5.93343625\n",
      " 6.10742675 4.56500875 4.66949821 6.43169013 6.82278433 6.22191869\n",
      " 5.84446353 5.96502152 5.06719459 6.9972545  5.53140402 5.01844715\n",
      " 5.03607113 6.36056912 6.49602308 4.52052313 5.74429297 5.4077932\n",
      " 5.35163895 5.86027274 5.74645076 5.50296557 6.03053169 4.67777928\n",
      " 5.92099964 5.46189205 6.24516337 4.21403007 5.56882744 5.31711657\n",
      " 4.78461716]\n",
      "\n",
      "What it should be:  [7.         5.33333333 5.16666667 6.16666667 5.16666667 4.5\n",
      " 4.83333333 5.83333333 5.83333333 4.66666667 3.66666667 6.33333333\n",
      " 6.33333333 6.83333333 4.83333333 5.66666667 4.83333333 5.83333333\n",
      " 6.         6.         5.66666667 5.33333333 6.         6.16666667\n",
      " 6.         6.         4.5        7.         6.5        6.33333333\n",
      " 6.16666667 5.33333333 5.83333333 4.         4.5        6.83333333\n",
      " 4.83333333 5.16666667 5.         6.33333333 6.16666667 5.16666667\n",
      " 5.33333333 6.33333333 4.16666667 6.83333333 5.16666667 5.33333333\n",
      " 5.66666667 5.66666667 6.16666667 4.66666667 5.33333333 4.83333333\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.28728353]\n",
      " [0.28728353 1.        ]]\n",
      "Mean absolute error = 0.71\n",
      "Mean squared error = 0.86\n",
      "Median absolute error = 0.48\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.41\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.94747329 5.50761424 7.5401065  5.46112578 5.62858665 7.01473259\n",
      " 4.94937988 6.66106819 4.24732539 7.61883398 4.83694695 5.2926351\n",
      " 5.94654927 6.54747095 5.42678586 6.08732505 5.99833188 5.21872827\n",
      " 5.83399094 5.24995041 5.2507901  6.60905869 4.89931383 4.92445243\n",
      " 6.69710394 4.85432534 6.4137113  6.18269606 5.98388053 4.44821126\n",
      " 4.36390267 5.60983543 5.12640467 5.45219397 4.28656545 6.10492718\n",
      " 4.77308535 5.56638289 6.8288596  5.58561088 6.84589125 6.15816316\n",
      " 2.96558493 6.1113422  5.50718727 5.67102016 6.70868009 4.97377178\n",
      " 5.1585152  5.65543778 4.2862326  5.76083395 3.75192074 5.60920702\n",
      " 7.03930421]\n",
      "\n",
      "What it should be:  [5.83333333 6.16666667 7.         5.16666667 6.33333333 6.83333333\n",
      " 5.5        5.66666667 5.83333333 7.         4.83333333 4.83333333\n",
      " 5.33333333 5.66666667 6.16666667 6.16666667 6.83333333 5.66666667\n",
      " 4.16666667 4.66666667 6.16666667 5.33333333 6.16666667 4.33333333\n",
      " 5.16666667 5.83333333 4.83333333 6.16666667 6.66666667 6.\n",
      " 4.66666667 4.5        7.         6.16666667 4.         7.\n",
      " 6.         5.16666667 6.16666667 6.16666667 6.33333333 6.16666667\n",
      " 4.         4.83333333 5.33333333 5.16666667 5.66666667 6.16666667\n",
      " 5.83333333 5.         5.33333333 6.16666667 5.33333333 5.33333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.44732432]\n",
      " [0.44732432 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.81\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.26408516 5.10378924 4.51426711 5.55209343 6.86437119 5.15230249\n",
      " 5.45783797 5.66221364 5.38177154 6.19486954 6.17518805 5.23728721\n",
      " 5.68215132 5.52977291 5.61788118 5.57322213 6.07625346 6.61714584\n",
      " 5.43157333 5.1975934  4.65378461 4.74718707 5.92270744 4.60150704\n",
      " 6.35597778 5.33897402 6.57949237 4.26620089 5.03516112 5.55030289\n",
      " 4.90731443 5.76935455 5.34291775 5.5004919  5.9610807  6.06327492\n",
      " 5.44608045 5.58977099 6.41575179 5.34926507 5.69591975 5.45715802\n",
      " 4.70021324 5.52809854 4.99363697 4.95234322 6.5098397  4.94258183\n",
      " 5.04816801 5.6408791  6.0162262  6.67140222 6.10046888 5.77274967\n",
      " 5.65760089]\n",
      "\n",
      "What it should be:  [6.66666667 4.83333333 4.5        6.16666667 5.83333333 5.5\n",
      " 6.         5.33333333 5.         6.83333333 4.66666667 3.\n",
      " 6.         4.5        6.5        6.83333333 4.33333333 7.\n",
      " 4.         4.83333333 5.         4.83333333 5.66666667 7.\n",
      " 6.83333333 5.16666667 6.33333333 4.         6.5        5.33333333\n",
      " 4.         6.         5.         6.16666667 6.16666667 6.66666667\n",
      " 3.66666667 6.16666667 6.16666667 6.5        5.66666667 1.83333333\n",
      " 6.         5.5        6.16666667 5.         6.83333333 6.83333333\n",
      " 5.66666667 5.33333333 6.16666667 5.33333333 6.83333333 5.66666667\n",
      " 7.        ]\n",
      "Correlation:  [[1.         0.32228597]\n",
      " [0.32228597 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.54\n",
      "Explain variance score = 0.06\n",
      "R2 score = 0.06\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.79649254 5.71821468 6.16054527 5.08940057 5.25968289 5.71999397\n",
      " 5.87837817 5.88223467 4.81908411 5.93753011 5.30006468 4.96953697\n",
      " 5.35334023 5.52239148 5.62330968 5.68412469 5.34212571 5.5570308\n",
      " 6.14480509 5.41104752 5.48089168 6.00715379 5.28653204 6.70491936\n",
      " 4.53559122 5.70591577 5.83097419 5.24450657 6.82316151 5.83048898\n",
      " 5.6456235  5.60655679 4.63559234 5.41896529 6.14224481 5.21116339\n",
      " 5.68524823 7.01999731 6.84389097 4.61017942 5.47525859 6.18609957\n",
      " 5.25571424 6.35354033 6.1731125  5.85120948 3.85924598 6.18491132\n",
      " 6.09175322 5.52635912 6.08056466 5.38565102 3.7966942  4.95525808\n",
      " 5.33244206]\n",
      "\n",
      "What it should be:  [4.16666667 6.16666667 6.83333333 5.16666667 3.66666667 6.33333333\n",
      " 5.33333333 7.         6.         5.         4.         4.66666667\n",
      " 4.33333333 6.5        3.66666667 6.83333333 6.33333333 6.66666667\n",
      " 6.5        4.83333333 6.         4.5        4.33333333 6.33333333\n",
      " 7.         5.66666667 6.5        6.83333333 6.33333333 5.16666667\n",
      " 5.5        5.5        3.         6.5        5.83333333 6.16666667\n",
      " 6.83333333 6.5        4.66666667 3.33333333 6.         5.66666667\n",
      " 1.83333333 7.         6.83333333 6.5        5.33333333 5.16666667\n",
      " 5.33333333 6.66666667 4.66666667 5.5        6.         4.83333333\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.26053048]\n",
      " [0.26053048 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.34\n",
      "Median absolute error = 0.94\n",
      "Explain variance score = -0.02\n",
      "R2 score = -0.02\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.7179542  5.91156905 6.42436302 5.42156308 6.28600845 6.35102801\n",
      " 6.33236614 3.81821592 5.12225155 5.53297492 6.57144569 6.34506947\n",
      " 6.15806679 4.89561837 6.4716319  6.01023367 6.26049187 6.01505876\n",
      " 5.57373663 5.68908065 4.51180548 4.57007507 5.97666582 6.95864861\n",
      " 7.11945764 6.78487904 4.96584138 4.93355803 5.82785535 7.37982272\n",
      " 5.3119376  5.4152826  5.08301149 5.5638855  4.81198293 6.53523483\n",
      " 6.41512288 6.57457939 6.70515575 4.16353074 6.49797645 6.04757208\n",
      " 4.13063202 5.08226073 4.62356007 6.7120763  5.80579442 4.74295644\n",
      " 5.55122572 5.82235275 5.17050409 5.41537104 5.17824247 5.30624597\n",
      " 5.09542498]\n",
      "\n",
      "What it should be:  [6.5        7.         5.83333333 4.5        5.66666667 7.\n",
      " 5.33333333 5.33333333 5.66666667 5.         5.66666667 6.5\n",
      " 5.16666667 4.66666667 5.33333333 5.33333333 6.16666667 4.83333333\n",
      " 5.66666667 5.5        4.33333333 3.66666667 6.66666667 6.16666667\n",
      " 6.5        6.83333333 6.5        3.66666667 6.33333333 6.\n",
      " 1.83333333 6.5        5.33333333 5.5        6.         5.83333333\n",
      " 4.66666667 5.16666667 5.66666667 5.5        6.5        6.\n",
      " 4.66666667 6.5        4.83333333 4.66666667 6.33333333 6.33333333\n",
      " 5.5        5.         6.5        4.66666667 6.5        4.83333333\n",
      " 5.66666667]\n",
      "Correlation:  [[1.        0.3134506]\n",
      " [0.3134506 1.       ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.21\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.55123981 5.94711683 5.85280426 4.16555672 6.24858471 5.97682838\n",
      " 5.71699625 5.63245121 5.11834149 5.44903656 7.16355273 6.31195455\n",
      " 6.0354435  5.42253661 6.4647111  6.18197931 5.51997845 6.74650542\n",
      " 4.56829509 4.95558903 5.75828149 6.21342692 5.8317681  6.49572419\n",
      " 6.08938417 5.18799583 4.62278061 4.54595442 6.41680643 5.04783901\n",
      " 5.71669983 5.52551838 6.76509585 5.42090879 6.0128864  8.08948169\n",
      " 5.49363833 5.93471261 4.51116814 6.49321985 5.0655611  4.76439094\n",
      " 5.83346869 5.15009825 5.91912837 5.6145227  5.36564972 4.77902913\n",
      " 5.07481268 6.88666188 5.13397219 5.1618689  6.10407773 5.52665459\n",
      " 5.04458182]\n",
      "\n",
      "What it should be:  [4.83333333 5.33333333 6.66666667 4.5        5.83333333 5.16666667\n",
      " 4.83333333 5.33333333 5.16666667 5.16666667 7.         6.33333333\n",
      " 6.16666667 5.33333333 5.         6.16666667 6.83333333 5.\n",
      " 6.16666667 4.33333333 5.66666667 4.66666667 6.16666667 7.\n",
      " 3.83333333 6.         6.5        6.         6.16666667 5.5\n",
      " 5.33333333 4.         6.83333333 5.16666667 4.83333333 4.\n",
      " 6.16666667 5.66666667 4.83333333 5.83333333 6.66666667 6.33333333\n",
      " 6.33333333 6.33333333 6.5        4.5        5.16666667 5.83333333\n",
      " 6.16666667 4.33333333 4.66666667 3.33333333 6.16666667 6.\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.03220602]\n",
      " [0.03220602 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.28\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.69\n",
      "R2 score = -0.71\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.7244443  6.05832162 6.26469382 7.12761285 6.13175158 7.60341477\n",
      " 4.78910444 4.79349269 5.14759898 3.65180459 5.1983254  6.08902428\n",
      " 5.77633762 5.66288499 5.95825626 8.83242258 6.08061209 5.75264698\n",
      " 4.60164012 5.00175538 4.91066161 5.91663086 6.10644045 4.50423708\n",
      " 6.05325844 4.2534787  6.28925301 6.35916504 4.29740696 4.54861573\n",
      " 4.82872926 6.03831334 6.97874791 5.24774064 6.2592201  5.17914748\n",
      " 6.3945143  5.28961493 7.5827142  5.2386724  6.68524013 6.27258238\n",
      " 5.96094946 4.26358931 6.89625727 5.24646766 5.64105883 5.02748268\n",
      " 5.76340813 3.77455587 6.14308115 6.61009366 5.78282216 5.94540545\n",
      " 4.6185575 ]\n",
      "\n",
      "What it should be:  [4.66666667 5.33333333 5.         5.16666667 6.         6.33333333\n",
      " 3.66666667 5.5        5.5        5.         6.83333333 5.66666667\n",
      " 6.5        7.         6.         6.66666667 5.83333333 6.\n",
      " 7.         3.66666667 5.5        4.5        6.5        6.33333333\n",
      " 6.66666667 5.5        6.5        5.16666667 5.66666667 5.33333333\n",
      " 6.83333333 4.16666667 4.66666667 6.33333333 5.16666667 5.16666667\n",
      " 5.16666667 5.83333333 7.         5.33333333 6.         5.66666667\n",
      " 6.16666667 4.83333333 7.         5.33333333 5.66666667 5.33333333\n",
      " 6.16666667 4.83333333 4.66666667 6.83333333 5.83333333 6.33333333\n",
      " 4.66666667]\n",
      "Correlation:  [[1.         0.23982526]\n",
      " [0.23982526 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.31\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.9\n",
      "R2 score = -0.91\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.91829903 5.58700678 5.72122667 7.37566374 6.2223401  6.59637672\n",
      " 5.94480559 6.24283101 5.36979665 6.47449034 3.78064379 6.97960524\n",
      " 3.66001848 6.03156337 6.91570618 5.13465651 7.04341792 4.42712228\n",
      " 6.41287871 7.40664453 6.65457645 5.85610392 4.38434696 5.15648405\n",
      " 5.46258282 5.448242   6.50592412 5.42666639 5.06157203 6.47968274\n",
      " 5.8095929  6.42586018 3.62886328 5.01777576 4.41980138 4.7899054\n",
      " 5.86667992 6.11758151 6.5657996  7.70927628 5.445865   7.27942391\n",
      " 4.33245905 5.31805358 5.41701705 6.74622792 4.46058905 7.15012306\n",
      " 5.1144694  5.13031535 5.58796338 4.66154225 5.8565266  6.52435772\n",
      " 5.33976816]\n",
      "\n",
      "What it should be:  [5.         6.66666667 5.33333333 5.66666667 5.16666667 5.16666667\n",
      " 4.83333333 6.         6.5        6.83333333 7.         6.\n",
      " 4.5        5.83333333 5.83333333 5.5        5.16666667 5.16666667\n",
      " 6.         6.33333333 6.         4.5        4.         5.\n",
      " 5.16666667 1.83333333 5.66666667 5.66666667 4.66666667 5.33333333\n",
      " 5.66666667 5.16666667 6.83333333 6.33333333 6.83333333 4.\n",
      " 4.83333333 6.         6.33333333 6.5        4.83333333 5.33333333\n",
      " 4.5        5.         5.83333333 5.66666667 3.33333333 6.33333333\n",
      " 4.33333333 4.66666667 4.66666667 4.83333333 5.33333333 6.66666667\n",
      " 5.16666667]\n",
      "Correlation:  [[1.         0.28529791]\n",
      " [0.28529791 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.44\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.5\n",
      "R2 score = -0.62\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.26127865 6.09460811 5.42207824 6.19439079 5.7624747  6.27475019\n",
      " 6.00285339 5.60848278 5.69691622 6.35910237 3.96863489 6.6133072\n",
      " 7.12814119 6.44183931 5.90641904 5.58466653 5.77052642 5.96423602\n",
      " 5.38153614 6.01421711 5.67009985 4.15204819 6.76877023 5.85316782\n",
      " 5.76335736 5.2287926  6.11574044 6.30532037 7.27634093 4.54405176\n",
      " 6.06469877 5.6616379  6.44166312 6.30230983 1.93449746 4.38632847\n",
      " 5.25570394 6.06396686 4.59531854 5.868606   5.98365341 5.75263359\n",
      " 4.70229393 5.05038558 5.02088095 6.4294715  5.13733268 5.89966275\n",
      " 5.7474783  5.58319165 5.47865296 5.40531904 6.11513492 3.91389247\n",
      " 6.13110908]\n",
      "\n",
      "What it should be:  [3.66666667 5.33333333 6.5        5.66666667 5.5        6.16666667\n",
      " 6.16666667 4.5        5.33333333 6.83333333 4.         4.66666667\n",
      " 7.         6.16666667 6.33333333 5.66666667 6.16666667 6.16666667\n",
      " 5.5        6.83333333 5.33333333 5.16666667 4.         6.\n",
      " 5.33333333 4.5        5.66666667 4.16666667 5.83333333 6.33333333\n",
      " 5.16666667 5.83333333 5.66666667 5.         5.5        6.83333333\n",
      " 5.         6.16666667 5.5        4.33333333 5.83333333 6.33333333\n",
      " 5.33333333 6.         3.66666667 6.5        5.33333333 5.16666667\n",
      " 5.5        4.83333333 6.16666667 6.66666667 5.83333333 4.\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.26384705]\n",
      " [0.26384705 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.54\n",
      "R2 score = -0.54\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.96289055 6.01655868 6.05450421 7.00381622 5.88674577 4.20516543\n",
      " 5.38017279 6.40286891 5.60348852 5.78465932 6.49399874 4.83513815\n",
      " 4.97870593 5.14201498 6.39344801 5.06262231 6.51387387 6.1908113\n",
      " 6.16026701 3.96898153 4.58056305 7.11548178 5.90854829 6.40825766\n",
      " 4.99765717 4.99320001 5.87814263 5.47634954 5.6136982  6.3877612\n",
      " 4.42944114 4.87628853 5.95693153 4.99959392 5.9230208  6.4365429\n",
      " 5.5817055  5.66478111 7.24242501 6.62608889 3.52262411 6.40282955\n",
      " 6.81570673 5.17071995 4.38938628 6.16374563 6.43715654 5.61998279\n",
      " 5.9166441  6.21408623 5.60217024 7.32017399 5.9927123  6.17152402\n",
      " 7.66891147]\n",
      "\n",
      "What it should be:  [6.33333333 6.33333333 5.83333333 6.         5.66666667 6.33333333\n",
      " 5.16666667 5.83333333 7.         5.83333333 5.33333333 4.5\n",
      " 4.33333333 4.83333333 5.66666667 6.5        6.5        6.16666667\n",
      " 5.33333333 6.33333333 6.         6.5        6.         6.83333333\n",
      " 5.66666667 6.83333333 6.83333333 6.5        5.83333333 5.33333333\n",
      " 4.         5.         6.16666667 4.83333333 6.5        6.5\n",
      " 6.16666667 1.83333333 5.83333333 4.66666667 5.33333333 6.16666667\n",
      " 4.66666667 5.33333333 4.         4.66666667 6.33333333 5.16666667\n",
      " 6.5        6.5        6.         6.5        5.66666667 6.16666667\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.26267817]\n",
      " [0.26267817 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.41\n",
      "R2 score = -0.42\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.06071642 4.9075084  5.65324211 5.08285363 4.79277008 4.59493053\n",
      " 5.58878264 5.86235704 5.80351057 4.81686247 5.60052851 3.45484055\n",
      " 5.65536433 5.22107091 6.37334226 5.02863281 5.57908209 5.48226549\n",
      " 5.9468836  4.06392661 5.56635381 6.63501018 6.41798502 5.62484848\n",
      " 5.03459282 5.26022426 5.65784743 6.0635635  5.62250857 6.7980385\n",
      " 4.91238118 5.20206556 5.11730871 5.80762191 5.75328861 5.65928041\n",
      " 5.94349435 4.77001667 5.47106243 4.88584865 5.50027314 6.60380295\n",
      " 5.53131653 5.11628777 6.52498804 6.40590375 5.50301802 6.23342182\n",
      " 5.58314898 6.00836627 5.09529282 6.74662835 5.50472055 4.42513738\n",
      " 5.42729469]\n",
      "\n",
      "What it should be:  [6.16666667 5.         6.5        5.5        6.66666667 4.\n",
      " 5.83333333 6.16666667 1.83333333 4.33333333 4.         4.5\n",
      " 4.83333333 5.83333333 5.83333333 6.         7.         5.16666667\n",
      " 5.33333333 4.33333333 5.33333333 6.33333333 6.5        7.\n",
      " 4.66666667 5.66666667 5.16666667 4.33333333 5.83333333 5.83333333\n",
      " 4.83333333 6.         4.66666667 4.66666667 4.5        5.66666667\n",
      " 5.16666667 4.83333333 3.33333333 6.16666667 6.66666667 5.33333333\n",
      " 4.         6.         6.16666667 4.66666667 6.         6.\n",
      " 4.66666667 6.83333333 6.5        5.83333333 5.83333333 6.5\n",
      " 5.66666667]\n",
      "Correlation:  [[1.        0.1629115]\n",
      " [0.1629115 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.23\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.18196031 6.59466686 5.48904219 5.96746056 5.52260839 5.92957715\n",
      " 6.7751951  4.77187558 7.14703613 6.80571863 5.83754419 5.11085127\n",
      " 5.40041508 6.17443483 5.36355002 5.47081388 4.49088976 6.73192469\n",
      " 6.70074093 4.54859603 4.8361161  5.42359221 6.41514605 5.30916457\n",
      " 5.63921942 6.07534422 4.69382937 5.00779769 5.9107362  5.04835706\n",
      " 5.5811674  6.14024989 6.20227462 6.23675205 3.75619528 6.72624896\n",
      " 6.29055514 4.11491738 6.36602452 5.11122943 4.81507371 5.66741738\n",
      " 4.43087496 5.31200246 5.13704138 4.8102324  3.88043424 5.9662043\n",
      " 5.42329914 5.94192788 6.88978229 4.83383721 5.75165059 6.05769257\n",
      " 5.83888576]\n",
      "\n",
      "What it should be:  [6.16666667 4.66666667 6.33333333 6.16666667 5.5        6.16666667\n",
      " 5.16666667 3.66666667 6.5        6.33333333 4.66666667 6.66666667\n",
      " 4.33333333 6.83333333 4.66666667 4.         4.33333333 6.33333333\n",
      " 5.66666667 6.5        4.83333333 5.66666667 5.33333333 4.\n",
      " 5.66666667 5.33333333 5.5        6.66666667 3.66666667 5.33333333\n",
      " 4.5        5.33333333 4.33333333 5.83333333 5.5        5.83333333\n",
      " 6.66666667 4.83333333 6.5        6.16666667 4.5        5.83333333\n",
      " 5.66666667 6.83333333 6.16666667 7.         5.83333333 5.33333333\n",
      " 7.         6.66666667 6.16666667 6.16666667 5.16666667 6.83333333\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.16489354]\n",
      " [0.16489354 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.48\n",
      "R2 score = -0.48\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.80621922 5.96257996 6.30304234 4.44504117 6.86115406 5.19474774\n",
      " 5.80766828 5.18009538 5.99334959 4.78281283 5.27054978 6.08008283\n",
      " 6.12099941 4.63347639 5.5928397  5.69361281 6.03259849 5.08524307\n",
      " 6.66677965 5.34198653 7.32031971 5.86869653 6.26253426 4.65119511\n",
      " 5.34376554 5.81659516 6.66410322 5.40664665 5.57929148 7.28258131\n",
      " 6.79775412 5.76641077 6.00014709 4.63676956 6.26856352 5.79808815\n",
      " 4.67311042 4.55380523 7.26349484 7.25621452 6.62229943 5.81447513\n",
      " 5.55162722 5.87800709 5.44222845 5.28209847 7.00357111 5.19606775\n",
      " 7.15295215 5.7860165  6.16674004 6.12421152 4.74706344 5.89938652\n",
      " 6.30743469]\n",
      "\n",
      "What it should be:  [5.33333333 4.         4.83333333 7.         6.66666667 5.83333333\n",
      " 5.16666667 6.16666667 6.16666667 4.66666667 5.66666667 6.\n",
      " 5.33333333 4.83333333 6.5        5.83333333 5.33333333 4.66666667\n",
      " 6.16666667 5.         6.16666667 6.         5.83333333 5.5\n",
      " 6.         5.5        4.33333333 6.83333333 5.         5.83333333\n",
      " 6.33333333 5.5        6.         5.83333333 5.33333333 5.\n",
      " 6.83333333 5.33333333 6.66666667 5.33333333 6.66666667 4.\n",
      " 4.33333333 6.66666667 5.5        6.5        6.         6.5\n",
      " 5.83333333 4.5        5.66666667 5.         4.83333333 4.\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.08396352]\n",
      " [0.08396352 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.83\n",
      "R2 score = -0.94\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.4495959  5.85957827 4.94780565 4.27371277 5.42221048 4.85079318\n",
      " 5.82975676 5.34407263 5.36081097 4.98345044 4.57054866 4.66918085\n",
      " 5.60192327 5.32692792 6.58986971 6.22765905 5.78813703 4.89818526\n",
      " 4.36929242 5.15154748 5.23752779 5.85663944 5.9890816  4.60438215\n",
      " 6.1663004  4.99039004 4.32655005 6.90457693 5.31846537 5.76460889\n",
      " 4.76843926 4.38424454 5.04999159 5.1806868  5.12988196 5.67713702\n",
      " 5.41182127 3.79364775 5.86541577 5.59925367 5.034231   6.16678858\n",
      " 5.54138939 5.29975643 4.29533274 6.36346323 5.282353   4.7581412\n",
      " 5.83109457 4.86990838 5.24590483 5.24914818 5.82178592 5.90357193\n",
      " 4.78476558]\n",
      "\n",
      "What it should be:  [6.83333333 4.         4.83333333 5.5        3.5        6.16666667\n",
      " 5.66666667 6.5        6.         5.33333333 4.         4.5\n",
      " 5.5        5.83333333 5.66666667 5.33333333 6.         3.66666667\n",
      " 3.66666667 4.83333333 6.33333333 6.         6.5        4.66666667\n",
      " 6.16666667 4.83333333 6.         6.5        6.16666667 6.\n",
      " 5.83333333 6.33333333 6.         5.         5.83333333 6.5\n",
      " 5.66666667 6.33333333 5.         5.33333333 6.16666667 5.33333333\n",
      " 4.         5.16666667 6.66666667 5.66666667 5.33333333 3.\n",
      " 6.83333333 4.66666667 6.16666667 5.         6.83333333 5.33333333\n",
      " 6.        ]\n",
      "Correlation:  [[1.         0.15600077]\n",
      " [0.15600077 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.32\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.69677077 7.31133553 4.24216418 7.09422204 6.76835689 6.44123069\n",
      " 5.413104   5.68121005 5.80791718 6.55965089 5.39925089 5.16268711\n",
      " 7.5149315  7.47085661 5.62938083 5.7445559  6.63903132 6.21147475\n",
      " 5.26170287 6.12866868 5.21128229 5.79343639 5.55458026 4.38593064\n",
      " 5.95555789 5.78687386 4.73750215 6.35738953 6.2164641  5.64598583\n",
      " 4.83683508 6.34235082 4.61572669 5.89114861 6.18168804 6.33122071\n",
      " 5.4808242  5.90462667 5.70743447 6.80281723 5.13805085 4.70639676\n",
      " 6.64282069 5.67726815 6.47101278 5.1879897  5.90339743 5.89287142\n",
      " 4.31123784 6.10801319 6.08633732 5.70030873 5.82066816 6.21786772\n",
      " 6.22574289]\n",
      "\n",
      "What it should be:  [5.33333333 6.66666667 6.83333333 5.33333333 6.         5.16666667\n",
      " 5.83333333 6.5        4.66666667 6.5        6.33333333 5.5\n",
      " 6.5        6.33333333 5.66666667 6.5        6.66666667 4.5\n",
      " 6.         6.83333333 5.5        6.         5.66666667 6.\n",
      " 5.16666667 6.33333333 4.         6.16666667 6.         6.5\n",
      " 6.16666667 4.83333333 6.         6.5        4.16666667 6.5\n",
      " 6.83333333 5.5        5.         5.83333333 6.         6.16666667\n",
      " 6.33333333 5.5        5.66666667 6.16666667 5.         4.5\n",
      " 6.66666667 6.16666667 6.16666667 4.5        3.5        4.83333333\n",
      " 5.5       ]\n",
      "Correlation:  [[1.         0.01989141]\n",
      " [0.01989141 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.9\n",
      "R2 score = -0.91\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.59757216 6.75032707 6.37970048 5.94452993 6.38094458 5.33672838\n",
      " 5.02694558 3.65833284 5.84318894 6.59360519 6.27767077 6.60375375\n",
      " 4.94797049 5.35765762 6.90570353 6.33253811 5.16343202 5.47755045\n",
      " 4.52367349 5.77022695 5.57116327 5.37494777 6.44666469 4.61464729\n",
      " 5.64728632 5.77941949 6.23409701 6.94225981 5.10590953 5.24452552\n",
      " 6.3005221  7.03355757 4.88593526 5.42301644 5.53398207 1.70611521\n",
      " 5.24326861 6.02910388 4.97497077 5.7466019  4.53158805 6.1144309\n",
      " 5.33026585 6.03479734 5.85414412 6.09815797 6.15576291 4.92117224\n",
      " 4.61403421 7.49070413 5.1368818  5.70253577 5.26538416 4.47392703\n",
      " 6.10403833]\n",
      "\n",
      "What it should be:  [5.16666667 5.16666667 5.66666667 6.         5.5        5.5\n",
      " 6.         5.33333333 4.33333333 5.         6.         6.83333333\n",
      " 3.5        4.83333333 6.5        5.83333333 3.66666667 6.5\n",
      " 5.         5.16666667 6.66666667 6.         4.83333333 4.83333333\n",
      " 6.         5.83333333 5.16666667 6.83333333 4.66666667 6.5\n",
      " 4.66666667 6.16666667 5.83333333 5.33333333 6.16666667 5.5\n",
      " 6.33333333 6.16666667 6.         5.16666667 5.16666667 4.\n",
      " 5.         6.16666667 6.66666667 6.5        3.         6.16666667\n",
      " 5.5        5.83333333 4.5        6.33333333 6.16666667 4.83333333\n",
      " 5.66666667]\n",
      "Correlation:  [[1.        0.1692745]\n",
      " [0.1692745 1.       ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.29\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.81\n",
      "R2 score = -0.82\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.652661   5.6341096  5.7379317  5.08772687 3.84949663 6.24816084\n",
      " 6.05691787 4.68399134 5.26388009 6.36445344 4.86098901 6.1498155\n",
      " 6.25072568 6.897694   5.21327469 7.05828802 6.32536381 6.0959987\n",
      " 5.92220718 5.02525633 5.80934299 5.79118957 6.12573141 5.89809974\n",
      " 5.07793987 5.24352562 5.78532074 5.52443246 3.85772551 6.3283937\n",
      " 2.50747238 6.22198172 5.25822444 5.65186763 4.95878616 5.78634761\n",
      " 5.35692092 5.15354236 4.93609127 4.19843901 4.91439205 5.01519781\n",
      " 5.85496334 5.36885782 5.69613204 5.79977539 4.20657293 6.17548669\n",
      " 5.79674173 5.78345899 5.5320409  5.77280335 6.08384806 6.75816313\n",
      " 6.95363635]\n",
      "\n",
      "What it should be:  [5.33333333 6.83333333 6.         5.83333333 5.16666667 6.66666667\n",
      " 6.16666667 6.5        5.66666667 5.83333333 6.83333333 6.66666667\n",
      " 6.33333333 6.5        5.83333333 6.16666667 5.33333333 4.\n",
      " 4.83333333 5.66666667 5.         3.5        5.33333333 5.33333333\n",
      " 6.16666667 6.16666667 6.33333333 6.33333333 6.         6.33333333\n",
      " 5.5        6.         3.66666667 5.33333333 5.5        4.5\n",
      " 4.16666667 6.16666667 4.66666667 7.         3.66666667 4.\n",
      " 6.16666667 6.         7.         6.16666667 4.         6.83333333\n",
      " 6.5        6.5        4.5        6.5        6.66666667 7.\n",
      " 6.16666667]\n",
      "Correlation:  [[1.         0.22678393]\n",
      " [0.22678393 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.35\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.3920107  6.42668488 5.54442215 5.47984234 5.77287573 6.02376164\n",
      " 5.58964781 5.89376225 5.93618613 5.485132   5.55589831 6.99203167\n",
      " 4.81668891 4.89308714 8.2088312  6.7351898  5.95161778 5.26322017\n",
      " 5.08354402 5.51660219 1.39310167 6.54142122 5.12798837 7.40477993\n",
      " 6.43107872 5.73405864 4.88922191 5.66956166 5.24893015 6.52719568\n",
      " 6.9576802  5.04734598 5.0265875  6.97327795 6.65381838 5.78295098\n",
      " 6.78168475 6.35967519 4.7777576  5.24360101 6.01729954 5.59647386\n",
      " 5.53244664 4.72985479 5.77892179 6.55264908 6.98938751 4.30266398\n",
      " 5.06415892 5.01537652 6.06494352 6.55962589 5.15023181 6.24938806\n",
      " 6.0435226 ]\n",
      "\n",
      "What it should be:  [6.         6.66666667 3.33333333 6.16666667 5.83333333 5.83333333\n",
      " 5.33333333 5.5        6.16666667 5.5        5.66666667 5.66666667\n",
      " 6.33333333 6.         6.5        5.33333333 6.83333333 6.33333333\n",
      " 6.16666667 5.66666667 5.5        6.5        5.5        6.16666667\n",
      " 6.5        4.66666667 6.83333333 6.16666667 6.5        5.83333333\n",
      " 6.5        6.33333333 3.66666667 5.83333333 6.         6.16666667\n",
      " 6.16666667 7.         6.5        6.16666667 5.33333333 6.\n",
      " 5.16666667 4.33333333 5.33333333 5.5        4.66666667 4.83333333\n",
      " 4.83333333 6.16666667 6.66666667 5.83333333 6.5        5.16666667\n",
      " 5.33333333]\n",
      "Correlation:  [[1.         0.17408472]\n",
      " [0.17408472 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.25\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -1.27\n",
      "R2 score = -1.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.17160433 6.60343938 6.62521737 5.20882578 5.87204662 5.8115769\n",
      " 5.98339248 7.63546991 6.01963706 6.42278094 5.65283389 6.02103909\n",
      " 3.52476382 5.72260283 5.29114114 6.24564092 5.1463901  3.5494593\n",
      " 5.1360044  5.86038277 6.003432   5.84162316 5.55992348 5.89669028\n",
      " 5.44434351 5.53307161 5.83446843 4.95308672 4.96630398 5.59655819\n",
      " 5.41541807 5.88949712 5.81693761 5.97322984 5.00554875 6.08048093\n",
      " 5.59842733 5.62375344 6.71959161 5.80930195 6.60180623 5.13165039\n",
      " 5.00746214 4.8537938  5.14816157 5.11312091 5.62623817 4.73776484\n",
      " 5.31250476 5.00262749 6.39940358 4.86569399 5.9314964  5.43897609\n",
      " 3.95431014]\n",
      "\n",
      "What it should be:  [6.16666667 6.66666667 6.83333333 6.66666667 5.33333333 6.66666667\n",
      " 4.33333333 6.16666667 6.16666667 5.66666667 6.         5.16666667\n",
      " 4.83333333 4.66666667 3.5        6.         6.66666667 5.33333333\n",
      " 6.16666667 5.66666667 6.         6.16666667 5.66666667 5.66666667\n",
      " 5.5        6.33333333 5.83333333 5.83333333 5.33333333 6.16666667\n",
      " 5.33333333 6.         5.33333333 6.83333333 6.66666667 5.16666667\n",
      " 5.5        4.33333333 6.33333333 5.66666667 5.83333333 6.16666667\n",
      " 4.83333333 5.33333333 5.33333333 6.83333333 3.33333333 4.33333333\n",
      " 5.66666667 6.16666667 7.         5.5        6.         5.16666667\n",
      " 6.33333333]\n",
      "Correlation:  [[1.         0.22169101]\n",
      " [0.22169101 1.        ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.91\n",
      "Median absolute error = 0.57\n",
      "Explain variance score = -0.43\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.61214548 5.89755206 5.08948611 5.68572302 4.94177923 5.33223158\n",
      " 5.23762406 5.79231704 4.57706524 6.48650065 6.32064453 5.75127109\n",
      " 6.2184627  7.17337455 4.9677689  5.87926699 5.31297942 5.30873992\n",
      " 5.07913098 5.36304336 4.98870984 5.86766208 5.80395292 5.52912878\n",
      " 6.37247453 5.54450809 7.16155036 4.49325053 3.96909392 5.90913146\n",
      " 4.33381158 6.8476415  6.14851689 6.59654409 5.01977633 4.73252133\n",
      " 5.69611098 6.63003535 4.98844242 4.29245834 3.89622609 6.03378222\n",
      " 6.28649905 6.76269328 6.32858071 6.20028276 6.83552312 5.28985255\n",
      " 4.83855711 6.41996738 5.12227285 6.62743582 5.59864504 5.52823878\n",
      " 4.89433282]\n",
      "\n",
      "What it should be:  [5.33333333 4.16666667 5.5        6.16666667 5.5        6.5\n",
      " 5.5        5.16666667 5.16666667 5.33333333 6.16666667 5.33333333\n",
      " 4.66666667 7.         6.16666667 6.16666667 6.16666667 6.16666667\n",
      " 5.66666667 3.66666667 5.83333333 5.33333333 4.66666667 6.66666667\n",
      " 6.83333333 6.         5.16666667 4.         4.66666667 5.66666667\n",
      " 6.5        3.         4.5        5.66666667 4.83333333 5.83333333\n",
      " 6.83333333 7.         3.83333333 6.5        5.33333333 6.16666667\n",
      " 6.16666667 6.5        5.83333333 6.33333333 6.5        4.5\n",
      " 6.         6.5        4.83333333 5.33333333 5.83333333 4.5\n",
      " 6.66666667]\n",
      "Correlation:  [[1.         0.14110231]\n",
      " [0.14110231 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.52\n",
      "R2 score = -0.52\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.94264815 5.09534758 5.79714479 5.96336788 5.69607949 6.4288486\n",
      " 5.46974504 6.8940755  5.72151201 5.94611463 5.57454188 6.41141122\n",
      " 5.85794633 6.00352114 4.45676275 5.04755522 6.29789546 5.77282543\n",
      " 5.18144997 6.70048471 6.54243722 5.16301377 5.30291039 5.02508102\n",
      " 5.17207621 5.00040452 5.30924237 6.36206354 6.69083413 6.64319089\n",
      " 5.8652957  6.53456028 5.47418521 5.63203439 6.60249124 4.81680714\n",
      " 6.0270461  5.7937962  6.20115555 6.56271127 5.41804272 6.35403673\n",
      " 5.78326425 7.05587006 6.42819329 6.22036417 5.00538763 6.13074029\n",
      " 5.06092271 5.52868139 5.44584126 6.37927321 6.4230708  7.92649897\n",
      " 5.31531568]\n",
      "\n",
      "What it should be:  [5.66666667 5.83333333 5.66666667 5.83333333 5.83333333 6.\n",
      " 5.66666667 6.5        4.33333333 4.66666667 6.83333333 6.5\n",
      " 5.33333333 7.         6.33333333 6.33333333 5.66666667 6.5\n",
      " 6.66666667 6.16666667 6.         4.33333333 4.66666667 4.33333333\n",
      " 4.83333333 5.         3.66666667 5.16666667 4.         6.66666667\n",
      " 6.         6.16666667 6.5        6.5        6.83333333 3.66666667\n",
      " 5.66666667 3.33333333 4.33333333 5.66666667 4.83333333 6.16666667\n",
      " 3.5        6.33333333 7.         5.83333333 6.16666667 5.16666667\n",
      " 5.83333333 6.         6.66666667 4.66666667 5.         6.66666667\n",
      " 6.83333333]\n",
      "Correlation:  [[1.         0.22757022]\n",
      " [0.22757022 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.15\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.8137816  6.09904837 5.82597056 5.75606915 4.51079585 6.40592248\n",
      " 5.35299709 5.01518797 5.56173318 5.51322694 6.4531613  5.38793132\n",
      " 5.54709035 5.2994386  5.20719863 5.32289355 6.27291411 5.38147601\n",
      " 4.15452883 6.67853614 4.81025106 5.79297392 6.40185844 5.48907432\n",
      " 4.68505675 5.51078037 5.74041431 6.00318537 5.05912794 5.61106148\n",
      " 4.92817872 6.05764293 6.14068129 6.1239494  5.75376808 4.86536514\n",
      " 5.90968565 6.00709839 4.56849792 4.46800244 5.47089599 4.26553122\n",
      " 6.59482806 5.65871876 5.39501585 6.37798244 5.22077895 6.98175427\n",
      " 6.07025319 5.81735371 5.64606177 5.85313335 5.50463857 4.52464146\n",
      " 6.46967293]\n",
      "\n",
      "What it should be:  [6.         6.83333333 6.83333333 5.33333333 4.         6.16666667\n",
      " 4.         4.5        4.33333333 5.5        5.33333333 6.16666667\n",
      " 5.5        6.         6.16666667 5.16666667 5.83333333 7.\n",
      " 5.16666667 7.         6.5        5.16666667 3.83333333 5.\n",
      " 5.83333333 4.33333333 6.66666667 6.         6.16666667 4.33333333\n",
      " 5.66666667 6.5        5.33333333 5.33333333 5.83333333 6.66666667\n",
      " 5.83333333 5.66666667 4.66666667 5.5        5.83333333 6.33333333\n",
      " 6.5        5.         4.83333333 6.16666667 6.16666667 6.33333333\n",
      " 6.         5.16666667 4.83333333 4.66666667 6.5        6.\n",
      " 1.83333333]\n",
      "Correlation:  [[1.         0.03503794]\n",
      " [0.03503794 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.27\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.73355233 5.67568895 6.2345051  5.53254381 5.56544625 6.49409016\n",
      " 5.43959569 6.19187627 5.54254257 6.30121666 5.91681411 4.80568479\n",
      " 5.49216175 4.82471616 5.26169622 6.531257   3.61772339 7.00846808\n",
      " 5.53510912 6.33477934 5.36253619 5.81058671 5.88387927 7.73318626\n",
      " 6.28407024 5.84957426 6.3981741  5.77429146 5.13745299 6.7131809\n",
      " 5.21194836 5.7222825  5.21122656 4.77937978 7.20517697 5.3477574\n",
      " 5.45267832 5.07281636 4.84560974 5.5689922  6.67011805 5.6783381\n",
      " 6.39237567 5.41441007 4.13982472 6.13878922 6.25639233 5.42163783\n",
      " 6.40139426 4.70693167 3.84592079 6.61981387 4.38593023 6.1332906\n",
      " 5.62389714]\n",
      "\n",
      "What it should be:  [6.16666667 6.         6.16666667 4.         5.83333333 6.16666667\n",
      " 5.5        6.         6.5        7.         4.83333333 5.33333333\n",
      " 5.5        7.         5.33333333 5.33333333 5.33333333 7.\n",
      " 4.5        5.16666667 5.         6.16666667 6.16666667 6.5\n",
      " 6.5        6.16666667 5.83333333 5.5        5.33333333 5.66666667\n",
      " 5.5        5.16666667 5.33333333 4.         6.16666667 4.83333333\n",
      " 4.83333333 3.5        5.83333333 4.83333333 5.83333333 6.16666667\n",
      " 6.5        5.5        4.66666667 5.16666667 6.16666667 1.83333333\n",
      " 6.         5.5        3.         4.66666667 4.33333333 6.33333333\n",
      " 5.16666667]\n",
      "Correlation:  [[1.         0.48109138]\n",
      " [0.48109138 1.        ]]\n",
      "Mean absolute error = 0.68\n",
      "Mean squared error = 0.88\n",
      "Median absolute error = 0.51\n",
      "Explain variance score = 0.12\n",
      "R2 score = 0.06\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.4\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.59849238 4.47035292 5.76884544 5.17149887 5.81935417 5.77344152\n",
      " 4.66225929 5.06257227 7.49001347 5.49781538 5.87841023 5.21569386\n",
      " 5.73511453 4.98948288 4.81342951 6.31843321 5.60979922 4.98907533\n",
      " 5.259948   5.31585157 6.49058829 5.46480794 5.53112239 5.99046035\n",
      " 5.02687598 5.98377371 5.09818779 4.4520137  6.37501719 4.91145937\n",
      " 5.05333761 6.15121581 6.07679903 5.09617064 6.19842508 4.57054816\n",
      " 6.67298495 5.62567    4.07760007 4.81999392 5.89868424 5.31480926\n",
      " 4.88149433 5.12612524 5.29934306 6.48140416 5.56423518 5.78100101\n",
      " 5.30654239 7.24841305 5.86342259 5.31241171 5.19963902 5.67137313\n",
      " 5.92231083 6.42905223 5.38930113 6.5514457  5.97966683 6.9973417\n",
      " 5.97675545 6.19260618 5.65021755 5.57932584 3.48554055 6.14906184\n",
      " 5.24654646 6.08068058 6.50210668 6.09091061 5.55000851 5.70336446\n",
      " 6.13255811 5.29778079]\n",
      "\n",
      "What it should be:  [4.83333333 5.5        4.         5.83333333 6.16666667 6.33333333\n",
      " 3.33333333 3.66666667 6.16666667 6.83333333 4.66666667 5.33333333\n",
      " 5.33333333 6.16666667 5.         6.33333333 4.33333333 6.33333333\n",
      " 4.33333333 5.83333333 5.83333333 4.83333333 5.5        6.33333333\n",
      " 6.         6.66666667 5.33333333 5.83333333 4.66666667 5.33333333\n",
      " 4.33333333 6.66666667 6.5        5.         6.         5.5\n",
      " 6.33333333 5.33333333 4.83333333 4.         6.33333333 4.\n",
      " 5.83333333 3.66666667 5.33333333 6.5        4.66666667 4.83333333\n",
      " 3.5        5.66666667 4.5        5.66666667 7.         5.16666667\n",
      " 6.5        5.83333333 4.5        6.33333333 5.16666667 6.\n",
      " 3.         5.66666667 6.83333333 6.83333333 5.5        6.\n",
      " 3.83333333 4.5        5.66666667 6.16666667 6.16666667 6.16666667\n",
      " 5.16666667 6.5       ]\n",
      "Correlation:  [[1.         0.28849581]\n",
      " [0.28849581 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.12\n",
      "R2 score = -0.15\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.43956881 4.99013981 4.60343718 4.8389856  4.98774874 5.43148509\n",
      " 6.07775449 5.9067068  5.46415362 5.1987697  6.14920679 5.18673656\n",
      " 6.77905389 5.42243691 3.81735749 4.51038566 5.56287131 6.14300696\n",
      " 5.24659506 3.64662497 4.383105   5.00210502 6.3382049  5.00884245\n",
      " 5.00444826 4.47935929 5.21241524 5.1119123  6.23617621 7.02934362\n",
      " 6.24387149 7.2719898  5.46362349 6.298338   5.38804305 5.04502587\n",
      " 5.85560898 5.45695684 5.69622261 5.78097317 4.90068069 6.17921018\n",
      " 6.13880054 6.51131798 6.34589744 6.23697989 5.0570368  5.79543155\n",
      " 6.64276109 4.80588391 5.57093051 5.24368497 5.33211937 6.86439907\n",
      " 5.75407365 5.06928001 5.38302832 6.15369704 5.5911893  6.23650239\n",
      " 5.89314805 6.51354518 6.00012908 5.46665402 6.75539699 5.42585508\n",
      " 6.27496212 6.18147927 5.23540523 5.97145208 5.29830552 5.54649311\n",
      " 5.39737687 6.74273358]\n",
      "\n",
      "What it should be:  [5.5        6.5        5.66666667 4.83333333 6.         6.16666667\n",
      " 5.66666667 4.83333333 5.5        5.66666667 6.5        3.66666667\n",
      " 6.5        5.83333333 5.5        6.33333333 6.16666667 6.16666667\n",
      " 5.66666667 4.5        3.66666667 6.66666667 5.33333333 5.\n",
      " 6.16666667 5.16666667 4.5        6.66666667 4.66666667 6.33333333\n",
      " 5.5        5.83333333 3.66666667 6.         4.83333333 6.\n",
      " 6.         6.16666667 5.         6.16666667 7.         5.33333333\n",
      " 4.33333333 5.33333333 5.83333333 6.         5.83333333 6.66666667\n",
      " 5.66666667 6.5        6.5        6.83333333 4.33333333 6.16666667\n",
      " 6.16666667 3.         5.83333333 5.16666667 6.         6.\n",
      " 5.33333333 6.5        6.16666667 6.16666667 6.83333333 6.\n",
      " 6.33333333 4.5        6.83333333 6.5        1.83333333 4.83333333\n",
      " 6.16666667 5.66666667]\n",
      "Correlation:  [[1.         0.19484279]\n",
      " [0.19484279 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.93521686 6.42942004 4.81634198 4.25227958 6.45944079 6.92047123\n",
      " 6.02371001 4.4842424  6.30847156 5.52292019 6.621543   5.05740104\n",
      " 6.49297641 5.34232561 5.97699858 4.14879271 6.07270426 4.29107392\n",
      " 5.613676   5.13182264 4.7035781  4.66736146 5.98450078 5.51659497\n",
      " 4.84858442 4.33003869 6.29653385 7.10397999 5.17476248 6.99768808\n",
      " 4.51977179 6.04887023 5.26015668 6.09580722 5.24426959 6.38305322\n",
      " 6.32104407 4.06058335 4.91638027 5.57581549 5.73778327 6.26513403\n",
      " 2.50044685 5.78958513 6.07040172 6.65711907 4.99647856 6.3195101\n",
      " 5.65390876 5.94563424 5.42375098 5.80642927 5.64236657 5.4915385\n",
      " 6.05616701 5.88938074 4.38472865 5.14288303 6.0406976  5.79429557\n",
      " 4.42490955 6.03820325 4.82030757 5.38214607 5.64348557 5.77375205\n",
      " 4.87731481 5.7227442  4.6051862  5.57768854 6.74381649 5.52244474\n",
      " 4.9224172  3.63273039]\n",
      "\n",
      "What it should be:  [6.66666667 4.5        6.66666667 4.66666667 6.66666667 5.83333333\n",
      " 6.83333333 6.16666667 6.         6.5        4.         5.66666667\n",
      " 6.5        6.16666667 6.66666667 6.83333333 5.33333333 6.16666667\n",
      " 7.         4.66666667 5.66666667 4.83333333 6.33333333 5.33333333\n",
      " 6.16666667 4.5        6.16666667 5.66666667 6.33333333 5.16666667\n",
      " 5.5        6.         4.         5.83333333 6.         5.16666667\n",
      " 6.16666667 6.5        5.5        6.16666667 6.66666667 6.\n",
      " 5.5        6.5        6.         6.16666667 4.         5.16666667\n",
      " 6.16666667 4.66666667 4.16666667 5.33333333 6.5        4.83333333\n",
      " 5.33333333 5.66666667 4.         6.16666667 5.         6.16666667\n",
      " 4.5        6.83333333 6.33333333 5.         4.66666667 7.\n",
      " 3.66666667 5.66666667 5.5        3.66666667 6.66666667 5.83333333\n",
      " 5.5        3.66666667]\n",
      "Correlation:  [[1.         0.21051935]\n",
      " [0.21051935 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.52\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.36884586 5.03943983 5.37466438 5.63628056 5.50095862 6.24493327\n",
      " 6.23955832 4.95234548 6.49150401 6.21125522 4.95251045 5.50915503\n",
      " 5.82789101 6.3770104  4.8143581  5.62993067 5.56546392 5.89862651\n",
      " 5.31211513 6.44968432 5.26704091 6.55893048 6.16305224 5.68084792\n",
      " 5.25084027 5.86147235 5.7894885  4.79381487 6.63038627 5.55394337\n",
      " 7.08357046 5.71996699 5.40761139 6.03588031 5.56329618 6.71648249\n",
      " 5.29025622 6.69301385 6.63865204 5.83992547 5.775052   6.00785243\n",
      " 5.40113194 5.74634633 5.27347387 5.70348876 5.35847561 6.14203849\n",
      " 5.39150484 5.99392593 6.50059816 5.4735169  5.42961547 5.62059511\n",
      " 6.15670956 5.02260456 5.16218119 7.21387432 4.74508727 5.73618093\n",
      " 5.52801212 6.37165567 6.66581395 5.52099194 5.38451328 5.10949048\n",
      " 5.78558183 3.99339779 5.32335973 6.4065429  4.77632326 5.03793491\n",
      " 5.56110335 6.55904182]\n",
      "\n",
      "What it should be:  [3.         6.16666667 6.5        5.66666667 6.5        7.\n",
      " 6.16666667 1.83333333 4.66666667 4.         4.66666667 6.\n",
      " 4.66666667 5.5        4.83333333 5.66666667 6.         6.16666667\n",
      " 5.83333333 5.16666667 4.33333333 6.5        5.33333333 5.5\n",
      " 5.66666667 6.16666667 6.16666667 6.83333333 4.83333333 5.5\n",
      " 5.66666667 5.         5.83333333 5.16666667 6.         4.33333333\n",
      " 5.33333333 5.66666667 6.83333333 4.66666667 4.         6.16666667\n",
      " 4.         6.16666667 6.5        3.33333333 3.83333333 5.33333333\n",
      " 6.5        4.66666667 6.5        6.5        5.83333333 3.66666667\n",
      " 5.33333333 6.         6.         6.16666667 3.5        5.66666667\n",
      " 5.83333333 6.5        6.33333333 5.         4.83333333 6.33333333\n",
      " 5.83333333 5.5        5.33333333 6.33333333 5.5        6.16666667\n",
      " 4.5        6.5       ]\n",
      "Correlation:  [[1.        0.1849097]\n",
      " [0.1849097 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -0.14\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.05280702 4.22485887 5.04059497 2.9701782  4.28405892 6.14116752\n",
      " 5.1562112  4.91540095 5.24658671 6.2247228  4.7587297  5.91489355\n",
      " 4.14389927 5.80087057 6.64926431 5.93644648 6.2806233  6.47269636\n",
      " 4.82956011 5.20349223 6.14975589 6.53748645 4.46688614 5.52690005\n",
      " 5.33394391 5.58654598 6.09264778 5.50827501 6.08663657 5.41077108\n",
      " 6.35189334 6.24854287 5.30069569 5.50998723 4.29589825 6.07442584\n",
      " 6.61426115 6.07360503 4.75478064 5.30268766 6.97298143 6.78963064\n",
      " 5.68464101 6.59136771 4.44093907 6.22740352 5.64325685 4.6831369\n",
      " 5.61170781 4.40915997 5.4946313  4.17484253 5.6462351  6.50757582\n",
      " 5.64911395 4.7037158  4.90709998 3.08263235 3.8271993  5.78813946\n",
      " 5.98093958 4.59156303 5.19280272 6.25563966 5.24711828 6.31997544\n",
      " 5.878027   4.46907122 4.68188138 4.65144659 5.23525725 6.36083937\n",
      " 5.78942758 5.90623865]\n",
      "\n",
      "What it should be:  [5.33333333 6.16666667 6.33333333 4.66666667 5.83333333 5.83333333\n",
      " 6.16666667 6.33333333 6.5        4.66666667 5.83333333 6.\n",
      " 4.83333333 5.66666667 5.33333333 4.5        6.66666667 6.16666667\n",
      " 6.33333333 6.5        5.83333333 6.33333333 6.33333333 3.66666667\n",
      " 6.5        6.16666667 6.         6.         6.66666667 6.66666667\n",
      " 6.16666667 5.66666667 4.83333333 5.         7.         6.5\n",
      " 6.5        6.16666667 4.66666667 6.5        6.5        5.16666667\n",
      " 5.16666667 6.66666667 6.16666667 5.16666667 5.16666667 5.5\n",
      " 5.66666667 6.5        6.         4.         5.16666667 5.16666667\n",
      " 6.83333333 6.16666667 6.83333333 5.5        6.         5.33333333\n",
      " 5.         7.         6.66666667 5.83333333 5.33333333 5.33333333\n",
      " 5.33333333 6.16666667 5.5        6.         6.5        6.16666667\n",
      " 5.66666667 5.33333333]\n",
      "Correlation:  [[1.         0.03175927]\n",
      " [0.03175927 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.34\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -1.36\n",
      "R2 score = -1.68\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.14335978 5.31474374 5.65301985 5.58523796 5.43251856 5.7782727\n",
      " 5.94201907 6.63519736 5.7785497  3.9547574  4.9059797  5.04082266\n",
      " 6.64274536 5.30763154 5.87929659 5.06815678 7.29017028 4.27499292\n",
      " 4.8645732  6.42585682 5.24800192 5.70492609 6.02692227 5.95790266\n",
      " 5.71430382 5.94097406 6.45807108 7.32444012 4.84895338 6.02889777\n",
      " 7.2928676  5.09935965 4.84346813 4.98960161 5.46905314 4.90449219\n",
      " 6.27136815 5.13574912 6.76866165 5.79902375 6.58002233 5.02431117\n",
      " 5.03088297 5.76756654 6.99431194 6.3401205  4.54157812 3.75732654\n",
      " 5.10260804 5.31606325 4.74976958 6.37442574 4.70373388 5.18674366\n",
      " 4.82319128 5.10306612 5.90961281 4.52366043 5.8024167  5.14419466\n",
      " 4.5763768  6.7891015  6.39257705 5.69918374 6.1688899  4.30214779\n",
      " 5.87155191 6.96292803 6.91517046 5.27770646 7.17021156 5.47073083\n",
      " 5.15921709 4.94095646]\n",
      "\n",
      "What it should be:  [6.16666667 3.66666667 5.66666667 6.16666667 4.83333333 5.83333333\n",
      " 6.5        6.         6.16666667 4.83333333 6.66666667 4.\n",
      " 7.         6.5        7.         4.83333333 6.16666667 7.\n",
      " 5.83333333 6.         5.66666667 4.5        5.83333333 5.16666667\n",
      " 6.33333333 4.33333333 4.66666667 5.66666667 5.83333333 6.5\n",
      " 5.33333333 5.5        6.5        5.83333333 5.33333333 3.5\n",
      " 6.83333333 3.33333333 3.         4.5        5.66666667 6.16666667\n",
      " 4.66666667 5.5        6.33333333 6.33333333 6.83333333 4.83333333\n",
      " 5.16666667 4.66666667 6.5        6.83333333 4.83333333 5.66666667\n",
      " 6.33333333 6.         6.         4.33333333 6.16666667 4.66666667\n",
      " 4.83333333 5.83333333 7.         4.         5.16666667 5.83333333\n",
      " 5.16666667 6.5        4.33333333 6.83333333 6.33333333 7.\n",
      " 6.         4.33333333]\n",
      "Correlation:  [[1.         0.16061547]\n",
      " [0.16061547 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.38\n",
      "Median absolute error = 0.84\n",
      "Explain variance score = -0.47\n",
      "R2 score = -0.47\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.54380629 5.14493843 5.98137063 5.98070898 5.26588736 4.18952245\n",
      " 5.39914937 5.48677232 5.82283302 5.73982429 4.83021682 5.13854345\n",
      " 5.90942699 6.6607518  5.33810234 5.07324665 6.14280267 5.45621625\n",
      " 5.14558677 5.87770623 5.72181979 5.49173601 5.14298629 6.08794206\n",
      " 7.30685956 6.07704203 5.64765412 6.27047214 4.59557525 5.44621341\n",
      " 5.92630335 4.97927105 6.11391399 7.10419339 6.6299607  5.17263385\n",
      " 5.97240816 6.26622624 6.60420698 6.43204462 5.65125396 5.64661392\n",
      " 3.91130128 5.34476002 5.0100414  6.10545611 5.26689903 5.48034289\n",
      " 4.53680116 6.0534432  5.48902298 5.0998796  5.50132473 5.65441906\n",
      " 4.90633605 5.92604378 5.36687042 5.84047382 5.86415461 6.10351045\n",
      " 6.68115852 5.92827973 5.89770436 4.67128123 5.68743306 5.46215215\n",
      " 4.08430137 5.23792605 5.05196345 5.14965791 5.58498619 4.26132215\n",
      " 4.88436265 6.47052827]\n",
      "\n",
      "What it should be:  [6.83333333 6.33333333 6.16666667 5.66666667 6.5        6.83333333\n",
      " 6.5        6.         5.5        6.         5.5        4.66666667\n",
      " 5.33333333 6.66666667 5.5        4.         5.16666667 4.\n",
      " 6.16666667 5.5        6.66666667 6.66666667 6.16666667 5.16666667\n",
      " 6.5        6.         5.83333333 4.83333333 6.16666667 6.83333333\n",
      " 5.5        7.         6.66666667 6.33333333 6.5        4.5\n",
      " 5.33333333 5.83333333 5.16666667 6.         5.83333333 5.33333333\n",
      " 6.         4.66666667 4.5        6.16666667 5.         6.83333333\n",
      " 4.83333333 6.33333333 6.5        4.         7.         5.16666667\n",
      " 5.66666667 6.33333333 3.66666667 5.83333333 4.33333333 6.\n",
      " 7.         6.16666667 6.83333333 6.33333333 3.5        3.\n",
      " 6.         5.16666667 3.66666667 5.83333333 6.66666667 5.33333333\n",
      " 4.33333333 6.5       ]\n",
      "Correlation:  [[1.         0.19365775]\n",
      " [0.19365775 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.21\n",
      "R2 score = -0.23\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.72966573 4.66608886 5.92925291 6.66578639 6.23121712 4.40372587\n",
      " 6.16759591 6.84400641 4.31893911 5.61669018 6.04090036 6.55376912\n",
      " 6.80857378 6.14949576 6.2374921  6.70746341 4.89608425 4.94155401\n",
      " 3.51109826 5.50842952 6.42361705 5.9544034  6.40624615 6.0543724\n",
      " 4.29864236 6.56699756 4.63273859 5.70377935 5.93136734 6.03488409\n",
      " 4.71919731 5.80944209 5.35458914 6.06963542 5.5276009  6.78309376\n",
      " 4.23665912 5.1592349  4.37840049 4.113407   5.79795589 5.77092775\n",
      " 6.14733003 5.74681588 4.58174069 5.72858926 5.60035627 7.83718245\n",
      " 6.2652764  6.73904241 5.41763618 5.39226975 6.58768688 6.79044769\n",
      " 6.3251407  5.95600095 4.93561751 5.4166236  5.35299129 5.63745785\n",
      " 5.76206482 5.60991789 6.38357705 5.94574546 5.53747232 6.6257595\n",
      " 5.33437953 2.98677941 5.41069714 6.00085275 7.25010441 6.27247846\n",
      " 5.96941992 6.90963709]\n",
      "\n",
      "What it should be:  [4.16666667 6.16666667 5.33333333 6.33333333 6.16666667 5.33333333\n",
      " 4.66666667 6.5        6.5        3.         5.83333333 5.66666667\n",
      " 6.66666667 5.83333333 6.5        6.33333333 4.83333333 4.66666667\n",
      " 4.         5.83333333 6.5        5.5        6.83333333 6.16666667\n",
      " 5.16666667 5.16666667 6.83333333 6.16666667 5.         5.16666667\n",
      " 5.5        5.83333333 4.83333333 6.83333333 4.83333333 5.66666667\n",
      " 6.16666667 6.         6.83333333 4.83333333 5.         5.33333333\n",
      " 6.         6.16666667 4.5        6.         3.83333333 7.\n",
      " 5.33333333 5.83333333 5.5        5.33333333 6.5        4.\n",
      " 5.66666667 6.         4.         6.16666667 6.16666667 5.5\n",
      " 6.33333333 5.5        6.         5.33333333 6.         7.\n",
      " 6.5        5.5        5.         4.83333333 5.33333333 5.66666667\n",
      " 6.16666667 6.66666667]\n",
      "Correlation:  [[1.         0.27819199]\n",
      " [0.27819199 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 1.04\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.52\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.12309018 6.02908898 6.07868312 5.88996076 5.29166871 5.03253403\n",
      " 5.3044887  5.67153013 6.10459521 6.23460452 5.72605921 4.96928057\n",
      " 5.86179496 5.39974187 5.1574285  3.0474386  5.25087323 6.46528612\n",
      " 5.23623254 6.86540235 4.35051982 5.23100664 6.62775218 6.63019117\n",
      " 5.39900696 5.63486072 4.94562496 5.6804098  5.05064858 5.53621545\n",
      " 5.41505774 5.55203068 5.30907318 4.62891714 6.48487242 5.14883848\n",
      " 6.47719514 6.73311106 5.01950775 5.38661086 5.41869977 6.2336831\n",
      " 5.20999073 5.50675929 5.95263561 6.04744729 4.55833859 5.79920908\n",
      " 5.68407381 5.07278043 6.05769584 4.79772427 5.53016318 5.70277001\n",
      " 5.76347269 6.30255677 6.73702519 5.19623916 5.28570681 6.87608244\n",
      " 5.85588762 5.61300928 5.59550951 6.6913063  5.7822433  5.39237459\n",
      " 6.53504044 5.9274393  5.54042365 5.66812118 3.97322644 5.02339679\n",
      " 5.50839989 6.39366043]\n",
      "\n",
      "What it should be:  [3.         4.33333333 6.         6.16666667 5.83333333 6.16666667\n",
      " 6.5        5.33333333 6.66666667 5.33333333 1.83333333 5.5\n",
      " 6.16666667 6.         6.66666667 5.5        5.83333333 4.83333333\n",
      " 7.         5.66666667 5.33333333 5.33333333 6.83333333 5.33333333\n",
      " 5.33333333 6.         4.5        6.66666667 6.33333333 5.\n",
      " 4.66666667 4.66666667 6.5        3.66666667 6.16666667 4.83333333\n",
      " 5.16666667 5.66666667 4.5        3.66666667 5.66666667 6.16666667\n",
      " 6.83333333 6.66666667 5.5        5.83333333 5.         5.5\n",
      " 5.83333333 4.33333333 4.66666667 6.33333333 6.83333333 6.16666667\n",
      " 5.83333333 4.5        4.66666667 3.33333333 3.66666667 5.\n",
      " 5.83333333 5.83333333 5.16666667 6.5        5.66666667 5.\n",
      " 5.66666667 5.83333333 5.83333333 6.83333333 4.33333333 4.83333333\n",
      " 6.16666667 6.5       ]\n",
      "Correlation:  [[1.         0.11382528]\n",
      " [0.11382528 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.88418969 4.3411067  4.8123057  5.78763016 5.33539296 5.15125771\n",
      " 5.04227725 5.97124932 5.51320276 4.53362215 6.22489193 5.57202301\n",
      " 6.71657691 4.53412464 5.32131198 5.13935988 5.59823707 5.89572278\n",
      " 6.2586089  5.88192204 6.28221136 4.9491069  4.55993234 5.29636537\n",
      " 5.1072873  4.69688532 5.45054306 4.99735978 4.17668429 4.80999886\n",
      " 4.26967855 5.70739621 5.17611056 5.09629559 6.07449358 5.81176616\n",
      " 6.16178138 4.10926737 4.98744821 6.24367051 6.24154784 5.08892222\n",
      " 5.20445387 6.17283421 5.5190489  6.71102938 5.88274288 5.93959855\n",
      " 5.16293846 5.9654153  5.19737275 4.38966665 6.6907577  5.45136421\n",
      " 5.36104458 5.23659432 5.62328205 6.51984039 6.27352281 4.72843266\n",
      " 6.50326282 4.8681678  7.78872618 6.53116462 4.69398971 6.75512143\n",
      " 5.60783753 5.68207124 5.95955149 5.72105318 6.29342304 4.11748376\n",
      " 4.53831963 3.54936491]\n",
      "\n",
      "What it should be:  [6.83333333 3.66666667 4.5        6.5        5.66666667 5.83333333\n",
      " 4.5        6.16666667 5.         6.33333333 6.83333333 5.66666667\n",
      " 6.16666667 5.83333333 6.         6.16666667 6.83333333 6.5\n",
      " 6.         6.83333333 6.83333333 5.5        3.66666667 4.\n",
      " 5.83333333 5.5        6.         4.83333333 6.33333333 7.\n",
      " 5.5        6.5        6.16666667 6.5        6.66666667 5.\n",
      " 6.16666667 4.66666667 4.83333333 5.33333333 5.33333333 6.66666667\n",
      " 6.66666667 4.66666667 5.         5.83333333 5.16666667 5.33333333\n",
      " 6.         6.16666667 6.83333333 5.33333333 6.         6.5\n",
      " 4.83333333 4.83333333 7.         5.83333333 5.16666667 4.\n",
      " 5.83333333 7.         6.5        6.33333333 6.         4.66666667\n",
      " 6.33333333 6.16666667 6.66666667 5.33333333 4.         5.16666667\n",
      " 5.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.20022673]\n",
      " [0.20022673 1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.46\n",
      "R2 score = -0.57\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.6384995  4.99067645 5.51362191 7.41984308 5.75659168 6.20536448\n",
      " 5.34228821 5.85381978 6.36859331 4.15812428 6.42834558 6.0366627\n",
      " 5.88394078 5.88590299 5.02325193 5.37496467 4.00873871 6.17086064\n",
      " 6.33373303 4.91554913 5.55208066 5.80767591 6.03955819 5.91523687\n",
      " 5.30386709 5.63399969 5.47636083 5.33965792 5.70074082 5.69482356\n",
      " 5.69475423 5.63381848 6.5508202  5.92401621 5.10752877 6.14317955\n",
      " 5.90943989 4.48269014 6.27187174 5.84785629 5.66271295 5.7048579\n",
      " 4.5672841  4.1639791  4.89183197 6.35771401 5.99877425 5.85579677\n",
      " 4.83321756 5.53127072 5.38958402 5.81455709 5.64038676 4.74102426\n",
      " 5.53524318 5.78858026 5.22118673 6.3794088  6.22415691 5.64425778\n",
      " 6.21906259 5.28520521 4.89638236 7.05221449 6.36103245 5.08989659\n",
      " 6.34083735 6.15492586 5.67722968 5.3833976  5.76152996 5.35190804\n",
      " 5.88683538 5.89041804]\n",
      "\n",
      "What it should be:  [6.66666667 6.66666667 6.16666667 6.5        5.33333333 5.\n",
      " 5.5        1.83333333 4.66666667 4.33333333 4.         6.\n",
      " 5.5        6.66666667 5.         5.83333333 5.5        5.33333333\n",
      " 4.83333333 5.5        5.16666667 6.66666667 5.83333333 6.5\n",
      " 5.33333333 5.         6.         6.5        6.         6.33333333\n",
      " 6.5        6.16666667 6.33333333 5.33333333 6.5        6.83333333\n",
      " 4.16666667 4.         5.33333333 5.         5.33333333 6.16666667\n",
      " 6.16666667 4.5        6.33333333 6.5        5.66666667 6.16666667\n",
      " 6.16666667 6.16666667 5.83333333 6.66666667 6.5        4.33333333\n",
      " 5.83333333 5.33333333 4.5        4.66666667 6.16666667 7.\n",
      " 3.33333333 4.66666667 4.66666667 5.83333333 5.83333333 5.83333333\n",
      " 6.16666667 6.66666667 6.         4.33333333 5.5        6.83333333\n",
      " 6.16666667 4.83333333]\n",
      "Correlation:  [[1.         0.12394364]\n",
      " [0.12394364 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.90724476 5.64933751 5.79404688 4.62337341 5.93883787 5.64807082\n",
      " 5.62708278 7.19572154 6.9895584  5.95321413 4.95406783 5.97174452\n",
      " 6.6808044  4.46199731 5.17878395 7.24414217 6.25729298 6.62856275\n",
      " 4.30963569 5.89073992 4.90835881 5.74690663 7.09588508 4.72119747\n",
      " 6.62749099 4.96137474 5.96146998 4.76476758 5.21589943 6.23872931\n",
      " 5.64356975 3.47041203 6.36262852 6.36774432 4.60468729 5.9017045\n",
      " 6.23893824 4.61855154 5.42727537 5.39883399 5.48047281 4.94288067\n",
      " 6.29638093 6.35553732 5.43847876 3.46820084 6.8093847  5.9963788\n",
      " 6.52598679 6.71928686 6.08453336 5.05988823 1.51458664 6.42223396\n",
      " 5.70779491 4.15792535 6.89381216 6.16304549 5.44775463 7.18919687\n",
      " 5.1294838  5.59881784 4.66816453 5.87785602 5.51000069 6.15112796\n",
      " 4.89244254 5.92903878 5.31907336 5.24670307 5.04461156 5.64121168\n",
      " 5.28120099 4.82070999]\n",
      "\n",
      "What it should be:  [4.5        4.66666667 5.33333333 3.66666667 6.         6.16666667\n",
      " 5.83333333 6.16666667 6.33333333 6.         6.         6.83333333\n",
      " 5.66666667 4.83333333 5.5        6.33333333 4.         4.66666667\n",
      " 5.         4.83333333 6.33333333 5.66666667 5.33333333 4.33333333\n",
      " 6.         4.66666667 6.16666667 6.16666667 5.66666667 4.\n",
      " 5.33333333 4.         6.         6.83333333 5.33333333 6.\n",
      " 4.5        4.         6.66666667 4.         5.         6.33333333\n",
      " 5.33333333 5.83333333 5.16666667 4.83333333 7.         5.16666667\n",
      " 6.16666667 5.16666667 5.66666667 6.5        5.5        5.66666667\n",
      " 6.66666667 6.16666667 5.66666667 5.66666667 6.         5.16666667\n",
      " 6.         5.         3.         6.16666667 6.16666667 6.33333333\n",
      " 5.33333333 6.16666667 5.16666667 4.5        5.66666667 5.33333333\n",
      " 4.16666667 6.16666667]\n",
      "Correlation:  [[1.         0.26731156]\n",
      " [0.26731156 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.69\n",
      "R2 score = -0.71\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.86786748 5.62040127 5.69865317 5.99997266 6.66107106 6.24345329\n",
      " 5.51371818 5.25874156 5.07015754 5.0207175  5.66092313 5.68188726\n",
      " 4.22832675 5.51565026 5.78302021 6.10807066 5.68571982 6.63683077\n",
      " 6.5532226  5.0183619  5.62105892 4.14422337 5.81403456 5.33050687\n",
      " 3.07929295 5.87471222 6.23765197 5.87135232 5.714      4.31238182\n",
      " 5.72867255 5.29188972 6.41795997 6.37339539 5.76974665 6.86987764\n",
      " 5.73715902 6.66134583 6.52408201 5.44382739 5.87931835 5.29680309\n",
      " 5.61418199 5.02618962 5.14061286 5.6635302  5.67356263 4.56116676\n",
      " 4.62906074 5.05526008 5.45181956 5.30485546 4.28080852 5.74393098\n",
      " 4.46085506 5.38199424 5.77408689 5.56429872 5.32531224 5.7320218\n",
      " 5.04830305 5.73604402 6.55365655 5.85188817 5.39583294 4.34568011\n",
      " 5.08149354 5.27496953 6.44178105 5.09910072 4.85647475 7.04765945\n",
      " 5.8518702  5.17331721]\n",
      "\n",
      "What it should be:  [5.33333333 5.83333333 4.         6.66666667 6.16666667 5.66666667\n",
      " 6.83333333 5.33333333 7.         6.5        5.5        5.33333333\n",
      " 6.16666667 5.33333333 4.83333333 6.66666667 5.33333333 4.\n",
      " 6.16666667 5.83333333 4.33333333 5.16666667 5.33333333 5.5\n",
      " 5.5        6.5        6.         6.16666667 4.66666667 4.66666667\n",
      " 6.16666667 5.83333333 4.5        5.33333333 6.66666667 6.33333333\n",
      " 5.83333333 6.5        5.16666667 4.83333333 6.66666667 4.83333333\n",
      " 5.         5.33333333 6.         3.         6.83333333 6.83333333\n",
      " 6.33333333 4.33333333 5.66666667 5.33333333 3.66666667 5.16666667\n",
      " 6.83333333 5.5        6.66666667 3.33333333 5.         6.\n",
      " 3.66666667 5.5        6.16666667 6.66666667 5.83333333 6.5\n",
      " 6.16666667 5.33333333 5.16666667 6.5        5.16666667 7.\n",
      " 6.         6.5       ]\n",
      "Correlation:  [[1.         0.08101695]\n",
      " [0.08101695 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.47\n",
      "R2 score = -0.48\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.91467088 5.77723636 5.60562009 6.44497606 5.41254264 5.57908031\n",
      " 5.79325853 6.33332468 5.11429868 5.72357    4.94925274 5.67225611\n",
      " 3.09809661 4.27367893 5.92699091 5.32744943 6.2218213  7.16549094\n",
      " 5.41266655 5.55926631 6.46992545 5.08614369 6.53491079 5.90952731\n",
      " 4.63195383 5.73721201 5.32804446 6.00963695 5.23599243 4.94892573\n",
      " 5.71784861 5.18239876 5.64274047 5.1005677  4.46527921 6.04431638\n",
      " 5.22362455 6.85564451 6.09816245 5.97605673 6.63291116 5.30503439\n",
      " 5.3226569  5.89665204 5.49637858 5.97917631 5.4956089  5.03422396\n",
      " 6.24976501 6.64006116 5.27653962 5.68769587 6.07304416 5.00263561\n",
      " 5.42030486 5.55582643 6.59515814 5.12069088 4.41613084 6.3288224\n",
      " 4.55103173 6.8367566  5.85667604 6.23872714 5.75441089 6.07219119\n",
      " 6.08606398 6.06206521 5.88249592 5.16995957 5.83928199 6.95391213\n",
      " 5.67644839 5.53913555]\n",
      "\n",
      "What it should be:  [5.5        6.33333333 6.66666667 5.33333333 6.16666667 6.5\n",
      " 3.5        7.         4.83333333 4.66666667 4.33333333 5.5\n",
      " 5.5        5.66666667 6.83333333 6.16666667 6.33333333 3.\n",
      " 6.16666667 6.33333333 4.66666667 6.16666667 5.83333333 5.33333333\n",
      " 4.83333333 5.33333333 6.16666667 6.         4.83333333 7.\n",
      " 5.16666667 6.         5.83333333 6.5        6.5        6.66666667\n",
      " 6.16666667 6.83333333 6.33333333 5.83333333 5.33333333 3.66666667\n",
      " 6.5        5.33333333 6.         5.66666667 5.33333333 6.5\n",
      " 6.         5.16666667 5.83333333 4.83333333 4.16666667 6.\n",
      " 5.5        6.5        6.16666667 3.83333333 6.33333333 5.33333333\n",
      " 6.66666667 5.66666667 4.5        5.66666667 6.         6.16666667\n",
      " 6.5        5.66666667 6.16666667 4.66666667 5.16666667 4.\n",
      " 5.83333333 6.16666667]\n",
      "Correlation:  [[ 1.         -0.13935645]\n",
      " [-0.13935645  1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.85\n",
      "R2 score = -0.85\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.07006803 5.04317451 6.32770738 6.1864633  5.95102927 5.92059441\n",
      " 6.57090732 5.73370354 6.32205519 6.63547005 5.22936788 5.97752829\n",
      " 5.67883832 5.21788855 5.47592575 4.26443259 6.10970151 5.42608484\n",
      " 6.03230718 5.76623121 5.65817432 5.1223766  5.78047827 4.70222194\n",
      " 6.21748016 4.75313808 4.03315142 7.34586395 5.36836593 6.69868619\n",
      " 5.67111751 5.13971507 6.29930767 5.69654331 6.39888023 6.12010907\n",
      " 6.38634392 6.56686792 5.84467469 5.43271864 6.76198966 5.96637511\n",
      " 5.99430809 5.66328304 5.06442454 5.2876347  5.05757555 5.15537914\n",
      " 6.34746225 5.22900495 6.4549082  5.44187752 5.18781222 5.91211065\n",
      " 4.66411696 5.61587005 5.91364044 5.28918898 5.60886564 5.3158036\n",
      " 5.78865595 5.87233613 5.86987086 6.40922452 6.24691812 6.14106964\n",
      " 6.2806376  6.43389699 5.88974501 5.42343785 5.79406015 6.52824847\n",
      " 5.79864879 5.55077831]\n",
      "\n",
      "What it should be:  [6.66666667 4.33333333 6.5        5.83333333 5.66666667 4.66666667\n",
      " 5.33333333 6.         4.83333333 6.5        6.16666667 5.66666667\n",
      " 3.66666667 6.5        4.83333333 6.5        6.33333333 5.\n",
      " 5.66666667 1.83333333 7.         6.16666667 5.83333333 5.\n",
      " 5.16666667 6.5        4.83333333 5.66666667 4.66666667 5.16666667\n",
      " 5.83333333 5.33333333 6.16666667 4.66666667 6.33333333 6.83333333\n",
      " 6.33333333 4.66666667 5.33333333 5.5        6.5        4.83333333\n",
      " 5.83333333 6.83333333 6.         6.33333333 6.16666667 4.\n",
      " 6.16666667 4.33333333 6.16666667 6.         5.66666667 5.16666667\n",
      " 4.5        6.16666667 6.         6.5        5.16666667 6.33333333\n",
      " 5.66666667 4.66666667 6.83333333 4.16666667 6.66666667 6.16666667\n",
      " 6.83333333 6.5        5.         5.5        6.83333333 5.83333333\n",
      " 6.16666667 6.83333333]\n",
      "Correlation:  [[1.         0.13363819]\n",
      " [0.13363819 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 1.05\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.73111936 5.96188331 6.09051668 6.12226393 5.23326898 4.9568577\n",
      " 5.675736   5.64918879 4.72795587 4.63718995 5.62674249 4.10268936\n",
      " 4.55570557 5.21340259 3.22414036 5.19679493 4.9336441  6.22347935\n",
      " 4.85127578 5.30589232 4.79707219 5.82616592 5.42590148 5.37583983\n",
      " 5.95593574 5.43274729 6.14636043 5.3392295  5.61051499 5.49618744\n",
      " 5.18950991 6.09778387 3.98236068 4.76273336 6.2803437  4.87394228\n",
      " 4.26337516 5.67213615 5.89140226 6.03402432 4.54864364 5.58361462\n",
      " 4.84341805 4.80862017 4.6833511  5.92823433 5.0813777  5.36367767\n",
      " 6.0461444  4.5806847  4.62548538 4.48520286 5.14745512 5.72011283\n",
      " 5.15326576 4.95699991 5.45006541 5.22747613 5.0870304  5.7080317\n",
      " 5.65020151 6.90971536 6.04958017 6.30482825 4.83016325 5.72289175\n",
      " 5.55832919 5.62023623 6.242518   5.11951184 5.35638344 5.54298307\n",
      " 5.36615481 6.44043833]\n",
      "\n",
      "What it should be:  [6.         6.83333333 6.33333333 5.66666667 6.5        5.5\n",
      " 5.16666667 5.83333333 4.83333333 5.33333333 6.5        6.16666667\n",
      " 5.16666667 1.83333333 4.5        6.66666667 5.         6.66666667\n",
      " 6.16666667 6.         6.83333333 6.5        5.         4.\n",
      " 6.         6.83333333 6.5        4.         6.33333333 6.16666667\n",
      " 3.66666667 6.33333333 6.33333333 5.5        5.33333333 6.5\n",
      " 6.         6.16666667 5.66666667 5.83333333 3.66666667 6.33333333\n",
      " 5.         4.33333333 5.16666667 6.         5.66666667 4.\n",
      " 6.16666667 5.5        7.         5.33333333 4.83333333 4.66666667\n",
      " 5.83333333 3.5        5.33333333 6.83333333 3.66666667 4.83333333\n",
      " 4.         6.5        6.         6.83333333 6.5        5.\n",
      " 4.83333333 6.16666667 6.         6.5        4.66666667 4.5\n",
      " 6.66666667 6.5       ]\n",
      "Correlation:  [[1.         0.24637787]\n",
      " [0.24637787 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.08\n",
      "R2 score = -0.13\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.83970628 5.04749968 5.18404    5.71735643 6.08833861 6.72962314\n",
      " 7.12375307 4.67765681 6.69796975 6.0456164  4.79485868 5.69248189\n",
      " 5.56774419 4.72120619 4.19607616 5.03835915 4.64509895 6.17223594\n",
      " 4.65563012 6.22459349 5.75900693 6.228454   5.31453878 5.52469126\n",
      " 5.16032751 7.78347512 4.07528692 5.21212479 4.40674236 7.40164025\n",
      " 4.92103688 6.46507353 5.02657824 3.43575923 4.97208074 7.08661892\n",
      " 6.07398102 5.72275671 4.19622079 6.42442952 5.8445156  6.04972285\n",
      " 6.0385221  5.46433253 5.41378936 6.95677332 4.89584767 6.2875769\n",
      " 6.26330712 6.25852103 4.77745566 6.48325971 6.51651391 5.55759527\n",
      " 4.80777369 5.05321707 7.17624165 6.01740143 5.34473207 6.25133411\n",
      " 5.64513559 5.97641741 5.35590041 6.89059541 5.2622201  5.92937795\n",
      " 4.08211245 4.8933167  5.75649475 6.01334958 5.80822365 6.3804069\n",
      " 6.49723422 5.85271931]\n",
      "\n",
      "What it should be:  [5.83333333 4.33333333 6.33333333 5.66666667 6.33333333 4.66666667\n",
      " 5.33333333 4.83333333 6.5        5.         6.16666667 6.\n",
      " 4.66666667 4.83333333 6.         5.5        3.83333333 4.5\n",
      " 4.5        6.16666667 3.66666667 6.         6.16666667 6.16666667\n",
      " 6.16666667 6.33333333 6.33333333 6.33333333 4.         5.83333333\n",
      " 6.16666667 5.66666667 6.5        4.66666667 5.         6.16666667\n",
      " 6.         4.83333333 5.         6.16666667 6.         6.5\n",
      " 6.16666667 5.33333333 5.83333333 5.33333333 5.5        5.66666667\n",
      " 6.         4.66666667 4.66666667 5.33333333 5.33333333 4.5\n",
      " 5.33333333 5.83333333 6.         6.5        6.         6.83333333\n",
      " 5.5        5.16666667 6.16666667 5.83333333 4.83333333 6.66666667\n",
      " 7.         5.83333333 5.66666667 5.33333333 4.83333333 6.33333333\n",
      " 6.83333333 6.16666667]\n",
      "Correlation:  [[1.        0.2319229]\n",
      " [0.2319229 1.       ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.01\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.8\n",
      "R2 score = -0.81\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.00604157 6.34964697 7.12331104 5.27547495 5.70278923 5.36786948\n",
      " 3.92768161 6.4875499  5.2188904  5.04595311 6.46015428 4.63844375\n",
      " 5.94971496 5.00530671 5.53032603 6.70153991 5.82556873 6.09185771\n",
      " 4.02986987 6.01177407 5.91041164 4.79086785 5.79685711 5.47721634\n",
      " 5.57090607 5.27565929 5.23647979 6.41817206 6.04104759 5.46612097\n",
      " 5.60984481 6.33578646 6.67865481 6.229695   4.97230461 5.39443586\n",
      " 5.85039137 5.71377254 6.42244627 5.03821881 6.02203125 6.12211169\n",
      " 4.85926303 6.05624576 5.69522045 7.13849077 5.46023026 6.47897148\n",
      " 5.54822893 5.67604246 4.53380039 2.4693777  5.4227774  5.25025994\n",
      " 6.2497749  6.56542015 4.06842263 5.61878058 6.04512039 4.66404902\n",
      " 4.93905506 5.45752232 6.1770717  5.99090896 5.24836613 5.14392025\n",
      " 4.74024519 6.01761891 5.39692029 5.57497271 5.40453545 6.57471564\n",
      " 5.0946031  6.1522805 ]\n",
      "\n",
      "What it should be:  [4.33333333 5.83333333 6.16666667 5.33333333 6.5        5.5\n",
      " 5.66666667 5.33333333 5.33333333 4.66666667 4.         6.66666667\n",
      " 5.66666667 5.         6.66666667 4.         6.16666667 6.83333333\n",
      " 6.5        6.16666667 4.33333333 6.5        3.66666667 5.83333333\n",
      " 5.33333333 6.5        4.16666667 4.66666667 5.5        6.5\n",
      " 5.33333333 6.5        5.66666667 5.66666667 5.83333333 6.\n",
      " 5.16666667 6.5        6.16666667 5.5        5.33333333 4.66666667\n",
      " 6.         5.66666667 5.         6.16666667 6.5        6.16666667\n",
      " 6.66666667 6.83333333 3.66666667 5.5        6.66666667 5.5\n",
      " 7.         7.         4.83333333 6.66666667 4.83333333 6.16666667\n",
      " 4.66666667 6.33333333 5.33333333 6.83333333 6.33333333 3.5\n",
      " 6.16666667 3.         5.16666667 4.33333333 5.66666667 6.16666667\n",
      " 5.         5.66666667]\n",
      "Correlation:  [[1.         0.05638564]\n",
      " [0.05638564 1.        ]]\n",
      "Mean absolute error = 0.93\n",
      "Mean squared error = 1.35\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -0.6\n",
      "R2 score = -0.6\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.96963958 5.01679394 5.89021294 6.68995931 7.52267989 6.05157508\n",
      " 5.30411603 4.61765876 6.6812675  5.43924266 5.75997716 6.10157215\n",
      " 4.68572222 5.4233548  5.6590437  4.53039886 5.8387857  5.96093369\n",
      " 5.77583135 3.8347317  5.61181635 5.24003702 6.24571322 6.053857\n",
      " 6.97974343 5.80665971 6.61483842 7.73087016 5.77139956 4.53084516\n",
      " 4.88676789 4.96966433 5.93914877 5.78260603 6.30081124 6.50900547\n",
      " 5.81340889 5.85002385 6.2288356  7.07994307 5.15463906 5.78838215\n",
      " 6.88503798 5.81251949 6.32656943 6.30784556 6.7543619  5.85762157\n",
      " 5.16193298 5.90268072 7.37805571 7.58867196 5.89259521 5.85780302\n",
      " 5.38332147 4.54287438 5.94021943 6.09671534 5.63766221 6.80948741\n",
      " 4.70282065 5.8389105  4.85236356 5.28873043 5.77211637 6.3664944\n",
      " 5.44373824 5.71449247 5.33742853 7.16834617 6.96393595 4.75552392\n",
      " 6.41175831 6.33066203]\n",
      "\n",
      "What it should be:  [7.         4.5        4.16666667 5.83333333 5.83333333 6.\n",
      " 5.33333333 5.5        5.83333333 3.33333333 6.33333333 6.16666667\n",
      " 4.83333333 3.66666667 6.16666667 4.         4.5        6.66666667\n",
      " 5.         5.83333333 5.5        5.66666667 6.         6.16666667\n",
      " 6.33333333 6.16666667 6.66666667 6.66666667 6.66666667 4.83333333\n",
      " 6.         5.33333333 4.66666667 5.33333333 6.83333333 5.83333333\n",
      " 6.         6.66666667 4.5        6.5        3.66666667 6.83333333\n",
      " 6.83333333 5.33333333 6.66666667 6.16666667 6.33333333 6.5\n",
      " 6.16666667 5.16666667 6.5        5.16666667 6.         4.66666667\n",
      " 4.33333333 6.5        6.         6.16666667 4.66666667 5.33333333\n",
      " 6.16666667 6.16666667 5.5        4.83333333 5.66666667 5.33333333\n",
      " 5.66666667 6.5        6.66666667 7.         5.83333333 7.\n",
      " 5.16666667 5.16666667]\n",
      "Correlation:  [[1.         0.27416422]\n",
      " [0.27416422 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.56970115 5.62989119 6.22228718 6.69184647 5.8137401  5.94706604\n",
      " 6.69902188 5.10810871 5.97445804 6.36080521 6.63893708 6.69319941\n",
      " 3.75750169 5.71759272 5.20113735 4.94465746 5.88071762 5.0727425\n",
      " 6.24530538 6.25827851 5.60295294 4.8754252  5.22007598 5.64611085\n",
      " 5.75862649 5.321209   5.10382375 5.81547905 4.22335123 5.73531582\n",
      " 5.96314152 5.06931451 5.8646672  5.69247771 7.08038827 4.42980803\n",
      " 5.87147043 5.29525463 5.16006018 6.91287919 4.75939873 4.33423011\n",
      " 5.2563005  4.72529877 6.6727539  6.27967675 5.56106803 5.92818473\n",
      " 4.8904843  4.75393278 5.26588817 5.60172949 5.63579817 6.02952369\n",
      " 6.15661193 6.10387401 5.36069418 5.5008965  6.42642417 5.43986009\n",
      " 6.40987342 6.04942246 6.39257145 5.95799833 5.12220496 3.98144933\n",
      " 5.34647581 6.57221813 5.1800491  7.05711193 5.01454788 6.11986805\n",
      " 5.60986149 5.21501934]\n",
      "\n",
      "What it should be:  [6.         5.33333333 4.83333333 6.16666667 6.66666667 4.33333333\n",
      " 4.83333333 3.83333333 5.16666667 5.33333333 5.83333333 6.\n",
      " 5.83333333 5.66666667 7.         6.         6.16666667 6.83333333\n",
      " 6.66666667 3.66666667 4.66666667 6.66666667 6.         5.66666667\n",
      " 5.16666667 6.66666667 4.         5.33333333 4.83333333 4.5\n",
      " 5.16666667 6.33333333 4.16666667 4.66666667 5.83333333 4.83333333\n",
      " 6.16666667 6.16666667 6.         5.66666667 3.33333333 5.83333333\n",
      " 6.5        5.83333333 6.33333333 5.33333333 6.33333333 5.83333333\n",
      " 6.5        6.16666667 5.33333333 4.83333333 5.66666667 5.33333333\n",
      " 5.5        6.16666667 6.83333333 4.33333333 6.66666667 4.83333333\n",
      " 5.16666667 7.         5.83333333 6.33333333 4.66666667 6.\n",
      " 5.66666667 5.66666667 5.83333333 3.         5.5        5.83333333\n",
      " 4.66666667 6.83333333]\n",
      "Correlation:  [[ 1.         -0.07498614]\n",
      " [-0.07498614  1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.37\n",
      "Median absolute error = 0.86\n",
      "Explain variance score = -0.76\n",
      "R2 score = -0.77\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.40650215 6.0379216  5.7920412  6.06166238 6.93025869 5.87000974\n",
      " 5.74416091 6.55382564 5.83454424 6.41490412 4.92022317 5.32720217\n",
      " 4.92375042 4.55180354 6.35963466 5.33205551 6.99682334 4.83661832\n",
      " 6.24002981 3.47752274 6.62501932 5.06587674 5.08841908 5.40284211\n",
      " 5.6696208  5.64941225 5.90988057 6.03192284 5.76057172 4.98045629\n",
      " 5.30725789 5.21726081 5.13541722 5.59497118 5.55845976 5.23602592\n",
      " 5.61984967 6.76726671 5.00936411 4.93410784 6.82830337 6.29516182\n",
      " 6.13351953 5.91884224 5.74423133 5.03119843 5.72349424 5.32390129\n",
      " 5.39257112 5.57568771 5.19213059 5.12092406 5.03483826 6.66491362\n",
      " 5.49917104 5.70618227 4.95378636 5.11469935 5.14581782 5.42494476\n",
      " 4.71545581 6.10780351 6.29478847 6.3145853  5.79737537 5.18843116\n",
      " 6.09096996 5.60482825 5.30797275 5.025553   5.63432572 5.04653575\n",
      " 5.23481914 6.13434484]\n",
      "\n",
      "What it should be:  [6.66666667 6.83333333 6.83333333 3.         6.33333333 6.5\n",
      " 6.16666667 5.83333333 5.66666667 4.66666667 4.83333333 4.\n",
      " 6.16666667 4.33333333 5.16666667 6.66666667 7.         5.66666667\n",
      " 6.33333333 5.5        4.33333333 5.33333333 4.5        5.5\n",
      " 6.5        6.66666667 6.         5.66666667 4.16666667 5.33333333\n",
      " 5.83333333 5.5        4.83333333 6.66666667 6.33333333 6.\n",
      " 7.         6.83333333 6.16666667 3.66666667 6.33333333 5.33333333\n",
      " 6.66666667 5.83333333 4.66666667 6.16666667 5.33333333 7.\n",
      " 6.16666667 6.33333333 3.33333333 7.         4.66666667 5.\n",
      " 4.66666667 6.16666667 5.5        5.16666667 4.5        5.16666667\n",
      " 4.66666667 6.33333333 5.83333333 5.83333333 6.         5.83333333\n",
      " 5.66666667 1.83333333 6.16666667 6.33333333 6.16666667 6.5\n",
      " 5.66666667 5.83333333]\n",
      "Correlation:  [[1.         0.17944801]\n",
      " [0.17944801 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.16\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.61061752 5.38962146 6.8865486  5.41570799 6.57176201 6.3786375\n",
      " 4.97324149 6.24375387 5.54392563 6.16591434 5.90648833 6.21102339\n",
      " 6.00341489 5.07421489 7.30529176 6.13343511 6.32328049 6.20556184\n",
      " 4.99361833 6.34697722 6.28320916 6.05907682 4.77258151 6.66874455\n",
      " 4.32826716 4.59017003 7.15068389 6.15306278 6.48748823 5.63494332\n",
      " 5.81284805 5.94852312 6.47289534 5.34278295 6.23786108 5.97308961\n",
      " 5.40795265 5.96332703 3.90787726 6.5887406  5.21621904 5.83232976\n",
      " 5.32903022 6.14786638 5.37428842 5.59068108 6.70252371 6.87643279\n",
      " 6.42771381 5.82659442 5.81069962 5.67571963 5.98337654 5.2434775\n",
      " 5.9207272  6.82422042 6.56421727 5.45922325 6.3305497  5.88545728\n",
      " 5.42641344 4.71881484 5.00470869 6.75026811 5.82781794 5.78057264\n",
      " 5.48789515 6.78981212 6.31673211 6.10946637 4.20931106 5.51523135\n",
      " 6.33734099 5.96189851]\n",
      "\n",
      "What it should be:  [4.66666667 6.16666667 6.5        6.5        6.         5.16666667\n",
      " 4.33333333 5.16666667 5.33333333 6.         5.33333333 6.\n",
      " 6.33333333 3.66666667 6.33333333 6.83333333 5.66666667 5.16666667\n",
      " 5.83333333 7.         6.         6.16666667 6.         6.5\n",
      " 6.5        5.33333333 5.83333333 4.66666667 5.16666667 5.66666667\n",
      " 6.83333333 6.33333333 6.33333333 7.         5.33333333 4.83333333\n",
      " 5.33333333 6.16666667 5.5        5.83333333 4.66666667 5.83333333\n",
      " 5.16666667 5.66666667 5.5        6.66666667 6.83333333 6.\n",
      " 5.83333333 7.         4.33333333 6.16666667 5.66666667 5.\n",
      " 5.5        5.33333333 6.16666667 3.5        4.83333333 1.83333333\n",
      " 6.16666667 4.83333333 5.33333333 5.83333333 4.83333333 6.16666667\n",
      " 6.33333333 6.83333333 5.33333333 5.83333333 4.5        6.16666667\n",
      " 7.         6.5       ]\n",
      "Correlation:  [[1.         0.26212074]\n",
      " [0.26212074 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.97\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.23\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.98807112 5.36488615 5.71988978 7.09746145 5.47989504 5.46150368\n",
      " 6.14066678 4.79441061 5.02881986 5.62783321 4.72132028 6.03410442\n",
      " 5.31765548 6.0383674  5.30125779 6.08080978 4.93533945 6.39835578\n",
      " 4.6189384  5.97751405 4.87978412 5.79613998 5.8609173  4.55224639\n",
      " 4.44562675 5.47865709 4.50127152 4.60382492 5.2187418  7.02521316\n",
      " 5.01316851 6.85525354 5.33668265 7.26699031 5.00319236 5.73998304\n",
      " 6.54266687 6.80278419 6.9627742  5.90969775 4.99977597 5.38382754\n",
      " 4.91640716 4.9372255  5.87925325 6.97272605 6.42974229 6.49386861\n",
      " 5.62560055 5.69978215 4.7931936  6.4027662  5.12079566 5.80116465\n",
      " 4.52470496 5.7216316  6.22211756 4.7276839  5.99149567 5.9377089\n",
      " 6.1045024  7.2545782  5.39159172 5.72827409 5.67431272 6.06821365\n",
      " 4.73314344 5.76725694 2.68327722 6.11978434 5.40514344 6.27614148\n",
      " 5.88267509 5.56141023]\n",
      "\n",
      "What it should be:  [5.         5.         6.16666667 5.83333333 6.16666667 6.5\n",
      " 6.5        4.66666667 6.16666667 5.66666667 6.66666667 6.16666667\n",
      " 5.83333333 6.16666667 6.16666667 6.33333333 6.         6.\n",
      " 6.83333333 6.5        3.66666667 5.16666667 6.83333333 5.33333333\n",
      " 4.5        6.66666667 5.33333333 6.5        5.5        4.33333333\n",
      " 4.5        6.16666667 5.33333333 7.         6.         5.\n",
      " 3.         4.83333333 7.         4.83333333 6.16666667 6.\n",
      " 5.5        6.16666667 4.66666667 6.33333333 5.83333333 5.16666667\n",
      " 6.         4.66666667 4.5        6.5        6.66666667 6.16666667\n",
      " 5.83333333 4.83333333 5.33333333 4.66666667 6.5        6.83333333\n",
      " 6.         6.5        4.33333333 1.83333333 5.83333333 4.33333333\n",
      " 4.83333333 4.66666667 5.5        6.83333333 4.83333333 4.\n",
      " 5.83333333 5.83333333]\n",
      "Correlation:  [[1.        0.1126525]\n",
      " [0.1126525 1.       ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.4\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.49\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.68618916 4.65218926 4.15941383 5.41840252 5.94261145 2.06857046\n",
      " 6.67418075 5.8186418  4.45065489 5.39475405 6.11037891 5.6432822\n",
      " 2.79993653 4.75864148 5.65371257 5.19784424 6.45006786 5.24461982\n",
      " 5.176605   5.82869351 5.64272141 5.55599419 6.14657663 4.79745013\n",
      " 4.0139807  6.74223735 6.01100504 5.1693022  5.67810926 6.46772093\n",
      " 5.03719553 5.10598262 4.9763067  5.79864544 6.10394186 5.60359089\n",
      " 5.60048074 4.02238448 5.91703769 5.8750522  4.74351844 5.58251218\n",
      " 5.61383569 5.1853167  4.96791266 4.66324417 5.12335326 5.76668662\n",
      " 5.70421474 5.19252682 6.09385807 6.17932077 5.67998905 5.54570654\n",
      " 5.54235682 5.90119732 5.37251364 5.40767419 6.88130085 4.66872236\n",
      " 5.82710003 5.40292851 5.55110736 5.63570731 6.06829459 7.50837483\n",
      " 4.97842103 4.72398139 5.45227799 4.46161928 5.64087627 6.2885559\n",
      " 5.21933082 5.54358993]\n",
      "\n",
      "What it should be:  [5.66666667 3.83333333 5.33333333 6.16666667 5.83333333 4.83333333\n",
      " 6.5        6.66666667 6.16666667 6.33333333 6.         6.16666667\n",
      " 5.5        7.         6.16666667 5.66666667 6.16666667 6.\n",
      " 5.33333333 6.83333333 5.33333333 6.5        5.33333333 6.83333333\n",
      " 6.5        5.16666667 4.83333333 5.         3.66666667 6.66666667\n",
      " 6.33333333 6.5        6.         4.83333333 5.16666667 6.66666667\n",
      " 5.33333333 4.5        4.         5.5        4.         6.5\n",
      " 5.66666667 6.         6.66666667 6.16666667 5.33333333 6.16666667\n",
      " 6.5        6.33333333 6.83333333 5.83333333 5.33333333 6.\n",
      " 5.5        5.33333333 4.33333333 6.66666667 5.16666667 6.16666667\n",
      " 5.33333333 5.66666667 6.16666667 6.5        4.16666667 7.\n",
      " 6.16666667 6.33333333 5.83333333 5.5        5.         6.66666667\n",
      " 6.16666667 6.16666667]\n",
      "Correlation:  [[1.         0.12724733]\n",
      " [0.12724733 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.25\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.8\n",
      "R2 score = -1.0\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.7833809  5.44601322 5.41626545 5.48512971 5.27123899 6.53563172\n",
      " 6.52752172 4.87521764 4.70302787 5.95477973 5.36270529 5.84580437\n",
      " 5.77897647 5.40255358 4.82585776 5.92190675 6.52881345 5.14241952\n",
      " 7.22719489 5.34066749 4.95844384 5.48128169 6.10039942 5.43414124\n",
      " 5.35138554 6.45395663 5.48963474 5.99829738 5.62199228 6.97858804\n",
      " 6.45119928 5.72480654 5.86268687 5.91275717 4.99033628 5.17472221\n",
      " 4.73611307 6.27299388 4.71515236 6.29234578 5.47824253 4.88800397\n",
      " 6.09679749 5.95220458 6.00446683 5.9758309  6.5246003  6.03689113\n",
      " 5.89352042 5.3435287  6.28124043 5.06407691 4.87602081 4.98204882\n",
      " 5.00155968 5.96983983 5.04031411 5.10788874 3.30959526 5.50386446\n",
      " 5.4895066  5.79521817 5.38422346 4.53344492 6.36380522 5.63624967\n",
      " 5.12342036 7.00611027 6.09513848 5.45287837 6.92465771 5.65605904\n",
      " 5.91420408 6.1402698 ]\n",
      "\n",
      "What it should be:  [5.16666667 4.         5.66666667 6.         6.66666667 5.66666667\n",
      " 5.16666667 6.83333333 5.83333333 5.33333333 6.33333333 5.16666667\n",
      " 6.5        5.         6.         6.         6.5        1.83333333\n",
      " 6.33333333 5.5        6.5        5.16666667 6.5        5.5\n",
      " 5.33333333 6.83333333 6.33333333 5.5        4.16666667 6.16666667\n",
      " 6.         6.16666667 4.5        6.16666667 6.66666667 5.83333333\n",
      " 4.33333333 5.83333333 4.83333333 6.83333333 5.5        6.33333333\n",
      " 6.16666667 4.         4.83333333 7.         6.         5.16666667\n",
      " 6.16666667 5.16666667 5.33333333 5.83333333 5.83333333 5.66666667\n",
      " 6.33333333 6.66666667 5.5        6.5        5.5        4.66666667\n",
      " 5.5        6.83333333 5.33333333 4.5        5.33333333 4.83333333\n",
      " 5.83333333 6.16666667 5.33333333 6.16666667 5.33333333 5.\n",
      " 6.5        5.83333333]\n",
      "Correlation:  [[1.         0.17032616]\n",
      " [0.17032616 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 0.96\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.36\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.33007731 6.25808199 6.66465864 4.93541031 5.04746123 5.88131761\n",
      " 6.76282765 6.26934674 5.72839427 6.06947702 6.22967684 5.39439034\n",
      " 5.49254893 6.18988612 5.56607214 4.78851148 5.37187127 5.40210704\n",
      " 6.75645946 4.86357373 5.52726392 5.6675992  5.15730845 5.87414032\n",
      " 5.11286974 6.0195858  5.80708424 3.83951607 5.70989983 4.31677257\n",
      " 4.85142062 4.13283833 5.58808517 5.38803738 5.78713572 5.44103929\n",
      " 6.86968157 5.64344722 5.15801584 6.403854   5.66776371 5.65087725\n",
      " 6.02657792 5.70342473 5.68204263 7.1549746  5.18353469 6.55532711\n",
      " 4.70541009 4.83601042 5.60990635 3.79758683 5.63399663 4.88225661\n",
      " 5.55008067 5.94845505 4.82755506 6.05357963 5.88421482 5.08056576\n",
      " 5.7935149  6.1085176  4.95530517 6.78368154 5.48804919 6.11087449\n",
      " 3.44279709 5.6326484  5.46402124 4.13901357 5.96298378 4.94558503\n",
      " 4.9910731  6.22883025]\n",
      "\n",
      "What it should be:  [6.83333333 6.33333333 5.66666667 4.66666667 5.         4.\n",
      " 6.5        7.         5.16666667 4.66666667 5.83333333 7.\n",
      " 6.16666667 5.33333333 5.83333333 4.33333333 5.66666667 3.66666667\n",
      " 6.         4.66666667 4.5        5.83333333 4.33333333 6.83333333\n",
      " 6.83333333 5.83333333 5.66666667 5.5        4.83333333 5.5\n",
      " 6.16666667 4.         5.66666667 6.16666667 6.16666667 5.33333333\n",
      " 5.33333333 4.66666667 6.66666667 4.83333333 1.83333333 6.16666667\n",
      " 5.66666667 4.5        6.16666667 6.16666667 5.         5.66666667\n",
      " 5.         5.83333333 6.         7.         5.83333333 5.66666667\n",
      " 5.33333333 6.5        6.33333333 7.         6.16666667 6.83333333\n",
      " 6.16666667 6.33333333 5.5        5.33333333 6.         5.16666667\n",
      " 4.5        6.         5.5        6.33333333 7.         6.5\n",
      " 6.83333333 6.66666667]\n",
      "Correlation:  [[1.         0.13598457]\n",
      " [0.13598457 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.42\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.98485733 6.71956023 5.91995457 5.88456462 5.20289791 5.6378073\n",
      " 4.66395249 6.92436533 5.70352789 5.84011967 5.02833097 6.03455995\n",
      " 4.66899813 4.31999342 5.93240172 6.72148507 5.44065462 5.27997525\n",
      " 5.33386985 5.87443802 6.21403292 5.40023446 5.05739853 5.19441729\n",
      " 6.07842771 4.70834403 4.42885777 5.72075914 5.371746   5.614856\n",
      " 7.11027259 5.42761548 6.4397296  6.20919011 5.08261596 6.10722837\n",
      " 5.6445109  6.672456   5.71926543 6.84181744 6.22401495 5.84829789\n",
      " 5.42398385 6.36927737 6.68081351 6.68295478 6.11710888 4.91487156\n",
      " 5.4238577  5.71165666 5.60684436 6.0529758  6.27921682 6.55314792\n",
      " 3.58324954 6.27255655 5.58284679 5.48701708 5.93794365 6.67498626\n",
      " 6.08599891 5.04356786 5.81919739 4.42818953 6.260061   5.77169726\n",
      " 5.05878459 5.67630347 6.96587944 4.7599738  5.31447951 6.72225369\n",
      " 6.97236939 5.64544569]\n",
      "\n",
      "What it should be:  [5.66666667 5.83333333 5.33333333 5.         6.66666667 6.5\n",
      " 3.5        7.         6.33333333 6.66666667 4.         5.33333333\n",
      " 6.66666667 6.33333333 1.83333333 4.16666667 6.         5.16666667\n",
      " 5.33333333 5.83333333 3.83333333 5.5        5.5        4.33333333\n",
      " 5.16666667 4.5        5.         6.83333333 6.16666667 3.66666667\n",
      " 6.5        5.33333333 6.33333333 5.16666667 5.5        6.16666667\n",
      " 5.5        6.16666667 5.83333333 5.33333333 5.66666667 4.83333333\n",
      " 6.5        6.16666667 5.83333333 5.66666667 5.5        4.33333333\n",
      " 6.83333333 6.         6.83333333 7.         6.16666667 6.5\n",
      " 5.5        6.16666667 6.83333333 4.66666667 6.16666667 6.83333333\n",
      " 3.         4.66666667 6.33333333 5.33333333 5.66666667 4.66666667\n",
      " 5.16666667 6.66666667 6.83333333 6.16666667 5.16666667 6.33333333\n",
      " 6.83333333 5.83333333]\n",
      "Correlation:  [[1.         0.22814024]\n",
      " [0.22814024 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.45323383 6.36791668 4.33029818 4.60318055 5.96978286 5.4321466\n",
      " 6.7739392  3.27251252 6.34230531 6.82099877 6.3454481  4.13315731\n",
      " 5.326286   5.84383015 5.88592838 5.87738233 5.0152145  4.26387064\n",
      " 6.06744467 4.36793911 6.15708792 6.04591463 5.49859507 5.22035966\n",
      " 5.17865067 6.36061936 5.17676776 5.78506386 3.99676752 5.94130258\n",
      " 5.26392328 6.33803708 4.09283742 5.37212699 3.42606161 6.70275603\n",
      " 5.39486369 5.55303602 5.12289174 5.02670815 5.38182646 7.34456821\n",
      " 5.6275477  3.25850581 5.71442908 5.77413005 5.30663528 5.25733935\n",
      " 6.6436887  6.17145463 5.57633837 6.52151044 4.81530448 6.3428412\n",
      " 4.84460903 5.44884622 3.28642639 5.3705375  3.58857255 4.32752493\n",
      " 5.96623409 5.62106403 5.39853694 5.47394322 5.67801937 5.28970147\n",
      " 4.84530003 5.60336298 7.18240168 5.74576635 5.51645048 5.21299245\n",
      " 5.16175269 5.90612654]\n",
      "\n",
      "What it should be:  [5.66666667 6.16666667 4.83333333 3.66666667 6.         5.\n",
      " 6.33333333 5.16666667 4.5        5.33333333 6.33333333 5.66666667\n",
      " 4.         6.83333333 6.16666667 6.         6.5        3.5\n",
      " 6.5        6.33333333 5.66666667 6.         4.66666667 7.\n",
      " 6.5        5.33333333 6.         5.33333333 6.16666667 5.66666667\n",
      " 4.66666667 5.5        4.5        6.5        6.83333333 6.83333333\n",
      " 4.83333333 5.33333333 5.5        5.66666667 6.16666667 6.16666667\n",
      " 6.33333333 6.83333333 4.33333333 5.83333333 5.83333333 6.\n",
      " 6.5        5.5        5.66666667 6.66666667 6.16666667 5.33333333\n",
      " 5.33333333 6.83333333 5.5        6.83333333 7.         6.33333333\n",
      " 5.33333333 6.16666667 6.16666667 6.66666667 7.         6.\n",
      " 6.         6.16666667 6.5        4.66666667 4.66666667 3.\n",
      " 6.         6.16666667]\n",
      "Correlation:  [[1.         0.09221452]\n",
      " [0.09221452 1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.5\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.88\n",
      "R2 score = -1.04\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.32275202 5.87216927 6.99537167 6.38990533 5.73055764 5.57895598\n",
      " 6.81124589 4.47123528 4.51255262 5.52354678 5.8631292  5.62714108\n",
      " 6.44417228 5.97883759 5.99494573 6.37163819 6.16876902 5.93582189\n",
      " 7.26482656 4.18803108 5.71262166 6.41141744 6.61038989 5.86269034\n",
      " 5.2234951  7.13314707 7.43235336 5.95605095 5.7238112  6.21356493\n",
      " 6.1262676  5.46801656 5.89869673 5.73094035 5.95579516 5.66363306\n",
      " 5.25891767 6.02429151 5.99084217 5.4719803  6.0177961  7.10918684\n",
      " 5.55249618 4.41653636 5.77159656 5.74848568 6.10066824 5.73667375\n",
      " 6.32341743 5.70851737 5.73086211 5.39797418 3.7382864  5.35857501\n",
      " 6.32886507 5.99883552 5.15325178 5.97109993 6.16503621 5.71972995\n",
      " 4.71371513 6.81712405 5.72545393 5.81642584 6.66655802 6.32683706\n",
      " 6.14201819 4.91858437 5.25840226 6.24643573 6.54840605 4.78880542\n",
      " 4.76313595 5.54779755]\n",
      "\n",
      "What it should be:  [5.66666667 5.16666667 4.66666667 5.83333333 6.5        6.\n",
      " 5.66666667 4.         7.         4.33333333 6.16666667 6.5\n",
      " 4.16666667 6.         5.83333333 5.16666667 6.83333333 4.\n",
      " 5.33333333 5.5        4.83333333 5.16666667 6.66666667 5.33333333\n",
      " 6.         5.33333333 6.5        5.5        4.33333333 5.33333333\n",
      " 6.66666667 4.66666667 6.16666667 5.33333333 5.83333333 3.66666667\n",
      " 5.66666667 5.16666667 5.83333333 6.         7.         5.33333333\n",
      " 5.66666667 4.         6.33333333 4.83333333 5.33333333 5.83333333\n",
      " 6.5        5.         5.16666667 4.83333333 5.83333333 6.5\n",
      " 6.         6.5        5.33333333 1.83333333 4.66666667 5.16666667\n",
      " 6.         6.         3.83333333 6.         5.16666667 6.16666667\n",
      " 5.83333333 5.16666667 4.33333333 5.5        6.16666667 5.33333333\n",
      " 3.33333333 3.5       ]\n",
      "Correlation:  [[1.         0.15918063]\n",
      " [0.15918063 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.35\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.52\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.12266923 5.53316114 4.98504875 4.1537019  5.45342307 6.20747774\n",
      " 6.50353254 5.45542334 6.09047062 5.46398727 7.02454312 5.62000075\n",
      " 5.79189104 4.86608978 5.53083121 4.67032854 4.7360234  5.26154761\n",
      " 4.17076209 6.36001787 6.32774978 5.65460872 6.59496788 5.22617712\n",
      " 4.93855141 5.34742666 6.72735446 4.39106195 6.48387838 4.62342921\n",
      " 4.48901119 4.1555843  5.82574527 5.47115973 5.47393106 5.48746958\n",
      " 5.10034418 4.9611699  4.76737684 5.92680561 7.22636923 5.80231954\n",
      " 6.48780662 6.18093005 5.75332589 5.84967369 5.30161646 5.5378213\n",
      " 6.21854134 5.67027895 5.17074049 3.96641214 5.19790711 5.34232911\n",
      " 5.49536293 5.9752974  3.72682026 5.30266684 6.02297651 6.12787249\n",
      " 5.45112946 6.10417084 5.4573858  4.07371999 6.77227091 5.59386897\n",
      " 5.66047536 5.58999048 4.39276945 5.35647258 5.1949067  5.67661389\n",
      " 6.07576148 4.74090728]\n",
      "\n",
      "What it should be:  [6.         5.16666667 6.16666667 4.         5.33333333 5.66666667\n",
      " 5.83333333 4.33333333 4.16666667 4.66666667 6.66666667 6.16666667\n",
      " 5.33333333 6.33333333 5.83333333 6.         5.33333333 5.5\n",
      " 5.5        5.16666667 5.83333333 5.5        5.33333333 7.\n",
      " 4.83333333 6.16666667 7.         6.16666667 5.66666667 6.5\n",
      " 6.33333333 5.16666667 5.66666667 6.66666667 6.16666667 4.\n",
      " 6.5        3.         6.16666667 6.66666667 6.16666667 4.5\n",
      " 6.5        5.66666667 6.5        6.83333333 7.         5.83333333\n",
      " 7.         4.         4.         7.         6.5        5.5\n",
      " 6.33333333 7.         6.83333333 5.         5.16666667 6.\n",
      " 6.33333333 5.16666667 6.16666667 6.16666667 5.16666667 4.5\n",
      " 6.83333333 6.83333333 4.33333333 6.66666667 6.         4.83333333\n",
      " 6.         4.83333333]\n",
      "Correlation:  [[1.         0.06460926]\n",
      " [0.06460926 1.        ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.33\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -0.56\n",
      "R2 score = -0.64\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.31031245 5.69153674 5.42577639 5.67717161 4.98413072 6.49433852\n",
      " 4.90270611 5.44143428 4.50945529 7.18265843 5.98001897 5.64505984\n",
      " 6.146324   6.02910629 6.3701271  5.13919427 5.93239022 5.76998781\n",
      " 5.6505298  5.57183634 4.82102009 6.28993972 5.82232341 5.52030118\n",
      " 6.41023367 5.3396224  4.81961149 6.1407431  4.2382533  4.87933072\n",
      " 5.43709525 4.73045512 5.1642606  5.94238917 4.37648397 5.38660441\n",
      " 6.55172435 5.82083549 6.02306118 6.71072046 5.85820644 5.56159201\n",
      " 6.73639086 6.63257089 6.71959235 7.10441594 5.42196066 5.52484193\n",
      " 5.14085846 5.2735949  6.10043885 5.15369512 6.18963144 7.01472397\n",
      " 5.36073947 5.34963504 6.69747862 5.69804457 4.72773088 4.58181149\n",
      " 5.54238987 5.648258   6.00596504 6.11273012 6.3138457  5.72577595\n",
      " 5.96956134 5.02954594 5.13035757 4.91120235 4.81178589 6.22929725\n",
      " 5.19526699 6.96678043]\n",
      "\n",
      "What it should be:  [7.         3.66666667 6.16666667 6.16666667 4.83333333 6.16666667\n",
      " 7.         5.33333333 6.33333333 6.66666667 7.         5.66666667\n",
      " 5.33333333 4.5        6.83333333 6.5        6.16666667 5.66666667\n",
      " 6.5        6.16666667 4.66666667 6.33333333 6.         6.\n",
      " 7.         5.83333333 6.         6.16666667 6.16666667 6.\n",
      " 5.33333333 4.5        5.16666667 3.83333333 6.83333333 6.66666667\n",
      " 5.33333333 4.16666667 3.5        4.66666667 5.83333333 6.16666667\n",
      " 6.5        5.66666667 5.16666667 6.5        6.         6.16666667\n",
      " 4.33333333 5.33333333 5.83333333 4.33333333 5.33333333 4.\n",
      " 5.5        6.16666667 7.         6.66666667 4.83333333 4.66666667\n",
      " 4.66666667 5.16666667 5.         6.83333333 5.66666667 6.16666667\n",
      " 5.83333333 5.66666667 6.5        4.         4.83333333 6.5\n",
      " 6.5        6.5       ]\n",
      "Correlation:  [[1.         0.11663481]\n",
      " [0.11663481 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.66495928 5.77572993 4.28934643 5.76274905 4.93951575 6.47437685\n",
      " 5.46924366 6.16890953 3.48270601 4.84157791 5.6872813  6.83472214\n",
      " 6.09050501 6.25278967 7.32767506 6.54622647 4.40893233 7.07156037\n",
      " 5.63988794 6.10775954 5.41932286 6.86381722 4.712631   6.2523191\n",
      " 5.96355956 5.60479947 5.04691616 5.48856408 4.79220157 4.10855768\n",
      " 6.24649479 4.67778741 5.67110178 5.56522227 5.45098819 5.94215067\n",
      " 5.72387573 5.89810668 4.97545019 5.9275219  5.27118675 4.85908288\n",
      " 5.09455681 4.42511087 4.53626291 5.94733835 5.39150787 5.92087413\n",
      " 5.78733303 6.03055829 5.50293099 5.51492735 6.35500989 6.2183656\n",
      " 6.92245967 6.01075987 5.22167483 6.06792663 5.60121847 5.00746449\n",
      " 6.41373495 6.39389974 5.37947753 5.34540634 5.35933908 5.52249439\n",
      " 5.64447176 5.22908568 3.64180741 5.14891777 5.23790287 5.03313842\n",
      " 3.14340768 5.96066882]\n",
      "\n",
      "What it should be:  [4.83333333 6.         6.16666667 6.66666667 6.66666667 6.33333333\n",
      " 4.66666667 5.33333333 5.5        6.83333333 6.16666667 5.83333333\n",
      " 6.83333333 7.         7.         5.16666667 6.33333333 6.5\n",
      " 5.16666667 5.66666667 3.33333333 6.66666667 6.5        5.83333333\n",
      " 6.66666667 6.         1.83333333 6.         5.66666667 6.\n",
      " 6.83333333 6.33333333 6.5        5.16666667 6.16666667 6.\n",
      " 6.16666667 5.16666667 3.66666667 6.5        5.33333333 5.\n",
      " 4.         4.83333333 5.33333333 4.83333333 4.66666667 4.66666667\n",
      " 5.33333333 3.         5.5        5.16666667 4.33333333 5.66666667\n",
      " 7.         6.83333333 6.5        5.83333333 5.83333333 6.\n",
      " 6.         6.66666667 5.66666667 6.16666667 4.33333333 5.33333333\n",
      " 6.16666667 5.83333333 4.         4.66666667 6.33333333 7.\n",
      " 4.5        6.        ]\n",
      "Correlation:  [[1.         0.27792222]\n",
      " [0.27792222 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.37438382 6.23175585 5.10247403 4.59517596 6.75554381 6.34887829\n",
      " 6.80602718 7.2003726  4.60930858 5.98376675 4.73449689 4.30897293\n",
      " 5.57059825 6.46880978 5.6993898  6.608439   7.42146577 5.92301962\n",
      " 3.84988967 6.29602135 6.47550119 5.42459802 6.24064899 5.79277279\n",
      " 5.25838202 6.92962539 6.17251752 5.94413694 5.43272531 4.93961929\n",
      " 6.43900663 6.15630136 7.31526234 6.45187548 5.57925864 6.27919452\n",
      " 5.4484128  6.3189358  6.35124717 5.95451791 5.79567472 4.98383733\n",
      " 6.32335387 4.73282974 6.12889712 5.28452061 4.72884721 5.73041606\n",
      " 4.39165978 5.45712707 5.92196431 7.04798992 4.32753835 5.98511031\n",
      " 5.99298791 5.71400483 6.79348843 6.28445601 5.99745941 5.67711899\n",
      " 5.32159434 6.75679235 6.05951759 6.2853077  6.68215809 6.42251671\n",
      " 6.90095948 5.16254207 5.39997806 5.84753074 4.27944469 8.278309\n",
      " 6.05509449 4.32660574]\n",
      "\n",
      "What it should be:  [5.5        6.33333333 5.16666667 6.         6.83333333 6.16666667\n",
      " 5.16666667 5.83333333 3.66666667 4.5        5.83333333 4.5\n",
      " 6.16666667 5.83333333 4.66666667 4.33333333 6.         5.83333333\n",
      " 6.33333333 6.5        4.83333333 4.5        4.16666667 5.5\n",
      " 6.16666667 6.5        5.33333333 3.33333333 4.33333333 4.66666667\n",
      " 5.16666667 6.83333333 6.33333333 6.         6.33333333 6.16666667\n",
      " 6.66666667 5.16666667 6.5        5.5        5.5        5.83333333\n",
      " 6.83333333 6.16666667 3.66666667 6.83333333 5.66666667 5.33333333\n",
      " 4.66666667 6.66666667 5.33333333 6.83333333 4.83333333 4.\n",
      " 5.66666667 5.         6.33333333 6.16666667 6.         5.\n",
      " 4.5        6.16666667 7.         6.5        6.         6.5\n",
      " 4.66666667 5.5        6.16666667 6.66666667 4.83333333 7.\n",
      " 5.16666667 4.83333333]\n",
      "Correlation:  [[1.         0.29441229]\n",
      " [0.29441229 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.36\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.07785408 4.22305252 5.31022014 5.51374506 5.22052499 5.52153911\n",
      " 5.87590685 5.20936064 6.24709933 6.15764311 3.89730559 5.46637627\n",
      " 5.02125536 4.69161745 2.45415152 6.44964737 6.78421768 6.09070199\n",
      " 5.93281757 5.3338051  6.62732974 6.57786666 6.35832908 5.88653168\n",
      " 6.65596843 4.78087652 5.95093421 6.01129549 4.42437176 4.13093066\n",
      " 5.72896438 5.80736114 6.35379584 5.41144615 5.65535152 3.96814607\n",
      " 5.4017362  5.18104046 4.99589835 6.33546559 5.62321654 5.1861571\n",
      " 5.14478956 5.31124672 4.39482965 5.62016937 5.55934894 4.86873643\n",
      " 7.30040525 6.45017631 5.6189025  7.60225491 4.51829992 5.73085299\n",
      " 6.10100213 5.61542804 6.59654335 6.25818    4.93979321 6.47057321\n",
      " 5.33893927 6.12179584 5.62154414 5.74529558 5.48290404 5.02630979\n",
      " 5.80350942 5.66960677 5.47577987 5.26828367 6.15752434 4.37151339\n",
      " 4.98092246 4.98180484]\n",
      "\n",
      "What it should be:  [6.16666667 6.33333333 6.83333333 6.66666667 4.5        5.33333333\n",
      " 5.5        5.83333333 6.         6.         6.33333333 6.33333333\n",
      " 5.5        6.5        5.5        5.66666667 6.         5.83333333\n",
      " 4.66666667 3.83333333 6.5        6.33333333 6.16666667 6.16666667\n",
      " 5.16666667 5.5        5.33333333 3.         4.83333333 6.33333333\n",
      " 5.         5.83333333 6.66666667 4.66666667 5.33333333 5.33333333\n",
      " 7.         6.         4.         4.83333333 6.         5.\n",
      " 5.16666667 5.16666667 4.33333333 5.66666667 6.         5.33333333\n",
      " 4.         6.16666667 6.         7.         4.83333333 5.66666667\n",
      " 6.83333333 4.5        6.16666667 5.         4.         6.16666667\n",
      " 4.66666667 6.83333333 6.5        6.83333333 4.66666667 6.\n",
      " 5.83333333 6.16666667 5.5        5.83333333 4.33333333 6.16666667\n",
      " 5.83333333 5.33333333]\n",
      "Correlation:  [[1.         0.11983638]\n",
      " [0.11983638 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.72\n",
      "R2 score = -0.73\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.02406183 5.21280952 5.1408048  6.14664115 4.89444731 5.31517864\n",
      " 5.51376997 5.21496014 4.87160261 6.08913475 5.49945413 5.37586021\n",
      " 5.62235813 5.61293236 5.6391803  4.08012019 4.65457117 6.22123379\n",
      " 6.0608912  5.86596192 5.97306498 6.27824826 6.6127839  5.45312567\n",
      " 7.59506594 6.22082643 6.02183235 5.41013406 5.31003896 5.96603868\n",
      " 5.21188198 5.50742437 5.81929264 6.93530916 6.75546727 3.50580779\n",
      " 6.28558217 6.88521072 6.5691201  6.38560862 5.23050507 4.05364622\n",
      " 5.17945043 5.37782021 5.66359215 4.47210864 5.27370137 6.42759568\n",
      " 4.559197   7.20840273 5.54755522 4.70988433 4.82929747 5.12989805\n",
      " 5.96875037 5.76734371 5.37072043 4.97130759 5.02902926 6.54612974\n",
      " 5.87237918 7.21913053 6.23521623 4.74760057 5.61882585 5.44264483\n",
      " 6.08785657 4.67937307 5.65029382 4.98903336 6.27383499 5.68733082\n",
      " 5.58695071 5.79984022]\n",
      "\n",
      "What it should be:  [6.         5.5        4.83333333 4.66666667 6.16666667 6.66666667\n",
      " 4.         4.83333333 4.66666667 5.5        5.         5.66666667\n",
      " 5.33333333 5.83333333 5.66666667 4.         6.5        4.5\n",
      " 5.83333333 5.83333333 6.5        5.66666667 4.33333333 6.66666667\n",
      " 6.5        5.16666667 5.33333333 5.33333333 6.16666667 5.\n",
      " 6.         6.16666667 5.83333333 5.16666667 6.33333333 4.83333333\n",
      " 5.66666667 6.16666667 4.16666667 5.33333333 7.         6.33333333\n",
      " 6.16666667 6.         4.83333333 6.16666667 6.5        6.\n",
      " 6.         5.83333333 6.16666667 5.33333333 6.5        5.5\n",
      " 5.16666667 6.83333333 5.66666667 4.66666667 5.66666667 6.66666667\n",
      " 6.16666667 7.         5.16666667 6.83333333 6.         3.5\n",
      " 4.33333333 5.33333333 5.83333333 6.33333333 5.16666667 5.\n",
      " 6.83333333 6.83333333]\n",
      "Correlation:  [[1.         0.02130901]\n",
      " [0.02130901 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.87\n",
      "R2 score = -0.87\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.70771732 6.17423206 5.2630382  5.98911192 6.86949535 5.45871162\n",
      " 5.18500054 6.18125829 5.1478494  6.21329182 5.08808896 5.07457783\n",
      " 6.10566638 3.18323709 6.41727793 6.47973825 5.52306655 4.98723179\n",
      " 5.81426948 5.68340119 5.7766867  4.11730789 5.29511604 6.0729821\n",
      " 5.04678325 4.93752449 6.5953244  3.68866609 4.05344546 6.28988562\n",
      " 5.84360196 6.43329776 6.279233   6.18221846 5.67908539 4.82635565\n",
      " 5.97262444 5.16920551 5.0939813  5.29357553 5.76686313 6.31562779\n",
      " 3.87749897 4.89385506 5.05287172 4.63403903 6.61035797 4.6305118\n",
      " 4.52178942 6.087008   5.43418606 5.67837501 6.60074344 5.92510626\n",
      " 5.08702651 5.6385916  6.91757048 6.55408493 5.45822655 5.45251328\n",
      " 5.72745352 5.59439695 4.69987723 4.78553222 6.11056493 7.47405712\n",
      " 4.26996077 7.65590307 5.08924103 3.69251691 5.92311656 6.84333294\n",
      " 6.48167208 4.144804  ]\n",
      "\n",
      "What it should be:  [6.         5.33333333 4.5        5.33333333 6.         6.16666667\n",
      " 5.         4.66666667 5.5        5.83333333 7.         6.83333333\n",
      " 5.33333333 6.83333333 5.33333333 6.33333333 4.         5.5\n",
      " 5.83333333 6.83333333 6.16666667 6.16666667 4.5        6.16666667\n",
      " 6.66666667 5.16666667 6.83333333 7.         6.33333333 6.\n",
      " 4.5        5.66666667 5.33333333 6.83333333 4.83333333 6.33333333\n",
      " 5.66666667 6.16666667 5.66666667 5.83333333 6.         5.16666667\n",
      " 6.         5.83333333 5.66666667 5.83333333 6.5        7.\n",
      " 5.83333333 6.         5.83333333 4.16666667 5.16666667 5.16666667\n",
      " 5.66666667 6.16666667 6.         5.5        6.         4.83333333\n",
      " 4.83333333 5.5        6.5        3.66666667 6.16666667 6.16666667\n",
      " 4.33333333 6.33333333 3.66666667 5.5        5.16666667 6.16666667\n",
      " 4.66666667 3.33333333]\n",
      "Correlation:  [[1.        0.0165981]\n",
      " [0.0165981 1.       ]]\n",
      "Mean absolute error = 0.96\n",
      "Mean squared error = 1.45\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -1.11\n",
      "R2 score = -1.12\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.77877836 6.07853499 5.76337382 5.98270314 5.54762362 6.45958805\n",
      " 5.27799036 5.17715765 4.64598084 5.61932616 6.15240842 5.88079212\n",
      " 5.26228618 5.01530281 5.63815756 5.71616495 5.77288806 6.47250785\n",
      " 5.74949868 6.21608244 5.40182045 5.07934329 5.32647615 5.65444523\n",
      " 5.37434497 5.34343406 6.31166927 5.98732118 4.88192601 4.78778726\n",
      " 5.28048248 5.84774055 6.40353945 6.05492599 5.49899647 6.50666066\n",
      " 5.34671365 6.50608303 5.84414984 5.76012926 6.00482757 6.31412805\n",
      " 4.90963414 5.43970436 5.35648434 5.77043888 6.11125618 3.8467217\n",
      " 5.11665972 6.41835049 4.85933705 5.82723411 5.48955443 6.42044065\n",
      " 7.38481434 6.03463658 5.12414469 5.9634718  6.01990837 5.11515776\n",
      " 6.25508077 4.2374073  5.32798041 6.13317559 6.51973008 5.44699887\n",
      " 5.46217784 5.65400897 5.84746177 5.95337369 5.61136963 5.03128513\n",
      " 6.75441901 5.7254099 ]\n",
      "\n",
      "What it should be:  [6.         6.5        5.83333333 6.33333333 4.         4.83333333\n",
      " 5.         6.         5.83333333 6.16666667 5.66666667 6.16666667\n",
      " 6.5        6.         4.83333333 6.66666667 4.         4.66666667\n",
      " 6.33333333 5.66666667 4.66666667 5.33333333 5.5        3.66666667\n",
      " 6.33333333 5.33333333 6.16666667 6.5        7.         6.83333333\n",
      " 6.5        4.66666667 1.83333333 6.5        4.83333333 5.5\n",
      " 4.33333333 6.16666667 5.66666667 6.5        4.83333333 6.16666667\n",
      " 6.33333333 3.5        5.16666667 6.16666667 6.16666667 6.33333333\n",
      " 4.33333333 6.         5.5        6.66666667 6.5        5.33333333\n",
      " 5.83333333 4.66666667 5.66666667 7.         4.         4.83333333\n",
      " 6.83333333 5.83333333 6.5        5.83333333 6.5        7.\n",
      " 3.66666667 4.5        5.66666667 5.16666667 3.83333333 6.\n",
      " 5.66666667 6.83333333]\n",
      "Correlation:  [[ 1.         -0.06968689]\n",
      " [-0.06968689  1.        ]]\n",
      "Mean absolute error = 0.95\n",
      "Mean squared error = 1.44\n",
      "Median absolute error = 0.83\n",
      "Explain variance score = -0.42\n",
      "R2 score = -0.43\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.04304699 4.68590435 5.90334735 6.42699132 4.98686998 4.42611969\n",
      " 6.15889263 5.37597548 5.50633452 4.69947305 5.81693017 5.86863793\n",
      " 5.39153865 6.40575688 6.25964954 5.97757127 5.49915107 5.38893383\n",
      " 5.68464533 6.64405565 6.69916802 6.59434308 5.00441117 5.69335197\n",
      " 4.56597722 6.18870877 6.34334162 6.22306799 4.90820229 6.55883287\n",
      " 6.60765386 6.6286479  4.6325426  3.91089128 6.38602098 5.09656485\n",
      " 6.60350707 5.25012686 5.1563521  5.62864048 5.08942769 6.28068919\n",
      " 6.54507309 5.85507954 7.00953402 6.04180464 5.49422507 6.07197829\n",
      " 5.9293347  4.74737639 6.47853988 5.44447117 5.64422895 4.90612473\n",
      " 5.14121924 4.67318894 7.14439583 5.95180208 4.39575338 7.22890559\n",
      " 6.1963576  5.0943686  6.95256914 7.19652957 6.77782761 5.19330852\n",
      " 5.17147336 5.60190143 4.90945915 5.86794392 6.79289217 5.50473095\n",
      " 6.59164311 5.83335938]\n",
      "\n",
      "What it should be:  [4.66666667 4.83333333 6.66666667 6.5        5.5        6.16666667\n",
      " 5.33333333 5.33333333 6.33333333 4.66666667 6.83333333 5.83333333\n",
      " 6.5        5.83333333 5.16666667 6.5        6.5        4.16666667\n",
      " 5.16666667 6.66666667 4.66666667 6.16666667 4.33333333 5.66666667\n",
      " 5.5        6.83333333 6.         4.83333333 6.         5.66666667\n",
      " 6.         4.5        6.         6.16666667 6.83333333 5.5\n",
      " 5.66666667 5.33333333 6.66666667 6.83333333 5.83333333 5.66666667\n",
      " 6.16666667 5.66666667 5.16666667 6.         4.66666667 6.\n",
      " 4.         6.33333333 6.5        6.33333333 5.83333333 6.\n",
      " 3.66666667 4.83333333 3.         6.16666667 6.5        6.33333333\n",
      " 6.16666667 6.83333333 4.         5.66666667 6.33333333 5.33333333\n",
      " 6.5        3.33333333 6.83333333 4.83333333 6.5        4.83333333\n",
      " 5.66666667 4.5       ]\n",
      "Correlation:  [[ 1.         -0.03131721]\n",
      " [-0.03131721  1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.44\n",
      "Median absolute error = 0.83\n",
      "Explain variance score = -0.79\n",
      "R2 score = -0.81\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.63226874 4.29751682 5.93587585 5.42123746 5.64954108 5.74294657\n",
      " 6.74316789 6.10122964 6.04705622 4.35868369 6.0504108  5.13724975\n",
      " 6.46631107 4.66614528 6.06929441 6.12255011 6.79486491 5.1344379\n",
      " 6.55859361 6.09173524 6.40059304 5.39525109 5.18678469 5.56761846\n",
      " 6.26935232 5.96558884 5.66508448 4.44442143 3.9282002  5.85060272\n",
      " 5.84359806 6.2141633  5.89937828 4.72100234 5.43439348 6.02527959\n",
      " 5.95000663 6.8922076  5.221229   5.6382264  5.07406054 5.9702457\n",
      " 5.22706352 5.94339555 6.53908615 6.49145968 5.32718155 5.36410225\n",
      " 4.1262717  5.62588702 4.58543093 5.12684751 5.12196872 6.21430116\n",
      " 5.48866713 5.16188423 4.69933236 5.1338155  6.71645923 5.13135832\n",
      " 4.45473976 4.8970026  6.13194682 6.25694721 5.58118585 4.73967486\n",
      " 5.93203387 6.59575651 5.13163422 6.29504162 5.79369885 6.36972679\n",
      " 5.66242534 5.27067728]\n",
      "\n",
      "What it should be:  [5.83333333 3.66666667 6.         6.66666667 5.83333333 6.\n",
      " 6.5        6.5        4.83333333 5.5        4.66666667 5.16666667\n",
      " 5.33333333 6.         6.5        4.16666667 5.16666667 5.33333333\n",
      " 6.66666667 5.16666667 6.83333333 4.33333333 5.5        6.16666667\n",
      " 6.5        7.         1.83333333 6.66666667 7.         5.33333333\n",
      " 6.66666667 6.16666667 6.16666667 6.5        5.66666667 6.\n",
      " 6.33333333 7.         6.16666667 6.5        6.5        6.83333333\n",
      " 6.16666667 5.83333333 6.         6.33333333 6.5        6.33333333\n",
      " 5.5        4.83333333 5.33333333 3.66666667 5.66666667 6.33333333\n",
      " 4.66666667 3.5        6.16666667 4.         6.33333333 5.83333333\n",
      " 6.83333333 5.         5.33333333 6.83333333 6.16666667 6.16666667\n",
      " 5.83333333 5.66666667 6.         6.5        6.16666667 5.5\n",
      " 4.83333333 6.33333333]\n",
      "Correlation:  [[1.        0.1439872]\n",
      " [0.1439872 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.92298648 5.22995035 4.61877352 6.64279809 5.86781094 6.45203175\n",
      " 5.26293534 5.08989353 5.21708031 5.36650232 4.32844518 6.19122256\n",
      " 6.73474684 4.19211736 5.80511568 5.52673961 7.12671713 5.15867827\n",
      " 4.60171654 4.38147573 5.69404237 5.55946931 5.16909859 4.17139775\n",
      " 6.43417058 6.41518817 2.42055426 5.21962018 4.9089965  6.00817127\n",
      " 5.65118157 6.28428573 6.88298897 6.188679   6.61307668 6.1983726\n",
      " 5.8127996  5.7719876  5.80679554 5.01741814 4.39244505 3.73837832\n",
      " 5.62274697 5.78503997 6.72234796 6.27871811 4.67162885 4.81644913\n",
      " 6.23076912 5.2366291  6.33135146 3.63034141 5.86702338 5.85392494\n",
      " 4.92463031 5.8300879  5.45457913 5.30395208 6.63285304 5.51941031\n",
      " 6.33653752 4.69898723 5.97874449 5.01780091 5.93869518 5.23383994\n",
      " 5.31405274 5.85388242 5.72444004 5.73630036 5.61420396 6.34702397\n",
      " 5.88046101 5.94674035]\n",
      "\n",
      "What it should be:  [5.66666667 4.33333333 5.5        5.33333333 5.66666667 5.83333333\n",
      " 5.16666667 4.5        6.66666667 4.33333333 6.5        5.33333333\n",
      " 3.66666667 4.66666667 5.33333333 3.33333333 6.16666667 4.66666667\n",
      " 6.33333333 4.83333333 6.5        6.83333333 6.         4.5\n",
      " 6.83333333 4.83333333 4.83333333 6.16666667 6.33333333 4.83333333\n",
      " 6.16666667 6.5        5.66666667 6.83333333 5.5        5.66666667\n",
      " 5.66666667 4.66666667 5.83333333 6.         6.         6.33333333\n",
      " 5.33333333 6.83333333 6.5        5.33333333 7.         5.5\n",
      " 6.66666667 5.83333333 6.         6.33333333 6.5        5.5\n",
      " 4.83333333 6.16666667 6.16666667 5.83333333 6.         4.66666667\n",
      " 5.83333333 5.83333333 6.5        5.         7.         6.5\n",
      " 5.33333333 5.16666667 5.33333333 6.66666667 5.5        4.5\n",
      " 6.5        5.66666667]\n",
      "Correlation:  [[1.         0.08212081]\n",
      " [0.08212081 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.26\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.92\n",
      "R2 score = -0.95\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.52567425 6.14834082 5.9390797  5.81939349 5.00412426 4.68344874\n",
      " 7.55551562 6.20140448 5.73250303 6.27163862 6.44011395 4.74998268\n",
      " 6.34987141 5.30830675 5.97378096 4.93291569 6.06682485 6.69497153\n",
      " 6.32070634 5.26759372 5.93083822 5.17700065 4.86904234 4.52689221\n",
      " 4.6820727  5.8500441  4.95219643 4.62140991 5.63828757 5.8304973\n",
      " 5.69090969 4.65113411 5.89545508 5.14283951 6.48546531 5.77915516\n",
      " 6.66227253 5.21616744 5.57888261 5.79174646 5.67419752 5.1557309\n",
      " 5.50296658 6.16447215 6.12760284 6.69105264 4.82786169 4.94448197\n",
      " 6.20306506 5.25971113 2.63073439 5.3254833  6.90834704 5.69552766\n",
      " 4.52988177 5.37862631 5.87482213 4.96487384 6.76955042 4.34729648\n",
      " 5.72186138 5.6228099  6.08889341 6.205563   5.95280281 5.5051019\n",
      " 5.60420848 6.13874562 5.34743567 6.22218474 5.95004536 5.66003228\n",
      " 5.72292233 5.17471566]\n",
      "\n",
      "What it should be:  [6.16666667 4.16666667 5.16666667 6.         5.5        6.16666667\n",
      " 6.33333333 5.83333333 4.83333333 6.83333333 5.66666667 6.33333333\n",
      " 6.16666667 6.16666667 5.66666667 6.16666667 5.         6.83333333\n",
      " 5.16666667 6.5        6.66666667 6.5        6.         5.83333333\n",
      " 6.33333333 6.83333333 5.33333333 7.         5.33333333 4.66666667\n",
      " 4.5        6.5        6.83333333 4.66666667 4.33333333 6.\n",
      " 5.5        4.83333333 5.66666667 4.66666667 6.66666667 4.\n",
      " 6.         5.33333333 5.5        5.16666667 6.83333333 5.5\n",
      " 5.66666667 5.66666667 5.5        5.33333333 6.5        4.66666667\n",
      " 4.33333333 4.5        5.33333333 4.83333333 7.         4.33333333\n",
      " 5.33333333 3.5        5.16666667 6.         5.83333333 3.66666667\n",
      " 5.33333333 6.16666667 6.33333333 6.16666667 5.16666667 5.33333333\n",
      " 6.66666667 5.83333333]\n",
      "Correlation:  [[1.         0.06774716]\n",
      " [0.06774716 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.15\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.67\n",
      "R2 score = -0.67\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.31093562 5.2513832  5.08635468 6.04864504 4.65635991 6.10883054\n",
      " 5.58523058 5.38595231 4.03398105 5.34141742 4.98330389 5.27835472\n",
      " 4.71229691 5.33509077 6.71868667 6.78575738 5.17493465 5.971812\n",
      " 4.71664339 5.73158875 5.99011627 5.21226183 5.45145105 6.57482256\n",
      " 6.20496998 5.33633121 6.46257352 4.10594745 4.78285519 6.25603864\n",
      " 6.19649529 6.10148327 4.47878827 3.88684099 4.08772149 6.9007214\n",
      " 4.49595373 5.03224903 5.59452878 6.28385375 5.63282305 6.59804842\n",
      " 5.79110452 6.74352193 5.60890846 6.4929065  5.48782588 5.28457863\n",
      " 4.61641109 4.26610677 5.87505434 6.85296109 4.04770368 6.94354465\n",
      " 5.82516008 5.95959645 6.08151431 4.69914746 6.24646701 6.52861202\n",
      " 5.03250416 6.07364721 4.76694047 6.64688599 5.85222291 6.42047315\n",
      " 5.15474951 6.03775773 5.30558412 4.52288487 5.67981859 6.74943219\n",
      " 5.34071695 5.36850292]\n",
      "\n",
      "What it should be:  [5.83333333 5.33333333 5.83333333 6.         5.66666667 6.83333333\n",
      " 5.33333333 5.5        5.16666667 4.83333333 6.5        6.\n",
      " 4.83333333 3.5        5.33333333 6.         6.66666667 6.5\n",
      " 5.83333333 6.16666667 6.33333333 6.         7.         6.33333333\n",
      " 5.83333333 5.16666667 3.         6.16666667 3.83333333 5.5\n",
      " 6.33333333 4.5        5.83333333 4.83333333 6.83333333 5.33333333\n",
      " 6.83333333 6.16666667 5.16666667 5.66666667 3.33333333 6.\n",
      " 6.         5.33333333 5.16666667 6.83333333 5.66666667 6.83333333\n",
      " 5.66666667 4.66666667 6.33333333 6.5        4.83333333 5.66666667\n",
      " 5.16666667 6.66666667 6.16666667 6.         4.66666667 6.16666667\n",
      " 4.33333333 7.         5.83333333 6.         6.16666667 5.83333333\n",
      " 6.33333333 5.16666667 5.33333333 6.         5.33333333 6.16666667\n",
      " 4.         5.66666667]\n",
      "Correlation:  [[1.         0.10055188]\n",
      " [0.10055188 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.71\n",
      "R2 score = -0.73\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.52844866 6.42322352 5.44757985 5.9844948  5.45573394 6.54000337\n",
      " 6.0030552  5.98847886 5.77831233 5.96397081 4.97083154 6.10084325\n",
      " 6.43956847 5.0285194  5.34720734 4.45276805 6.37399644 6.28229188\n",
      " 7.16399309 6.62097158 5.95626243 5.60203816 5.38476226 5.44789756\n",
      " 5.22042868 6.46368083 6.97942324 6.40766708 6.62863113 4.27082013\n",
      " 6.15192617 5.44371873 5.33469372 6.68485937 6.33622527 5.73389929\n",
      " 5.63979774 5.56480341 4.949473   5.75571481 5.68216289 5.81193297\n",
      " 7.01788267 5.35837612 5.705539   6.29104038 5.49523441 5.69667075\n",
      " 6.22591105 5.88225762 5.30468666 5.02645829 5.47376773 4.26149897\n",
      " 4.7933093  6.24119181 6.74321211 4.77739454 5.49642725 5.96558919\n",
      " 5.97844699 5.50345141 6.02959676 4.87069508 4.8535123  5.35649605\n",
      " 4.85148834 5.26250239 6.52602588 5.90685298 6.37780602 5.07105521\n",
      " 5.61686889 5.71212714]\n",
      "\n",
      "What it should be:  [6.66666667 4.66666667 6.66666667 5.33333333 6.83333333 6.5\n",
      " 6.16666667 5.33333333 6.16666667 6.         6.33333333 5.83333333\n",
      " 6.16666667 4.66666667 5.33333333 5.33333333 3.         5.16666667\n",
      " 6.33333333 7.         5.66666667 6.16666667 5.         4.5\n",
      " 5.5        5.33333333 6.83333333 4.66666667 5.83333333 5.33333333\n",
      " 6.83333333 5.16666667 6.33333333 5.66666667 6.         4.83333333\n",
      " 6.33333333 4.33333333 5.5        1.83333333 5.         7.\n",
      " 6.33333333 6.5        5.83333333 5.83333333 6.5        5.5\n",
      " 5.33333333 6.83333333 5.         6.83333333 5.33333333 7.\n",
      " 6.83333333 5.83333333 5.5        5.16666667 6.66666667 4.5\n",
      " 6.83333333 4.16666667 5.33333333 5.66666667 4.83333333 5.16666667\n",
      " 3.33333333 6.83333333 5.66666667 5.66666667 5.33333333 3.66666667\n",
      " 5.16666667 6.5       ]\n",
      "Correlation:  [[1.         0.09049988]\n",
      " [0.09049988 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.27\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.93000149 5.67987524 5.30690113 4.74593432 6.88029692 6.29007623\n",
      " 4.91833405 5.93880479 4.93642628 5.54784067 5.16403329 5.70835545\n",
      " 5.67398028 6.76327003 4.79230124 6.08848612 4.87224071 5.90702833\n",
      " 4.53598083 6.045834   6.92407184 7.28063741 6.80950553 4.3729621\n",
      " 6.76163308 5.22074371 5.12266329 5.16009646 4.78984229 5.51459888\n",
      " 6.24104522 6.34387602 5.78084019 5.43152806 5.22368445 5.83602068\n",
      " 4.92925437 2.88600918 4.32759122 6.09338392 5.97211747 5.39091265\n",
      " 4.62756059 6.4975762  5.22221851 7.09404748 5.89810615 5.36256302\n",
      " 5.98640883 6.4713143  6.05850246 7.43321924 6.37175241 5.85040768\n",
      " 5.9329756  5.97681669 6.49981589 6.58861221 5.93060209 5.4165489\n",
      " 5.08233517 6.31974001 6.36954066 5.11185589 6.85321014 5.46062499\n",
      " 6.6936821  5.58074489 4.87386376 6.91493508 4.88706967 4.65909047\n",
      " 5.18845231 6.31647681]\n",
      "\n",
      "What it should be:  [4.83333333 5.33333333 3.         4.5        6.16666667 4.66666667\n",
      " 6.5        6.83333333 5.83333333 6.5        6.33333333 6.5\n",
      " 7.         6.         6.83333333 6.16666667 6.         5.\n",
      " 5.16666667 5.66666667 6.         6.         5.66666667 5.\n",
      " 5.33333333 6.16666667 3.33333333 5.5        5.5        6.66666667\n",
      " 5.83333333 6.5        5.33333333 6.66666667 6.16666667 6.\n",
      " 6.5        4.83333333 4.33333333 5.16666667 6.         4.5\n",
      " 5.83333333 6.         5.33333333 5.33333333 6.16666667 5.66666667\n",
      " 6.83333333 7.         6.         5.33333333 6.         6.5\n",
      " 6.66666667 5.5        5.16666667 6.5        5.33333333 3.5\n",
      " 5.5        5.16666667 5.83333333 4.         6.83333333 6.33333333\n",
      " 5.16666667 6.16666667 3.83333333 5.66666667 7.         3.66666667\n",
      " 6.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.26248715]\n",
      " [0.26248715 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.89\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.07474864 5.67867383 4.87577747 6.15196297 5.37034672 5.66657009\n",
      " 5.84891552 4.83952782 5.16635565 5.95612699 5.18587945 5.83363687\n",
      " 4.54869879 4.87925561 4.17924358 5.26727721 6.06882976 6.28269072\n",
      " 5.52954696 7.51074246 5.89820903 4.57744575 4.34262665 4.95439015\n",
      " 5.04264685 5.00482416 5.82225586 5.36651671 6.67636287 5.9072961\n",
      " 4.65304062 6.15015858 6.07991276 4.26738417 4.9908867  5.40062912\n",
      " 4.58038816 5.57462542 6.47214689 6.30932747 5.34172755 5.88905443\n",
      " 5.93486892 5.15356753 5.2095374  5.86965409 5.39660505 5.21774719\n",
      " 5.26168449 5.05930356 5.72269719 6.29719041 4.23839655 5.54633623\n",
      " 5.5059125  5.25324454 5.84036263 4.24522599 5.77108703 6.85404814\n",
      " 4.74074511 5.26529863 4.56087278 5.08024456 5.90160948 5.7640459\n",
      " 4.93877255 4.86724674 5.65894394 3.88654209 4.8318563  5.68982504\n",
      " 5.47769899 4.70199198]\n",
      "\n",
      "What it should be:  [6.16666667 4.5        6.33333333 5.83333333 5.         6.66666667\n",
      " 4.83333333 3.33333333 5.33333333 5.5        4.66666667 6.\n",
      " 6.5        4.66666667 5.33333333 6.83333333 7.         4.5\n",
      " 5.5        6.         6.16666667 5.66666667 4.         6.83333333\n",
      " 5.83333333 6.         4.16666667 6.16666667 5.83333333 5.\n",
      " 6.         5.5        6.33333333 4.5        6.5        4.\n",
      " 5.5        5.33333333 5.83333333 4.         4.5        5.83333333\n",
      " 5.66666667 6.16666667 5.83333333 4.83333333 7.         5.16666667\n",
      " 5.16666667 6.16666667 6.5        6.16666667 4.83333333 5.5\n",
      " 5.33333333 6.16666667 6.83333333 3.66666667 5.66666667 4.83333333\n",
      " 6.16666667 6.16666667 3.66666667 6.66666667 6.66666667 6.83333333\n",
      " 6.5        6.33333333 6.         4.83333333 5.66666667 5.33333333\n",
      " 5.66666667 6.        ]\n",
      "Correlation:  [[1.         0.16698633]\n",
      " [0.16698633 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.05\n",
      "Median absolute error = 0.87\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.86891653 5.07571532 6.23107166 5.30642491 5.71212693 6.55669618\n",
      " 6.53243255 6.52836218 5.01835825 5.89236232 6.38159904 5.52707648\n",
      " 5.7168493  5.75588037 6.49352943 5.5683283  4.64472575 6.28872404\n",
      " 5.86438266 5.59256878 5.46954128 5.32571757 6.17744375 5.22453986\n",
      " 6.10163186 5.66213771 6.26491231 6.42464587 4.65709758 6.00243896\n",
      " 5.48295047 6.89677608 5.6734759  6.14873067 5.99056156 5.39036703\n",
      " 5.38469466 4.91612358 5.7836608  5.4902052  6.98064475 5.36617398\n",
      " 6.2247756  5.63061416 3.00550971 5.86953054 4.8965211  6.01061243\n",
      " 5.64373306 5.63120653 6.20792008 6.72150755 5.88266486 5.51295971\n",
      " 6.44907907 4.29101712 6.22296186 5.74548337 5.37196264 6.00213324\n",
      " 6.41864069 5.28891726 4.72912833 5.41888985 4.36318099 5.15962519\n",
      " 6.08901992 5.92348389 5.6566997  6.19723263 5.0321454  5.3933159\n",
      " 6.5283034  5.56921081]\n",
      "\n",
      "What it should be:  [4.5        4.66666667 5.66666667 4.33333333 6.         5.83333333\n",
      " 6.33333333 6.16666667 6.33333333 6.66666667 1.83333333 7.\n",
      " 5.5        6.         6.5        6.5        5.         6.83333333\n",
      " 6.83333333 4.5        6.5        6.33333333 3.83333333 6.16666667\n",
      " 6.16666667 5.33333333 4.83333333 6.5        6.33333333 6.16666667\n",
      " 4.83333333 7.         4.66666667 6.33333333 6.66666667 3.66666667\n",
      " 6.5        3.66666667 6.66666667 6.         6.33333333 6.5\n",
      " 5.33333333 5.33333333 4.5        5.66666667 6.5        4.66666667\n",
      " 5.33333333 3.         6.5        4.66666667 5.66666667 5.33333333\n",
      " 6.16666667 5.33333333 6.83333333 6.16666667 6.5        5.83333333\n",
      " 5.         6.16666667 6.         5.33333333 4.33333333 5.5\n",
      " 6.5        6.33333333 5.16666667 7.         6.         4.83333333\n",
      " 4.66666667 4.33333333]\n",
      "Correlation:  [[1.         0.18028834]\n",
      " [0.18028834 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.23\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.11860832 6.07076761 5.35622169 6.48842497 5.4032633  4.88651839\n",
      " 6.64087859 6.19775839 4.83951211 6.55888738 5.08888413 6.42820255\n",
      " 5.53076949 5.1002009  5.67361316 7.00552649 6.02120139 5.2361835\n",
      " 4.69155696 4.39157291 5.31682713 5.74302124 5.80979637 5.75326242\n",
      " 4.64011244 6.20676623 4.30656211 5.71572729 4.74880379 5.57460542\n",
      " 4.59644622 4.90725927 4.51528629 5.39581124 6.55232928 4.8810462\n",
      " 5.82840024 5.81430215 4.51128407 5.25862859 6.67899053 5.81329169\n",
      " 5.05062922 5.51538628 4.87935492 6.96877561 6.31578621 6.32270084\n",
      " 6.78544387 6.46156193 6.03134134 6.00623828 6.41592662 5.72839903\n",
      " 5.5606518  4.40595856 5.48666123 5.91578074 6.37335421 6.34142729\n",
      " 6.0877536  6.7475111  5.48209724 5.03466806 5.60292462 4.77414807\n",
      " 5.21058483 5.95319744 5.08724144 5.32954999 6.60436129 6.02491951\n",
      " 5.67075543 5.23315784]\n",
      "\n",
      "What it should be:  [5.33333333 6.33333333 4.83333333 6.66666667 5.66666667 7.\n",
      " 6.         6.16666667 5.16666667 6.5        6.33333333 5.33333333\n",
      " 6.         6.         6.66666667 5.16666667 3.5        5.33333333\n",
      " 4.83333333 4.5        5.16666667 6.83333333 6.5        1.83333333\n",
      " 5.66666667 4.5        4.         4.         5.5        4.83333333\n",
      " 5.83333333 4.33333333 5.5        6.16666667 5.66666667 6.5\n",
      " 5.33333333 5.5        5.33333333 6.         5.83333333 6.16666667\n",
      " 5.5        6.5        6.5        6.83333333 6.5        6.33333333\n",
      " 4.66666667 5.33333333 3.83333333 5.5        6.16666667 5.83333333\n",
      " 5.33333333 6.16666667 6.33333333 6.16666667 6.16666667 5.66666667\n",
      " 6.83333333 6.66666667 4.83333333 4.         5.         3.66666667\n",
      " 5.16666667 6.16666667 6.5        6.16666667 6.16666667 6.16666667\n",
      " 5.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.19562809]\n",
      " [0.19562809 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.26\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.36011651 4.99738676 3.58090993 5.14234411 5.01868886 4.46859835\n",
      " 5.40409844 4.96987253 5.17926398 5.77791693 6.30016976 5.5225867\n",
      " 5.59271901 5.51413963 5.65228317 5.30530414 5.9950549  5.62960468\n",
      " 3.94573984 5.07007298 5.42652949 5.88564478 4.56562772 4.98300528\n",
      " 5.59591702 4.75873296 5.86790893 5.64129185 6.53125732 6.26546427\n",
      " 6.30832378 5.39706069 5.24956646 6.10870351 5.84889757 6.2456574\n",
      " 5.82798164 5.31235332 5.29523264 5.03191029 5.47865234 5.93515911\n",
      " 6.24698182 6.02484179 5.48708994 5.29818383 5.58530919 6.8111446\n",
      " 3.63144217 5.96816089 4.5801218  5.18275676 6.33579991 5.55170832\n",
      " 6.33014876 4.10754142 5.66964956 7.06501169 6.59958489 4.9676524\n",
      " 5.777539   4.93456367 5.72437703 4.56881507 5.24380496 5.54622993\n",
      " 6.52038528 4.67806566 6.25971006 5.74824878 3.91696704 5.87300292\n",
      " 6.80347527 4.8921884 ]\n",
      "\n",
      "What it should be:  [5.83333333 6.         6.33333333 6.16666667 5.5        6.16666667\n",
      " 6.5        4.33333333 6.16666667 4.83333333 6.16666667 4.\n",
      " 3.5        5.5        6.16666667 6.5        6.16666667 3.66666667\n",
      " 6.33333333 5.16666667 4.66666667 4.16666667 4.33333333 5.66666667\n",
      " 6.16666667 6.16666667 7.         6.66666667 5.16666667 4.5\n",
      " 6.         6.33333333 5.83333333 4.66666667 6.5        6.66666667\n",
      " 4.83333333 5.         5.33333333 5.83333333 6.83333333 6.5\n",
      " 6.66666667 5.16666667 5.5        5.66666667 5.16666667 6.33333333\n",
      " 5.         7.         6.33333333 6.         6.16666667 5.33333333\n",
      " 6.5        4.83333333 5.66666667 6.5        5.16666667 5.5\n",
      " 5.66666667 6.83333333 5.83333333 4.83333333 4.83333333 5.5\n",
      " 6.16666667 5.5        5.16666667 6.33333333 4.         6.83333333\n",
      " 6.16666667 4.33333333]\n",
      "Correlation:  [[1.         0.19604746]\n",
      " [0.19604746 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.41\n",
      "R2 score = -0.45\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.68960728 4.85792097 5.94757255 5.7886241  4.79424489 7.6488397\n",
      " 5.71547076 6.37782914 5.41989777 5.12906866 5.64129338 5.81791165\n",
      " 5.21222151 3.76101491 4.38194895 5.04312258 5.08118102 6.68419513\n",
      " 6.68867337 6.5632814  4.65406069 5.15722222 6.10284237 5.71370238\n",
      " 5.70315409 5.07477898 6.29257475 5.16217873 5.64973027 5.6250429\n",
      " 5.5614208  5.62042416 5.1183468  6.14459778 7.07201555 4.92184418\n",
      " 5.73408115 4.84111858 5.48656496 4.82946029 4.10906852 6.42378153\n",
      " 5.40403805 5.48203821 5.82758752 4.36165093 5.68143753 4.95414821\n",
      " 4.91489068 6.72738153 6.43858517 6.82377484 5.84866901 5.00050867\n",
      " 6.14385825 6.10967313 5.45656694 5.37230892 5.46134258 6.08752731\n",
      " 5.1268708  5.0789675  5.56722171 4.60424194 7.28171175 5.70888699\n",
      " 5.69705091 6.33872488 6.03172444 5.43075393 6.79928924 5.06861103\n",
      " 5.49497988 5.78696456]\n",
      "\n",
      "What it should be:  [4.83333333 7.         5.         7.         6.         6.16666667\n",
      " 6.         5.83333333 5.33333333 3.66666667 6.16666667 6.5\n",
      " 3.83333333 4.83333333 5.83333333 4.66666667 5.83333333 5.33333333\n",
      " 6.16666667 6.83333333 5.33333333 5.5        6.         6.16666667\n",
      " 6.33333333 4.5        6.         4.5        5.33333333 6.33333333\n",
      " 4.         3.33333333 4.83333333 5.16666667 4.         4.33333333\n",
      " 6.66666667 4.66666667 6.         6.66666667 4.5        5.5\n",
      " 3.5        4.66666667 6.         6.         5.16666667 6.16666667\n",
      " 3.66666667 6.16666667 6.33333333 6.         4.33333333 6.83333333\n",
      " 4.66666667 5.16666667 6.         6.16666667 5.5        5.83333333\n",
      " 5.83333333 4.83333333 5.83333333 5.83333333 6.16666667 5.33333333\n",
      " 6.33333333 5.66666667 4.66666667 5.66666667 5.83333333 5.5\n",
      " 6.5        6.83333333]\n",
      "Correlation:  [[1.         0.20577803]\n",
      " [0.20577803 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.37517536 6.44064656 5.62894932 5.54327761 6.00472584 5.02865631\n",
      " 4.22490959 5.79324333 5.47975465 5.40775245 6.28588782 5.07985107\n",
      " 4.74948609 5.05852499 6.42114007 6.30226098 6.50404828 5.31650691\n",
      " 4.95168885 6.59148856 5.45462269 4.99627565 6.10857829 6.18426816\n",
      " 4.43025274 5.44074716 5.08052206 5.46329822 4.81187404 4.27605622\n",
      " 5.52075841 6.14101542 5.33632786 5.9954963  5.06152171 6.42847289\n",
      " 5.98486037 5.09222583 5.89641904 4.05624294 5.91712879 5.21053669\n",
      " 6.27427591 4.68690021 4.91566377 6.52644061 5.66634493 5.0292407\n",
      " 5.35717477 5.08948    5.97941987 5.90992661 4.22305605 3.83694953\n",
      " 6.22395169 6.91796383 5.6160351  6.56231916 7.14061345 5.96758054\n",
      " 7.02625783 5.81889671 5.89599718 4.74510168 5.4503215  5.29682295\n",
      " 4.59006321 5.08724729 5.24516969 5.32537723 6.97025197 5.68039735\n",
      " 5.55627696 2.19027321]\n",
      "\n",
      "What it should be:  [6.83333333 5.16666667 5.83333333 5.33333333 6.         6.5\n",
      " 5.83333333 5.16666667 4.66666667 5.66666667 6.16666667 5.5\n",
      " 6.33333333 5.5        6.5        6.5        6.5        4.83333333\n",
      " 6.5        4.83333333 4.         6.         6.16666667 6.83333333\n",
      " 5.5        6.83333333 6.5        6.33333333 5.         4.83333333\n",
      " 4.66666667 4.83333333 5.         6.33333333 6.5        6.83333333\n",
      " 3.         6.83333333 5.33333333 4.66666667 6.33333333 4.\n",
      " 6.16666667 5.33333333 5.33333333 6.16666667 6.66666667 6.\n",
      " 6.16666667 6.83333333 4.66666667 5.83333333 5.5        4.\n",
      " 6.         7.         6.16666667 5.66666667 6.         5.\n",
      " 6.16666667 5.33333333 6.66666667 4.         3.66666667 5.33333333\n",
      " 6.33333333 5.16666667 6.66666667 4.66666667 6.5        5.5\n",
      " 7.         5.5       ]\n",
      "Correlation:  [[1.         0.25608762]\n",
      " [0.25608762 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.12\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.43\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.5\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.4280373  5.58778339 5.5923995  5.41368971 5.28271098 6.50898707\n",
      " 6.34655925 5.6529947  4.39151293 4.15895027 5.12645902 5.58035181\n",
      " 5.93733697 5.52516822 5.27800696 6.41797692 5.90406142 5.53265087\n",
      " 5.06180636 6.55544574 5.10841256 4.79623134 4.72773347 6.30267957\n",
      " 5.2379391  6.3468833  4.55463868 5.54679857 4.77088498 4.81822316\n",
      " 6.21333201 6.03103365 6.89730945 5.39470097 6.69344455 5.41441014\n",
      " 4.55974734 5.65010194 5.06421175 7.05020323 5.31653215 5.50129247\n",
      " 5.82760272 5.34968069 4.85456848 6.13058427 5.26001617 5.23004837\n",
      " 7.17317976 5.61339807 5.55180547 5.12049382 7.04783905 6.25921914\n",
      " 4.27707525 6.09108231 5.68875664 5.37428956 5.95459094 5.76806574\n",
      " 5.22249503 5.84784366 5.37994767 4.52399449 5.86026688 5.44910974\n",
      " 5.28528956 5.55826125 6.2250775  5.50580549 6.05044618 6.01552124\n",
      " 5.16646753 5.56464213 5.58820795 6.47645334 5.38228021 5.22257448\n",
      " 5.71039996 4.08167985 4.30695628 6.83115231 4.94085595 7.0043823\n",
      " 6.04500841 6.55179134 7.11970968 5.55867393 5.71560373 6.28003662\n",
      " 6.39905603 6.62762199]\n",
      "\n",
      "What it should be:  [6.66666667 4.         6.33333333 6.16666667 5.16666667 6.66666667\n",
      " 6.         5.16666667 6.16666667 6.16666667 6.16666667 6.\n",
      " 4.83333333 5.16666667 4.83333333 6.5        1.83333333 5.33333333\n",
      " 6.5        4.66666667 4.5        5.33333333 6.83333333 5.83333333\n",
      " 5.         5.5        4.         5.83333333 6.16666667 4.33333333\n",
      " 6.83333333 5.83333333 6.83333333 7.         6.16666667 5.16666667\n",
      " 6.66666667 5.83333333 5.66666667 5.83333333 6.5        6.66666667\n",
      " 5.5        5.         4.66666667 6.         5.33333333 6.\n",
      " 6.16666667 4.33333333 6.         4.33333333 6.33333333 6.\n",
      " 5.83333333 6.33333333 5.5        7.         4.33333333 6.16666667\n",
      " 5.5        5.66666667 4.66666667 6.33333333 6.16666667 7.\n",
      " 6.         3.5        6.         5.         6.         6.66666667\n",
      " 6.66666667 5.66666667 4.66666667 4.66666667 5.33333333 6.16666667\n",
      " 5.         5.16666667 6.83333333 6.33333333 5.5        5.33333333\n",
      " 6.         6.5        5.33333333 6.16666667 6.5        6.33333333\n",
      " 5.66666667 6.33333333]\n",
      "Correlation:  [[1.        0.0824895]\n",
      " [0.0824895 1.       ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.51\n",
      "R2 score = -0.51\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.75628457 5.30096031 5.22079352 4.98258227 5.2134666  5.76659864\n",
      " 6.39723826 4.83782099 5.35339859 5.47462413 6.89664521 6.39771274\n",
      " 6.55345728 5.96795964 6.33578427 5.53458377 5.3203901  5.04174766\n",
      " 5.76001799 5.81186454 5.10722766 6.28768173 6.25356807 6.67654084\n",
      " 6.01770614 4.17161141 6.32253392 5.83583165 6.17016146 5.12522208\n",
      " 4.54792869 4.96665381 6.20068768 5.4962766  5.69306238 5.21655492\n",
      " 5.9944886  5.14862164 4.66469346 6.25261952 5.56751849 6.48921868\n",
      " 5.72686603 5.31335717 7.23818506 5.78627796 5.53973155 4.69756512\n",
      " 5.27857397 5.05477441 5.04528922 4.38336147 4.94751181 4.83766092\n",
      " 5.55408874 6.50840559 6.04591594 5.8564242  5.53472778 5.50984415\n",
      " 5.99516121 4.8727208  6.19752136 6.06000329 5.4475009  5.85600061\n",
      " 5.41236376 6.3313378  5.36702899 5.46204383 6.32287464 5.45252728\n",
      " 6.48791675 6.29681006 6.81733622 5.60390868 4.95650072 4.99589496\n",
      " 6.11588879 5.89952792 5.15483671 5.29457372 5.73994562 5.63921148\n",
      " 5.10248056 5.29681427 5.22094057 5.69465107 5.83260189 6.36050064\n",
      " 6.02896548 6.38858783]\n",
      "\n",
      "What it should be:  [5.83333333 6.66666667 5.         6.         4.33333333 5.66666667\n",
      " 4.66666667 7.         4.         7.         5.66666667 6.\n",
      " 6.16666667 6.33333333 6.83333333 3.33333333 6.         5.33333333\n",
      " 6.         6.16666667 6.83333333 5.83333333 6.33333333 5.33333333\n",
      " 6.33333333 6.16666667 6.33333333 5.33333333 5.16666667 4.33333333\n",
      " 6.83333333 6.5        5.33333333 4.66666667 6.83333333 5.66666667\n",
      " 4.         6.83333333 1.83333333 5.33333333 4.66666667 6.16666667\n",
      " 5.         6.33333333 5.16666667 5.5        3.         7.\n",
      " 5.83333333 6.16666667 6.         4.83333333 5.66666667 5.83333333\n",
      " 6.5        6.5        6.16666667 6.         6.16666667 5.\n",
      " 5.5        4.66666667 6.5        5.16666667 5.5        5.16666667\n",
      " 5.5        5.5        6.16666667 6.16666667 7.         4.66666667\n",
      " 5.66666667 4.5        6.66666667 6.33333333 6.83333333 5.5\n",
      " 6.16666667 5.16666667 3.66666667 6.         4.83333333 5.66666667\n",
      " 4.5        6.16666667 6.33333333 5.33333333 6.         6.83333333\n",
      " 6.83333333 6.5       ]\n",
      "Correlation:  [[1.         0.10493515]\n",
      " [0.10493515 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.26\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.36202674 5.86741003 5.32125132 6.71953006 6.42620059 5.54722181\n",
      " 5.64910981 5.1797862  4.20760606 5.8553669  6.34329673 6.49916588\n",
      " 5.46868014 4.50996209 6.0902413  6.21343314 3.63123622 5.89760713\n",
      " 5.26849838 6.44429767 5.4240982  5.38959797 5.63621431 4.51766684\n",
      " 5.77924804 5.46916466 5.66766263 5.80796583 5.77659537 5.15561818\n",
      " 5.66128436 6.27376249 6.25547582 5.72734473 5.50994801 5.62949698\n",
      " 4.88457713 5.24791618 4.578208   5.87654619 5.17280604 5.40777001\n",
      " 3.89571061 6.79924239 5.27678601 5.13916278 5.62226157 6.42363651\n",
      " 6.26147263 5.73266797 5.54110117 5.52424962 5.77504741 6.50290773\n",
      " 6.75308037 5.21521207 5.87364128 5.06518246 6.01683172 6.39994074\n",
      " 5.67264792 6.27990777 6.0734151  5.83395059 6.45213041 6.29910871\n",
      " 6.83390774 5.54392605 6.77243344 5.14569129 7.36537036 5.19966484\n",
      " 4.87749252 5.51171203 6.20180301 5.32520572 6.40831736 4.94318299\n",
      " 4.56382713 5.26726408 5.19823076 5.46409942 5.95499609 4.81123241\n",
      " 6.33792709 5.90239051 4.18939997 6.10869766 5.90570671 5.70404965\n",
      " 5.32696805 5.80664254]\n",
      "\n",
      "What it should be:  [6.33333333 5.16666667 5.33333333 5.33333333 6.16666667 4.83333333\n",
      " 6.33333333 5.33333333 4.         1.83333333 7.         6.66666667\n",
      " 6.33333333 4.83333333 6.5        4.5        5.         5.5\n",
      " 6.83333333 6.         5.         5.         5.83333333 5.5\n",
      " 6.5        4.33333333 4.5        6.16666667 5.16666667 4.\n",
      " 4.83333333 5.66666667 6.33333333 6.16666667 6.         6.\n",
      " 6.         4.83333333 6.16666667 5.66666667 6.66666667 5.16666667\n",
      " 6.33333333 6.83333333 5.16666667 6.83333333 4.66666667 6.5\n",
      " 4.83333333 3.33333333 6.         5.83333333 6.66666667 6.83333333\n",
      " 5.16666667 4.33333333 4.5        6.83333333 5.33333333 6.5\n",
      " 6.         4.83333333 6.16666667 4.         5.83333333 5.66666667\n",
      " 6.83333333 6.         6.16666667 5.         6.66666667 4.5\n",
      " 6.         6.16666667 6.83333333 5.33333333 5.16666667 5.66666667\n",
      " 5.33333333 4.66666667 6.5        6.5        4.66666667 5.83333333\n",
      " 5.66666667 3.66666667 6.         7.         6.16666667 5.33333333\n",
      " 5.33333333 5.83333333]\n",
      "Correlation:  [[1.         0.19531951]\n",
      " [0.19531951 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.24\n",
      "R2 score = -0.25\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.09441041 5.86449564 6.25804141 5.86070306 5.99171584 6.41797906\n",
      " 5.93954598 5.30609028 5.61726222 7.08701252 5.88126503 6.55236786\n",
      " 6.96115252 5.9707035  5.68570803 5.42285815 5.03548331 7.62202108\n",
      " 6.44053386 6.88161642 5.62655526 4.55519217 6.03360512 6.11984716\n",
      " 4.906491   5.48007545 4.78716252 6.6410442  7.06678708 5.62316722\n",
      " 5.54029045 6.42368792 5.53683572 4.44100735 5.58956784 5.25373309\n",
      " 7.17429565 6.40570388 5.41525623 6.18416792 5.47216291 5.99455818\n",
      " 6.98056909 7.06838792 6.73055819 5.76656614 5.34972979 6.25516553\n",
      " 5.53911322 5.4127426  4.75579578 4.87157146 5.18223927 5.63508091\n",
      " 6.01984841 6.15555311 5.74075323 5.13492511 8.47706367 5.86293294\n",
      " 6.00935863 5.63437268 4.09492612 6.16946232 5.15853733 6.54822276\n",
      " 6.14131766 6.10480359 6.5534394  6.6642683  5.81674254 5.58036567\n",
      " 6.1808989  6.24339903 5.7394832  5.56254488 2.8142928  5.16513225\n",
      " 6.10619827 6.37679153 5.41722541 5.22993767 5.33389565 6.24957318\n",
      " 6.53628631 4.50534981 6.80062583 5.38838944 4.90910499 5.38258836\n",
      " 6.30057709 6.6504353 ]\n",
      "\n",
      "What it should be:  [5.66666667 4.5        4.5        6.         6.         4.\n",
      " 6.33333333 6.         6.         5.16666667 6.33333333 6.16666667\n",
      " 6.5        5.         4.16666667 6.16666667 4.83333333 6.33333333\n",
      " 5.83333333 5.66666667 5.5        5.83333333 6.16666667 6.16666667\n",
      " 4.         7.         4.83333333 5.83333333 6.16666667 5.33333333\n",
      " 5.66666667 6.66666667 4.66666667 4.83333333 5.5        5.\n",
      " 4.         5.5        6.5        5.16666667 4.33333333 5.66666667\n",
      " 6.5        6.5        6.         6.83333333 7.         6.5\n",
      " 5.83333333 6.5        5.5        6.         5.33333333 6.33333333\n",
      " 5.33333333 5.33333333 3.33333333 4.         6.66666667 6.83333333\n",
      " 6.66666667 4.5        4.83333333 6.16666667 6.83333333 4.33333333\n",
      " 6.33333333 4.83333333 6.66666667 7.         6.5        5.33333333\n",
      " 5.33333333 6.33333333 5.         5.83333333 5.5        5.\n",
      " 5.83333333 6.5        6.16666667 5.66666667 4.         6.33333333\n",
      " 5.33333333 3.66666667 6.66666667 3.66666667 4.33333333 5.16666667\n",
      " 4.66666667 6.        ]\n",
      "Correlation:  [[1.         0.30186549]\n",
      " [0.30186549 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.97553149 6.17565197 5.77889723 6.37980946 4.68626784 5.97807823\n",
      " 5.46440192 5.28682504 5.29360279 6.05047579 5.28131681 5.89196947\n",
      " 5.0716669  5.12527994 5.50058743 5.97646525 5.63067535 5.44743073\n",
      " 6.18544947 7.74590186 5.90579398 4.93993423 6.33565408 6.18512949\n",
      " 5.76580216 5.8969804  5.00907426 6.81389942 5.81739968 5.63787645\n",
      " 6.71251806 5.52340513 5.61398111 5.93533343 6.75831207 4.66448088\n",
      " 5.0373096  5.50893903 5.49815335 6.00251616 6.08397772 5.79696856\n",
      " 5.38943349 6.5158367  5.43142795 5.01297666 6.61035697 5.49065776\n",
      " 5.02226953 6.60519088 5.35936966 5.90776504 2.82074886 5.36785396\n",
      " 5.65483289 2.74624986 6.71687264 5.21408274 4.80741201 4.90388056\n",
      " 5.08410169 6.61748315 6.35087852 7.17146918 6.46083146 5.28698226\n",
      " 4.75110319 5.82683908 5.64930867 5.07997738 5.55605178 4.83516713\n",
      " 7.13415255 4.23699186 6.72777032 6.66533801 6.95682022 4.03243932\n",
      " 5.91826999 4.74319882 6.40935588 6.73620065 5.51159072 5.58070983\n",
      " 6.72377113 5.91960882 4.83498448 5.53798386 6.45027221 5.15006593\n",
      " 6.20200446 5.71021607]\n",
      "\n",
      "What it should be:  [6.33333333 6.83333333 4.5        4.66666667 6.         7.\n",
      " 5.66666667 5.83333333 5.16666667 6.         5.33333333 5.5\n",
      " 4.33333333 6.5        5.5        5.33333333 6.83333333 4.66666667\n",
      " 6.16666667 6.         6.         5.         6.66666667 4.5\n",
      " 6.33333333 6.16666667 6.33333333 4.66666667 5.16666667 6.\n",
      " 6.33333333 5.66666667 5.66666667 6.33333333 6.5        6.16666667\n",
      " 5.83333333 5.5        6.83333333 5.83333333 6.         4.\n",
      " 5.33333333 6.83333333 6.16666667 5.33333333 5.83333333 6.83333333\n",
      " 5.5        5.33333333 6.16666667 6.16666667 4.83333333 6.33333333\n",
      " 5.16666667 5.5        6.5        5.33333333 6.         5.33333333\n",
      " 4.5        6.5        5.33333333 6.5        6.83333333 6.16666667\n",
      " 4.83333333 3.66666667 4.33333333 5.         6.33333333 6.\n",
      " 7.         4.         7.         6.66666667 5.66666667 3.66666667\n",
      " 5.83333333 6.5        6.16666667 3.         5.33333333 5.\n",
      " 6.5        5.33333333 4.83333333 6.66666667 6.16666667 5.\n",
      " 6.83333333 4.66666667]\n",
      "Correlation:  [[1.         0.31359868]\n",
      " [0.31359868 1.        ]]\n",
      "Mean absolute error = 0.71\n",
      "Mean squared error = 0.97\n",
      "Median absolute error = 0.56\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.46836198 5.52911408 5.79782406 5.40376287 4.77738094 5.64700495\n",
      " 6.0342489  5.09053672 5.35082929 6.05301945 5.44574325 5.54438813\n",
      " 4.65952168 6.53384732 5.48898712 6.06856809 5.91847261 5.41769534\n",
      " 5.65463309 5.65122563 4.45197892 5.53828089 4.44576774 6.15084992\n",
      " 5.69294752 6.75458193 5.64095555 4.5608711  5.7606514  5.97875902\n",
      " 5.45673499 6.66821551 5.31434937 5.16322721 4.78885231 5.12319933\n",
      " 5.91207929 5.42194234 6.05180007 5.95459358 5.67685994 5.11108171\n",
      " 6.03076109 5.78728491 6.00350441 5.6361592  6.34239861 6.92667249\n",
      " 5.31007734 6.15566563 5.17500222 5.65620076 5.8250698  6.20434703\n",
      " 5.42477753 6.3987162  5.56204863 5.1642428  5.41895846 6.39060656\n",
      " 5.69663071 5.93823532 5.56911207 5.56901018 5.21256982 5.17931453\n",
      " 5.57416653 5.25765886 5.80838446 6.44185259 5.88012712 6.0875308\n",
      " 4.65000113 5.34879274 5.03819624 5.30013348 5.2306897  5.25836163\n",
      " 6.30026104 5.86482292 5.3759152  6.39707046 5.3619338  5.99961203\n",
      " 4.81762705 5.97291863 6.89781761 6.10951062 5.17048069 5.60176121\n",
      " 4.95517983 5.51741506]\n",
      "\n",
      "What it should be:  [6.33333333 6.         5.16666667 6.16666667 6.16666667 5.83333333\n",
      " 5.66666667 6.83333333 4.33333333 5.66666667 4.5        6.83333333\n",
      " 5.5        6.33333333 4.33333333 6.66666667 6.16666667 5.66666667\n",
      " 6.16666667 6.83333333 6.66666667 5.33333333 5.33333333 4.83333333\n",
      " 6.83333333 5.83333333 6.83333333 6.33333333 7.         6.16666667\n",
      " 5.33333333 6.5        6.16666667 5.33333333 6.66666667 3.66666667\n",
      " 5.5        5.66666667 5.33333333 6.33333333 5.16666667 5.5\n",
      " 4.83333333 6.33333333 4.66666667 1.83333333 6.16666667 6.33333333\n",
      " 4.66666667 5.16666667 6.5        6.5        3.66666667 4.83333333\n",
      " 5.5        5.83333333 6.83333333 3.66666667 6.5        6.16666667\n",
      " 5.83333333 6.33333333 5.83333333 5.5        6.33333333 6.5\n",
      " 6.         4.33333333 5.83333333 6.83333333 5.16666667 5.33333333\n",
      " 4.33333333 5.         6.66666667 6.66666667 6.16666667 4.5\n",
      " 7.         6.16666667 6.33333333 6.         4.66666667 6.5\n",
      " 4.         5.33333333 6.         5.16666667 6.16666667 3.83333333\n",
      " 4.         5.5       ]\n",
      "Correlation:  [[1.         0.14898556]\n",
      " [0.14898556 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.14\n",
      "R2 score = -0.14\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.46395014 5.38961942 4.81525579 4.41523876 5.62930625 5.37673439\n",
      " 5.59317101 6.03693916 4.87867726 6.60620785 4.82907311 5.41165028\n",
      " 5.54106953 6.00222892 5.64323356 5.47230485 5.79410833 6.84291248\n",
      " 6.11456576 5.2824244  5.93251139 6.37849871 5.28147408 5.96446174\n",
      " 5.17385689 5.4163586  6.28913162 5.27363464 6.02928102 6.01518418\n",
      " 7.10089126 5.64132228 3.96855517 6.42903264 6.64998461 5.70467045\n",
      " 5.62263756 6.03732339 5.11237556 6.23559664 4.21602083 5.44381748\n",
      " 5.41155001 5.50191004 5.59905715 6.01369639 6.40172849 4.43929416\n",
      " 5.27150189 3.37846623 4.43514695 5.5773255  5.80741812 5.3267785\n",
      " 5.10557263 5.55195318 6.58413446 6.18828632 6.98900015 4.82103436\n",
      " 6.19402749 4.38789896 4.853702   6.1842836  4.58931775 5.51392633\n",
      " 6.01473351 4.1149228  5.49067801 5.25644694 4.15034395 6.09035852\n",
      " 5.84544287 4.85371612 5.63843696 5.01742779 4.71067878 4.87419242\n",
      " 5.71604617 4.81003845 6.94745005 6.48818326 4.61905929 4.95555449\n",
      " 5.2463297  5.27860854 5.13638171 5.71736128 6.50002736 5.15172411\n",
      " 5.45523312 6.3989579 ]\n",
      "\n",
      "What it should be:  [3.         6.         6.83333333 4.33333333 4.33333333 5.16666667\n",
      " 6.16666667 6.16666667 6.83333333 5.5        6.33333333 4.66666667\n",
      " 5.66666667 4.66666667 5.33333333 6.66666667 6.33333333 7.\n",
      " 6.         6.33333333 5.66666667 6.         6.5        6.5\n",
      " 6.5        5.16666667 6.5        6.5        5.33333333 5.83333333\n",
      " 5.83333333 6.5        4.         6.33333333 6.5        5.66666667\n",
      " 5.16666667 6.5        6.16666667 6.83333333 6.         4.16666667\n",
      " 6.16666667 5.83333333 5.33333333 6.66666667 6.16666667 4.83333333\n",
      " 6.66666667 5.5        5.5        6.83333333 6.16666667 5.83333333\n",
      " 3.66666667 6.         5.66666667 5.33333333 6.33333333 5.83333333\n",
      " 5.16666667 4.83333333 5.83333333 5.83333333 4.5        6.66666667\n",
      " 5.5        6.33333333 6.83333333 4.83333333 4.66666667 4.66666667\n",
      " 5.33333333 5.5        5.66666667 4.83333333 4.83333333 6.16666667\n",
      " 6.16666667 3.33333333 6.16666667 6.5        6.66666667 6.33333333\n",
      " 6.16666667 3.83333333 5.         5.66666667 5.         3.5\n",
      " 6.33333333 6.16666667]\n",
      "Correlation:  [[1.         0.27467495]\n",
      " [0.27467495 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.90815384 5.17917659 5.34350154 7.02264879 6.11058479 5.2578547\n",
      " 5.23428389 5.8271443  5.48481391 5.99433744 5.8470959  5.51602381\n",
      " 5.43568823 6.41566802 5.16894601 6.35278646 4.64115209 5.7339952\n",
      " 5.64847529 4.39838243 4.46091661 4.68220365 6.16744965 5.19575153\n",
      " 4.6122747  6.03325787 6.32614439 5.444302   5.40883357 5.72620556\n",
      " 5.06063339 6.18315042 4.76637775 4.04961855 5.37946416 5.8591763\n",
      " 5.7393133  6.65366373 6.58555466 6.21986572 6.13900262 6.29524205\n",
      " 5.76942    5.0056245  4.89020452 6.17431197 5.4544379  5.81951046\n",
      " 4.47165425 5.99778062 4.38575153 5.9624721  5.16616236 5.31917214\n",
      " 5.24735234 6.25355105 6.26631575 4.50750551 5.18937906 5.78735155\n",
      " 5.42247418 6.03982718 5.57832514 5.43167292 5.64594615 5.91313607\n",
      " 6.43542586 5.8561425  5.13423259 5.34809564 5.61253221 5.3668774\n",
      " 6.74938885 5.72568592 5.98652248 6.68252908 5.28252895 6.34709013\n",
      " 5.71199537 6.39908228 4.52195328 5.66060267 5.85683897 5.21141803\n",
      " 5.90132997 4.46986851 5.87693013 5.0848282  5.99014602 4.22474162\n",
      " 5.26937853 5.50408719]\n",
      "\n",
      "What it should be:  [6.         6.16666667 6.         6.16666667 6.         6.\n",
      " 5.5        5.33333333 4.5        6.66666667 6.16666667 6.16666667\n",
      " 6.66666667 6.16666667 5.33333333 6.33333333 7.         4.16666667\n",
      " 5.66666667 5.5        6.83333333 5.83333333 5.66666667 6.33333333\n",
      " 4.83333333 5.16666667 5.83333333 6.16666667 7.         5.33333333\n",
      " 6.83333333 6.5        5.         4.5        3.83333333 5.66666667\n",
      " 5.33333333 5.83333333 7.         6.66666667 7.         4.66666667\n",
      " 6.83333333 4.83333333 4.83333333 5.33333333 5.33333333 4.66666667\n",
      " 5.66666667 7.         5.33333333 6.5        6.5        4.\n",
      " 4.5        4.83333333 6.83333333 5.66666667 5.5        5.66666667\n",
      " 6.33333333 5.66666667 4.33333333 4.83333333 6.16666667 6.33333333\n",
      " 6.83333333 1.83333333 6.66666667 6.         5.33333333 6.5\n",
      " 6.5        5.66666667 6.5        6.66666667 5.16666667 5.83333333\n",
      " 6.5        6.33333333 6.16666667 5.83333333 5.16666667 6.16666667\n",
      " 6.16666667 4.66666667 5.83333333 5.5        5.16666667 6.33333333\n",
      " 4.66666667 5.16666667]\n",
      "Correlation:  [[1.         0.19536305]\n",
      " [0.19536305 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.97\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.97087965 6.36987706 5.34047892 4.4572815  4.34035946 5.25883217\n",
      " 5.01333038 5.71191697 4.00026139 6.7827652  4.88528619 5.22279332\n",
      " 5.56554881 6.62145486 5.86534994 6.19368728 7.0638963  4.17529671\n",
      " 5.6489744  5.79403649 5.65704871 4.84979688 3.5272917  4.66335049\n",
      " 5.9352304  5.22944155 4.84873483 4.90356763 5.1043864  5.53047225\n",
      " 4.90830162 6.15341102 5.53758682 6.84409673 6.10225806 6.16004321\n",
      " 3.20329607 4.52104243 5.86054665 4.83710479 5.70522328 5.21820848\n",
      " 6.71224858 6.27489024 6.33420769 5.93252792 6.28471682 6.35994117\n",
      " 6.80230661 5.08125826 5.48599538 5.59811804 5.26403265 4.59759602\n",
      " 5.66899383 6.08031805 5.32683928 5.43792105 5.12698567 5.32809709\n",
      " 5.7291964  5.46406078 4.90022152 6.21278382 5.70312047 4.49342936\n",
      " 5.79344442 5.83719278 5.87594676 5.90031921 6.29737149 5.95145849\n",
      " 5.99671485 6.11906152 5.53595558 6.01745837 4.58749837 6.57528605\n",
      " 5.66715353 6.32190558 4.51414678 6.45296488 5.27571334 4.03316629\n",
      " 5.8778608  6.42289339 4.23951187 4.81185547 5.63270851 5.80619411\n",
      " 4.62248286 5.96062894]\n",
      "\n",
      "What it should be:  [5.33333333 5.33333333 6.83333333 5.33333333 6.83333333 6.66666667\n",
      " 5.33333333 4.83333333 6.5        6.5        4.         5.5\n",
      " 6.         5.83333333 3.66666667 4.66666667 4.5        5.66666667\n",
      " 6.5        6.         6.16666667 7.         4.83333333 6.5\n",
      " 5.33333333 5.         6.16666667 7.         6.16666667 5.\n",
      " 4.66666667 6.33333333 5.33333333 6.83333333 4.66666667 6.\n",
      " 5.83333333 6.         5.83333333 5.83333333 5.5        5.\n",
      " 7.         6.         5.5        5.33333333 5.16666667 5.83333333\n",
      " 6.83333333 4.33333333 4.33333333 6.         4.83333333 6.5\n",
      " 7.         4.83333333 5.5        6.16666667 6.66666667 4.66666667\n",
      " 5.66666667 6.83333333 3.66666667 5.66666667 5.66666667 6.66666667\n",
      " 4.66666667 6.5        6.83333333 6.5        4.16666667 6.\n",
      " 6.16666667 5.5        4.5        6.16666667 4.83333333 6.5\n",
      " 5.33333333 5.66666667 4.66666667 7.         3.5        5.5\n",
      " 4.5        5.33333333 5.83333333 5.66666667 5.83333333 4.\n",
      " 3.83333333 3.33333333]\n",
      "Correlation:  [[1.        0.0488515]\n",
      " [0.0488515 1.       ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.61\n",
      "R2 score = -0.62\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.36467417 4.96986358 6.32862864 6.17294678 6.14084094 5.52255663\n",
      " 5.91694183 5.44518719 5.31430546 5.73015039 5.31513525 6.25701051\n",
      " 4.77715748 5.46566006 5.60056744 6.58934588 5.39045009 6.4500255\n",
      " 5.98703217 6.27162853 5.86929267 6.17096396 4.01313172 5.63570144\n",
      " 5.19199291 6.10751369 5.02873983 4.93229438 5.39841556 5.8259784\n",
      " 4.0342225  5.20637442 5.30337027 5.91406034 5.29890272 4.74620919\n",
      " 4.24853086 6.01771405 5.4422082  4.53834425 6.24078619 4.02890363\n",
      " 6.91238378 6.75642957 5.86557601 4.46352943 5.87604805 5.49041035\n",
      " 4.80573328 5.1910652  6.12185047 5.20911767 4.96350143 6.24810736\n",
      " 5.30571805 6.37068076 5.59333135 6.98550523 5.84548236 6.58321905\n",
      " 5.9383368  5.71769262 5.19152316 5.33311543 4.67199935 5.51162235\n",
      " 4.53700765 6.86372996 5.64508565 6.34257528 6.49042589 5.84390533\n",
      " 4.243539   6.58022372 5.58129838 5.65705649 6.32206906 4.98333541\n",
      " 4.76286311 6.01804091 5.68026441 5.27247268 3.92658798 5.98253196\n",
      " 6.74135321 6.54547641 5.77903458 7.46186837 6.97282175 5.69970986\n",
      " 4.96162623 5.91655758]\n",
      "\n",
      "What it should be:  [4.83333333 6.16666667 6.         6.66666667 5.33333333 6.16666667\n",
      " 6.66666667 5.33333333 5.83333333 5.         4.83333333 6.5\n",
      " 4.         6.         5.33333333 6.         5.33333333 5.83333333\n",
      " 4.83333333 5.66666667 6.33333333 6.16666667 6.         6.33333333\n",
      " 5.83333333 7.         3.66666667 4.         5.33333333 6.16666667\n",
      " 4.66666667 4.5        5.83333333 5.83333333 6.33333333 5.83333333\n",
      " 5.33333333 5.33333333 4.66666667 6.5        6.66666667 6.33333333\n",
      " 5.33333333 4.66666667 6.5        3.5        6.         5.5\n",
      " 6.5        6.         5.83333333 3.83333333 5.5        6.33333333\n",
      " 6.16666667 6.5        6.83333333 7.         5.66666667 5.66666667\n",
      " 5.33333333 4.83333333 5.66666667 6.         7.         7.\n",
      " 6.5        6.33333333 6.33333333 5.33333333 5.66666667 5.16666667\n",
      " 6.         6.66666667 6.33333333 6.83333333 5.5        5.66666667\n",
      " 7.         6.16666667 5.83333333 5.5        6.33333333 6.83333333\n",
      " 6.         5.33333333 3.         6.16666667 6.16666667 5.16666667\n",
      " 5.66666667 4.66666667]\n",
      "Correlation:  [[1.         0.16502927]\n",
      " [0.16502927 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.53\n",
      "R2 score = -0.55\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.35604162 6.17613536 6.23309601 5.89244071 5.36656027 6.39031876\n",
      " 5.91067965 6.40826583 6.37079526 5.44276985 6.87900499 6.62057828\n",
      " 5.14085843 6.35467097 5.63266826 5.62795099 6.03194308 4.80945176\n",
      " 6.23248354 5.78358469 6.00291197 4.41562595 6.15934917 6.1210495\n",
      " 5.54996286 5.16159027 6.40430827 6.75490504 5.72532425 6.06305378\n",
      " 6.40260618 5.73302733 6.60077397 5.72742544 4.8340383  5.73011331\n",
      " 6.05229903 5.59001459 5.93545881 5.75900996 4.85615044 6.19246622\n",
      " 4.11812055 5.20253363 6.376353   6.28348263 6.16160393 5.47455896\n",
      " 5.23844688 6.15768909 4.54086108 6.52766326 4.54795476 6.44768313\n",
      " 4.96143375 5.77636801 7.00898304 5.25139397 6.09354709 5.83716885\n",
      " 5.91766404 5.95004478 5.92731838 6.28023398 5.32626292 5.80586561\n",
      " 4.48732791 5.70054807 4.83951947 6.04258011 6.09207934 5.51552722\n",
      " 4.7151126  6.70503562 5.88526995 5.65682268 5.40738423 5.81126998\n",
      " 4.95765419 5.55255036 3.1013496  6.02818998 5.88204115 5.11329212\n",
      " 5.81277553 6.22101326 5.58688203 5.80848198 6.22692929 5.69819578\n",
      " 6.34372143 5.83426922]\n",
      "\n",
      "What it should be:  [6.16666667 5.66666667 6.         6.33333333 4.66666667 6.83333333\n",
      " 6.66666667 5.83333333 4.         4.         6.5        6.16666667\n",
      " 6.         6.5        5.83333333 5.16666667 5.66666667 4.66666667\n",
      " 5.66666667 4.5        6.16666667 6.5        6.5        5.\n",
      " 6.5        6.16666667 5.33333333 4.33333333 6.16666667 5.16666667\n",
      " 6.16666667 5.83333333 6.16666667 5.66666667 5.83333333 6.83333333\n",
      " 4.83333333 4.         6.5        6.         6.83333333 6.83333333\n",
      " 6.16666667 4.         5.83333333 5.66666667 6.16666667 6.\n",
      " 5.33333333 5.33333333 6.33333333 6.66666667 4.33333333 3.83333333\n",
      " 5.         6.83333333 4.83333333 5.66666667 5.33333333 6.16666667\n",
      " 4.66666667 6.         6.5        7.         6.         6.83333333\n",
      " 5.66666667 6.5        6.83333333 5.33333333 6.         4.16666667\n",
      " 3.66666667 5.16666667 1.83333333 6.16666667 5.83333333 4.5\n",
      " 7.         5.33333333 4.5        4.83333333 3.66666667 6.5\n",
      " 4.66666667 4.33333333 5.         5.16666667 4.66666667 6.\n",
      " 5.33333333 6.66666667]\n",
      "Correlation:  [[1.         0.03517678]\n",
      " [0.03517678 1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.34\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.41\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.44923532 4.74791958 4.94526223 5.49880015 4.06856844 5.05280212\n",
      " 5.54986411 5.87246004 5.83610826 6.8578936  3.10916273 6.20515531\n",
      " 3.31896195 5.58517589 5.90439782 3.6332474  6.77474264 5.54206764\n",
      " 3.52142682 5.24958777 5.38985132 5.37187847 6.17950721 3.72059659\n",
      " 4.69456759 4.97216916 5.88043225 5.83320819 5.84338533 4.95367841\n",
      " 5.77519607 5.85052965 5.02706691 5.77334204 5.23507262 5.71678243\n",
      " 6.50940242 6.1809793  6.130835   5.94734009 4.93106859 5.57950646\n",
      " 6.09695148 5.74929145 5.605136   5.74301573 5.53661754 6.4220909\n",
      " 4.50739702 5.17788275 5.47701629 6.08417169 6.39165211 6.23543209\n",
      " 5.27923006 4.71299736 6.18522225 5.36217234 5.88581085 6.11660048\n",
      " 6.25962749 5.5134438  3.7567529  5.16520512 5.31027402 6.15917988\n",
      " 5.38007954 5.28067798 5.47350112 5.86381567 5.80469037 6.79014197\n",
      " 6.08722161 6.00041325 4.83879984 5.51118049 5.99541219 6.32206011\n",
      " 4.57359226 4.95131283 5.19453665 6.41442606 4.67504407 5.77314348\n",
      " 5.84202454 6.73658572 5.83173541 6.49716602 5.93678937 6.03847011\n",
      " 5.87560377 4.53991202]\n",
      "\n",
      "What it should be:  [6.16666667 6.33333333 6.         5.         4.83333333 4.83333333\n",
      " 5.33333333 6.         6.66666667 5.83333333 5.16666667 5.16666667\n",
      " 4.83333333 6.         3.33333333 5.83333333 5.33333333 5.16666667\n",
      " 3.         5.33333333 4.66666667 6.16666667 5.33333333 6.16666667\n",
      " 4.66666667 5.5        4.83333333 5.83333333 5.16666667 6.83333333\n",
      " 6.5        6.16666667 6.         4.5        6.16666667 7.\n",
      " 6.         5.66666667 6.33333333 6.         3.66666667 6.16666667\n",
      " 6.5        5.83333333 4.33333333 4.83333333 6.16666667 4.\n",
      " 6.5        4.66666667 3.5        7.         5.66666667 5.66666667\n",
      " 4.66666667 4.33333333 6.66666667 5.83333333 5.83333333 4.5\n",
      " 5.83333333 5.83333333 6.83333333 6.5        5.66666667 5.5\n",
      " 5.         7.         3.83333333 5.83333333 6.83333333 6.83333333\n",
      " 6.16666667 5.33333333 5.66666667 5.5        4.16666667 6.33333333\n",
      " 6.5        6.16666667 6.83333333 6.33333333 6.         5.5\n",
      " 4.         6.16666667 5.         4.         5.83333333 6.33333333\n",
      " 5.16666667 5.16666667]\n",
      "Correlation:  [[1.        0.0994498]\n",
      " [0.0994498 1.       ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.27\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.56\n",
      "R2 score = -0.56\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.43297303 4.85566792 6.05425609 5.2014007  5.19413997 5.57173346\n",
      " 5.05653114 6.53789179 5.08094464 5.43879329 5.26429188 6.07514533\n",
      " 4.92264531 5.99028673 5.38820772 5.40768448 5.24347551 5.61209685\n",
      " 6.24614111 5.63513282 5.54215105 5.0950663  5.01023842 6.7250272\n",
      " 5.84133495 5.74353993 5.43096682 6.64530915 5.11067189 6.28105628\n",
      " 4.84844728 5.26225634 5.72259838 5.23591946 5.68533123 5.86571857\n",
      " 5.37011475 5.67001828 5.25490139 6.31736049 4.26811561 5.23777157\n",
      " 6.93913858 5.87404334 6.44789106 6.51485056 5.2484814  5.36231649\n",
      " 6.32665945 5.94692912 5.67040065 5.39245459 5.24617063 5.09630476\n",
      " 6.52674191 5.6149602  5.48147758 5.76584879 6.33353198 5.81161016\n",
      " 5.42047833 5.47103704 5.7566512  4.57468835 5.41297443 5.55590167\n",
      " 5.38327202 6.95830727 5.27478064 4.20881066 5.27379642 6.41859132\n",
      " 6.60543866 6.39713838 4.27981774 4.89533736 5.2522758  4.7079298\n",
      " 5.56376286 5.65775952 6.15296019 5.25247325 5.96550664 5.60043939\n",
      " 5.15049327 6.06335985 6.17237059 5.29445524 6.27538441 6.13323513\n",
      " 5.57859498 4.98119613]\n",
      "\n",
      "What it should be:  [4.83333333 6.66666667 6.83333333 6.5        6.16666667 6.16666667\n",
      " 6.16666667 6.33333333 6.5        5.33333333 4.66666667 6.5\n",
      " 6.16666667 4.66666667 6.16666667 6.33333333 5.         3.66666667\n",
      " 6.16666667 6.         6.66666667 5.5        5.5        4.\n",
      " 5.33333333 6.16666667 6.33333333 6.5        5.33333333 5.33333333\n",
      " 5.83333333 5.33333333 4.33333333 6.5        6.66666667 6.33333333\n",
      " 6.33333333 4.5        5.5        5.83333333 5.83333333 4.83333333\n",
      " 7.         6.83333333 6.83333333 5.33333333 3.         5.33333333\n",
      " 4.83333333 4.83333333 4.83333333 6.5        7.         6.16666667\n",
      " 5.83333333 1.83333333 5.5        4.16666667 6.83333333 6.16666667\n",
      " 6.         3.33333333 5.83333333 5.         5.16666667 5.83333333\n",
      " 5.16666667 6.         6.33333333 6.83333333 5.83333333 5.66666667\n",
      " 6.16666667 5.33333333 6.5        5.16666667 5.66666667 3.66666667\n",
      " 5.33333333 6.66666667 6.83333333 5.33333333 5.5        4.33333333\n",
      " 6.5        3.83333333 6.5        4.         6.16666667 6.33333333\n",
      " 5.16666667 4.5       ]\n",
      "Correlation:  [[1.         0.07909947]\n",
      " [0.07909947 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.25\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.43595822 4.91956542 5.25897532 5.40089709 5.1937539  5.82255296\n",
      " 5.2562275  5.0103956  5.42420526 4.25260517 3.50272006 4.86659999\n",
      " 6.78004792 5.11863037 5.70139654 5.09197957 5.37878462 7.10599316\n",
      " 5.60796624 5.50820171 5.26204601 5.55158114 6.54877429 6.08523908\n",
      " 5.01148064 6.32528977 5.61866907 5.36068727 5.50749298 6.09443859\n",
      " 5.72678207 4.63311864 5.549674   5.03520427 6.01928415 4.50960067\n",
      " 4.09839157 6.08137035 6.36439681 5.1947991  6.74240017 5.68807455\n",
      " 5.31158816 4.85542233 5.58970397 6.60532605 6.7193321  4.1704269\n",
      " 5.53027732 6.45037318 4.68323402 6.31114798 5.20014191 6.05704063\n",
      " 3.85040594 5.81857124 4.74041847 6.04153257 5.44930081 6.5746808\n",
      " 5.7100044  3.34343549 5.73525606 5.0407038  6.16125539 4.96747678\n",
      " 5.36375551 5.8259271  6.7936001  4.87542777 6.34934689 5.18146059\n",
      " 7.02053732 5.26885435 5.14944856 5.37999765 3.66552484 5.58638569\n",
      " 5.95509995 5.67409706 5.19875193 5.5234064  4.80773972 5.15471965\n",
      " 7.13786524 5.02711386 4.98815389 4.60598923 5.20163853 5.73701825\n",
      " 5.83131465 6.11180247]\n",
      "\n",
      "What it should be:  [6.         6.16666667 6.         6.16666667 5.33333333 5.83333333\n",
      " 5.83333333 4.83333333 6.83333333 4.83333333 5.33333333 6.\n",
      " 6.66666667 6.5        5.         7.         5.66666667 6.5\n",
      " 5.66666667 5.66666667 4.83333333 5.16666667 6.16666667 6.16666667\n",
      " 4.83333333 6.         4.5        5.33333333 5.66666667 6.5\n",
      " 6.66666667 4.33333333 6.33333333 6.5        6.5        6.66666667\n",
      " 6.5        5.33333333 5.5        6.5        4.66666667 6.83333333\n",
      " 6.33333333 4.66666667 5.5        6.66666667 6.33333333 5.16666667\n",
      " 6.16666667 6.66666667 6.33333333 5.83333333 6.16666667 5.83333333\n",
      " 5.83333333 5.33333333 6.33333333 6.5        5.33333333 5.\n",
      " 4.5        5.         5.33333333 4.66666667 6.16666667 6.\n",
      " 5.5        6.         6.83333333 7.         7.         5.16666667\n",
      " 5.83333333 4.83333333 3.66666667 6.33333333 6.33333333 5.66666667\n",
      " 6.16666667 6.16666667 4.33333333 5.83333333 6.         6.5\n",
      " 7.         3.83333333 4.         4.         3.33333333 6.\n",
      " 6.16666667 6.        ]\n",
      "Correlation:  [[1.         0.26665516]\n",
      " [0.26665516 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 1.01\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.49\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.42791861 5.01460727 6.39930289 5.14010173 6.77980842 7.15914476\n",
      " 6.22059473 5.97346768 5.58312925 5.20236571 5.04019091 5.25484501\n",
      " 5.17803687 6.00294971 5.13071407 5.643624   5.51119243 6.39150136\n",
      " 5.99927363 5.04783279 5.8874213  4.35316618 6.03269181 5.22884359\n",
      " 6.48069671 4.15380565 4.74117173 5.70533428 5.98365322 5.49382085\n",
      " 5.12810148 4.56550581 5.20215642 4.72638296 5.51493015 5.85228289\n",
      " 4.88703551 5.50493622 5.37820819 4.79441282 6.16021219 5.74317406\n",
      " 5.20949082 5.49668924 6.1264042  5.38231719 5.57654885 6.64174704\n",
      " 6.65077517 5.9003282  7.28851235 5.26463256 5.4737274  6.47888001\n",
      " 5.79102446 4.9355808  5.17789599 4.92239319 6.49546216 4.97620902\n",
      " 6.32515181 5.28134204 5.81149329 5.19287276 4.68688677 4.50850631\n",
      " 5.34249015 5.27341828 6.4389448  5.25846214 5.64793222 5.13854945\n",
      " 4.54603176 5.75845383 5.322532   5.16874032 5.84569162 5.27726274\n",
      " 6.70142649 6.07440867 5.51945493 5.86939898 5.25764815 5.63666781\n",
      " 4.97314419 5.85575498 5.01305627 5.54261022 4.48319927 5.98697342\n",
      " 5.65883833 5.04292184]\n",
      "\n",
      "What it should be:  [4.66666667 6.16666667 6.33333333 5.         5.33333333 7.\n",
      " 5.83333333 6.83333333 6.66666667 5.33333333 6.16666667 4.5\n",
      " 5.66666667 3.33333333 6.         6.5        4.83333333 6.5\n",
      " 5.83333333 6.16666667 4.         5.66666667 6.16666667 6.5\n",
      " 6.66666667 5.16666667 6.33333333 6.16666667 6.5        4.66666667\n",
      " 6.5        4.         6.66666667 5.5        6.33333333 6.83333333\n",
      " 5.         5.5        6.16666667 4.33333333 5.33333333 5.16666667\n",
      " 6.83333333 7.         6.16666667 3.         6.66666667 5.83333333\n",
      " 5.66666667 4.5        6.33333333 5.66666667 3.5        6.\n",
      " 5.         6.         6.33333333 1.83333333 6.5        4.66666667\n",
      " 5.66666667 7.         6.         6.33333333 4.83333333 6.16666667\n",
      " 4.83333333 5.83333333 6.16666667 6.5        5.16666667 5.83333333\n",
      " 5.33333333 6.         5.33333333 6.33333333 5.66666667 6.\n",
      " 5.5        5.33333333 5.83333333 4.         5.83333333 6.16666667\n",
      " 6.5        4.66666667 4.33333333 5.5        6.83333333 6.66666667\n",
      " 6.         3.66666667]\n",
      "Correlation:  [[1.         0.18486237]\n",
      " [0.18486237 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.12\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.41416715 6.10396419 6.47385092 7.29299076 5.56410865 6.0487278\n",
      " 5.95570865 5.76538044 5.97727425 6.13513081 3.84527637 5.48896007\n",
      " 5.15409932 6.60943177 5.39803658 4.39482143 5.67273378 5.58498012\n",
      " 5.38502291 4.49025441 6.6967199  4.86510616 6.26903102 4.29521936\n",
      " 6.57168394 5.70051169 5.91443273 6.10327268 5.78318135 5.54575284\n",
      " 5.66986049 6.06829397 6.3513075  3.5486895  6.41417301 5.39276643\n",
      " 5.16564947 6.2755314  6.79381015 5.7238931  5.09510825 5.41153582\n",
      " 5.88567941 6.09609801 6.45243934 6.0324798  6.34939404 5.89608069\n",
      " 5.41530862 5.39540383 6.36226899 4.88615232 5.79423069 6.17041521\n",
      " 6.40249501 6.40478609 5.58845151 3.56631497 5.68336442 5.28451009\n",
      " 4.92326754 6.15530731 5.0687954  6.47762497 5.67769286 6.01964601\n",
      " 4.37139508 6.45243797 3.84584764 5.53555785 5.66006373 5.63908457\n",
      " 6.27942789 6.44775239 5.19076275 5.37011571 5.58379359 5.72394943\n",
      " 5.4512297  5.8651036  6.37856938 5.6668908  6.48734647 5.41673235\n",
      " 6.09936198 6.34028526 4.90801431 3.56930377 5.92243763 5.91481281\n",
      " 5.43550176 4.70970654]\n",
      "\n",
      "What it should be:  [5.66666667 6.16666667 4.66666667 6.5        3.83333333 4.83333333\n",
      " 5.83333333 5.66666667 5.33333333 6.33333333 4.83333333 7.\n",
      " 4.33333333 5.83333333 5.33333333 5.16666667 5.5        6.\n",
      " 3.5        6.33333333 6.66666667 5.83333333 6.5        6.\n",
      " 5.33333333 6.5        5.16666667 6.5        5.66666667 6.16666667\n",
      " 5.5        5.         4.66666667 6.83333333 4.83333333 6.16666667\n",
      " 6.33333333 6.16666667 4.         5.83333333 5.83333333 5.5\n",
      " 6.5        4.5        4.5        6.83333333 6.16666667 5.83333333\n",
      " 6.         6.66666667 5.16666667 4.83333333 5.66666667 5.66666667\n",
      " 6.         6.5        5.         7.         5.33333333 5.66666667\n",
      " 6.         5.33333333 5.66666667 6.16666667 5.83333333 6.33333333\n",
      " 3.         6.83333333 6.83333333 5.33333333 5.33333333 6.33333333\n",
      " 4.83333333 6.         5.33333333 5.         4.33333333 6.16666667\n",
      " 6.         6.33333333 6.16666667 4.16666667 6.16666667 5.5\n",
      " 7.         6.66666667 4.66666667 6.16666667 6.83333333 6.83333333\n",
      " 6.83333333 4.66666667]\n",
      "Correlation:  [[1.         0.02987466]\n",
      " [0.02987466 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.22\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.73\n",
      "R2 score = -0.73\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.87261547 4.56628903 6.4380039  5.76737446 6.15401267 6.06647943\n",
      " 5.18229741 5.59334435 6.00689939 6.43975878 5.97047904 5.14348933\n",
      " 5.11948244 4.96408978 5.2364293  5.56897933 5.2406932  5.30872475\n",
      " 5.63339711 4.41699069 5.15438628 6.09052379 6.06003199 6.28492153\n",
      " 4.4632593  5.60297281 5.67309145 5.99124688 6.30749808 5.02428732\n",
      " 4.70320303 5.05543044 5.95192232 5.84841256 5.3555595  5.34595953\n",
      " 4.96854321 5.3241882  5.59809319 5.76329626 6.01405676 6.00141745\n",
      " 5.59728359 5.79453787 5.33948446 6.1759442  3.8706862  6.87740198\n",
      " 5.42681291 5.42434078 5.60586866 5.10585523 5.72345565 5.94232999\n",
      " 5.27548537 6.20060565 5.4457701  5.1751614  5.35853774 5.1547726\n",
      " 4.97728819 4.91465186 5.47356327 4.806432   4.50019005 5.34722255\n",
      " 3.52894117 4.18215736 5.01956494 5.5251247  5.26128002 6.16649957\n",
      " 6.40084214 6.31192272 5.46648387 6.50978459 5.77004166 5.04211805\n",
      " 5.47518693 6.27768153 5.59875476 6.80106391 4.81516279 5.8653853\n",
      " 6.05130246 6.47900698 5.94591241 5.48910669 6.19269346 6.17691813\n",
      " 6.44359176 5.84868468]\n",
      "\n",
      "What it should be:  [6.5        4.83333333 4.66666667 4.         5.83333333 4.66666667\n",
      " 3.5        6.66666667 6.16666667 5.16666667 5.83333333 6.83333333\n",
      " 6.66666667 6.33333333 6.33333333 5.66666667 4.83333333 6.\n",
      " 6.5        6.5        3.         5.83333333 5.33333333 5.83333333\n",
      " 4.33333333 4.66666667 6.         6.33333333 6.5        6.83333333\n",
      " 4.         6.66666667 6.66666667 5.         6.83333333 5.83333333\n",
      " 5.5        5.83333333 5.         6.33333333 5.66666667 5.5\n",
      " 5.83333333 4.66666667 7.         6.33333333 6.16666667 5.83333333\n",
      " 6.         5.16666667 6.5        5.5        5.5        5.33333333\n",
      " 5.5        5.16666667 5.         5.16666667 7.         6.16666667\n",
      " 5.33333333 6.83333333 5.83333333 4.33333333 4.83333333 6.16666667\n",
      " 4.5        1.83333333 6.33333333 6.16666667 3.33333333 6.66666667\n",
      " 5.5        6.33333333 4.83333333 6.5        6.         6.16666667\n",
      " 4.83333333 5.66666667 5.16666667 5.83333333 4.         5.16666667\n",
      " 4.5        7.         6.5        4.83333333 5.33333333 6.16666667\n",
      " 6.66666667 5.        ]\n",
      "Correlation:  [[1.         0.24560616]\n",
      " [0.24560616 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.1\n",
      "R2 score = -0.1\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.44164929 7.07151634 5.43683054 6.70423982 7.04798997 5.12251474\n",
      " 5.60437545 6.41467772 5.61145817 6.00065978 6.5250386  4.84529183\n",
      " 5.85551199 4.84081497 5.76891937 5.53762819 5.93558282 5.79452045\n",
      " 4.9422441  4.86896311 5.79941617 5.77949008 6.18071408 6.42445298\n",
      " 5.82604204 5.132252   4.67657759 6.29569165 5.50496131 5.50897837\n",
      " 5.57199282 5.03430159 5.57578752 4.52752874 5.66082581 6.06355849\n",
      " 4.56664418 6.57750351 5.81162417 5.23107952 5.62382139 6.2507394\n",
      " 7.03907447 3.84504895 6.08872139 5.02661801 6.43325804 5.86257675\n",
      " 6.23424559 6.15230508 6.51677445 6.10550885 5.71013556 6.55474717\n",
      " 5.61961838 5.47509114 3.9742221  5.78025995 6.2929018  4.82038773\n",
      " 6.31120862 6.45237882 5.39924021 4.98857706 6.63984075 6.92948124\n",
      " 5.98972876 4.65090536 6.11614549 5.4890185  6.60661072 5.78475314\n",
      " 5.4618827  6.13878317 5.89824388 5.52976781 5.66124788 6.18802701\n",
      " 6.43270398 5.93198852 5.87369915 4.49784954 4.80066833 5.39606165\n",
      " 6.34522202 5.11782075 6.85055358 5.2567066  5.017811   5.50442565\n",
      " 5.26025289 6.21103174]\n",
      "\n",
      "What it should be:  [6.16666667 5.5        6.16666667 5.66666667 6.16666667 4.66666667\n",
      " 6.33333333 6.         5.16666667 6.83333333 6.83333333 6.66666667\n",
      " 4.         5.5        4.83333333 6.5        6.5        5.66666667\n",
      " 1.83333333 7.         4.5        5.5        6.16666667 6.83333333\n",
      " 4.5        4.5        3.         5.33333333 6.5        5.\n",
      " 4.83333333 4.66666667 4.83333333 6.83333333 5.66666667 4.83333333\n",
      " 6.5        5.16666667 6.16666667 5.83333333 4.33333333 5.66666667\n",
      " 7.         4.83333333 5.33333333 4.33333333 5.16666667 5.66666667\n",
      " 5.16666667 6.         6.16666667 6.33333333 6.16666667 4.66666667\n",
      " 5.83333333 6.16666667 5.5        6.66666667 6.16666667 6.16666667\n",
      " 5.66666667 5.33333333 6.         5.5        5.83333333 5.33333333\n",
      " 5.83333333 5.5        5.16666667 4.66666667 5.33333333 3.5\n",
      " 6.16666667 6.83333333 5.83333333 6.         4.83333333 5.83333333\n",
      " 5.33333333 6.66666667 5.16666667 4.5        6.16666667 6.16666667\n",
      " 5.5        4.         4.66666667 5.33333333 6.         5.5\n",
      " 5.         6.5       ]\n",
      "Correlation:  [[1.         0.18452848]\n",
      " [0.18452848 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.29\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.57664683 5.18480252 5.18192812 5.68687816 6.95557785 6.62295621\n",
      " 5.96683655 5.59075407 4.60294087 5.42861257 5.94296595 5.6183231\n",
      " 6.31981806 6.03206109 4.56432513 4.91683609 6.17957881 5.19860388\n",
      " 5.15237563 6.22781653 5.40411356 6.53961664 5.2715358  4.63758274\n",
      " 5.4418323  5.2594619  6.2545183  6.30233893 4.45988195 6.00539439\n",
      " 5.45031156 5.32272729 5.69788813 6.69043031 5.3341987  6.23022307\n",
      " 7.04352994 5.62620518 4.79306455 6.1678846  4.40225857 4.87758607\n",
      " 5.93129409 5.02502007 6.26328625 6.43854398 4.42337707 6.18312601\n",
      " 6.32398237 6.04716975 5.63418475 5.19300566 4.26770022 6.83211898\n",
      " 4.54956539 6.45441249 5.38190973 5.87103245 5.13243055 5.44049786\n",
      " 6.51911803 6.07736284 4.92428364 6.23520465 6.83434563 5.36920903\n",
      " 6.08117131 4.40517293 5.58627776 6.04550488 5.72672862 4.87318403\n",
      " 5.56566609 4.82841266 6.11571105 5.5330923  6.35805685 5.04372008\n",
      " 5.63067032 4.923118   6.38150827 5.57122083 5.72890766 5.93622428\n",
      " 5.53177194 5.09369071 4.59479371 5.73022899 5.65077137 5.57080095\n",
      " 6.45728021 5.39760612]\n",
      "\n",
      "What it should be:  [5.5        4.16666667 5.33333333 6.66666667 6.66666667 5.83333333\n",
      " 6.16666667 7.         4.83333333 7.         5.16666667 5.5\n",
      " 4.         7.         4.33333333 5.83333333 6.         5.66666667\n",
      " 5.         5.83333333 6.16666667 6.33333333 5.33333333 4.\n",
      " 3.         6.5        5.16666667 5.5        4.66666667 6.33333333\n",
      " 4.33333333 6.33333333 5.66666667 5.66666667 5.33333333 4.5\n",
      " 5.33333333 4.66666667 4.         7.         5.83333333 6.66666667\n",
      " 5.16666667 5.5        5.66666667 4.5        6.         6.16666667\n",
      " 6.83333333 6.16666667 5.5        4.66666667 6.33333333 6.66666667\n",
      " 6.         5.66666667 5.5        5.16666667 6.16666667 3.5\n",
      " 6.         6.5        4.83333333 6.5        6.16666667 5.83333333\n",
      " 6.33333333 6.83333333 6.16666667 6.83333333 5.66666667 6.5\n",
      " 5.83333333 6.5        3.33333333 5.33333333 4.83333333 4.83333333\n",
      " 5.33333333 7.         5.83333333 3.66666667 6.66666667 4.\n",
      " 6.33333333 6.5        6.16666667 4.         6.66666667 6.33333333\n",
      " 6.83333333 5.33333333]\n",
      "Correlation:  [[1.        0.1048842]\n",
      " [0.1048842 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.34\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.18745568 6.82984471 5.60030812 5.32661567 5.57331628 5.51797283\n",
      " 5.9300663  4.29325271 5.71314956 6.06996509 5.62920371 5.99519586\n",
      " 5.66624458 5.24154465 4.15820683 5.65144128 5.00471986 6.72530161\n",
      " 6.04390369 5.01390235 5.67107206 5.43409443 6.6905207  4.3077218\n",
      " 5.66730265 5.86807481 5.33146754 6.05176891 5.31079131 5.49904336\n",
      " 5.06930669 4.84423735 4.80326685 5.9081412  5.28351162 6.27885642\n",
      " 4.41562849 5.42743121 5.28911297 6.07871426 5.26663706 4.9777245\n",
      " 6.31777129 6.23132824 5.61929284 5.69704009 5.83833143 6.3673869\n",
      " 5.65625111 6.91023632 4.77582174 5.4580241  5.66309417 5.8506729\n",
      " 5.37850938 4.46102633 6.13066447 5.38480518 6.12004991 5.20808374\n",
      " 5.26001848 5.58419    6.24389528 5.96099809 4.20348811 5.88971527\n",
      " 5.66884079 7.84777393 6.34336587 5.85588943 6.05661326 5.15219096\n",
      " 5.84287843 5.54664522 6.41108113 5.14574979 5.64004219 5.16685884\n",
      " 5.81313087 6.38963044 6.14116475 6.48723338 5.9583665  5.63873138\n",
      " 5.24083019 5.18681973 6.4397771  5.87572692 6.93893257 6.46554098\n",
      " 5.37408139 4.88497109]\n",
      "\n",
      "What it should be:  [4.         5.33333333 6.         6.16666667 3.33333333 5.16666667\n",
      " 6.5        5.66666667 4.33333333 5.33333333 5.66666667 6.16666667\n",
      " 6.33333333 5.66666667 4.83333333 6.         6.5        4.66666667\n",
      " 6.         5.33333333 6.         6.16666667 6.         4.5\n",
      " 5.16666667 4.66666667 5.33333333 5.33333333 6.33333333 4.83333333\n",
      " 4.5        5.83333333 6.33333333 6.66666667 5.83333333 4.\n",
      " 4.83333333 5.16666667 7.         5.33333333 1.83333333 5.66666667\n",
      " 6.16666667 6.         6.66666667 6.16666667 6.         5.83333333\n",
      " 5.83333333 6.33333333 5.83333333 6.33333333 6.83333333 5.33333333\n",
      " 7.         5.5        6.66666667 4.66666667 6.83333333 6.16666667\n",
      " 5.33333333 5.33333333 5.66666667 5.66666667 4.66666667 7.\n",
      " 6.16666667 6.66666667 5.16666667 5.66666667 5.33333333 6.66666667\n",
      " 5.         6.5        5.33333333 4.83333333 6.         4.\n",
      " 6.5        6.5        6.16666667 6.16666667 5.33333333 6.5\n",
      " 4.33333333 6.         6.33333333 5.83333333 6.5        6.\n",
      " 4.33333333 5.83333333]\n",
      "Correlation:  [[1.         0.22105165]\n",
      " [0.22105165 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.93\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.12809336 5.49791883 5.76612624 6.15008449 4.09519275 4.86735733\n",
      " 4.43379553 5.70764143 6.04733515 4.40824343 5.63219706 5.1805875\n",
      " 5.99311246 6.21476568 5.27152814 5.95662042 5.82891942 5.67318648\n",
      " 5.41764614 5.96373783 5.64154731 7.07009156 4.62606178 5.12074682\n",
      " 5.38182152 5.25576974 5.69273562 6.44552627 5.87465591 6.63342472\n",
      " 4.53628854 5.09435426 5.42971461 7.24859016 6.52643892 4.71917793\n",
      " 5.55238093 5.95994431 4.01787922 6.10300792 4.91354935 5.13009995\n",
      " 5.02399346 5.32140001 6.26690561 6.16837744 6.09034055 5.09249251\n",
      " 4.44313277 5.80969115 5.57541028 5.73026996 4.83783018 5.09006256\n",
      " 5.2608138  4.34036073 5.68143683 4.66800683 4.8013206  5.94012595\n",
      " 6.60046797 5.07239987 5.3594404  4.98384427 5.08970667 6.21948401\n",
      " 5.42924908 5.02178596 5.50156722 5.26842798 5.38108811 6.10969454\n",
      " 4.56061552 5.99832513 5.19112148 4.56742473 5.92584092 6.27108968\n",
      " 5.22122242 6.78051144 5.96786903 5.39620138 6.6361537  4.07874534\n",
      " 5.37954415 5.64036985 4.40348568 4.84811381 5.25824497 5.75232379\n",
      " 5.16751747 6.44314431]\n",
      "\n",
      "What it should be:  [5.16666667 6.83333333 5.16666667 4.5        5.33333333 6.16666667\n",
      " 5.         6.5        6.33333333 6.         6.16666667 5.83333333\n",
      " 5.83333333 6.5        5.83333333 6.         4.16666667 6.33333333\n",
      " 6.5        5.16666667 6.         4.66666667 7.         6.5\n",
      " 6.5        4.5        6.33333333 6.5        4.5        6.5\n",
      " 6.5        4.66666667 6.66666667 6.5        5.16666667 6.16666667\n",
      " 6.         5.33333333 6.33333333 6.16666667 6.5        4.5\n",
      " 5.83333333 5.5        7.         5.33333333 6.83333333 4.33333333\n",
      " 4.33333333 4.5        5.         3.5        6.16666667 5.5\n",
      " 5.66666667 6.83333333 4.         5.5        4.83333333 6.16666667\n",
      " 6.16666667 6.83333333 3.33333333 6.83333333 5.5        5.\n",
      " 4.66666667 6.33333333 6.16666667 4.66666667 6.5        5.83333333\n",
      " 5.16666667 5.66666667 4.83333333 4.83333333 3.         6.\n",
      " 6.66666667 7.         5.83333333 6.5        6.16666667 7.\n",
      " 5.5        6.83333333 6.33333333 4.33333333 5.5        6.33333333\n",
      " 6.16666667 6.66666667]\n",
      "Correlation:  [[1.         0.00266735]\n",
      " [0.00266735 1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.64\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.23047779 6.55735218 5.30870561 6.35837092 5.55280416 5.20701699\n",
      " 5.70310026 6.37876722 5.52423264 6.60153577 5.62572487 5.88921895\n",
      " 5.98393781 6.67100091 6.58473226 5.45162109 4.34781528 6.18816725\n",
      " 6.16437381 5.20853184 5.44448373 6.24812485 6.35645223 5.39132519\n",
      " 6.01106307 5.58618866 5.64535827 4.68009406 6.33425676 6.48904671\n",
      " 4.88837671 5.13597834 5.94993731 4.2864573  5.75133629 5.02532134\n",
      " 6.19389541 6.33319165 5.60564104 4.54680194 5.70221674 5.14069053\n",
      " 6.47022945 5.32412115 4.71257828 4.82071872 6.52887905 5.33107622\n",
      " 5.10478969 4.54287879 4.78628979 6.33934148 4.50720333 5.20069411\n",
      " 6.09768026 5.4746806  6.04728969 5.66573232 5.41102552 6.1613631\n",
      " 5.47013208 4.35084617 5.85040267 5.68114013 5.45839309 5.0800066\n",
      " 5.20476636 6.00879345 6.88507377 5.84271772 5.5774961  5.09191695\n",
      " 5.81474549 4.72517189 7.25244112 6.01394297 5.81433247 6.05436799\n",
      " 5.81159415 5.02508892 5.65873859 5.64446923 4.67607754 5.66133625\n",
      " 5.04704688 5.42759645 6.8086591  5.96617515 6.03753634 5.44110682\n",
      " 7.09932217 4.87250066]\n",
      "\n",
      "What it should be:  [4.66666667 6.5        4.         6.16666667 6.         6.16666667\n",
      " 5.66666667 6.16666667 6.83333333 5.83333333 5.33333333 6.5\n",
      " 4.16666667 6.83333333 6.83333333 6.16666667 4.         5.33333333\n",
      " 6.33333333 5.5        6.16666667 5.33333333 6.66666667 6.66666667\n",
      " 6.83333333 6.16666667 6.16666667 5.66666667 5.33333333 6.5\n",
      " 5.5        6.33333333 5.83333333 6.33333333 5.         6.16666667\n",
      " 6.         4.         5.33333333 3.66666667 5.16666667 3.66666667\n",
      " 5.66666667 5.33333333 3.         3.5        6.5        6.33333333\n",
      " 6.         6.83333333 4.66666667 6.66666667 6.         5.33333333\n",
      " 4.83333333 5.66666667 4.33333333 5.66666667 6.33333333 5.83333333\n",
      " 3.83333333 5.83333333 6.16666667 6.5        6.16666667 6.\n",
      " 6.         6.33333333 4.66666667 6.5        3.66666667 5.\n",
      " 5.83333333 6.16666667 7.         5.83333333 6.83333333 5.83333333\n",
      " 5.83333333 5.         4.83333333 5.16666667 6.5        6.5\n",
      " 6.66666667 4.5        6.33333333 5.         5.16666667 6.5\n",
      " 6.5        4.33333333]\n",
      "Correlation:  [[1.         0.27871451]\n",
      " [0.27871451 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.1\n",
      "R2 score = -0.11\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.98670528 5.11381407 7.06286622 5.54681266 5.30732316 5.38178735\n",
      " 5.28819528 5.58620298 5.48441446 6.02034462 6.0287271  4.81397997\n",
      " 4.91725987 5.93051402 6.30254262 4.91358869 5.66415404 5.08292749\n",
      " 5.49151667 6.15148272 5.25032034 5.74164828 6.0532441  6.05633313\n",
      " 5.1110017  5.70034592 5.93904898 5.95559469 6.32283568 6.54384156\n",
      " 4.92904925 6.52070898 4.39833536 4.60352928 5.6828018  4.3240836\n",
      " 6.25047924 7.0158757  5.82462621 5.44613676 4.78883535 5.60107885\n",
      " 5.91294933 6.48397095 5.66638079 4.44883102 3.50611959 6.75916297\n",
      " 5.03272854 6.24075291 5.8108085  6.17990756 5.54387556 5.57618019\n",
      " 5.4066953  4.53928596 6.97309034 5.62573394 6.59503113 4.98322808\n",
      " 4.89777303 5.51168247 4.48095437 5.05339674 6.19362565 5.00941191\n",
      " 6.02040415 5.21973642 5.6854361  6.58360039 5.51745502 5.39263716\n",
      " 4.575685   4.78309894 6.0576645  5.08903227 5.00772021 6.19937304\n",
      " 4.70463143 5.64519495 5.42665908 5.33700349 5.39763267 5.79989767\n",
      " 6.46006475 4.99351159 6.17658469 6.26364112 6.57654948 5.3251523\n",
      " 5.36404124 5.42510005]\n",
      "\n",
      "What it should be:  [6.33333333 6.16666667 5.66666667 4.66666667 6.33333333 5.33333333\n",
      " 6.         6.16666667 6.33333333 4.33333333 5.33333333 6.33333333\n",
      " 6.66666667 6.5        7.         6.         6.16666667 6.83333333\n",
      " 6.33333333 6.16666667 5.83333333 6.66666667 5.33333333 5.66666667\n",
      " 6.16666667 4.66666667 5.66666667 6.5        6.83333333 7.\n",
      " 6.83333333 6.5        4.83333333 4.5        7.         3.66666667\n",
      " 6.83333333 6.         6.5        5.66666667 7.         6.66666667\n",
      " 6.5        6.83333333 6.16666667 5.5        4.83333333 5.33333333\n",
      " 6.5        5.83333333 5.33333333 7.         5.5        5.83333333\n",
      " 5.5        4.         5.66666667 6.         5.5        4.33333333\n",
      " 4.5        6.66666667 5.83333333 6.         4.         3.5\n",
      " 6.         4.66666667 5.16666667 6.         4.66666667 6.5\n",
      " 4.33333333 4.83333333 5.16666667 5.83333333 6.83333333 6.66666667\n",
      " 6.16666667 3.         4.83333333 3.33333333 5.83333333 6.16666667\n",
      " 5.16666667 6.5        5.16666667 5.33333333 6.33333333 4.\n",
      " 5.16666667 5.33333333]\n",
      "Correlation:  [[1.        0.2403327]\n",
      " [0.2403327 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.80245923 5.90203284 6.06940327 5.802834   4.60807877 5.69024715\n",
      " 6.68315862 4.64578834 6.06143571 5.97262402 4.84307814 5.93712865\n",
      " 5.95671671 4.65137611 5.70629712 5.27492711 6.19043996 5.46685887\n",
      " 6.69987532 5.06632118 4.90752341 6.2322423  7.13683952 4.80010822\n",
      " 6.83550057 6.29733058 6.51653846 5.7182672  5.94895531 5.9094748\n",
      " 4.84425753 5.65010785 5.24907459 5.42514141 5.93278726 6.12631145\n",
      " 5.66862116 6.4557255  6.91140298 6.55540986 4.80355565 5.46138501\n",
      " 6.55837748 5.65859964 5.36674667 6.38130963 5.99404989 5.51722082\n",
      " 5.35987636 6.63065261 6.23413861 6.24630389 5.67710139 6.14022687\n",
      " 5.50111488 5.44148185 5.36501605 7.08147931 5.15643585 4.93859248\n",
      " 6.02916437 4.46172346 5.46044033 6.75189048 6.06452063 3.81637363\n",
      " 6.0414057  5.89247157 5.06000498 5.90397324 4.89174748 5.75409408\n",
      " 5.65025646 5.63052243 5.12349756 6.08823436 5.91502176 5.55881092\n",
      " 5.75395412 6.18798814 5.89650413 6.43754313 6.87130079 4.73533595\n",
      " 5.98438523 6.96162219 4.55480257 6.14852447 6.09497198 5.38256782\n",
      " 6.91268931 6.46647924]\n",
      "\n",
      "What it should be:  [6.16666667 6.16666667 5.66666667 7.         4.33333333 4.66666667\n",
      " 5.66666667 4.5        4.83333333 7.         4.83333333 4.66666667\n",
      " 5.66666667 5.16666667 4.5        6.66666667 5.16666667 6.83333333\n",
      " 4.16666667 5.         3.66666667 6.16666667 6.83333333 6.5\n",
      " 6.16666667 6.5        5.33333333 6.16666667 5.33333333 5.16666667\n",
      " 4.         6.5        4.66666667 6.16666667 6.83333333 6.5\n",
      " 5.83333333 5.33333333 6.66666667 6.5        6.16666667 4.83333333\n",
      " 5.83333333 5.5        4.33333333 5.33333333 4.83333333 6.5\n",
      " 4.66666667 6.66666667 6.         5.33333333 6.83333333 1.83333333\n",
      " 6.16666667 4.83333333 6.         5.66666667 5.5        5.33333333\n",
      " 6.83333333 6.         6.         4.66666667 5.66666667 4.\n",
      " 6.33333333 6.16666667 5.66666667 6.         6.16666667 3.\n",
      " 5.83333333 6.         5.5        4.66666667 5.33333333 5.66666667\n",
      " 5.66666667 5.83333333 5.33333333 6.16666667 5.33333333 6.16666667\n",
      " 5.         5.5        4.66666667 6.66666667 5.83333333 6.\n",
      " 5.16666667 6.        ]\n",
      "Correlation:  [[1.         0.20675404]\n",
      " [0.20675404 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.24\n",
      "R2 score = -0.29\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.29476683 5.01007389 4.73413549 5.91556512 5.81323409 6.7036663\n",
      " 6.41340994 5.80450529 6.62984154 5.93994888 7.29999823 6.3358571\n",
      " 7.25162009 5.5830464  6.32126668 5.79365581 5.21060281 5.1812579\n",
      " 6.54290434 5.70429432 5.17603895 6.48909417 5.71745851 5.75313304\n",
      " 6.07635305 4.35087624 5.46357029 3.49788023 5.55415212 5.39812801\n",
      " 5.2865209  6.79042379 5.02995469 6.26046769 5.25423757 5.99749464\n",
      " 5.64745801 6.30440081 6.51275747 5.90239944 5.81391195 6.22448903\n",
      " 4.52545201 5.71117169 5.25856421 5.55507469 6.29206301 5.70180213\n",
      " 5.9005922  6.77949016 6.50710703 4.47511944 5.24800303 6.29745365\n",
      " 5.88406995 4.30535031 5.37530411 6.30719721 6.05938138 5.23005948\n",
      " 5.18666859 5.85810821 5.88761474 5.17910464 6.84540914 5.95316754\n",
      " 4.45673537 5.64832869 5.07673512 5.16132815 6.2037962  6.25352531\n",
      " 7.58067669 5.65940115 4.77406303 5.88154796 6.48991263 5.70804172\n",
      " 6.82920021 6.31839045 6.12008179 5.54858722 5.17004423 7.07393787\n",
      " 5.11894262 6.22242159 5.4249028  6.06545819 6.29368037 5.08932902\n",
      " 4.99821046 5.86541973]\n",
      "\n",
      "What it should be:  [6.5        6.83333333 6.33333333 4.33333333 5.66666667 5.16666667\n",
      " 5.5        5.33333333 4.66666667 6.5        6.5        6.83333333\n",
      " 5.66666667 5.66666667 6.33333333 4.66666667 5.33333333 3.33333333\n",
      " 6.83333333 5.33333333 6.         7.         5.83333333 5.83333333\n",
      " 5.83333333 4.83333333 5.         4.5        7.         3.66666667\n",
      " 3.66666667 6.         5.33333333 4.66666667 3.66666667 4.16666667\n",
      " 5.16666667 4.83333333 5.33333333 7.         6.83333333 5.5\n",
      " 4.66666667 6.16666667 5.5        5.         6.16666667 4.83333333\n",
      " 6.5        6.5        5.33333333 5.         6.5        7.\n",
      " 6.16666667 6.66666667 6.33333333 6.16666667 5.33333333 6.66666667\n",
      " 5.16666667 6.16666667 4.83333333 4.         5.16666667 6.5\n",
      " 6.33333333 6.66666667 5.83333333 5.83333333 5.16666667 6.66666667\n",
      " 6.33333333 5.33333333 5.5        5.         5.83333333 4.83333333\n",
      " 5.66666667 4.5        6.33333333 6.16666667 5.16666667 7.\n",
      " 5.5        5.16666667 5.66666667 5.16666667 6.16666667 5.83333333\n",
      " 5.5        6.5       ]\n",
      "Correlation:  [[1.         0.22069058]\n",
      " [0.22069058 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.90941207 5.57966286 5.38809157 6.14590185 5.74349897 6.17864156\n",
      " 6.36231799 5.52123245 5.56147737 5.42945707 6.34085592 5.35848928\n",
      " 6.54091617 7.55949379 6.56254957 6.45485951 6.60315134 6.11829911\n",
      " 6.42967728 5.91794587 5.95063231 5.79817259 5.72961597 6.22571681\n",
      " 5.55304968 5.56815761 6.10969171 6.14977419 5.84055812 5.96796561\n",
      " 5.99936287 5.52292209 6.01372538 6.23297051 6.00010594 6.09986986\n",
      " 5.43222491 5.3541348  5.54635591 6.46412757 5.11536901 5.85262842\n",
      " 4.02477857 4.57503999 6.05016393 5.80059376 5.58638369 4.88030395\n",
      " 6.12565184 5.87956475 5.66701129 6.23823069 5.68238514 7.2507913\n",
      " 5.83135792 6.3352308  5.88219436 5.48725143 5.52881069 5.54888796\n",
      " 5.53843611 5.48152642 5.1794686  7.093292   6.04951284 5.13513263\n",
      " 5.02558675 5.27683812 5.88615754 5.516255   5.15080339 5.69316843\n",
      " 6.78995724 5.79904828 5.71177918 5.53586853 5.21640352 6.4396281\n",
      " 6.00433412 4.72771902 5.90897914 5.54215428 6.61731042 5.51483619\n",
      " 4.31980128 5.58580603 6.05695209 5.30527568 5.97290864 6.42465613\n",
      " 6.01150244 5.25740117]\n",
      "\n",
      "What it should be:  [1.83333333 6.16666667 6.33333333 6.5        4.         5.5\n",
      " 5.83333333 5.33333333 5.16666667 5.33333333 6.16666667 6.5\n",
      " 4.         7.         6.33333333 6.16666667 6.         6.33333333\n",
      " 6.5        4.33333333 6.16666667 5.16666667 4.         5.16666667\n",
      " 6.33333333 4.66666667 5.66666667 6.         3.5        6.83333333\n",
      " 6.83333333 5.16666667 5.16666667 6.66666667 7.         5.\n",
      " 4.33333333 5.33333333 5.         3.33333333 6.33333333 6.16666667\n",
      " 4.5        6.33333333 6.5        5.33333333 6.83333333 4.83333333\n",
      " 4.5        7.         4.83333333 5.83333333 6.5        6.5\n",
      " 3.66666667 5.33333333 4.33333333 5.83333333 6.         5.66666667\n",
      " 3.66666667 5.         6.         4.66666667 6.83333333 4.83333333\n",
      " 5.83333333 4.5        5.33333333 6.83333333 5.5        4.66666667\n",
      " 6.16666667 5.33333333 6.         5.33333333 6.66666667 5.83333333\n",
      " 5.33333333 5.5        6.33333333 7.         6.16666667 3.66666667\n",
      " 6.33333333 6.16666667 3.83333333 6.33333333 4.         6.33333333\n",
      " 6.66666667 7.        ]\n",
      "Correlation:  [[1.        0.1437766]\n",
      " [0.1437766 1.       ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.29\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.2\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.80717733 4.83713636 6.95054926 6.45821543 5.14043753 5.75747307\n",
      " 3.87447621 4.65700008 5.62774091 6.19846418 5.5692982  6.22415087\n",
      " 5.84592011 6.53976219 6.25210382 6.13881812 5.01233109 6.98768564\n",
      " 6.01865846 6.91882495 5.95178521 5.47213667 5.47360433 3.74818093\n",
      " 5.38013138 6.01879287 5.26880512 4.99448257 5.94203701 5.80828891\n",
      " 5.60828569 6.09463089 6.05374449 4.83051425 5.31223516 5.94335825\n",
      " 5.79599137 5.17831884 6.54563971 4.69061121 5.06366607 5.7175146\n",
      " 6.73045037 6.7615385  5.20978047 5.81998776 5.23265129 5.26234964\n",
      " 5.63674061 4.48345482 6.04015029 6.28921542 5.0875139  5.15532565\n",
      " 6.98843951 5.2884037  5.7586621  7.7272039  6.19063618 6.49793108\n",
      " 6.0393642  6.24361239 5.45339544 5.1386481  5.65318774 5.11158982\n",
      " 5.28961809 6.18531632 5.96404402 5.64569075 6.07127677 6.14749631\n",
      " 5.49804621 5.10622244 5.77087892 5.88782688 5.86443968 6.02582633\n",
      " 5.75443703 5.5804339  5.56807205 5.61145758 5.88637541 5.81847425\n",
      " 6.23607321 6.17940361 5.03953136 5.69085208 6.47042965 5.84086881\n",
      " 5.86018548 5.15408032]\n",
      "\n",
      "What it should be:  [4.83333333 6.         4.83333333 4.66666667 5.33333333 4.66666667\n",
      " 6.16666667 5.16666667 3.66666667 6.33333333 4.33333333 6.33333333\n",
      " 4.83333333 6.5        6.5        6.33333333 5.33333333 4.66666667\n",
      " 4.33333333 6.66666667 6.5        5.33333333 5.66666667 6.83333333\n",
      " 4.5        5.33333333 4.33333333 6.16666667 3.5        6.\n",
      " 4.66666667 5.83333333 5.83333333 7.         5.33333333 5.33333333\n",
      " 7.         6.66666667 6.5        5.         4.83333333 6.66666667\n",
      " 6.33333333 5.5        5.83333333 5.66666667 5.5        6.16666667\n",
      " 5.5        6.16666667 5.83333333 6.         6.5        5.5\n",
      " 6.16666667 5.66666667 5.16666667 6.66666667 4.         4.16666667\n",
      " 5.66666667 5.66666667 4.66666667 5.83333333 6.16666667 7.\n",
      " 6.5        6.         5.33333333 3.33333333 6.16666667 6.\n",
      " 5.83333333 5.5        6.16666667 5.33333333 5.16666667 6.16666667\n",
      " 6.66666667 5.33333333 1.83333333 6.         6.         5.66666667\n",
      " 5.33333333 5.33333333 4.83333333 6.16666667 6.5        6.5\n",
      " 5.16666667 6.33333333]\n",
      "Correlation:  [[ 1.         -0.00997837]\n",
      " [-0.00997837  1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.26\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.53\n",
      "R2 score = -0.56\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.43154091 5.49461393 6.00366982 7.01702212 5.85173585 5.14248605\n",
      " 5.54710804 5.60820185 6.07721009 6.0002086  5.02233464 6.03100152\n",
      " 6.05198306 4.83365253 6.1378981  5.15582791 6.29425041 6.13780436\n",
      " 6.38071828 5.38227775 6.46783596 5.36567717 6.18833238 5.22070689\n",
      " 5.55107306 5.88494597 5.03794985 5.875174   5.50439528 4.56804997\n",
      " 5.36331327 5.66132699 5.64937984 4.46070985 5.47465339 6.24686989\n",
      " 4.64294451 5.30856839 4.95217972 5.93881038 5.38965087 5.74280668\n",
      " 5.74085059 5.36685978 5.22476295 4.7665382  5.58457645 5.65905447\n",
      " 5.75064015 5.71173325 6.52635174 5.8935369  4.22566489 6.17953428\n",
      " 5.62335392 6.05652746 5.26015886 4.65862512 5.7718208  5.54041631\n",
      " 4.52939224 3.94005887 5.58778717 6.50592941 5.41270124 6.01529705\n",
      " 5.13644894 5.14296326 5.75766813 5.71576773 5.98034646 5.893987\n",
      " 5.96088047 5.01212361 6.11332671 4.94370511 6.1440468  6.83845093\n",
      " 5.70002194 4.32179292 5.91612907 6.85239634 4.34525506 5.56407726\n",
      " 5.24311982 5.6265801  5.24973777 6.71341411 4.67975638 5.77957286\n",
      " 5.42704956 5.20602311]\n",
      "\n",
      "What it should be:  [4.         4.66666667 6.         5.83333333 6.5        5.16666667\n",
      " 5.         4.83333333 4.5        5.16666667 6.33333333 6.16666667\n",
      " 4.66666667 6.         4.5        6.5        6.         4.16666667\n",
      " 5.83333333 4.         6.5        6.83333333 6.83333333 5.83333333\n",
      " 7.         5.33333333 6.66666667 6.         6.33333333 6.5\n",
      " 6.83333333 3.5        5.66666667 4.5        5.66666667 5.16666667\n",
      " 6.83333333 5.5        6.         5.33333333 6.33333333 3.66666667\n",
      " 6.33333333 6.16666667 5.33333333 6.5        7.         5.83333333\n",
      " 5.33333333 4.83333333 5.66666667 5.66666667 6.5        6.16666667\n",
      " 5.66666667 6.16666667 5.         5.16666667 5.5        6.5\n",
      " 6.5        6.33333333 6.66666667 5.16666667 6.16666667 6.66666667\n",
      " 6.33333333 5.33333333 4.83333333 5.83333333 3.66666667 5.83333333\n",
      " 4.66666667 5.16666667 3.33333333 3.83333333 6.33333333 6.5\n",
      " 6.16666667 5.83333333 5.5        4.66666667 4.         6.83333333\n",
      " 6.16666667 5.33333333 5.66666667 6.33333333 4.33333333 6.5\n",
      " 5.66666667 5.5       ]\n",
      "Correlation:  [[ 1.         -0.06542737]\n",
      " [-0.06542737  1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.55\n",
      "R2 score = -0.55\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.09468544 5.39088201 5.90621513 5.66428765 5.68230832 6.12986062\n",
      " 5.95277463 5.96528602 5.9724337  4.07059664 6.21916057 5.32416237\n",
      " 5.03526808 5.15583321 5.06863223 6.70497499 5.75726989 4.7658187\n",
      " 5.60297689 6.54181967 5.45082871 5.55300056 6.821677   5.60077601\n",
      " 6.10228045 5.51621534 5.6344708  6.13449533 5.42248983 6.04383395\n",
      " 5.31359506 4.89546077 6.21567807 6.23123503 5.37097026 5.39235117\n",
      " 6.36694941 6.65628688 6.22271234 5.27251136 6.72034315 7.02494673\n",
      " 4.77677339 4.45157492 5.60985079 6.07093323 4.86675497 5.83148019\n",
      " 5.48107053 5.21875152 6.14931238 5.74853471 5.3616395  5.47082945\n",
      " 6.05424614 5.61334459 6.44528346 5.4693982  5.34332798 5.53611036\n",
      " 5.98244988 5.76770262 5.34353284 5.33145509 5.7512113  6.01016492\n",
      " 5.63837436 5.11332405 4.86412117 6.13030308 5.17708649 5.18005132\n",
      " 6.5014804  6.49753299 4.77627426 5.35327952 5.10479463 4.17588479\n",
      " 6.24402828 5.38738781 4.94391632 4.28505008 7.21706759 5.71478724\n",
      " 5.20383223 6.39390843 6.46824099 5.86496857 5.98199484 5.59877344\n",
      " 5.90361427 6.96721734]\n",
      "\n",
      "What it should be:  [5.83333333 6.33333333 6.33333333 5.83333333 6.5        6.\n",
      " 5.33333333 6.5        5.16666667 4.83333333 6.83333333 5.83333333\n",
      " 4.5        6.16666667 1.83333333 4.66666667 6.16666667 4.\n",
      " 5.         5.66666667 3.83333333 5.5        6.66666667 4.83333333\n",
      " 5.16666667 4.         5.83333333 6.16666667 5.5        6.33333333\n",
      " 6.66666667 5.5        5.16666667 5.16666667 6.16666667 5.16666667\n",
      " 6.83333333 6.5        7.         5.83333333 5.16666667 6.16666667\n",
      " 6.33333333 4.66666667 5.33333333 6.5        4.33333333 6.5\n",
      " 4.83333333 3.33333333 5.83333333 5.83333333 6.16666667 6.16666667\n",
      " 6.83333333 5.33333333 5.         6.16666667 7.         6.\n",
      " 6.         6.         5.         4.         5.5        6.\n",
      " 5.33333333 3.66666667 5.5        5.66666667 5.33333333 5.16666667\n",
      " 5.33333333 6.5        6.         6.33333333 6.         4.\n",
      " 6.5        6.16666667 6.5        5.33333333 7.         3.\n",
      " 4.83333333 6.16666667 6.66666667 5.33333333 5.5        6.33333333\n",
      " 5.16666667 4.66666667]\n",
      "Correlation:  [[1.         0.35072419]\n",
      " [0.35072419 1.        ]]\n",
      "Mean absolute error = 0.72\n",
      "Mean squared error = 0.88\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = 0.03\n",
      "R2 score = 0.01\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.52454847 6.10153364 5.23571596 4.80795439 5.58239693 5.2709188\n",
      " 6.0149674  5.56404792 5.53458419 5.32047237 4.53665413 5.23422857\n",
      " 6.20642219 5.5891965  5.72793551 5.42311503 4.59658234 5.4508499\n",
      " 5.33441316 6.10005116 5.92847886 4.43705611 5.56014914 4.73622711\n",
      " 5.28893443 6.8245251  5.0920575  5.9509786  6.15168578 5.73219618\n",
      " 5.80340833 5.89782392 6.49285343 4.53650373 4.38751333 5.71066824\n",
      " 6.52837473 6.6765501  6.29051313 6.82600822 3.91109215 5.44048096\n",
      " 3.56207934 6.06968075 6.04705633 5.28471871 6.00657934 5.46680995\n",
      " 4.3642814  5.65374998 5.67230535 5.86507264 6.30505288 5.12972069\n",
      " 5.88449375 5.41450875 6.74122461 5.54318147 5.61499593 5.18983896\n",
      " 4.95759859 5.73798112 5.82132996 5.37165202 6.44369621 5.41460763\n",
      " 6.00997513 5.7335515  6.11751893 6.11044694 5.13381797 6.13399351\n",
      " 5.5986883  5.29750146 6.56139902 4.81975091 5.67530508 5.28489511\n",
      " 5.54293914 5.68652315 6.26490988 4.57218201 4.72352723 5.31898548\n",
      " 5.69241847 4.97456824 5.54064612 5.97934497 5.29446248 5.87648732\n",
      " 7.48421089 5.45050993]\n",
      "\n",
      "What it should be:  [5.33333333 6.         6.66666667 6.16666667 6.16666667 6.66666667\n",
      " 6.83333333 6.66666667 7.         6.5        6.83333333 6.16666667\n",
      " 6.5        5.16666667 6.16666667 6.83333333 5.5        6.66666667\n",
      " 6.5        6.         6.33333333 3.66666667 6.83333333 6.\n",
      " 5.33333333 4.66666667 5.66666667 5.33333333 5.33333333 4.\n",
      " 6.16666667 6.66666667 7.         4.33333333 5.16666667 5.83333333\n",
      " 5.66666667 5.83333333 5.16666667 6.33333333 5.66666667 4.66666667\n",
      " 5.33333333 5.         6.66666667 3.66666667 5.33333333 6.33333333\n",
      " 6.16666667 5.33333333 6.         6.16666667 4.16666667 5.83333333\n",
      " 5.83333333 1.83333333 6.33333333 5.5        6.16666667 5.33333333\n",
      " 5.33333333 6.5        4.83333333 6.16666667 6.         4.66666667\n",
      " 3.33333333 5.83333333 6.33333333 6.33333333 5.5        5.5\n",
      " 5.66666667 5.33333333 6.66666667 4.66666667 5.33333333 6.16666667\n",
      " 6.83333333 4.5        5.16666667 4.83333333 6.         6.\n",
      " 4.83333333 7.         5.5        6.16666667 4.83333333 5.5\n",
      " 5.83333333 5.16666667]\n",
      "Correlation:  [[1.         0.11522986]\n",
      " [0.11522986 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.36\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.85297839 5.78218151 5.10938541 6.57380023 4.73640293 5.20112252\n",
      " 5.88850794 4.51028893 6.19724712 6.15865309 4.34787188 5.0119644\n",
      " 6.51104539 4.737532   5.10503389 5.31206861 5.25722988 5.54014871\n",
      " 5.35592762 5.65103972 5.31495142 4.69851279 5.60809499 6.20458774\n",
      " 5.570342   5.74593052 6.2611226  5.75942088 6.68678858 6.5369771\n",
      " 6.51391325 4.6015221  5.89438608 5.6515248  5.44295407 6.25465239\n",
      " 6.30081214 5.63598966 5.79101189 5.37639032 5.74041362 5.16488421\n",
      " 5.82669025 5.30551452 2.96058654 4.97173589 4.73452065 5.1869672\n",
      " 5.6631426  5.35313753 5.33688383 5.51168461 6.33196868 5.34200648\n",
      " 6.36489423 6.14515528 4.96012638 5.64591629 6.09296317 6.79418758\n",
      " 5.24841815 5.8342186  5.64691705 7.18719202 5.78026724 7.53746171\n",
      " 5.09397774 5.7956453  5.11310478 5.21883958 5.26316473 4.63363494\n",
      " 5.2182728  6.76144637 6.76631361 2.43549394 5.20865089 6.93764226\n",
      " 5.87599886 6.39926383 5.3807667  5.48753379 5.12893955 5.40139696\n",
      " 4.74972404 5.94923364 5.00280242 5.16754072 5.66398566 5.25581635\n",
      " 6.15641003 5.18937035]\n",
      "\n",
      "What it should be:  [4.16666667 6.5        5.5        5.83333333 3.66666667 6.\n",
      " 5.33333333 5.83333333 6.83333333 6.66666667 4.66666667 5.83333333\n",
      " 5.16666667 3.66666667 6.16666667 5.83333333 6.5        5.66666667\n",
      " 6.16666667 6.16666667 5.33333333 5.5        6.16666667 6.5\n",
      " 5.         6.16666667 5.16666667 6.83333333 3.         6.\n",
      " 6.83333333 4.66666667 6.         6.5        4.83333333 5.66666667\n",
      " 6.         4.66666667 6.16666667 3.83333333 5.33333333 4.33333333\n",
      " 5.5        5.33333333 4.83333333 5.33333333 6.16666667 6.5\n",
      " 5.         5.33333333 5.5        5.         6.33333333 5.83333333\n",
      " 6.83333333 6.16666667 6.33333333 6.33333333 5.33333333 6.\n",
      " 6.16666667 5.83333333 6.16666667 6.5        6.83333333 7.\n",
      " 4.5        6.5        6.         4.5        5.33333333 6.66666667\n",
      " 6.33333333 5.66666667 4.66666667 5.5        5.83333333 7.\n",
      " 4.5        5.33333333 5.66666667 5.33333333 3.33333333 6.66666667\n",
      " 6.83333333 4.66666667 6.5        5.33333333 6.66666667 5.5\n",
      " 6.66666667 6.66666667]\n",
      "Correlation:  [[1.         0.21765444]\n",
      " [0.21765444 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.38\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.18933332 5.79748252 5.53185004 6.55004461 4.94197296 5.11028082\n",
      " 5.45305504 5.51730822 5.6893608  5.59428549 4.42655383 5.39981922\n",
      " 4.92013375 5.81185955 5.42921834 6.17536428 5.60881449 5.12059759\n",
      " 5.74293463 6.0565857  5.10281218 5.73231713 6.41625535 3.98702595\n",
      " 5.89686368 5.57701535 5.15619954 5.9499312  5.95945409 5.6244679\n",
      " 5.71563041 5.53748633 4.80865319 6.322199   5.89979835 5.73527562\n",
      " 5.91273503 4.92720621 3.74641601 5.69506787 5.80741192 6.36855564\n",
      " 5.31449778 6.59675795 5.56197659 5.24302187 6.32500352 5.47004203\n",
      " 6.52552059 4.92830044 5.1098317  5.75219233 5.84982523 5.82780253\n",
      " 4.85863207 6.31522028 3.85533735 5.29407997 3.74443394 4.75303735\n",
      " 5.85415322 4.782905   5.76516926 4.32427673 6.44616121 6.82650907\n",
      " 5.24268515 5.41017563 6.73324797 4.59688183 3.84360228 4.93854251\n",
      " 6.21492531 5.1550986  4.56721348 6.85402559 5.37132407 5.96362856\n",
      " 6.63015747 5.71469298 5.42503117 4.80372973 6.03394712 6.30358034\n",
      " 5.44650306 4.94075425 5.78898069 5.83901895 4.7247822  5.6983023\n",
      " 4.91006    6.34172286]\n",
      "\n",
      "What it should be:  [5.33333333 5.5        5.83333333 7.         6.         3.33333333\n",
      " 5.66666667 6.66666667 6.         6.66666667 6.16666667 4.83333333\n",
      " 4.33333333 6.33333333 5.83333333 5.33333333 6.5        5.\n",
      " 5.66666667 5.5        4.         6.         5.66666667 6.83333333\n",
      " 6.         5.16666667 6.16666667 3.66666667 4.66666667 4.66666667\n",
      " 5.66666667 6.33333333 4.33333333 5.33333333 6.83333333 6.83333333\n",
      " 5.33333333 5.83333333 4.         6.66666667 6.         6.\n",
      " 4.5        6.33333333 5.16666667 6.5        6.5        5.33333333\n",
      " 6.66666667 6.5        5.66666667 6.83333333 5.83333333 5.\n",
      " 5.         4.83333333 5.5        6.         7.         4.66666667\n",
      " 4.66666667 5.33333333 6.         5.83333333 5.33333333 7.\n",
      " 5.33333333 6.33333333 5.16666667 6.         4.5        5.\n",
      " 6.83333333 4.83333333 6.         5.16666667 6.83333333 6.33333333\n",
      " 7.         5.33333333 6.5        6.33333333 6.33333333 5.66666667\n",
      " 1.83333333 4.83333333 5.33333333 5.83333333 5.33333333 5.5\n",
      " 5.5        6.16666667]\n",
      "Correlation:  [[1.         0.19183327]\n",
      " [0.19183327 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.32\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.86236315 6.89576032 6.01110231 6.49498554 6.37083542 5.67733839\n",
      " 7.00699656 5.64064432 6.79820798 6.40782877 5.96613564 6.27288887\n",
      " 5.05259566 6.0710131  6.1931082  6.08326777 6.29535352 6.1182177\n",
      " 5.35899679 6.97295011 5.8525387  4.94421737 4.45349903 5.57298473\n",
      " 5.30535686 5.43386817 5.29128149 6.47837344 6.79756918 5.66910499\n",
      " 5.12033601 5.98946201 5.3790654  7.3906465  5.10157526 5.24268731\n",
      " 5.86256095 5.05158633 5.30930763 5.36419357 5.28865611 6.38647291\n",
      " 6.39741684 5.43578256 4.31975944 5.17265558 5.147178   5.12635425\n",
      " 6.40321943 5.33108223 4.64825546 5.53141588 6.66375221 5.32956543\n",
      " 5.91719307 5.96201674 5.45214787 6.62427584 5.53379775 5.07790621\n",
      " 6.338893   5.60426866 5.58029913 6.08816316 5.57060211 6.41589575\n",
      " 5.56662414 5.29509628 6.30783702 4.77462992 5.90147429 6.7056185\n",
      " 5.67580452 5.79211538 5.20870878 5.40619009 6.0478993  5.59682041\n",
      " 5.67063566 6.35716715 6.10745147 5.25846342 6.39185806 5.38829511\n",
      " 5.56906744 6.46975183 6.18455126 5.69433344 6.00064187 6.2419992\n",
      " 5.72757816 5.87736808]\n",
      "\n",
      "What it should be:  [6.66666667 4.5        5.66666667 6.83333333 6.5        6.16666667\n",
      " 5.66666667 5.5        4.         6.         6.33333333 5.33333333\n",
      " 5.         5.5        5.83333333 5.33333333 6.5        6.83333333\n",
      " 5.83333333 6.16666667 5.33333333 5.66666667 4.83333333 4.66666667\n",
      " 6.33333333 3.83333333 7.         5.16666667 5.33333333 6.33333333\n",
      " 6.33333333 6.5        6.         7.         4.66666667 5.\n",
      " 6.33333333 5.33333333 6.16666667 6.83333333 5.5        5.5\n",
      " 7.         4.66666667 5.5        6.16666667 6.16666667 6.\n",
      " 5.33333333 5.83333333 6.33333333 6.16666667 6.         6.\n",
      " 6.83333333 5.33333333 4.16666667 6.5        6.         3.66666667\n",
      " 6.5        4.         5.         5.33333333 5.66666667 5.\n",
      " 6.16666667 6.5        4.33333333 4.83333333 5.33333333 6.66666667\n",
      " 6.5        6.33333333 6.16666667 4.33333333 4.5        5.5\n",
      " 4.5        4.66666667 6.         5.83333333 6.5        5.5\n",
      " 3.33333333 6.16666667 5.83333333 6.33333333 5.66666667 4.66666667\n",
      " 6.66666667 5.33333333]\n",
      "Correlation:  [[1.         0.13529233]\n",
      " [0.13529233 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.59404673 5.72177451 5.56017452 4.7571024  5.00013514 6.56024223\n",
      " 4.67322378 5.73087699 4.60879426 5.34395714 5.45420788 5.51435104\n",
      " 5.27973195 5.5456119  6.34692223 6.07139544 6.27968534 6.04536486\n",
      " 5.28380228 4.72174333 4.90992427 6.5157479  5.58913339 5.38652984\n",
      " 5.40553545 6.75477126 6.81776977 5.11364168 5.55904503 6.0524478\n",
      " 5.72517221 6.10613057 6.00297463 4.6969961  5.74428899 5.64983881\n",
      " 4.896354   5.15721517 6.03752251 6.35443174 5.97650593 5.61505651\n",
      " 5.94245641 5.9435879  5.72374348 4.34535647 5.53434488 5.21857281\n",
      " 6.48317354 5.63378327 5.18057036 5.20181594 5.00842434 6.17373677\n",
      " 6.14787629 5.45328419 5.32106383 6.02045952 5.40183677 4.2944049\n",
      " 4.92399303 6.24371503 4.66759194 5.99394585 6.47703488 6.44582634\n",
      " 5.74239857 6.20258366 6.07507703 5.64873173 5.86640324 5.75031419\n",
      " 4.66024792 6.65437125 4.90475418 5.11879534 7.16716856 5.55124191\n",
      " 5.96948379 5.28804757 6.12441564 5.89487863 5.40333378 5.03989442\n",
      " 5.23344559 5.55314134 5.39757225 5.38345821 5.23714566 5.62251823\n",
      " 5.29190802 6.33616559]\n",
      "\n",
      "What it should be:  [6.83333333 6.83333333 4.33333333 1.83333333 5.5        6.16666667\n",
      " 6.5        6.83333333 6.33333333 7.         4.83333333 7.\n",
      " 4.33333333 3.33333333 4.16666667 5.         6.33333333 5.33333333\n",
      " 4.33333333 6.16666667 3.5        6.5        6.         6.5\n",
      " 5.16666667 6.5        6.         5.66666667 6.         6.83333333\n",
      " 5.66666667 5.5        5.83333333 4.         7.         4.66666667\n",
      " 5.16666667 5.16666667 5.33333333 6.33333333 5.33333333 6.\n",
      " 6.16666667 6.66666667 6.16666667 3.         5.33333333 6.16666667\n",
      " 6.83333333 5.83333333 4.66666667 4.83333333 5.5        5.5\n",
      " 6.33333333 5.66666667 6.33333333 4.         6.5        5.5\n",
      " 4.33333333 6.83333333 5.16666667 5.33333333 5.16666667 4.66666667\n",
      " 4.5        6.16666667 6.16666667 5.66666667 5.83333333 4.5\n",
      " 6.16666667 5.16666667 4.         6.         4.83333333 6.33333333\n",
      " 6.5        6.33333333 5.83333333 6.         5.66666667 5.\n",
      " 5.         5.5        5.33333333 4.66666667 5.         6.5\n",
      " 4.5        4.        ]\n",
      "Correlation:  [[1.        0.2616825]\n",
      " [0.2616825 1.       ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.04\n",
      "R2 score = -0.05\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.38221877 5.95531315 5.47566285 6.00887658 5.03366874 5.75180904\n",
      " 4.18070296 6.27640444 6.51197958 4.9753136  4.11519608 5.98448455\n",
      " 5.4002436  5.87933643 4.55688833 4.76971859 5.88738774 5.07851187\n",
      " 5.41567953 5.40343757 5.92632018 5.07688044 5.5560981  5.16251327\n",
      " 5.62384493 5.43456381 3.81919811 6.59271061 5.62728986 5.81875651\n",
      " 5.39858006 5.24710259 4.95613469 6.39802711 6.21069248 4.7593131\n",
      " 5.45727865 6.30069378 5.37634904 6.29087207 6.1273185  5.65935983\n",
      " 5.85225741 6.3097977  5.38387265 6.76661962 5.39904598 5.51537624\n",
      " 5.71005768 5.09780217 6.21531416 5.3553785  4.95751736 6.23942174\n",
      " 4.81128909 5.3657712  5.45118951 4.18571308 5.82676034 5.95536257\n",
      " 6.17271125 6.28314088 5.727207   5.48632486 5.08270639 6.73693042\n",
      " 5.34302968 5.410151   3.87985173 5.31369476 5.41579286 4.98344386\n",
      " 5.43513522 5.04703399 5.15422795 6.78138791 5.29751017 5.40231915\n",
      " 6.55661578 5.21657938 4.91403686 5.09027625 5.49170754 5.08772471\n",
      " 5.37362629 5.92162795 5.50296993 5.83090886 5.32603083 4.98640826\n",
      " 5.07124764 5.4458925 ]\n",
      "\n",
      "What it should be:  [6.66666667 5.         4.5        4.33333333 5.83333333 5.16666667\n",
      " 3.33333333 4.         5.33333333 6.5        4.83333333 4.83333333\n",
      " 5.66666667 5.33333333 7.         3.66666667 6.         5.33333333\n",
      " 6.83333333 6.16666667 6.5        6.16666667 6.         3.66666667\n",
      " 6.83333333 5.33333333 6.83333333 6.16666667 6.         5.\n",
      " 3.83333333 6.5        6.16666667 5.16666667 6.5        4.5\n",
      " 3.         6.33333333 6.66666667 4.5        5.83333333 6.5\n",
      " 5.83333333 5.33333333 5.33333333 5.83333333 4.         4.83333333\n",
      " 6.16666667 4.5        5.66666667 4.83333333 5.5        6.66666667\n",
      " 7.         6.33333333 6.5        6.16666667 6.66666667 5.66666667\n",
      " 5.16666667 5.33333333 6.16666667 5.16666667 5.         5.83333333\n",
      " 7.         6.66666667 6.83333333 5.33333333 4.66666667 4.33333333\n",
      " 5.16666667 5.66666667 6.33333333 6.16666667 6.16666667 6.33333333\n",
      " 6.         5.66666667 6.33333333 5.83333333 5.5        5.66666667\n",
      " 6.16666667 5.16666667 5.33333333 5.83333333 6.16666667 5.5\n",
      " 3.5        5.83333333]\n",
      "Correlation:  [[1.         0.01017545]\n",
      " [0.01017545 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.43\n",
      "R2 score = -0.45\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.22165018 5.49392168 5.78042288 5.59543172 5.43322594 5.74541265\n",
      " 5.94512576 5.34673392 4.42516269 5.54875046 4.52399092 5.06092461\n",
      " 5.7049754  4.58218169 4.72941457 5.47469757 6.0591021  5.9877876\n",
      " 5.22728362 5.78308396 6.19712207 6.66410029 5.70195301 4.90144165\n",
      " 4.76944428 4.65004456 5.15759932 5.55344573 5.79562314 5.15365785\n",
      " 5.0051761  6.40799463 5.61764081 5.059205   6.91814786 6.04210466\n",
      " 5.57546099 5.85803301 5.23966775 4.45567552 4.75903508 5.25169886\n",
      " 4.25739133 5.8321595  5.72692589 5.8666365  4.96694    5.74517201\n",
      " 5.73445137 5.87870532 5.62794036 5.38403939 5.98574011 6.11177984\n",
      " 4.66366108 5.13338566 5.09550924 6.23702622 5.69214321 4.22785208\n",
      " 5.94889453 5.65773347 5.97420835 6.32453958 6.7347443  5.62649014\n",
      " 6.5674252  4.96485333 6.0497836  5.44549824 6.7556086  5.5891428\n",
      " 5.70227974 4.81662782 5.88659191 5.916528   5.61728953 5.36483224\n",
      " 5.33902983 5.24053736 5.83544263 4.91764455 6.67490802 5.81899894\n",
      " 5.64156045 5.51222084 5.84566294 4.93769391 5.71070116 6.02033858\n",
      " 5.94659109 5.76474645]\n",
      "\n",
      "What it should be:  [4.66666667 5.5        6.83333333 4.83333333 4.5        5.66666667\n",
      " 5.83333333 5.66666667 6.33333333 5.16666667 5.33333333 5.\n",
      " 5.         5.16666667 6.33333333 6.16666667 6.33333333 5.33333333\n",
      " 4.         3.66666667 5.83333333 6.5        5.33333333 5.83333333\n",
      " 6.5        4.33333333 4.33333333 6.66666667 5.66666667 4.66666667\n",
      " 6.         5.16666667 5.5        6.66666667 6.33333333 6.\n",
      " 6.16666667 6.5        5.5        4.66666667 5.66666667 6.5\n",
      " 6.5        5.66666667 6.16666667 6.16666667 7.         6.16666667\n",
      " 5.33333333 6.5        5.5        1.83333333 7.         6.66666667\n",
      " 4.83333333 5.83333333 5.5        6.33333333 4.16666667 3.\n",
      " 6.         5.33333333 4.66666667 6.16666667 3.33333333 6.16666667\n",
      " 5.66666667 5.         5.83333333 5.16666667 6.83333333 5.16666667\n",
      " 6.         6.16666667 6.83333333 6.16666667 4.83333333 4.33333333\n",
      " 6.16666667 6.16666667 6.         6.83333333 6.5        5.83333333\n",
      " 6.33333333 4.66666667 6.16666667 6.         6.33333333 6.66666667\n",
      " 6.16666667 6.83333333]\n",
      "Correlation:  [[1.         0.20524063]\n",
      " [0.20524063 1.        ]]\n",
      "Mean absolute error = 0.73\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.13\n",
      "R2 score = -0.14\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.50450517 4.75569079 6.20071684 5.5161382  5.97024006 5.75912227\n",
      " 5.19145908 3.34509123 5.85622587 4.83325321 5.61649697 5.2119589\n",
      " 5.40393975 5.87815562 6.48258116 6.28164938 5.90181431 5.51409932\n",
      " 4.45206174 6.31498114 3.91000996 3.34158222 6.13768956 4.98610302\n",
      " 6.06796771 6.94316157 5.93782292 6.9597812  4.49465564 4.30674799\n",
      " 6.12596693 4.95077977 5.64797147 5.6144912  6.00374845 5.83749483\n",
      " 5.3890411  5.49055372 5.58146889 4.68013172 4.5916556  5.46105413\n",
      " 5.29535672 6.05804187 6.41904707 4.86639801 5.69076208 5.70996636\n",
      " 3.86110857 6.92024159 6.52674742 5.8789807  6.16135501 6.66642611\n",
      " 5.11965736 4.58363548 5.97052462 6.26201535 5.77470434 4.8266129\n",
      " 4.53323737 5.49849141 5.79204119 4.91512198 5.8503566  5.50130023\n",
      " 5.79521008 6.09965473 4.15352766 5.7290077  5.76578659 4.65497281\n",
      " 5.52106204 6.07662103 5.56795482 6.27944238 5.07106739 5.54294738\n",
      " 6.95797835 5.88396933 5.82531556 5.64771863 4.66849063 5.08960013\n",
      " 4.59942548 5.68582698 5.82062723 6.13019048 4.87513774 6.2446473\n",
      " 5.22778578 6.18445621]\n",
      "\n",
      "What it should be:  [5.33333333 4.5        6.33333333 3.66666667 4.16666667 6.83333333\n",
      " 6.5        7.         6.83333333 6.5        6.33333333 5.\n",
      " 6.5        6.66666667 5.16666667 6.16666667 5.         5.5\n",
      " 5.16666667 5.33333333 6.         4.         6.66666667 5.66666667\n",
      " 6.16666667 6.5        4.66666667 5.5        6.83333333 6.83333333\n",
      " 5.33333333 5.66666667 6.         6.         5.66666667 4.5\n",
      " 5.33333333 5.16666667 6.33333333 5.         5.5        3.83333333\n",
      " 5.5        6.16666667 7.         5.66666667 6.83333333 4.\n",
      " 3.         6.66666667 5.16666667 5.83333333 6.16666667 6.16666667\n",
      " 4.         6.66666667 6.5        4.83333333 6.33333333 5.\n",
      " 5.83333333 6.16666667 6.66666667 5.83333333 3.5        7.\n",
      " 5.5        6.5        6.33333333 6.66666667 6.16666667 5.33333333\n",
      " 5.16666667 6.16666667 4.66666667 6.5        5.83333333 5.66666667\n",
      " 5.83333333 5.83333333 6.5        5.66666667 4.83333333 4.33333333\n",
      " 6.33333333 6.83333333 5.66666667 4.33333333 4.66666667 6.5\n",
      " 5.33333333 6.        ]\n",
      "Correlation:  [[1.         0.16898088]\n",
      " [0.16898088 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.52384562 5.09633089 5.71719027 6.77076511 3.79756582 4.97734139\n",
      " 5.51534617 5.44803121 4.9495125  6.26785278 6.507563   5.99923369\n",
      " 5.96398977 5.55699373 4.28705634 5.39684076 5.46489234 5.59167901\n",
      " 4.83356571 4.81195119 5.53810722 7.25689222 3.73162171 5.99774829\n",
      " 6.60331125 4.92534978 5.00012312 5.68632062 6.19011385 4.85993552\n",
      " 5.06427229 5.11409693 5.7906437  5.67162612 5.87746123 5.15578554\n",
      " 5.30679831 4.73644808 6.128093   5.00856075 5.98669607 4.76179677\n",
      " 6.07930279 5.8660265  5.08327682 5.03469613 6.89209711 4.75882045\n",
      " 5.2123918  4.0241513  6.15124827 5.35062722 5.94254671 5.5567283\n",
      " 6.28078758 6.72732036 5.21445207 5.92612382 6.62998394 5.25333059\n",
      " 6.62941258 4.4773072  6.61908316 5.59905847 5.18293802 7.12170077\n",
      " 4.50190685 5.545108   6.13089419 4.1390453  6.84991757 4.78350136\n",
      " 5.92525836 5.97893694 5.5173974  6.16454811 7.28861262 5.6717225\n",
      " 5.35408795 3.69771171 4.53012317 5.59191206 4.99528341 6.3500047\n",
      " 5.94234581 4.00170042 4.54672282 5.67537954 4.66178316 5.12685089\n",
      " 5.5819281  5.07575781]\n",
      "\n",
      "What it should be:  [6.         6.83333333 4.83333333 5.83333333 6.         6.66666667\n",
      " 5.5        6.66666667 6.5        6.83333333 6.16666667 6.\n",
      " 4.5        6.         6.16666667 6.83333333 6.16666667 6.33333333\n",
      " 4.5        4.66666667 6.16666667 6.5        6.83333333 4.16666667\n",
      " 5.66666667 4.33333333 6.5        6.         6.         5.\n",
      " 4.66666667 3.66666667 4.83333333 6.         5.83333333 6.16666667\n",
      " 6.16666667 4.83333333 5.33333333 5.5        6.5        5.5\n",
      " 5.66666667 5.66666667 5.66666667 6.33333333 5.66666667 6.66666667\n",
      " 7.         5.16666667 6.5        5.83333333 5.83333333 3.\n",
      " 6.16666667 5.16666667 5.33333333 5.66666667 6.33333333 6.5\n",
      " 5.16666667 4.33333333 6.16666667 5.16666667 6.16666667 7.\n",
      " 6.83333333 5.5        5.16666667 7.         6.5        3.83333333\n",
      " 5.16666667 6.         5.33333333 6.16666667 6.5        4.66666667\n",
      " 5.66666667 5.5        5.5        6.         5.83333333 4.83333333\n",
      " 4.         4.66666667 6.5        5.83333333 5.33333333 6.83333333\n",
      " 5.83333333 6.33333333]\n",
      "Correlation:  [[1.         0.08464086]\n",
      " [0.08464086 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.25\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.76\n",
      "R2 score = -0.83\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.7047393  6.09123993 5.7066734  5.74922308 4.7295929  5.72330244\n",
      " 5.57309151 5.83272725 5.31936485 5.70144039 5.20092237 4.89250841\n",
      " 5.62594329 6.20544318 5.6023526  5.36223967 6.18866317 5.3753986\n",
      " 4.78130416 4.38816507 4.7112848  5.66928397 5.21830276 6.26148272\n",
      " 6.06832985 5.36008849 6.45072525 6.13248865 5.72283732 6.33813749\n",
      " 5.43354707 4.91704969 4.90467257 6.04037031 3.58975213 6.22374356\n",
      " 6.57123425 5.96700899 4.86394383 5.75506965 6.38406264 5.89630392\n",
      " 5.30736983 5.45542823 6.5941611  4.95011367 6.44102336 5.91230298\n",
      " 5.68977042 5.74771625 6.39918162 5.8699772  6.29613611 5.14572837\n",
      " 5.58630014 5.82918024 6.19405271 5.1139226  5.59196104 4.63223805\n",
      " 4.82137255 6.45860946 6.26582937 5.39448338 4.01417744 6.19778283\n",
      " 5.8868129  6.24431745 7.13033238 6.96445438 4.64794503 5.32908899\n",
      " 5.83665777 5.41896541 5.1212809  6.08846511 5.19099253 6.3147411\n",
      " 7.49684852 6.52318846 4.22140291 5.70378444 6.02323658 7.15468989\n",
      " 5.56540237 4.65831247 5.90244848 4.93813115 5.89306861 5.38504217\n",
      " 5.74289076 6.1342869 ]\n",
      "\n",
      "What it should be:  [3.5        6.33333333 6.66666667 5.66666667 3.66666667 6.66666667\n",
      " 5.33333333 6.16666667 6.16666667 5.83333333 4.83333333 6.\n",
      " 5.33333333 4.5        6.         4.66666667 5.33333333 5.33333333\n",
      " 6.5        6.         6.16666667 6.         5.5        6.\n",
      " 6.5        5.33333333 4.5        6.16666667 6.83333333 7.\n",
      " 3.66666667 5.5        5.83333333 4.83333333 4.83333333 5.16666667\n",
      " 5.16666667 5.83333333 3.83333333 5.83333333 5.66666667 5.33333333\n",
      " 3.66666667 6.83333333 6.5        6.83333333 5.83333333 7.\n",
      " 5.66666667 6.5        4.16666667 6.83333333 6.5        6.5\n",
      " 6.66666667 6.16666667 4.         7.         6.         6.16666667\n",
      " 4.5        4.66666667 6.83333333 5.66666667 4.66666667 5.66666667\n",
      " 5.         5.83333333 6.         4.5        5.83333333 4.83333333\n",
      " 5.66666667 6.33333333 5.83333333 6.33333333 6.5        6.66666667\n",
      " 6.83333333 5.16666667 5.66666667 3.         5.33333333 6.5\n",
      " 5.83333333 6.33333333 5.66666667 6.         7.         4.33333333\n",
      " 6.66666667 6.16666667]\n",
      "Correlation:  [[1.         0.11105363]\n",
      " [0.11105363 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.8\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.25665188 6.44875429 5.53454841 5.55025084 6.30788528 5.33356333\n",
      " 5.6317371  6.38611248 5.08742358 6.34033913 5.78982809 5.16968225\n",
      " 6.54619717 5.68512747 6.90974196 5.72633592 5.54926762 5.22768419\n",
      " 5.05958948 5.91145471 5.92812164 5.47515064 6.07576093 6.05239655\n",
      " 5.4188127  6.27779618 5.30678184 5.31846679 5.78888086 5.27545183\n",
      " 5.53616181 6.08008028 5.15656713 6.30843133 5.81447661 4.98188642\n",
      " 5.30098267 6.08246926 5.64299697 5.21436727 6.17660752 6.85173045\n",
      " 6.18044231 5.93113374 6.42983003 5.63040503 6.3533672  6.43344246\n",
      " 4.36774987 4.73023906 6.12880769 6.15331679 4.75315816 4.95639402\n",
      " 5.32936454 6.05414137 3.90085282 5.88157579 4.85099294 6.29406461\n",
      " 6.30534574 4.84001329 6.32247245 5.67537311 6.15633653 6.07369347\n",
      " 5.5397258  5.64103117 4.41485946 5.83124843 4.35906086 6.25947459\n",
      " 6.6354973  6.61878635 5.11458444 5.41098204 5.68283991 6.40587526\n",
      " 5.66593747 6.11758023 5.65276767 4.72608175 6.26919622 6.04023178\n",
      " 5.66181548 6.08470076 6.15317026 5.8887038  5.05441712 5.69677811\n",
      " 5.95052096 6.1710155 ]\n",
      "\n",
      "What it should be:  [6.16666667 5.33333333 6.83333333 6.16666667 5.         6.5\n",
      " 4.66666667 6.83333333 5.5        6.16666667 5.16666667 4.33333333\n",
      " 4.         4.83333333 7.         5.33333333 5.33333333 6.16666667\n",
      " 5.33333333 4.66666667 6.33333333 6.5        6.16666667 6.66666667\n",
      " 6.         7.         6.83333333 5.33333333 6.66666667 5.5\n",
      " 3.66666667 1.83333333 5.66666667 5.83333333 5.16666667 4.5\n",
      " 5.83333333 4.33333333 6.33333333 6.         6.5        6.5\n",
      " 4.16666667 5.83333333 3.         4.83333333 6.16666667 6.16666667\n",
      " 5.83333333 5.16666667 4.83333333 6.33333333 6.66666667 5.66666667\n",
      " 6.         6.         4.         5.66666667 5.33333333 5.16666667\n",
      " 6.16666667 3.66666667 6.33333333 6.66666667 6.33333333 5.66666667\n",
      " 6.         5.33333333 7.         6.16666667 6.83333333 5.5\n",
      " 3.83333333 6.5        5.5        6.5        4.5        4.83333333\n",
      " 6.5        4.5        6.33333333 6.5        4.33333333 4.66666667\n",
      " 6.16666667 6.5        6.83333333 6.         5.83333333 6.16666667\n",
      " 5.66666667 6.        ]\n",
      "Correlation:  [[ 1.         -0.03738005]\n",
      " [-0.03738005  1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.37\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.45\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.04212755 5.14694137 5.25162235 5.60403022 5.82340819 5.37451889\n",
      " 6.53774289 5.96026346 5.68248091 4.6356701  6.20309535 6.59370699\n",
      " 5.67202625 5.17332058 5.26603237 5.89818918 5.94906923 5.66236504\n",
      " 6.48575871 6.15289539 4.76966392 6.15517995 5.87368415 6.2446301\n",
      " 6.95329764 5.84772644 4.94155693 5.27747055 4.86773498 5.7494364\n",
      " 5.86300155 6.10569341 6.94220526 6.73563396 5.12850963 5.44616844\n",
      " 6.45017364 5.37981097 6.00597947 6.15197052 5.93457723 6.06972433\n",
      " 4.48977915 5.30825999 5.85202253 6.24976435 4.49387591 5.7711635\n",
      " 5.14578501 6.07370539 6.56453884 5.96100126 6.23670718 6.08240315\n",
      " 5.45204517 5.72506416 5.74832533 5.66361119 5.63667112 5.11161136\n",
      " 5.28787591 5.33613831 5.72080316 4.42578833 5.15806678 4.70576128\n",
      " 4.78618157 6.57791723 5.4412334  5.34493722 4.59655479 5.39294878\n",
      " 2.49975403 5.52648263 5.01171864 4.97799788 5.42122863 5.21462157\n",
      " 5.47045603 4.49659529 6.30159492 3.0309811  4.91428056 4.8186233\n",
      " 5.44291476 5.49808373 5.04737276 4.25753483 5.1662488  5.9189226\n",
      " 5.95334496 5.66521137]\n",
      "\n",
      "What it should be:  [6.66666667 5.83333333 5.33333333 5.33333333 6.5        6.66666667\n",
      " 6.33333333 6.5        6.16666667 6.5        6.         6.16666667\n",
      " 6.         6.83333333 4.66666667 5.66666667 5.33333333 6.16666667\n",
      " 6.5        4.33333333 6.5        5.33333333 6.33333333 6.66666667\n",
      " 6.         6.5        4.5        6.16666667 4.33333333 5.\n",
      " 6.66666667 4.66666667 7.         5.83333333 6.33333333 5.5\n",
      " 6.         6.         4.         5.5        5.33333333 5.16666667\n",
      " 6.         5.83333333 5.16666667 6.33333333 4.83333333 4.66666667\n",
      " 4.83333333 6.83333333 6.5        3.66666667 6.83333333 6.66666667\n",
      " 4.83333333 6.5        5.16666667 5.5        5.83333333 5.16666667\n",
      " 4.33333333 5.66666667 6.16666667 5.33333333 4.5        6.5\n",
      " 6.5        5.33333333 4.66666667 4.66666667 5.66666667 7.\n",
      " 5.5        5.16666667 4.         6.33333333 6.66666667 5.16666667\n",
      " 5.83333333 5.83333333 6.33333333 4.83333333 5.         5.33333333\n",
      " 6.5        6.16666667 3.33333333 6.         6.         4.5\n",
      " 5.33333333 5.16666667]\n",
      "Correlation:  [[1.         0.20070843]\n",
      " [0.20070843 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.42\n",
      "R2 score = -0.44\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.58851637 6.4993716  5.29380062 6.18619211 6.40499765 4.64302736\n",
      " 5.45231667 6.33693908 6.12982353 3.10519645 4.6436476  5.03636161\n",
      " 6.1507676  5.83950594 5.51435495 6.12076145 4.38895483 5.89605196\n",
      " 4.3781622  5.79208793 5.06878422 4.9856233  5.29821096 4.78773619\n",
      " 5.03138071 5.73246615 5.40851487 6.75603112 5.18470789 4.86388487\n",
      " 5.23677598 7.61694999 4.85987761 6.52068012 6.12134275 6.2077689\n",
      " 5.00581117 5.72475906 5.32655654 4.76461882 5.40109586 5.96937559\n",
      " 4.66968552 5.33350907 5.05728974 4.7858131  5.03375236 4.45778054\n",
      " 6.0526427  4.54171261 5.75422683 5.33686439 6.80079589 5.40975664\n",
      " 4.26911118 5.40374157 4.96532002 6.79614342 4.75349052 5.54760915\n",
      " 5.53400818 5.01369437 5.49383259 6.02697978 6.64326439 5.7165293\n",
      " 6.0536787  4.96436947 5.24461036 5.96389537 5.77606838 4.96147317\n",
      " 5.13260735 6.22282675 5.90163153 5.80654821 5.19864005 5.29679773\n",
      " 5.77142645 6.15535535 5.42598434 5.5288204  4.52898094 5.86173022\n",
      " 5.23417713 6.5360448  5.43755991 5.38692385 6.88137709 4.87986495\n",
      " 4.07759327 4.63481871]\n",
      "\n",
      "What it should be:  [6.66666667 5.5        3.83333333 4.83333333 7.         6.83333333\n",
      " 5.5        6.33333333 6.83333333 4.83333333 6.83333333 4.66666667\n",
      " 6.         5.66666667 5.33333333 6.         3.66666667 5.83333333\n",
      " 5.5        4.5        5.16666667 6.5        4.         7.\n",
      " 5.66666667 6.         5.33333333 5.66666667 5.16666667 4.33333333\n",
      " 5.33333333 5.33333333 6.33333333 6.16666667 5.16666667 5.16666667\n",
      " 6.5        4.5        4.66666667 6.16666667 6.16666667 6.33333333\n",
      " 5.83333333 5.83333333 4.83333333 4.83333333 6.         5.33333333\n",
      " 6.16666667 5.83333333 4.66666667 6.5        6.5        5.5\n",
      " 6.         4.5        6.16666667 5.83333333 5.83333333 3.\n",
      " 6.         6.16666667 5.         6.16666667 6.16666667 5.66666667\n",
      " 6.16666667 5.33333333 4.33333333 6.83333333 6.16666667 6.33333333\n",
      " 6.5        6.         4.         6.5        6.66666667 5.\n",
      " 5.16666667 6.         4.83333333 6.16666667 3.66666667 6.66666667\n",
      " 5.83333333 6.66666667 4.83333333 6.66666667 5.66666667 3.33333333\n",
      " 6.33333333 5.5       ]\n",
      "Correlation:  [[1.         0.17066472]\n",
      " [0.17066472 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.39\n",
      "R2 score = -0.41\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.71446015 5.01055462 4.98739297 6.46049167 6.0442405  5.90364098\n",
      " 5.21447089 5.55880572 6.79480718 5.91108673 5.14090895 5.40594051\n",
      " 3.06174298 5.92850634 5.55174489 6.04094141 6.23121896 6.93374307\n",
      " 5.35949867 5.16805035 4.5099201  5.24331685 5.21550209 5.63640839\n",
      " 4.83978176 5.91973987 5.83269021 6.44249077 5.93381334 6.48356645\n",
      " 6.27767575 4.73752699 6.10893579 7.08668151 4.66489917 6.00456988\n",
      " 5.71356594 5.40508925 4.74401662 6.17778313 6.80270402 4.82045732\n",
      " 5.74510346 6.30684062 5.11500338 5.48692192 5.74308024 5.23464468\n",
      " 6.48238189 5.62002238 5.3954398  5.56419485 4.68067612 6.58928712\n",
      " 5.03873338 4.31717046 7.01214487 6.49991059 4.69896119 6.63013373\n",
      " 5.29160443 7.0348516  5.74103639 6.65705615 4.90358994 5.37946\n",
      " 5.85713824 6.9198082  5.68180399 6.82394123 6.36534997 5.99302607\n",
      " 5.95773125 5.37060288 6.1699276  5.47720195 5.1847638  3.97177376\n",
      " 4.494685   4.80044623 5.74639079 5.42854496 5.52735646 5.37907424\n",
      " 5.54654151 5.21551305 6.75244117 4.36151755 6.22007388 5.49986839\n",
      " 5.84218955 5.18167913]\n",
      "\n",
      "What it should be:  [4.5        5.16666667 3.66666667 5.83333333 5.66666667 6.\n",
      " 5.         4.5        4.         4.         5.33333333 6.5\n",
      " 5.5        6.16666667 6.16666667 6.83333333 5.83333333 6.16666667\n",
      " 5.         5.83333333 5.66666667 5.33333333 6.16666667 4.66666667\n",
      " 5.83333333 6.16666667 6.16666667 5.16666667 6.         7.\n",
      " 5.66666667 6.33333333 6.16666667 6.5        5.33333333 5.83333333\n",
      " 6.5        5.5        4.33333333 6.66666667 4.66666667 4.83333333\n",
      " 5.33333333 4.33333333 5.66666667 6.5        6.16666667 6.83333333\n",
      " 7.         4.66666667 5.33333333 5.33333333 6.         6.5\n",
      " 5.66666667 5.83333333 6.66666667 6.83333333 7.         6.5\n",
      " 5.16666667 6.         5.33333333 6.16666667 3.66666667 5.66666667\n",
      " 6.         4.83333333 4.33333333 5.33333333 6.66666667 5.83333333\n",
      " 5.16666667 6.         5.66666667 5.5        4.         6.83333333\n",
      " 5.5        6.5        5.5        6.66666667 7.         6.33333333\n",
      " 3.         6.5        5.83333333 4.5        6.         5.66666667\n",
      " 4.66666667 7.        ]\n",
      "Correlation:  [[1.        0.1033519]\n",
      " [0.1033519 1.       ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.58\n",
      "R2 score = -0.58\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.02945605 5.23467908 5.374752   5.67172868 5.6899994  5.77633957\n",
      " 6.01866551 4.49457259 5.65763034 4.82432725 5.67230935 5.8303228\n",
      " 6.13677528 5.18076751 5.45724917 5.46931184 5.71005454 6.15732577\n",
      " 5.53516262 5.8483249  4.71670904 6.54195062 5.19232865 5.96689922\n",
      " 5.91127227 5.8615994  5.60124591 5.38943781 5.68584817 5.68925403\n",
      " 5.37847735 5.14037346 5.43344397 5.85761716 5.11211115 5.36845819\n",
      " 4.85630501 5.52283647 5.80717882 4.98718876 4.71305305 5.83178985\n",
      " 5.62259312 5.55157725 6.16794061 5.94492637 5.6446423  5.61765932\n",
      " 6.22797596 5.88996661 4.98251338 6.14751468 5.60640731 5.30692808\n",
      " 6.97077731 5.88409281 5.62015324 6.02758731 5.65858354 5.32622406\n",
      " 6.54291112 5.29778736 5.33879726 5.45839854 5.27695276 4.41121058\n",
      " 6.33726693 6.25986566 6.59034708 4.9255181  5.54340904 5.5596064\n",
      " 5.93525074 6.6756338  5.06406475 5.96330431 4.75335667 5.96814124\n",
      " 5.17152354 4.70310718 5.60636806 6.32019521 5.48447992 6.16005658\n",
      " 6.27027608 6.00842796 6.21320674 6.31709652 5.47956623 5.73437104\n",
      " 6.0549621  5.98523676]\n",
      "\n",
      "What it should be:  [6.5        6.         4.33333333 5.66666667 4.5        4.83333333\n",
      " 6.33333333 4.         6.16666667 6.33333333 5.         4.5\n",
      " 6.5        4.33333333 6.16666667 6.83333333 5.33333333 5.66666667\n",
      " 6.         6.16666667 7.         5.83333333 4.66666667 6.83333333\n",
      " 6.5        4.83333333 7.         5.33333333 6.         5.5\n",
      " 6.33333333 5.33333333 3.33333333 5.83333333 5.83333333 5.83333333\n",
      " 6.83333333 6.5        5.83333333 6.5        4.66666667 6.16666667\n",
      " 6.5        5.33333333 6.16666667 6.33333333 6.66666667 5.5\n",
      " 6.16666667 6.16666667 5.66666667 5.16666667 5.33333333 4.5\n",
      " 6.         4.33333333 5.33333333 6.5        5.         5.5\n",
      " 5.66666667 5.83333333 6.16666667 6.83333333 5.66666667 6.\n",
      " 7.         4.83333333 4.66666667 1.83333333 4.         5.5\n",
      " 6.16666667 6.         4.         6.         6.33333333 5.33333333\n",
      " 4.33333333 3.66666667 6.16666667 6.33333333 3.5        6.16666667\n",
      " 6.16666667 6.         5.33333333 4.66666667 6.33333333 6.\n",
      " 3.         5.83333333]\n",
      "Correlation:  [[1.         0.19809997]\n",
      " [0.19809997 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.07\n",
      "R2 score = -0.08\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.06353366 5.20874762 6.47979703 6.33493028 5.25028738 5.57271116\n",
      " 6.48197405 5.6789271  6.27830338 5.53005174 4.3862897  5.92496936\n",
      " 7.21795587 6.19616035 5.93976064 5.34167777 6.02369773 6.56043287\n",
      " 4.9439598  4.93395496 5.80505323 5.99500988 5.34811465 5.29486396\n",
      " 4.74706975 5.92909268 6.1136607  6.77372799 5.71585203 6.32056535\n",
      " 6.39069827 5.11115661 5.08383175 5.25915489 5.31533134 5.20323686\n",
      " 6.07029189 5.78758676 5.70668087 5.97345689 6.04536216 5.85411175\n",
      " 5.33931928 4.68358217 6.17231651 5.81015098 5.65067156 5.3639493\n",
      " 6.28055312 5.47313761 5.3051206  5.93094591 4.51461634 6.20181362\n",
      " 5.95996759 5.97745219 6.06899103 5.59586032 6.58687053 6.16615183\n",
      " 6.0421057  5.47731138 5.43603827 5.48704056 4.92348973 5.09332469\n",
      " 5.5977885  6.6835653  5.74377838 5.24032017 5.34372482 5.8349318\n",
      " 5.63867837 5.35582821 5.78378953 5.8843587  5.66228731 5.62992373\n",
      " 5.87151525 6.83351578 5.41167241 6.03889943 4.37738884 5.79549427\n",
      " 6.21168462 5.80828162 6.47745108 5.70680605 5.74357031 5.20621708\n",
      " 5.02616154 6.32892921]\n",
      "\n",
      "What it should be:  [5.16666667 5.83333333 5.66666667 6.83333333 3.66666667 5.16666667\n",
      " 6.16666667 6.5        5.16666667 3.83333333 4.33333333 6.5\n",
      " 7.         6.66666667 6.16666667 5.16666667 6.         5.66666667\n",
      " 5.5        5.         5.5        5.66666667 5.83333333 6.16666667\n",
      " 6.5        5.66666667 4.66666667 6.16666667 6.16666667 6.83333333\n",
      " 5.83333333 3.66666667 6.33333333 6.5        5.16666667 5.16666667\n",
      " 4.16666667 5.5        5.16666667 6.16666667 6.         6.66666667\n",
      " 5.5        4.66666667 6.33333333 4.83333333 6.33333333 5.\n",
      " 5.         6.5        5.33333333 4.83333333 4.         5.83333333\n",
      " 4.83333333 5.33333333 4.66666667 6.66666667 4.33333333 5.5\n",
      " 6.5        5.5        5.         6.16666667 3.66666667 4.5\n",
      " 6.5        5.83333333 6.         6.33333333 6.5        6.\n",
      " 4.         6.16666667 5.83333333 6.83333333 5.33333333 4.66666667\n",
      " 4.         5.83333333 6.83333333 5.66666667 5.5        6.16666667\n",
      " 5.83333333 1.83333333 6.33333333 5.83333333 5.33333333 6.\n",
      " 7.         6.5       ]\n",
      "Correlation:  [[1.         0.23561441]\n",
      " [0.23561441 1.        ]]\n",
      "Mean absolute error = 0.74\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.07\n",
      "R2 score = -0.1\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.18611748 5.8876443  5.82848936 5.61852263 5.7516862  5.14242407\n",
      " 5.92136337 6.01778199 4.85927739 5.56747663 5.14755904 4.39845961\n",
      " 5.35615995 5.21043755 5.61948291 4.73887155 6.09050685 5.84637174\n",
      " 6.19805085 5.02953779 6.56772715 5.35211409 6.61587818 6.60937899\n",
      " 4.60551824 4.60475864 4.86373427 6.1270392  5.34054717 4.80135845\n",
      " 6.01628229 5.52023841 6.67939176 5.86783446 6.53100462 5.32505617\n",
      " 7.04582953 5.14012154 5.85713586 5.88968258 5.60540785 5.80143729\n",
      " 5.71503165 6.47064559 5.96991461 6.41615027 5.49363722 6.64522187\n",
      " 6.51277586 6.31512267 5.05235556 6.13712633 5.62573643 5.42777702\n",
      " 5.64071804 6.68493231 6.04767713 5.6539704  7.09284949 4.18756792\n",
      " 5.48215699 6.08615406 5.70421011 5.99749175 6.51359656 5.87444932\n",
      " 5.35178941 5.70159556 5.4047418  5.01432669 5.70865059 5.9493201\n",
      " 5.28846724 5.69434192 6.19620621 5.67425558 5.57095739 5.83347109\n",
      " 3.98069553 7.18009731 5.43744234 5.13266661 5.6659101  5.93504282\n",
      " 5.70574821 6.41820608 5.42853209 4.6400783  5.30871891 5.25743211\n",
      " 4.8977855  5.83122214]\n",
      "\n",
      "What it should be:  [6.5        3.83333333 5.33333333 5.33333333 5.16666667 6.33333333\n",
      " 6.16666667 5.33333333 6.         5.33333333 5.16666667 4.33333333\n",
      " 7.         6.33333333 5.16666667 4.66666667 6.66666667 5.83333333\n",
      " 6.16666667 6.16666667 6.16666667 6.         6.66666667 6.5\n",
      " 6.         5.5        3.         6.16666667 6.5        3.5\n",
      " 6.5        6.         6.16666667 5.5        5.66666667 5.\n",
      " 5.66666667 6.5        6.         6.16666667 4.33333333 5.66666667\n",
      " 5.         6.83333333 6.33333333 5.83333333 6.16666667 5.5\n",
      " 6.16666667 5.33333333 6.66666667 4.66666667 4.33333333 1.83333333\n",
      " 6.5        6.66666667 5.16666667 6.         6.83333333 4.5\n",
      " 4.66666667 5.66666667 5.66666667 6.83333333 5.33333333 4.5\n",
      " 4.5        6.         4.83333333 5.16666667 4.         6.33333333\n",
      " 4.66666667 3.66666667 7.         5.83333333 5.5        6.16666667\n",
      " 5.5        5.33333333 6.16666667 5.83333333 5.33333333 6.83333333\n",
      " 6.33333333 6.         6.66666667 4.         5.5        4.5\n",
      " 6.33333333 5.5       ]\n",
      "Correlation:  [[1.         0.32852855]\n",
      " [0.32852855 1.        ]]\n",
      "Mean absolute error = 0.74\n",
      "Mean squared error = 0.91\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.0\n",
      "R2 score = -0.02\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.23017294 5.06767757 5.47508829 5.45079903 4.06998062 5.58691163\n",
      " 6.10716718 5.62018521 4.25898267 5.81411799 5.29158175 6.91488764\n",
      " 5.63194842 6.68421657 4.92623225 4.55666845 4.88875557 6.29855144\n",
      " 4.67929987 5.72598225 4.50617276 4.11881399 5.72458466 5.44868083\n",
      " 7.07162696 6.3348951  6.08016001 5.30715288 4.27550808 3.83082542\n",
      " 4.74106067 5.15528939 6.35511916 5.64393312 5.60160788 5.26245322\n",
      " 6.17281902 7.04896967 5.84853229 5.20759901 6.35715452 5.24254138\n",
      " 6.20189007 4.16957066 5.87170264 5.77645021 5.63957066 5.31461904\n",
      " 5.78841301 7.19930666 5.37022509 6.05220461 7.29919648 4.69809127\n",
      " 6.25874403 5.63442969 4.8292367  5.64647781 6.40438024 6.15294768\n",
      " 6.49542813 5.57900509 6.3870369  5.77607949 4.72457932 5.88047382\n",
      " 5.17662301 4.76790318 5.70063691 5.92011737 6.9857703  5.13743073\n",
      " 5.76714404 6.14108256 5.67121326 4.12869289 7.08040317 6.35049197\n",
      " 5.32127104 6.4250326  6.62879761 4.23465003 4.91296151 4.37210074\n",
      " 6.22476918 6.76178623 6.43103138 4.87539676 6.58834419 6.09723827\n",
      " 6.03505904 6.58841609]\n",
      "\n",
      "What it should be:  [5.33333333 6.83333333 5.83333333 4.66666667 5.5        5.33333333\n",
      " 6.         6.33333333 6.5        6.16666667 5.83333333 5.33333333\n",
      " 5.         5.83333333 5.66666667 6.33333333 5.5        6.66666667\n",
      " 6.16666667 5.66666667 4.66666667 5.66666667 6.33333333 5.33333333\n",
      " 3.         4.66666667 6.16666667 5.33333333 4.83333333 6.83333333\n",
      " 5.83333333 5.66666667 5.66666667 5.         5.5        6.\n",
      " 5.66666667 4.5        6.         4.83333333 6.16666667 5.33333333\n",
      " 3.33333333 6.83333333 6.33333333 4.5        5.66666667 7.\n",
      " 4.83333333 6.5        5.83333333 5.33333333 5.16666667 5.83333333\n",
      " 5.83333333 5.16666667 6.16666667 4.         7.         6.66666667\n",
      " 7.         6.16666667 5.33333333 6.83333333 5.         5.5\n",
      " 4.33333333 5.16666667 5.66666667 4.66666667 6.16666667 4.\n",
      " 5.16666667 6.         6.83333333 4.83333333 6.5        6.83333333\n",
      " 6.66666667 4.5        5.83333333 4.33333333 5.33333333 6.33333333\n",
      " 6.5        6.16666667 6.5        7.         5.66666667 6.83333333\n",
      " 4.5        5.5       ]\n",
      "Correlation:  [[ 1.         -0.01736391]\n",
      " [-0.01736391  1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.39\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.96\n",
      "R2 score = -0.96\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.54704302 6.48503977 6.29885392 5.2033988  6.84707376 5.77267551\n",
      " 5.20242211 6.00671534 5.35148833 4.43463572 5.8321679  6.25816023\n",
      " 5.11437878 6.306382   5.92074902 5.12217816 6.15982031 4.92165666\n",
      " 5.68236259 5.95813787 5.50194296 3.15319768 4.47954574 4.77982423\n",
      " 4.59050018 6.03603008 5.66916232 5.85910421 7.33536359 5.90520755\n",
      " 5.3251565  4.81677581 5.43275748 5.48461466 5.37349733 6.95385175\n",
      " 6.81820428 5.85978473 5.30973004 4.82600847 5.70845666 5.91490859\n",
      " 5.62800687 4.68330275 5.78544034 5.56810743 6.14497737 4.65173205\n",
      " 6.21606473 5.09112956 6.10212077 7.15124371 4.94857797 5.85994111\n",
      " 5.18810636 3.53301214 6.53159449 5.18232416 5.82537956 6.41298606\n",
      " 6.7154505  5.82797281 4.99398098 5.21739242 5.59726026 5.85396194\n",
      " 5.4849227  5.47094438 3.74361908 5.42877992 6.17611822 5.31031102\n",
      " 5.36316812 4.86465166 7.70657342 7.02320522 5.60353558 5.66843265\n",
      " 8.594369   7.41721871 5.58084902 4.18814203 6.82374384 5.97958818\n",
      " 3.90885348 5.61382514 5.83974321 5.94471846 5.90455021 5.91585248\n",
      " 5.90146328 5.11987444]\n",
      "\n",
      "What it should be:  [6.         4.         6.         6.5        6.5        6.\n",
      " 4.66666667 4.66666667 5.66666667 6.         4.66666667 6.83333333\n",
      " 5.83333333 5.16666667 5.16666667 5.33333333 6.16666667 6.5\n",
      " 6.16666667 5.66666667 6.33333333 5.5        6.33333333 5.16666667\n",
      " 4.33333333 5.66666667 6.16666667 4.66666667 5.83333333 5.66666667\n",
      " 6.5        5.66666667 6.16666667 5.         3.33333333 6.33333333\n",
      " 6.5        5.66666667 5.83333333 4.         6.16666667 5.33333333\n",
      " 6.33333333 5.5        6.66666667 5.83333333 6.16666667 6.33333333\n",
      " 6.         4.5        6.83333333 6.5        6.16666667 5.5\n",
      " 4.83333333 6.         5.66666667 5.         5.33333333 7.\n",
      " 5.33333333 5.83333333 6.83333333 6.66666667 4.66666667 6.33333333\n",
      " 5.83333333 4.83333333 6.16666667 5.83333333 6.16666667 5.83333333\n",
      " 6.33333333 5.5        7.         6.33333333 5.33333333 6.16666667\n",
      " 6.         7.         4.5        4.5        6.66666667 5.33333333\n",
      " 4.33333333 5.5        4.83333333 5.16666667 5.33333333 6.16666667\n",
      " 5.33333333 5.5       ]\n",
      "Correlation:  [[1.         0.28000371]\n",
      " [0.28000371 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.67\n",
      "R2 score = -0.67\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.80993915 5.78942009 6.43706196 5.93267606 5.4733905  6.14666213\n",
      " 4.56246058 6.96886342 4.77764251 5.43585399 6.43091512 5.41370666\n",
      " 5.42121821 5.73770197 5.81256018 5.92558785 5.71909696 5.24852428\n",
      " 5.35094633 5.89672964 5.0037132  5.19051378 5.51798705 6.29837907\n",
      " 5.30679542 4.89381618 5.56478539 5.48995898 5.26284675 5.90359546\n",
      " 5.13320917 5.25799743 6.1993799  5.80596361 5.46091402 6.2002724\n",
      " 6.32397597 4.50243298 5.53910055 5.89807392 4.92970279 4.53602675\n",
      " 5.81276402 4.66989806 5.96323354 5.65633128 5.88813065 5.99112122\n",
      " 7.06468756 6.01922859 4.92719596 4.88417538 5.57708341 5.44989801\n",
      " 6.39847578 6.36799215 5.44790803 4.91359182 5.13989388 5.77889245\n",
      " 5.62525835 4.32765366 4.85038512 6.09650174 5.26354947 7.00176603\n",
      " 6.02645832 5.63290222 5.96338678 6.08968738 4.71843697 5.82031182\n",
      " 5.35313323 5.41882952 5.42991656 6.10563893 5.65139358 4.73900698\n",
      " 5.56619939 5.20099887 5.55002138 5.12116506 6.30724447 5.33368542\n",
      " 4.39719363 6.85649893 4.90132196 6.26624054 4.74324563 3.63185997\n",
      " 4.48730742 5.9684974 ]\n",
      "\n",
      "What it should be:  [6.16666667 4.         5.16666667 6.16666667 5.66666667 4.5\n",
      " 6.5        6.         5.66666667 4.5        4.66666667 5.66666667\n",
      " 3.66666667 6.16666667 4.66666667 5.16666667 5.5        5.83333333\n",
      " 5.         6.         4.33333333 6.83333333 5.33333333 6.\n",
      " 6.66666667 6.33333333 6.         5.         5.66666667 6.16666667\n",
      " 4.66666667 6.66666667 6.66666667 4.5        5.         6.5\n",
      " 5.83333333 5.5        6.33333333 6.16666667 5.33333333 5.83333333\n",
      " 6.83333333 6.33333333 6.         6.5        5.16666667 5.33333333\n",
      " 7.         6.16666667 5.66666667 5.33333333 5.83333333 6.33333333\n",
      " 4.33333333 5.83333333 6.5        6.16666667 6.83333333 4.5\n",
      " 5.33333333 5.33333333 6.16666667 5.33333333 6.66666667 6.5\n",
      " 6.16666667 5.16666667 6.66666667 6.83333333 6.16666667 6.5\n",
      " 6.         3.5        4.         6.66666667 5.16666667 6.33333333\n",
      " 6.83333333 3.83333333 5.         4.66666667 4.16666667 5.83333333\n",
      " 7.         4.66666667 4.33333333 6.5        5.66666667 5.5\n",
      " 7.         5.66666667]\n",
      "Correlation:  [[ 1.         -0.02987082]\n",
      " [-0.02987082  1.        ]]\n",
      "Mean absolute error = 0.91\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.61\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.40600058 4.2863694  4.83177721 6.37315959 4.77378116 5.4435046\n",
      " 6.33364145 6.2879484  5.91156907 4.93177883 5.56585298 6.18724441\n",
      " 4.83597647 5.52934868 6.27270357 6.05791076 6.38304815 5.21127558\n",
      " 5.25300839 5.25774844 6.37678599 4.91889217 5.29679089 5.1653883\n",
      " 4.46313906 4.57784703 4.61255731 5.82029391 5.30993116 4.70608839\n",
      " 5.83189374 5.82936608 4.46602286 6.17371254 5.2246798  4.67060996\n",
      " 4.53343615 6.40386851 6.26761275 5.26727372 5.45472428 6.56107359\n",
      " 5.78549137 5.62885526 4.63481123 5.3980887  6.27981771 5.2963727\n",
      " 5.76758767 5.64962755 6.02520181 6.25876779 6.46746317 5.58959365\n",
      " 4.69386822 6.5165611  5.50893426 5.39721597 4.84345759 6.47311879\n",
      " 5.16241748 4.80804273 5.38462725 5.26214523 6.10958949 4.2675854\n",
      " 6.7948518  5.81835581 7.15140282 6.44787435 5.75530119 5.44443733\n",
      " 6.2180356  5.67283555 5.99561466 5.98571342 4.47449427 6.62560437\n",
      " 5.82173858 5.07861905 5.089493   3.00079547 5.37649716 5.72673081\n",
      " 5.84734565 4.78771616 6.5742168  6.09625581 5.73237453 6.87499373\n",
      " 6.1649074  5.64972441]\n",
      "\n",
      "What it should be:  [4.33333333 3.66666667 5.83333333 5.33333333 6.33333333 5.16666667\n",
      " 5.83333333 7.         6.83333333 7.         6.66666667 5.83333333\n",
      " 4.33333333 4.5        6.         3.33333333 5.         4.83333333\n",
      " 6.66666667 5.16666667 5.33333333 6.5        5.66666667 4.83333333\n",
      " 5.         5.5        6.83333333 6.16666667 5.16666667 6.\n",
      " 5.33333333 4.66666667 4.5        5.83333333 5.5        6.16666667\n",
      " 6.5        4.         5.         4.         5.         6.16666667\n",
      " 6.5        5.5        4.83333333 6.33333333 6.83333333 4.\n",
      " 6.66666667 5.66666667 6.         6.5        5.33333333 6.33333333\n",
      " 4.83333333 5.83333333 5.33333333 5.83333333 6.33333333 5.66666667\n",
      " 6.33333333 6.16666667 6.16666667 4.66666667 5.83333333 5.83333333\n",
      " 5.33333333 5.83333333 6.5        6.16666667 5.16666667 5.66666667\n",
      " 5.66666667 6.33333333 6.33333333 5.33333333 6.16666667 6.\n",
      " 3.5        4.66666667 5.5        5.5        6.66666667 5.16666667\n",
      " 7.         5.33333333 5.66666667 6.33333333 7.         6.\n",
      " 5.33333333 5.83333333]\n",
      "Correlation:  [[1.         0.11313045]\n",
      " [0.11313045 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.55\n",
      "R2 score = -0.56\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.6\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.805313   6.7312747  6.41540211 6.00494335 5.6374286  4.52535174\n",
      " 5.34819166 5.79528622 6.11301315 6.79233548 5.79789658 5.71674968\n",
      " 5.20294923 6.4568145  5.16449989 4.7991234  5.19991127 6.54305876\n",
      " 5.70288438 4.20750196 5.89652038 5.61603024 5.23753131 4.65724229\n",
      " 5.41922945 6.16702601 4.46945681 6.17387586 6.42156295 5.95490252\n",
      " 5.0169913  5.90134973 4.80493545 6.72483181 6.91188038 5.29629868\n",
      " 3.31928719 6.4713729  5.84098317 5.98297554 3.55065016 4.44139556\n",
      " 5.22901718 6.07444205 6.18076429 5.39041467 5.59327646 6.41266317\n",
      " 5.38359362 4.85355196 5.46868215 6.71822354 5.5805044  5.61883458\n",
      " 6.15643107 5.94834953 6.29847146 5.37130458 3.99823304 5.09653382\n",
      " 5.34977106 3.62649609 5.65139263 5.8931217  5.13314433 6.10112701\n",
      " 5.08932884 5.43498522 5.90341051 6.30794377 4.76909766 5.77631174\n",
      " 6.89535964 4.05403989 5.04813266 5.62648664 6.04322858 5.0661508\n",
      " 2.55555969 5.2480376  6.17008156 4.45755233 5.4019066  5.3261207\n",
      " 5.00887792 6.40169254 5.84002536 5.37399562 5.46661513 6.05864344\n",
      " 5.28920535 5.81347587 6.73070048 6.32607522 5.6283594  5.75014119\n",
      " 5.8548963  4.71200157 5.88624133 4.08350886 5.89112528 5.4190285\n",
      " 6.46133551 5.36405744 4.8024166  5.24740133 5.12703891 4.95704741\n",
      " 4.91312029 5.19494258]\n",
      "\n",
      "What it should be:  [5.         5.16666667 4.66666667 6.33333333 4.         6.\n",
      " 4.83333333 5.33333333 5.33333333 5.66666667 5.33333333 6.66666667\n",
      " 6.16666667 5.33333333 4.         5.83333333 5.83333333 6.66666667\n",
      " 6.83333333 6.5        5.66666667 6.83333333 4.66666667 6.5\n",
      " 4.33333333 6.83333333 4.83333333 6.         5.66666667 6.\n",
      " 5.83333333 5.         6.         6.16666667 6.5        5.\n",
      " 5.5        6.16666667 5.83333333 6.33333333 4.83333333 6.33333333\n",
      " 4.16666667 6.33333333 5.66666667 6.16666667 5.5        6.16666667\n",
      " 5.5        6.16666667 5.5        5.83333333 4.         6.\n",
      " 5.33333333 6.16666667 6.         5.5        6.         6.16666667\n",
      " 4.         6.83333333 6.5        7.         7.         5.66666667\n",
      " 3.66666667 5.83333333 5.83333333 6.         4.5        5.33333333\n",
      " 6.33333333 3.66666667 4.83333333 6.66666667 6.         5.16666667\n",
      " 4.83333333 5.83333333 6.66666667 5.66666667 5.33333333 5.5\n",
      " 5.66666667 6.66666667 6.5        4.5        4.         6.5\n",
      " 5.5        5.66666667 5.33333333 4.5        5.66666667 6.33333333\n",
      " 5.16666667 6.16666667 6.83333333 5.16666667 5.33333333 7.\n",
      " 6.5        4.66666667 6.83333333 5.83333333 6.5        6.33333333\n",
      " 5.16666667 7.        ]\n",
      "Correlation:  [[1.         0.17578544]\n",
      " [0.17578544 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.64\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.85380942 6.82617685 6.0299687  5.07883924 6.6418992  4.98729046\n",
      " 6.46201466 6.12165733 5.82825031 6.35962451 6.40820217 6.41482028\n",
      " 5.15828342 6.161871   5.34122959 5.5759191  6.18054693 6.195457\n",
      " 5.06267146 6.46543705 5.66129637 4.96080459 5.76480095 4.71184218\n",
      " 6.09888869 5.32620186 5.82507806 5.51296363 5.26626624 4.93820861\n",
      " 6.15004757 5.5467394  5.30235398 5.1808639  6.63572626 5.8519058\n",
      " 6.20125318 6.06853132 6.08912279 4.99737607 5.45078127 6.62088627\n",
      " 7.27496551 5.63091979 5.15993468 5.78698227 4.93836643 5.62910976\n",
      " 6.28123569 5.45281539 4.06643441 6.10934937 5.71799081 4.85450239\n",
      " 5.93647919 6.90408973 4.32640645 5.47092976 6.47921528 5.55692679\n",
      " 5.34532763 6.33600618 5.46745951 8.0334444  5.73064105 4.40555125\n",
      " 5.4493509  4.91124584 5.48793349 6.12720185 5.50457108 4.85124387\n",
      " 5.24316222 5.68632073 5.37904593 5.50295883 6.01644276 5.8331561\n",
      " 5.51813012 5.72244252 6.19680657 6.44354632 5.50500534 5.9433009\n",
      " 6.07742928 5.85656118 6.6894504  5.99325381 5.64121344 4.78268332\n",
      " 5.04708279 6.49871595 4.59439823 6.18725331 5.35984012 5.65455813\n",
      " 6.2134134  5.73180966 5.421596   5.57334071 7.03426631 5.95203554\n",
      " 5.01455675 5.7036493  4.54666693 5.18490405 6.12457619 6.10124944\n",
      " 4.67451061 6.40271421]\n",
      "\n",
      "What it should be:  [6.33333333 5.83333333 5.66666667 5.33333333 3.83333333 5.83333333\n",
      " 5.5        5.83333333 6.83333333 5.33333333 6.5        6.\n",
      " 6.16666667 4.         5.         4.         6.5        5.66666667\n",
      " 6.16666667 5.16666667 5.16666667 5.5        5.5        3.5\n",
      " 3.33333333 6.16666667 4.5        3.66666667 6.16666667 5.33333333\n",
      " 4.66666667 6.5        4.83333333 5.66666667 4.33333333 4.16666667\n",
      " 6.16666667 6.83333333 5.66666667 6.33333333 4.33333333 4.\n",
      " 6.33333333 6.         4.66666667 5.16666667 6.16666667 6.\n",
      " 5.83333333 5.16666667 5.5        6.         6.16666667 6.16666667\n",
      " 5.83333333 6.16666667 5.         4.83333333 5.33333333 5.33333333\n",
      " 5.33333333 6.83333333 6.66666667 7.         6.         4.33333333\n",
      " 6.66666667 6.         5.66666667 6.         5.         6.5\n",
      " 4.83333333 4.5        6.33333333 6.16666667 6.5        5.33333333\n",
      " 6.83333333 1.83333333 6.33333333 6.33333333 5.16666667 5.16666667\n",
      " 5.66666667 6.16666667 6.         6.66666667 5.83333333 6.33333333\n",
      " 6.16666667 6.5        4.5        6.33333333 5.5        5.83333333\n",
      " 6.83333333 5.33333333 4.         6.66666667 4.66666667 5.83333333\n",
      " 5.5        6.         6.         4.5        6.16666667 6.5\n",
      " 6.33333333 5.5       ]\n",
      "Correlation:  [[1.         0.11355157]\n",
      " [0.11355157 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.35\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.91835476 5.54623432 3.96518473 5.68340925 5.3232936  6.78150591\n",
      " 5.66992961 6.54209252 4.88263081 5.81107253 5.75150653 5.55017494\n",
      " 5.70708308 6.72243095 4.89145951 6.23666094 6.57075433 6.75420564\n",
      " 6.21804214 5.50195546 6.4559382  6.00497436 5.29403131 4.60923604\n",
      " 5.37708812 5.32619462 5.7647613  5.55225895 5.91019367 5.98292428\n",
      " 5.44353564 6.0446756  6.60240398 5.86630767 5.20812951 6.07475751\n",
      " 6.17933522 5.61185063 6.07622062 5.06722679 6.66282109 4.48948007\n",
      " 4.54658568 5.95179092 5.4212876  5.51624237 6.12983521 5.64761779\n",
      " 6.37266518 6.340824   5.10838441 5.55109544 5.45077689 5.50039777\n",
      " 5.43520802 5.26430366 5.01224974 5.87082953 5.79240716 6.70867788\n",
      " 5.77731454 5.13392409 5.21986422 6.66300435 6.04282601 5.70969453\n",
      " 5.32791962 5.07578997 5.60538435 5.67580222 6.14002501 5.27936089\n",
      " 5.21330322 5.71239059 6.08024965 5.93463481 5.42337542 5.5928122\n",
      " 5.90627503 7.13283784 5.20424238 4.79402833 5.36761263 5.84283951\n",
      " 5.59584322 5.45268658 6.32223223 5.84032907 5.32006081 6.61023186\n",
      " 4.57109962 5.01384177 6.25228556 4.5664371  7.10175464 5.5415132\n",
      " 4.82422109 6.28632827 5.49570725 5.90848141 5.60329314 4.82386315\n",
      " 5.91762481 5.41877012 5.50088767 4.28284732 6.60311284 5.08638018\n",
      " 6.24129932 6.90956883]\n",
      "\n",
      "What it should be:  [4.         4.83333333 6.83333333 5.33333333 5.         6.\n",
      " 4.66666667 5.66666667 5.5        5.16666667 6.5        3.5\n",
      " 5.         7.         3.83333333 6.5        4.33333333 4.5\n",
      " 4.66666667 7.         6.66666667 6.5        4.83333333 5.33333333\n",
      " 5.66666667 5.5        6.         5.83333333 6.66666667 5.66666667\n",
      " 4.66666667 5.16666667 6.16666667 5.5        6.83333333 5.33333333\n",
      " 5.83333333 5.33333333 5.33333333 6.16666667 6.5        5.33333333\n",
      " 4.66666667 5.33333333 4.5        6.16666667 6.16666667 6.5\n",
      " 6.16666667 6.         5.83333333 6.16666667 7.         6.66666667\n",
      " 6.66666667 3.33333333 4.         4.83333333 6.33333333 6.5\n",
      " 5.66666667 5.66666667 6.16666667 5.16666667 6.         4.5\n",
      " 6.33333333 5.83333333 5.83333333 5.5        6.         4.66666667\n",
      " 6.33333333 6.5        3.66666667 6.83333333 5.83333333 4.66666667\n",
      " 5.         3.         5.         6.5        4.         6.16666667\n",
      " 4.33333333 6.16666667 5.         5.33333333 4.83333333 5.66666667\n",
      " 5.66666667 6.33333333 5.33333333 6.66666667 5.66666667 4.5\n",
      " 6.83333333 5.16666667 6.66666667 4.5        4.16666667 5.83333333\n",
      " 7.         6.83333333 3.66666667 4.83333333 5.16666667 6.16666667\n",
      " 6.33333333 5.66666667]\n",
      "Correlation:  [[ 1.         -0.02803886]\n",
      " [-0.02803886  1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.28\n",
      "Median absolute error = 0.82\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.51\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.77892724 6.74009826 5.59691414 6.15305913 5.89732263 5.43240509\n",
      " 5.25452005 5.80494096 5.9172146  4.76806476 5.64204497 5.06449268\n",
      " 6.02569052 4.2352851  5.91768478 5.29916683 5.91262188 6.05727632\n",
      " 5.43021486 6.5753852  5.84672586 5.91750118 5.19900412 6.19809958\n",
      " 5.80252091 5.91799385 5.5602782  4.99304648 5.55144989 5.69849379\n",
      " 6.58339108 6.11308575 5.89912069 6.41262639 5.99066518 5.9123124\n",
      " 5.45568081 5.73472089 5.96572767 6.23354611 6.24120217 6.60355401\n",
      " 4.76863646 5.21597041 5.1790639  5.84171503 5.41124877 6.12020791\n",
      " 5.44780257 5.32012602 5.85694554 6.14961498 4.97863084 5.71869695\n",
      " 6.08052957 6.2466748  4.87244928 5.89285915 5.94660575 6.10854342\n",
      " 5.69268713 6.03878866 5.39070567 7.11856744 4.49959805 4.93553541\n",
      " 6.08119831 5.48426152 6.12427298 5.52007754 5.42129439 5.36536622\n",
      " 6.40599623 5.18732279 5.30963587 5.19851502 6.27551439 6.14205201\n",
      " 5.47641145 4.86086642 6.02874431 5.56593378 5.5878909  5.3980791\n",
      " 5.04512532 5.6207967  4.81516362 5.82814854 5.9504766  6.76058298\n",
      " 6.61813481 5.96590373 5.72989801 5.40355755 6.81244025 5.46522383\n",
      " 5.65186002 4.5766384  3.52894334 5.35319796 6.19958856 6.17533695\n",
      " 6.61657132 5.81532344 5.96788472 6.5223837  6.05906773 5.1921382\n",
      " 5.7159971  5.38714395]\n",
      "\n",
      "What it should be:  [6.5        5.33333333 5.33333333 6.16666667 6.16666667 5.5\n",
      " 5.16666667 6.83333333 4.83333333 3.66666667 6.16666667 4.33333333\n",
      " 5.33333333 6.33333333 6.5        4.         6.5        6.33333333\n",
      " 6.16666667 5.66666667 6.33333333 5.83333333 4.5        6.\n",
      " 5.83333333 5.33333333 6.5        6.5        5.33333333 5.\n",
      " 5.83333333 6.33333333 6.16666667 6.66666667 4.66666667 5.5\n",
      " 6.66666667 5.83333333 4.66666667 3.33333333 4.5        5.16666667\n",
      " 6.16666667 6.         4.         6.16666667 4.5        5.83333333\n",
      " 4.         3.66666667 4.33333333 5.33333333 4.83333333 5.5\n",
      " 5.83333333 7.         5.66666667 3.5        6.16666667 5.5\n",
      " 6.         5.66666667 4.33333333 5.83333333 4.83333333 4.\n",
      " 4.         7.         6.5        5.5        5.83333333 5.\n",
      " 6.         1.83333333 6.33333333 5.         5.66666667 6.83333333\n",
      " 6.66666667 5.33333333 6.5        6.         4.83333333 5.66666667\n",
      " 6.33333333 5.66666667 3.66666667 5.33333333 5.83333333 6.16666667\n",
      " 6.16666667 5.83333333 5.         6.         5.         6.83333333\n",
      " 6.83333333 4.5        5.5        6.16666667 6.         6.16666667\n",
      " 7.         5.33333333 5.66666667 7.         4.83333333 6.\n",
      " 6.5        5.5       ]\n",
      "Correlation:  [[1.         0.23008676]\n",
      " [0.23008676 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.09\n",
      "R2 score = -0.12\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.58700269 6.58050894 6.13037757 5.86183149 6.69062614 6.33354571\n",
      " 3.97144514 5.02047198 5.90268303 6.07502566 4.35135525 6.08119577\n",
      " 6.27937184 6.14457668 5.64776969 5.34082596 6.71171863 6.11788091\n",
      " 4.68518751 6.40330331 6.44703013 5.92911536 5.54657955 5.28200323\n",
      " 6.23178827 5.48145485 5.79807769 5.79851269 5.44058991 7.19082033\n",
      " 7.02429496 5.61041448 5.29832724 5.60254536 6.08667258 4.68636495\n",
      " 6.04045293 5.70419538 6.33766358 4.1075701  5.07414351 6.21449257\n",
      " 6.46313712 5.33069093 5.87007642 6.36202723 4.78952223 5.18598004\n",
      " 6.48540009 5.58833748 4.96552986 6.23791091 5.37876134 5.63565307\n",
      " 5.68748588 5.74584264 6.47241764 5.86794532 4.27266984 4.80853846\n",
      " 5.76801573 6.7954821  6.91682087 6.36940636 5.73442345 5.93589293\n",
      " 6.22545144 5.39936744 6.05474354 6.19319202 6.36259727 5.40609461\n",
      " 5.15881393 6.68126178 5.84127842 5.35831815 5.80420164 6.93458283\n",
      " 5.92250652 6.28590924 5.38875697 5.46180195 4.58881096 5.41640092\n",
      " 5.74719075 5.15829942 6.0627776  6.39348736 5.27996932 6.09363903\n",
      " 5.07613679 5.64852936 6.69924557 5.55177096 5.15455659 5.9379284\n",
      " 4.9037237  6.17873385 6.57622455 5.77638097 6.04534862 6.27509963\n",
      " 6.96674707 5.73910742 6.07239636 6.06234083 6.69239978 6.08129786\n",
      " 5.01259318 4.84440796]\n",
      "\n",
      "What it should be:  [5.33333333 6.         6.16666667 4.33333333 4.66666667 6.83333333\n",
      " 6.33333333 5.83333333 4.83333333 4.         6.33333333 4.5\n",
      " 6.         7.         5.83333333 4.5        5.33333333 4.66666667\n",
      " 6.16666667 6.33333333 7.         5.33333333 6.5        6.16666667\n",
      " 5.16666667 5.66666667 5.5        3.5        6.83333333 6.5\n",
      " 6.33333333 4.         5.33333333 6.16666667 3.66666667 5.5\n",
      " 5.66666667 5.5        5.83333333 4.33333333 6.5        4.\n",
      " 5.16666667 5.33333333 6.         5.33333333 4.83333333 4.66666667\n",
      " 4.66666667 5.33333333 6.66666667 5.83333333 6.16666667 6.66666667\n",
      " 6.16666667 5.         4.66666667 5.83333333 6.16666667 6.5\n",
      " 6.66666667 5.16666667 5.         6.16666667 6.5        5.66666667\n",
      " 5.16666667 3.33333333 5.16666667 5.5        4.66666667 6.66666667\n",
      " 5.33333333 4.33333333 6.         6.         4.16666667 5.83333333\n",
      " 5.66666667 5.66666667 6.83333333 5.         3.83333333 6.5\n",
      " 5.5        5.83333333 6.         6.83333333 6.5        6.16666667\n",
      " 6.         3.66666667 3.         4.83333333 7.         6.16666667\n",
      " 6.83333333 6.33333333 6.5        6.5        6.16666667 6.\n",
      " 6.83333333 6.66666667 5.16666667 6.83333333 6.16666667 5.83333333\n",
      " 5.5        7.        ]\n",
      "Correlation:  [[ 1.         -0.07282691]\n",
      " [-0.07282691  1.        ]]\n",
      "Mean absolute error = 0.94\n",
      "Mean squared error = 1.4\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.62\n",
      "R2 score = -0.65\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.61873941 5.40897235 5.06615709 5.46200166 5.36077776 5.46698038\n",
      " 4.07859948 5.18386458 6.68806825 5.85818    6.31590248 5.66063884\n",
      " 4.75464005 5.68390349 6.19047799 5.4475367  6.56691198 5.64846071\n",
      " 6.06150928 6.15416474 6.33112963 6.2347208  5.09100008 5.35613432\n",
      " 5.840692   5.37778654 5.92508746 5.56178983 5.14124586 5.95131167\n",
      " 6.48752576 6.60678361 5.05924874 5.67040504 5.57959293 6.36294527\n",
      " 4.71736625 5.13210404 5.7177688  6.56143816 5.32012333 6.39294111\n",
      " 5.91391421 4.74806009 5.54237638 6.04235864 6.02908245 5.89149417\n",
      " 5.2509266  6.54212826 6.08637507 5.4880483  5.73862547 4.60931277\n",
      " 4.87400348 4.37009089 3.88116984 5.30808974 5.41943978 5.91924364\n",
      " 6.32222987 5.2871088  6.28946259 6.81667281 6.00880871 4.47663529\n",
      " 4.64666101 5.14471926 4.92998507 5.71018654 4.92357506 5.43723818\n",
      " 7.19841756 5.26518716 6.04348455 6.1128305  4.99275518 5.65156372\n",
      " 7.23547352 5.22982071 6.12267169 5.19374309 6.85835355 5.16043816\n",
      " 5.06663637 6.99088754 5.82764124 6.47304436 5.03075689 6.75371427\n",
      " 5.52248097 5.72534053 6.58355951 5.00862224 4.9664503  5.28185694\n",
      " 6.37613516 5.92574166 5.55280744 5.95683925 6.56409436 5.78758629\n",
      " 5.95199109 5.28584193 5.94714395 4.74275568 6.78453611 6.56066386\n",
      " 5.58420932 5.55383209]\n",
      "\n",
      "What it should be:  [7.         5.5        3.66666667 4.83333333 4.66666667 5.\n",
      " 5.5        6.83333333 4.5        5.33333333 5.83333333 6.83333333\n",
      " 6.5        6.33333333 6.16666667 6.16666667 4.33333333 4.16666667\n",
      " 6.5        6.5        6.33333333 5.16666667 5.33333333 4.66666667\n",
      " 6.16666667 4.         6.66666667 3.66666667 6.33333333 5.66666667\n",
      " 4.83333333 6.16666667 4.         5.83333333 6.         6.66666667\n",
      " 6.16666667 5.5        5.33333333 5.83333333 6.         4.83333333\n",
      " 6.5        4.83333333 5.         5.33333333 5.33333333 4.5\n",
      " 5.33333333 5.16666667 5.16666667 5.66666667 6.16666667 4.5\n",
      " 4.33333333 4.         6.83333333 4.33333333 6.33333333 4.66666667\n",
      " 3.         6.83333333 6.         5.16666667 5.66666667 4.83333333\n",
      " 6.33333333 4.5        5.16666667 6.5        5.66666667 6.\n",
      " 6.33333333 5.83333333 5.66666667 5.5        6.16666667 6.\n",
      " 6.33333333 5.83333333 4.66666667 6.33333333 4.66666667 6.5\n",
      " 5.16666667 6.66666667 5.5        4.         6.5        5.16666667\n",
      " 5.5        4.5        6.66666667 7.         5.         6.83333333\n",
      " 6.66666667 6.16666667 6.5        5.66666667 6.16666667 5.83333333\n",
      " 6.33333333 4.66666667 5.33333333 7.         6.16666667 7.\n",
      " 5.66666667 6.66666667]\n",
      "Correlation:  [[1.        0.0652697]\n",
      " [0.0652697 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.47\n",
      "R2 score = -0.48\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.98331604 4.24504745 5.38367365 5.91348464 5.18235274 5.17524678\n",
      " 5.2418193  5.95161102 5.83950655 6.12768132 6.6376708  5.79417196\n",
      " 5.38160699 5.3802386  5.69434717 5.63847234 6.84223508 6.50440699\n",
      " 5.48775845 5.39084233 6.13591667 4.64525067 6.16153481 5.09101326\n",
      " 5.41225092 5.72614906 5.02538187 5.22115359 6.96467793 4.52505243\n",
      " 6.114541   5.20505631 5.27884934 5.58855708 5.7329131  6.39353253\n",
      " 4.96029506 5.0479933  5.96959945 5.55603147 6.28146348 4.34798115\n",
      " 5.26864963 6.42766541 5.2477112  4.86026023 5.92228579 5.74290468\n",
      " 5.40742562 5.76420933 5.91492548 5.92823337 4.61893173 5.81142727\n",
      " 5.16414522 5.08958462 5.63511219 6.26047998 5.23045868 5.79811825\n",
      " 5.62755365 5.47043851 5.36607237 6.93796762 5.91045493 5.49367097\n",
      " 4.65883134 4.58101016 5.25778231 5.32550271 5.64003321 6.4881073\n",
      " 4.61705938 6.43244729 5.82088354 4.95152153 6.25280655 5.32399122\n",
      " 5.34372613 5.5442114  5.51214699 5.27093276 6.14564692 5.87459233\n",
      " 4.57379026 5.39539893 6.40497815 4.50827858 5.25099199 6.28503498\n",
      " 5.09545217 6.0184525  5.70351236 5.55467665 5.3476125  6.42716819\n",
      " 5.55414978 5.20604661 5.11496013 5.87954178 5.54659217 6.10882338\n",
      " 5.78439139 5.8273769  6.58507225 5.78343597 6.74495668 5.85701411\n",
      " 6.45173915 4.66733796]\n",
      "\n",
      "What it should be:  [6.         6.16666667 4.66666667 6.33333333 6.         5.\n",
      " 4.83333333 6.83333333 6.83333333 5.83333333 5.66666667 6.5\n",
      " 6.33333333 6.33333333 5.83333333 5.16666667 4.83333333 6.16666667\n",
      " 5.16666667 1.83333333 5.33333333 6.16666667 6.66666667 4.33333333\n",
      " 4.         5.33333333 5.5        6.66666667 6.66666667 6.\n",
      " 4.66666667 5.83333333 5.83333333 6.16666667 6.         5.33333333\n",
      " 4.         6.83333333 6.33333333 5.33333333 5.33333333 7.\n",
      " 6.5        5.16666667 5.         6.33333333 6.83333333 4.83333333\n",
      " 5.66666667 5.         6.33333333 5.66666667 4.33333333 6.16666667\n",
      " 6.33333333 7.         3.66666667 5.5        4.83333333 4.33333333\n",
      " 6.16666667 5.33333333 4.5        6.5        5.83333333 6.\n",
      " 4.5        4.5        6.         3.5        6.16666667 5.66666667\n",
      " 5.5        7.         5.33333333 4.         6.33333333 5.66666667\n",
      " 6.5        6.         6.83333333 5.         6.33333333 3.66666667\n",
      " 5.5        5.66666667 5.16666667 4.66666667 6.16666667 4.66666667\n",
      " 4.83333333 7.         6.66666667 5.33333333 6.66666667 6.5\n",
      " 6.         5.33333333 4.83333333 4.66666667 6.5        6.\n",
      " 5.83333333 6.         6.         5.66666667 6.16666667 5.66666667\n",
      " 6.83333333 6.5       ]\n",
      "Correlation:  [[1.         0.17558611]\n",
      " [0.17558611 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.41361073 7.12016069 5.17738909 6.42486089 5.08653976 5.56688116\n",
      " 5.28576828 5.19346797 4.8496918  5.94492445 5.77550077 5.67253417\n",
      " 5.58808575 5.51088656 6.76064381 5.52597803 5.52145292 5.55519385\n",
      " 6.22405539 5.89295246 6.03888127 5.72721956 5.31817828 5.32721441\n",
      " 6.03505877 4.94577342 6.26797021 5.70598465 5.55914725 4.76856248\n",
      " 5.2522051  5.62736868 6.29468862 5.73991093 4.89336354 5.97925952\n",
      " 5.50037497 5.72421976 5.75346389 6.00979888 6.56136534 5.6064277\n",
      " 5.68799079 5.88675636 5.52736091 5.84452035 5.05071019 5.02246372\n",
      " 6.51756034 6.2407644  6.00794874 6.43360464 5.51995551 5.82884586\n",
      " 5.6958706  5.32354399 4.53347526 5.6947287  5.5514467  6.31238714\n",
      " 6.34721037 5.83334835 5.46171777 6.37666388 6.4200534  5.7128363\n",
      " 5.2839801  6.04804444 5.38875028 4.73871974 4.1784796  5.67017546\n",
      " 5.57076095 5.79246996 5.34645626 5.15442142 6.10016949 6.08633068\n",
      " 4.48342873 5.41472211 5.91165381 6.43735205 5.82727933 6.03723413\n",
      " 5.17288364 5.39726418 6.26897476 5.20686741 5.74202487 4.98052114\n",
      " 6.31861724 4.89974541 5.09756727 5.88187025 5.33203854 5.98671045\n",
      " 4.93390551 5.32988474 5.8029412  5.184148   4.34081733 5.36448731\n",
      " 4.85788718 5.20321401 6.98744871 5.08560079 5.47860135 5.53869805\n",
      " 5.00373837 5.02995303]\n",
      "\n",
      "What it should be:  [6.         6.16666667 6.16666667 6.83333333 4.83333333 5.5\n",
      " 5.66666667 3.66666667 6.5        5.66666667 5.83333333 6.16666667\n",
      " 6.5        5.33333333 7.         6.5        4.83333333 5.83333333\n",
      " 4.33333333 5.33333333 6.         6.66666667 4.         5.66666667\n",
      " 6.16666667 4.66666667 5.83333333 3.83333333 6.66666667 3.5\n",
      " 6.         6.         5.16666667 6.16666667 4.5        6.\n",
      " 4.5        5.16666667 5.         5.33333333 6.5        5.66666667\n",
      " 5.16666667 5.66666667 6.16666667 5.16666667 5.         3.66666667\n",
      " 5.33333333 4.66666667 6.         6.33333333 6.5        5.33333333\n",
      " 6.33333333 6.33333333 7.         5.16666667 4.5        4.66666667\n",
      " 6.5        4.83333333 4.83333333 6.83333333 6.5        6.66666667\n",
      " 3.66666667 7.         6.         4.33333333 6.83333333 6.33333333\n",
      " 4.33333333 7.         6.16666667 5.33333333 6.66666667 4.\n",
      " 4.66666667 1.83333333 5.66666667 5.83333333 6.16666667 6.\n",
      " 5.33333333 4.66666667 6.16666667 5.83333333 5.5        6.33333333\n",
      " 6.5        4.83333333 5.5        5.33333333 6.16666667 5.66666667\n",
      " 4.5        5.33333333 6.33333333 6.83333333 5.5        6.16666667\n",
      " 4.         3.         6.33333333 5.5        6.         3.33333333\n",
      " 5.83333333 6.33333333]\n",
      "Correlation:  [[1.         0.27875876]\n",
      " [0.27875876 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.97\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.0\n",
      "R2 score = -0.01\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.15272588 5.04071717 5.77741255 5.47626798 5.43972449 5.46993362\n",
      " 5.44615308 5.38263348 4.54412324 5.46967128 5.52083043 5.45050775\n",
      " 4.80776508 6.18818646 5.1671593  4.9370491  5.97092433 4.98635834\n",
      " 6.30158093 5.08471132 5.53148015 6.11937256 5.7084916  5.44143803\n",
      " 4.46326483 5.54256131 5.21477665 4.61321032 5.43409722 5.31179762\n",
      " 5.04145001 6.39008199 5.0329711  5.41771041 5.92050067 5.33320893\n",
      " 6.20525901 5.7532673  4.53239846 6.3434403  5.72047966 5.73935111\n",
      " 6.43567136 5.7787152  6.10533758 5.24480056 5.50687228 5.33466933\n",
      " 6.40110548 5.48080598 5.3789809  5.94823765 5.00755584 5.52734164\n",
      " 4.91707128 5.34396626 4.54061299 5.18166995 6.30294524 4.28212669\n",
      " 6.5198023  5.91123731 5.25512197 6.74557269 5.35865925 5.42933218\n",
      " 6.38150813 4.94552982 6.13494072 4.97378586 6.07872725 5.70242557\n",
      " 5.14829245 5.04831556 3.97562061 4.91156843 5.05003933 4.96812261\n",
      " 5.09401771 5.00567598 6.08429174 4.44804406 6.56570551 5.56354931\n",
      " 6.23673576 5.42379929 5.61524874 5.88924016 4.71242106 5.22855488\n",
      " 5.485348   5.92491235 6.49427206 5.77210828 4.91874665 4.2580827\n",
      " 4.99109374 5.30479376 5.99377384 5.21554247 5.78245986 6.20566426\n",
      " 5.43817261 4.75223271 4.59810418 5.08950493 4.82260713 5.72015692\n",
      " 5.22631133 5.6236816 ]\n",
      "\n",
      "What it should be:  [5.66666667 4.83333333 5.16666667 1.83333333 4.5        6.83333333\n",
      " 6.83333333 5.5        7.         5.33333333 6.         6.16666667\n",
      " 5.83333333 6.         6.5        6.66666667 6.         6.83333333\n",
      " 5.33333333 4.33333333 7.         6.33333333 7.         6.16666667\n",
      " 6.33333333 6.33333333 6.66666667 5.5        5.         6.16666667\n",
      " 6.         6.33333333 6.5        5.5        6.         4.33333333\n",
      " 6.5        5.66666667 5.83333333 5.83333333 5.66666667 6.83333333\n",
      " 6.66666667 5.83333333 5.83333333 6.33333333 6.66666667 5.33333333\n",
      " 3.66666667 7.         5.33333333 6.33333333 6.16666667 5.83333333\n",
      " 6.16666667 4.83333333 5.5        4.5        6.83333333 6.16666667\n",
      " 5.33333333 6.16666667 5.5        6.16666667 4.         5.33333333\n",
      " 4.66666667 5.         7.         6.         6.83333333 5.33333333\n",
      " 5.33333333 5.83333333 4.         5.5        6.5        6.66666667\n",
      " 6.         6.5        5.16666667 4.5        6.83333333 5.66666667\n",
      " 4.83333333 6.16666667 6.16666667 3.33333333 6.5        6.16666667\n",
      " 5.66666667 5.16666667 6.5        6.5        5.         6.\n",
      " 5.33333333 6.33333333 5.83333333 5.83333333 5.33333333 5.33333333\n",
      " 4.5        4.33333333 6.         4.83333333 6.33333333 6.83333333\n",
      " 6.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.06570313]\n",
      " [0.06570313 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.50282747 4.83413645 6.06923107 7.35424494 6.60025449 6.4448881\n",
      " 4.56538927 5.51394294 6.4098465  5.95788219 5.5922678  6.98381886\n",
      " 4.83371469 4.84370831 5.88250678 5.79098622 4.55518779 5.23616138\n",
      " 5.78642667 5.20083135 5.54227033 6.12231442 6.37837787 5.32143469\n",
      " 5.82677386 5.34927313 5.90126677 5.16797683 5.57355357 5.55793238\n",
      " 7.23197664 5.83710243 6.30734498 4.77488565 5.24446674 5.45090446\n",
      " 6.62687088 6.01175638 6.36687346 7.74464496 5.71922361 5.2452232\n",
      " 4.79009677 5.95122101 6.05264172 6.90915146 5.33101781 6.04612459\n",
      " 5.92443468 5.94601292 5.22935226 6.07700885 5.42669712 5.74244323\n",
      " 6.5601378  5.81356724 5.90235281 5.77346276 5.94148891 4.93759015\n",
      " 5.78953464 5.76943632 6.15633755 5.58047432 5.41457773 6.07986099\n",
      " 4.7372927  5.03803795 5.97928522 6.12757142 4.92476574 4.93361066\n",
      " 4.99583185 4.87507881 4.79209343 5.3512339  5.53821331 6.17228616\n",
      " 6.22737945 5.43493671 5.56954757 5.91556059 5.44177454 5.40177486\n",
      " 6.35825968 6.63695652 5.53850023 7.74049691 6.66692232 4.56196115\n",
      " 5.45832223 6.19463668 3.21960894 5.30650992 6.34637363 6.30814108\n",
      " 6.05264843 5.09894035 6.89549004 6.42680029 6.31391497 5.82959745\n",
      " 5.80957558 7.29505755 5.02381362 4.67546245 5.9566826  5.89317657\n",
      " 5.02565424 4.35490417]\n",
      "\n",
      "What it should be:  [6.         6.33333333 4.66666667 6.5        6.16666667 5.83333333\n",
      " 5.16666667 4.         6.33333333 5.83333333 6.5        5.33333333\n",
      " 3.83333333 4.33333333 5.66666667 5.         4.83333333 5.83333333\n",
      " 6.66666667 6.83333333 5.83333333 5.66666667 5.33333333 3.66666667\n",
      " 6.33333333 4.66666667 5.         7.         5.83333333 5.66666667\n",
      " 6.5        5.16666667 5.83333333 6.16666667 6.5        4.33333333\n",
      " 5.83333333 4.         6.         6.5        4.66666667 4.66666667\n",
      " 6.33333333 6.         6.66666667 5.66666667 3.33333333 6.66666667\n",
      " 5.33333333 5.33333333 5.16666667 5.33333333 6.16666667 6.66666667\n",
      " 6.83333333 6.83333333 6.         7.         4.83333333 7.\n",
      " 6.33333333 4.5        5.16666667 5.5        5.         5.33333333\n",
      " 4.83333333 5.83333333 6.         6.16666667 3.66666667 5.33333333\n",
      " 6.83333333 6.         4.         4.5        4.83333333 6.16666667\n",
      " 5.         6.5        6.         6.16666667 6.66666667 6.16666667\n",
      " 4.         6.16666667 5.5        6.16666667 7.         6.33333333\n",
      " 6.16666667 6.33333333 5.5        5.16666667 7.         7.\n",
      " 6.5        4.66666667 5.16666667 5.33333333 6.5        5.33333333\n",
      " 6.83333333 6.16666667 4.83333333 3.66666667 6.5        5.33333333\n",
      " 6.         5.66666667]\n",
      "Correlation:  [[1.         0.27196955]\n",
      " [0.27196955 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.24\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.29308991 5.84188673 6.7217526  5.75538338 5.73849186 5.81549544\n",
      " 6.17079502 6.05055751 6.12995339 4.47953068 5.02962741 5.35352712\n",
      " 6.26176615 6.06434538 5.95520287 4.44067421 6.04348432 5.62234924\n",
      " 4.94846312 5.53479833 5.80753516 6.45373485 6.0688893  5.79966387\n",
      " 6.18071625 4.41997498 4.99341133 6.94439114 6.1858444  5.94491631\n",
      " 6.31825992 6.64682791 5.23000559 5.58256982 4.44493925 6.27394101\n",
      " 6.72979489 4.94364907 5.67606747 5.29057479 6.45935778 5.15430513\n",
      " 5.3517463  5.96888598 4.23551016 4.82041606 4.43257619 5.76987437\n",
      " 6.39571452 5.53208387 6.20993742 7.41281434 5.54899907 6.21691021\n",
      " 5.65584551 5.09922594 6.06031112 5.27901236 4.49134964 5.70883354\n",
      " 4.64491099 3.86786201 6.9537083  5.2046189  6.48147946 4.80524914\n",
      " 6.91074907 5.5455301  5.5311791  5.2356502  6.3409389  4.89144866\n",
      " 4.18900744 5.0366242  2.93549324 5.46424363 7.28250359 5.94542955\n",
      " 6.10722467 7.13902246 5.65887248 5.75839989 6.19515499 5.85659372\n",
      " 6.21372211 6.37150276 6.15977074 3.3733898  6.89180834 4.91618873\n",
      " 5.44839623 5.63485896 6.03613314 5.69486673 6.92243223 5.52602825\n",
      " 5.52450132 4.34243085 5.3958513  4.17282144 5.63170544 4.75240081\n",
      " 6.32227762 6.04518808 6.42739556 6.59713765 5.87564977 4.99378177\n",
      " 5.79616365 5.41240539]\n",
      "\n",
      "What it should be:  [6.5        6.16666667 5.83333333 5.83333333 4.83333333 5.33333333\n",
      " 6.5        5.33333333 6.         4.5        4.66666667 6.66666667\n",
      " 6.66666667 5.66666667 6.33333333 7.         6.         5.33333333\n",
      " 5.33333333 6.16666667 5.33333333 6.33333333 4.66666667 5.83333333\n",
      " 5.66666667 6.33333333 6.         4.66666667 5.16666667 5.83333333\n",
      " 6.83333333 6.         5.83333333 5.33333333 5.33333333 5.5\n",
      " 5.66666667 4.83333333 7.         4.         5.66666667 3.66666667\n",
      " 4.5        4.5        6.         6.16666667 4.66666667 5.83333333\n",
      " 6.33333333 4.5        6.83333333 6.33333333 6.16666667 6.16666667\n",
      " 5.5        4.33333333 3.5        6.16666667 5.66666667 6.16666667\n",
      " 5.5        4.5        6.5        5.83333333 6.         4.\n",
      " 6.5        6.         5.83333333 7.         5.33333333 4.\n",
      " 6.83333333 6.16666667 5.5        4.33333333 5.66666667 5.66666667\n",
      " 5.5        6.66666667 5.66666667 3.66666667 5.16666667 5.33333333\n",
      " 6.         6.66666667 6.         5.16666667 6.16666667 6.33333333\n",
      " 5.         5.         4.83333333 6.66666667 6.16666667 6.33333333\n",
      " 6.33333333 6.16666667 6.16666667 4.83333333 6.16666667 4.83333333\n",
      " 6.5        5.33333333 6.83333333 5.16666667 4.16666667 5.5\n",
      " 6.66666667 5.66666667]\n",
      "Correlation:  [[1.       0.232481]\n",
      " [0.232481 1.      ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.01\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.53\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.46500827 5.72525071 5.17662562 5.07786727 5.18898953 6.02618748\n",
      " 5.55948883 6.60832529 6.0419151  5.22013085 6.57576355 6.18302227\n",
      " 5.81850683 4.37093318 5.94948557 5.6391528  6.32944471 5.05227008\n",
      " 5.18112702 6.26677838 5.41981716 6.48797183 5.13001816 6.62650781\n",
      " 5.48747039 5.81758868 5.68780417 5.43098756 5.24913954 5.31640456\n",
      " 5.53883197 5.92351839 5.71394357 5.9622807  6.12594552 5.62744922\n",
      " 5.27331321 5.21664803 5.42963531 4.65994045 5.33892942 5.45827082\n",
      " 5.08928147 5.82781284 6.5656693  4.95399717 5.18188167 5.88274278\n",
      " 5.26116258 5.92948844 5.17354681 5.32373981 5.49429652 3.93057599\n",
      " 5.42554458 5.22360486 5.76017207 5.17752643 6.09277719 4.33049399\n",
      " 5.41944433 6.07649636 5.86851108 4.96374275 5.87093519 4.6314691\n",
      " 5.6051682  4.64961375 5.33920417 4.66128201 5.5191842  5.84742295\n",
      " 5.66226364 6.1143297  5.41877143 5.50335821 5.52543039 5.47695834\n",
      " 6.90730334 6.48104199 6.20526016 5.78929552 5.46605242 6.29669743\n",
      " 5.47324473 6.48405449 4.7330853  4.97712267 5.35286028 5.87536868\n",
      " 5.67881084 4.78106186 6.006788   4.77770969 5.75927015 5.5255042\n",
      " 4.84584843 4.82565783 5.25059769 6.10684894 5.82387541 5.0584315\n",
      " 6.03334375 4.78707917 6.28118128 5.34834424 6.67960204 6.0151783\n",
      " 5.25180912 5.37131186]\n",
      "\n",
      "What it should be:  [5.66666667 5.33333333 6.33333333 5.5        6.5        6.16666667\n",
      " 6.83333333 3.66666667 4.66666667 5.5        6.33333333 6.16666667\n",
      " 6.16666667 6.33333333 1.83333333 4.83333333 6.5        6.16666667\n",
      " 5.66666667 3.         5.33333333 4.66666667 5.83333333 5.33333333\n",
      " 6.66666667 6.33333333 6.16666667 4.66666667 6.16666667 6.83333333\n",
      " 5.33333333 7.         4.83333333 6.83333333 6.33333333 6.83333333\n",
      " 3.66666667 5.         6.16666667 4.5        6.5        4.5\n",
      " 5.16666667 6.5        4.83333333 5.16666667 5.66666667 6.5\n",
      " 5.         5.83333333 6.33333333 6.5        5.83333333 4.66666667\n",
      " 6.83333333 5.33333333 6.         5.33333333 6.5        5.33333333\n",
      " 7.         4.83333333 6.5        5.83333333 5.16666667 5.5\n",
      " 6.5        5.5        6.66666667 4.66666667 5.33333333 5.16666667\n",
      " 5.66666667 6.5        6.16666667 4.33333333 6.16666667 5.5\n",
      " 5.83333333 5.83333333 5.5        6.66666667 4.83333333 6.33333333\n",
      " 6.16666667 6.         6.         4.5        6.         6.16666667\n",
      " 6.16666667 6.66666667 3.83333333 5.5        5.16666667 5.66666667\n",
      " 6.16666667 3.66666667 5.         7.         4.33333333 6.5\n",
      " 5.5        6.         4.83333333 6.16666667 5.16666667 6.66666667\n",
      " 6.66666667 5.33333333]\n",
      "Correlation:  [[ 1.         -0.00798341]\n",
      " [-0.00798341  1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.15\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.38\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.01874256 6.02126257 5.02448734 6.44149425 6.14484898 5.38297283\n",
      " 6.67687351 6.67583451 5.65042872 5.71386075 6.09171339 6.1360387\n",
      " 5.11560697 5.68305096 6.04531336 6.01777687 4.67952351 5.56166511\n",
      " 5.60316538 5.05143867 5.72368108 5.42196554 5.64516248 5.3849598\n",
      " 5.92595453 6.11139032 5.22771457 5.37615708 5.00313202 4.9770642\n",
      " 4.93458758 4.32690399 5.98507281 6.20079089 6.17586395 5.03218396\n",
      " 4.50395789 5.99183436 5.01820187 6.32036487 5.45057086 5.92833657\n",
      " 6.26977392 5.22944809 4.40729737 5.64444071 5.83575621 5.70381899\n",
      " 5.99692694 4.60305789 5.23095495 6.08421329 5.39101409 5.4719449\n",
      " 5.20352721 5.54543306 6.47275606 4.88196608 5.33431979 5.90820092\n",
      " 3.34180599 6.29762501 4.96233619 6.27079979 4.44314251 5.14466775\n",
      " 4.98478865 6.70056674 5.71282452 4.79536594 5.24738399 6.34200273\n",
      " 5.99196563 6.06239032 6.53210448 6.61587682 5.64971501 6.42504955\n",
      " 5.10441064 6.19824239 4.69407075 5.52249653 6.20284118 5.47266071\n",
      " 5.8522608  5.22535648 5.95432656 5.89738884 6.17989386 6.67944777\n",
      " 5.5570291  5.65668603 5.06776041 5.79014484 4.79158474 4.77296956\n",
      " 4.81226606 6.51966147 5.07501024 5.8826886  6.15826142 5.08662897\n",
      " 5.9052233  5.45436965 5.91817825 5.41095385 4.94214039 5.234372\n",
      " 6.58286957 5.64430551]\n",
      "\n",
      "What it should be:  [4.83333333 5.5        6.83333333 5.16666667 5.33333333 4.83333333\n",
      " 6.5        4.83333333 6.16666667 6.66666667 6.66666667 5.83333333\n",
      " 4.         4.33333333 5.66666667 6.16666667 6.33333333 5.16666667\n",
      " 7.         5.83333333 5.83333333 5.66666667 6.5        6.5\n",
      " 4.16666667 6.16666667 7.         3.5        6.33333333 3.83333333\n",
      " 5.         4.66666667 4.83333333 6.16666667 6.16666667 3.66666667\n",
      " 4.33333333 6.         6.5        5.5        6.16666667 6.\n",
      " 5.66666667 5.33333333 6.         6.33333333 5.33333333 4.66666667\n",
      " 5.16666667 4.83333333 5.83333333 6.83333333 6.         5.\n",
      " 5.33333333 6.16666667 5.83333333 5.         6.66666667 6.16666667\n",
      " 5.5        5.66666667 6.5        6.83333333 6.16666667 6.33333333\n",
      " 6.33333333 6.66666667 4.5        6.5        5.33333333 6.83333333\n",
      " 6.         6.16666667 4.5        5.66666667 4.66666667 6.\n",
      " 6.         5.33333333 6.83333333 5.83333333 6.33333333 5.\n",
      " 4.83333333 5.5        5.16666667 6.66666667 6.16666667 6.16666667\n",
      " 6.66666667 4.5        4.5        6.5        6.         5.5\n",
      " 5.5        6.33333333 5.5        6.83333333 5.33333333 7.\n",
      " 4.66666667 5.83333333 5.33333333 6.5        3.33333333 6.\n",
      " 4.66666667 5.16666667]\n",
      "Correlation:  [[1.         0.13781524]\n",
      " [0.13781524 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.41\n",
      "R2 score = -0.42\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.46695733 6.36451093 6.06135389 4.96235818 6.51152967 5.99505783\n",
      " 5.30806476 5.77965657 5.72852388 5.70719241 4.94966447 4.77149836\n",
      " 5.97297722 5.47533402 5.00010776 5.93679623 6.04532542 5.04861199\n",
      " 4.65665102 6.1349366  5.69313467 6.12556457 6.54193712 6.70540349\n",
      " 5.36716211 6.01768853 5.1184133  5.37685952 6.17753817 6.02187681\n",
      " 5.81362907 7.10560874 5.53866251 5.07279112 6.12504345 6.18103812\n",
      " 6.04830908 5.68216617 5.65410336 5.68753184 6.0272398  4.88507655\n",
      " 5.25215844 4.08022351 5.68832663 5.94063262 5.35347284 6.05387127\n",
      " 6.63040151 5.62945203 6.10175362 6.33368963 6.34178836 6.65889881\n",
      " 6.7844209  5.87150807 6.05851879 6.89579092 4.88216871 6.39418793\n",
      " 4.64194887 5.43927426 5.78083907 6.0286051  6.20938316 5.63859956\n",
      " 5.58082383 5.96441146 5.67376438 5.53395043 5.71664929 4.3460409\n",
      " 6.30394473 5.35601516 6.62732292 5.99191208 5.80762247 6.28391959\n",
      " 5.59593933 5.85151604 6.58757598 5.28517746 6.15704085 8.25861415\n",
      " 5.13672688 4.7119849  5.9182478  6.14365852 6.62369401 5.77456324\n",
      " 4.51062186 4.02290857 5.76252391 5.29517285 6.6022617  5.60503074\n",
      " 6.17019309 6.21795688 6.12604617 5.47353685 5.31719496 7.49041404\n",
      " 5.0513961  5.98275275 4.45504502 5.93028494 5.60819084 4.57853322\n",
      " 5.70582757 5.30264896]\n",
      "\n",
      "What it should be:  [3.         4.         6.16666667 6.5        5.16666667 4.5\n",
      " 6.66666667 6.16666667 6.66666667 4.         6.5        4.\n",
      " 5.33333333 5.83333333 6.33333333 5.5        5.83333333 5.83333333\n",
      " 6.33333333 4.83333333 7.         4.66666667 3.83333333 5.83333333\n",
      " 5.5        6.16666667 6.16666667 5.66666667 6.66666667 5.33333333\n",
      " 6.5        4.66666667 5.83333333 6.16666667 6.16666667 5.33333333\n",
      " 6.33333333 5.66666667 6.33333333 1.83333333 5.66666667 5.66666667\n",
      " 6.         5.16666667 4.16666667 5.16666667 4.83333333 6.83333333\n",
      " 6.         5.33333333 5.5        6.66666667 6.16666667 5.66666667\n",
      " 6.83333333 4.66666667 6.66666667 6.5        5.33333333 7.\n",
      " 6.83333333 3.66666667 5.         5.66666667 4.66666667 5.66666667\n",
      " 6.16666667 6.5        6.16666667 5.33333333 5.16666667 6.5\n",
      " 5.83333333 4.66666667 5.33333333 6.83333333 5.33333333 6.83333333\n",
      " 5.16666667 6.33333333 6.66666667 6.5        6.5        7.\n",
      " 6.         6.16666667 5.83333333 6.16666667 6.33333333 4.83333333\n",
      " 4.83333333 4.33333333 5.5        6.5        5.         5.16666667\n",
      " 5.33333333 3.33333333 5.33333333 6.83333333 6.         6.33333333\n",
      " 4.66666667 6.         5.33333333 5.16666667 5.         5.5\n",
      " 6.5        5.83333333]\n",
      "Correlation:  [[1.         0.10114352]\n",
      " [0.10114352 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.38\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.03797627 6.00704972 6.16562918 4.52763611 6.35682022 6.72040689\n",
      " 5.43528906 5.26010699 6.31166693 5.90143492 5.86624206 6.21158811\n",
      " 5.91935991 5.7906123  5.03488216 5.31518818 5.81943062 5.4039474\n",
      " 5.52287772 4.70576039 5.39374348 5.07167212 6.07233401 4.7440578\n",
      " 6.00228839 5.55612098 5.50509602 5.16182889 6.13250663 4.64823757\n",
      " 5.59030565 5.93858789 5.82671197 5.40481339 4.87348243 5.93989336\n",
      " 6.26021576 6.25778901 5.69052675 5.99010304 5.44167402 5.69540236\n",
      " 5.09418797 6.08949743 6.10780192 5.2770262  5.22299067 5.37987634\n",
      " 5.43695439 5.18002472 5.58086692 5.73447343 5.19755152 5.2341697\n",
      " 5.52673999 6.54960269 5.9509286  6.16594503 5.42215496 5.79569361\n",
      " 5.56078755 5.94021112 5.78165894 5.82956637 5.21985017 5.2761946\n",
      " 4.84309955 5.66413141 5.05111945 5.95100812 5.07088628 5.869148\n",
      " 6.84743251 6.21573786 6.33989837 4.80007386 5.35077082 6.81937134\n",
      " 6.3797257  5.32732016 5.67530827 5.43889831 6.48768712 4.77233559\n",
      " 5.71256055 5.3167116  5.62830707 5.18250551 5.51119468 4.95184636\n",
      " 5.32424247 5.41698148 5.31410402 6.19956498 5.54042242 6.16461114\n",
      " 4.35470127 5.45852183 5.32508027 5.73829559 5.82152393 6.08679351\n",
      " 6.32306465 5.76601659 5.59372348 5.3928328  5.14015073 5.14650742\n",
      " 5.50200194 5.61862036]\n",
      "\n",
      "What it should be:  [5.         6.16666667 4.5        5.5        6.5        4.\n",
      " 4.83333333 5.33333333 6.83333333 3.83333333 5.66666667 6.16666667\n",
      " 5.83333333 6.5        6.5        6.16666667 6.33333333 6.\n",
      " 6.83333333 5.33333333 7.         4.66666667 6.16666667 4.83333333\n",
      " 6.83333333 4.66666667 5.83333333 6.16666667 4.83333333 6.66666667\n",
      " 4.83333333 6.16666667 6.5        3.5        5.33333333 5.16666667\n",
      " 5.66666667 6.5        5.33333333 5.83333333 6.         5.33333333\n",
      " 6.33333333 7.         6.         6.         6.83333333 6.33333333\n",
      " 6.16666667 6.16666667 5.83333333 5.         6.33333333 5.5\n",
      " 6.         4.5        5.66666667 6.66666667 4.83333333 6.33333333\n",
      " 5.33333333 3.66666667 1.83333333 5.33333333 7.         4.33333333\n",
      " 6.33333333 6.33333333 4.33333333 5.83333333 3.66666667 5.16666667\n",
      " 6.5        4.66666667 5.66666667 6.5        5.5        6.16666667\n",
      " 4.66666667 6.66666667 4.         5.83333333 6.         5.83333333\n",
      " 5.33333333 6.83333333 5.16666667 4.         6.         5.5\n",
      " 5.83333333 5.16666667 7.         6.         6.66666667 5.33333333\n",
      " 4.         6.33333333 6.         6.5        6.16666667 5.33333333\n",
      " 6.66666667 6.16666667 7.         3.33333333 4.66666667 5.66666667\n",
      " 6.         6.83333333]\n",
      "Correlation:  [[1.         0.04015297]\n",
      " [0.04015297 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.12\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.23\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.51463396 5.86450547 6.37423109 6.45912849 5.55275748 4.76993198\n",
      " 4.68340704 5.79597286 5.10231977 5.63471846 5.83198651 6.17350313\n",
      " 5.48747397 6.30577717 6.25990789 6.6984883  5.85826802 5.87593463\n",
      " 6.33567581 5.44502356 4.51298641 5.03615618 5.47466542 6.16113214\n",
      " 5.3603703  5.60048906 5.02163483 5.12619411 5.35094032 4.46361463\n",
      " 5.30465    6.26598599 6.1910915  4.6592293  6.47523985 6.70433975\n",
      " 4.97943565 6.45251238 5.31268638 6.98345372 5.89722811 5.83826755\n",
      " 6.89256954 5.92795043 4.87348408 5.26977257 5.56780054 5.2470749\n",
      " 5.81833415 6.27642358 6.35950056 4.83538464 5.91468623 5.37980527\n",
      " 5.79941871 6.18844987 5.04529101 5.93376913 5.10558112 5.18669417\n",
      " 5.46582241 5.85766838 5.18115875 6.47827391 6.34946348 6.22515576\n",
      " 4.43217805 4.77244981 5.21556368 5.33537264 5.79267935 4.68402872\n",
      " 5.43925592 5.03222249 4.61380235 5.62976909 5.46645648 6.57603354\n",
      " 5.63539661 6.69771542 4.80939721 5.46800653 6.35452121 4.84874688\n",
      " 6.52056785 5.60148971 5.30980867 5.86605413 5.7713193  6.0858867\n",
      " 5.92134394 5.29931226 5.41385722 6.16402754 4.98205944 5.00990657\n",
      " 5.94187928 5.55259943 6.15772079 5.88344163 5.55998709 5.66909091\n",
      " 5.8431896  5.58272466 6.09221252 5.48362776 5.5676984  5.56411129\n",
      " 6.28370461 5.80260881]\n",
      "\n",
      "What it should be:  [5.33333333 5.33333333 5.83333333 4.66666667 6.16666667 6.5\n",
      " 4.83333333 6.16666667 4.33333333 6.16666667 7.         6.83333333\n",
      " 6.5        6.33333333 6.5        6.16666667 6.66666667 5.33333333\n",
      " 6.83333333 6.16666667 4.33333333 5.83333333 6.16666667 4.5\n",
      " 6.33333333 6.16666667 4.83333333 6.5        4.66666667 5.5\n",
      " 5.5        6.83333333 5.5        5.33333333 6.5        6.66666667\n",
      " 4.66666667 5.66666667 7.         5.33333333 4.83333333 6.16666667\n",
      " 6.16666667 6.66666667 5.16666667 1.83333333 5.66666667 6.33333333\n",
      " 6.5        5.16666667 6.33333333 4.83333333 4.16666667 6.83333333\n",
      " 5.16666667 5.66666667 6.         6.         6.83333333 4.33333333\n",
      " 5.         5.16666667 6.5        6.5        5.33333333 5.83333333\n",
      " 5.         5.33333333 6.5        6.         5.16666667 3.66666667\n",
      " 5.33333333 6.66666667 6.16666667 6.         3.83333333 6.16666667\n",
      " 4.66666667 6.         5.16666667 6.33333333 5.16666667 4.83333333\n",
      " 6.83333333 6.83333333 5.5        6.         5.66666667 7.\n",
      " 6.33333333 6.         5.83333333 6.16666667 6.83333333 5.5\n",
      " 5.66666667 5.5        3.         5.         5.83333333 3.33333333\n",
      " 6.         6.16666667 4.         5.66666667 6.5        6.5\n",
      " 4.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.18711584]\n",
      " [0.18711584 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.16\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.82595632 5.54836508 4.95647532 5.92730551 5.7869532  4.7900311\n",
      " 5.64490169 6.12714128 5.96005098 5.97323713 5.31355057 6.56733043\n",
      " 5.91781949 5.7388982  5.11469739 5.81357555 5.75208105 7.07256475\n",
      " 6.37714461 6.1398272  5.65021615 5.85614081 6.38606371 6.05807397\n",
      " 6.00638466 4.84834013 5.71304574 5.42054546 5.31667721 4.89707551\n",
      " 4.85831909 5.48694434 6.28692793 4.65529205 5.72044609 6.39519648\n",
      " 6.06202987 6.06363135 5.16045025 5.33015819 5.27752402 6.26040567\n",
      " 6.06046029 5.4338032  5.84223272 7.46552226 5.67291176 5.1984615\n",
      " 6.81621732 5.61620176 6.55238407 5.74669328 5.6444084  5.88641489\n",
      " 5.37854    5.60168523 5.29202071 5.50092092 5.63339926 6.42345288\n",
      " 6.17395403 5.75477379 5.35900272 5.47578235 5.73985047 5.49167141\n",
      " 5.37019462 5.86663055 5.96654931 5.486212   5.9475827  5.7974588\n",
      " 5.80521458 5.87189053 6.8844343  4.70333933 6.08064252 5.6528668\n",
      " 5.83947955 6.38172251 5.86295191 5.52776445 5.75141934 5.7057238\n",
      " 5.7023329  6.89379417 4.4180761  5.46184374 5.47630385 5.77395319\n",
      " 5.69846347 6.61041093 6.29752406 5.21839175 5.90225614 5.76827866\n",
      " 5.87779761 6.1235281  6.04729974 4.3354158  5.59041884 4.93446537\n",
      " 6.19477353 6.35564785 6.10422214 5.66588072 5.56693461 5.51565002\n",
      " 5.79239901 6.68218493]\n",
      "\n",
      "What it should be:  [7.         6.5        5.83333333 5.83333333 5.16666667 6.83333333\n",
      " 5.66666667 6.         5.83333333 6.         6.         5.66666667\n",
      " 6.16666667 5.66666667 5.5        6.66666667 7.         5.33333333\n",
      " 4.83333333 6.         6.         5.33333333 6.16666667 5.33333333\n",
      " 5.33333333 5.33333333 5.33333333 4.83333333 5.83333333 5.66666667\n",
      " 6.5        4.         4.5        6.16666667 3.83333333 4.33333333\n",
      " 6.16666667 4.         5.         6.         6.5        4.5\n",
      " 6.66666667 6.         7.         6.66666667 5.16666667 6.16666667\n",
      " 5.16666667 5.83333333 6.         5.83333333 6.33333333 5.16666667\n",
      " 5.5        5.83333333 5.33333333 6.         6.16666667 5.83333333\n",
      " 6.5        6.5        4.33333333 6.5        5.16666667 4.5\n",
      " 5.83333333 6.16666667 4.83333333 6.16666667 5.66666667 5.33333333\n",
      " 3.33333333 4.66666667 5.66666667 3.5        5.66666667 6.33333333\n",
      " 5.         6.16666667 4.66666667 5.5        6.16666667 6.5\n",
      " 6.16666667 3.         4.5        6.5        4.         6.66666667\n",
      " 6.16666667 4.66666667 6.83333333 6.16666667 7.         7.\n",
      " 1.83333333 6.83333333 4.83333333 4.         5.5        5.\n",
      " 6.         6.33333333 4.66666667 6.16666667 5.83333333 5.33333333\n",
      " 6.16666667 5.        ]\n",
      "Correlation:  [[1.         0.00819293]\n",
      " [0.00819293 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.02490251 6.09968248 6.09026092 6.57537117 5.54564754 5.55052734\n",
      " 5.99399448 5.67226103 5.12971802 6.05943474 5.16404927 6.20713156\n",
      " 5.49818247 5.78499105 5.89648604 5.75693458 6.08124514 5.90421644\n",
      " 5.08695831 5.42797383 6.4256432  5.68382605 6.16480187 5.84175997\n",
      " 6.29906136 5.06097319 6.09880353 5.34433644 5.29069626 5.28453741\n",
      " 6.22469593 6.36305813 5.6428839  6.18294418 5.63494878 5.8358494\n",
      " 5.86638441 5.40414758 5.25019438 5.55235354 5.78443531 5.44539816\n",
      " 4.59935415 5.06553851 4.53801917 5.85993311 5.04503851 5.78971172\n",
      " 6.51069076 5.66328537 5.02568424 5.01860897 4.96552251 5.64115313\n",
      " 5.75943431 6.03865853 6.34883908 5.26601293 5.39462273 5.90912667\n",
      " 5.9134817  5.6458006  4.88011644 4.06233721 5.14642646 5.31138107\n",
      " 5.45130163 6.41833162 5.796951   5.96639407 5.85978003 5.41873027\n",
      " 5.87119322 5.82900191 5.62902767 5.4955937  6.02798475 5.76263414\n",
      " 5.21874046 5.94934988 5.20388633 6.25421105 5.83384802 5.90460471\n",
      " 5.99774263 6.31439442 6.29998492 5.69376127 5.79176039 6.13579406\n",
      " 5.34993039 4.20495171 5.15879541 5.29523061 5.61801234 5.98024373\n",
      " 5.83396188 5.74217041 4.51472454 5.12998168 5.85017659 5.79624277\n",
      " 5.94937727 6.10870512 5.55239888 6.326398   4.8186122  6.25515724\n",
      " 6.38517427 5.47505363]\n",
      "\n",
      "What it should be:  [4.33333333 4.83333333 6.83333333 5.83333333 5.83333333 6.\n",
      " 6.16666667 6.33333333 5.16666667 6.16666667 5.16666667 4.5\n",
      " 6.83333333 6.16666667 4.66666667 5.83333333 4.83333333 5.5\n",
      " 5.83333333 6.5        5.83333333 5.83333333 6.16666667 3.5\n",
      " 6.5        6.         5.33333333 5.5        4.         5.33333333\n",
      " 4.66666667 6.66666667 6.33333333 5.16666667 6.83333333 6.\n",
      " 5.16666667 6.33333333 5.         5.66666667 6.33333333 5.66666667\n",
      " 5.5        6.         5.         4.83333333 7.         5.66666667\n",
      " 5.83333333 4.83333333 6.66666667 3.66666667 7.         4.5\n",
      " 6.33333333 1.83333333 5.66666667 6.16666667 6.16666667 7.\n",
      " 6.5        6.5        4.83333333 7.         5.5        6.66666667\n",
      " 6.33333333 3.66666667 6.66666667 5.33333333 6.16666667 5.\n",
      " 6.16666667 5.16666667 6.5        5.33333333 5.33333333 4.66666667\n",
      " 4.5        6.         6.16666667 3.83333333 4.         6.16666667\n",
      " 5.66666667 6.5        6.16666667 6.83333333 6.83333333 6.5\n",
      " 4.66666667 6.83333333 3.66666667 4.5        6.         5.66666667\n",
      " 4.         4.83333333 6.33333333 5.5        5.16666667 5.33333333\n",
      " 4.83333333 5.5        4.66666667 6.5        4.33333333 5.16666667\n",
      " 6.         4.5       ]\n",
      "Correlation:  [[ 1.         -0.07479987]\n",
      " [-0.07479987  1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.35\n",
      "R2 score = -0.36\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.53216091 5.87299539 5.68823916 5.68391449 6.12999312 5.71822243\n",
      " 5.17683372 5.78365849 5.87953499 5.59591947 6.11780026 6.89679581\n",
      " 6.58512936 5.51295688 7.10111736 5.78509083 4.23528672 5.28736492\n",
      " 4.99178705 4.94462995 4.6316674  5.34562295 6.4341033  5.36744804\n",
      " 6.32090749 5.08970067 6.06255065 5.38197361 5.38666687 6.21428152\n",
      " 5.39088058 5.13479699 5.26962927 5.0738371  5.28318451 6.10614361\n",
      " 4.8086813  5.83868738 4.64218259 5.3609507  5.91284396 5.83838963\n",
      " 6.11508915 5.26496392 6.50256794 6.79453237 6.00768111 5.45810243\n",
      " 6.08516399 5.69531687 5.88852458 5.19518031 6.51970494 6.63527053\n",
      " 6.04227007 5.86861342 5.26947194 5.28336496 5.92413842 5.90500485\n",
      " 5.64932219 5.88013278 5.61022365 5.45068462 5.88745475 5.50917048\n",
      " 5.68964873 5.66569411 5.73012218 5.87648386 5.37455618 6.4335444\n",
      " 5.23627068 5.73875134 5.49803915 5.72462955 4.60168616 5.53682551\n",
      " 5.30398586 5.72285804 4.87676981 5.87522668 5.73047296 5.29803107\n",
      " 5.10492372 6.16824124 5.51169408 6.69563709 5.54078285 5.57816447\n",
      " 6.13171418 6.80350131 5.89856683 5.71109709 5.89707031 5.81549699\n",
      " 5.08428451 5.43027695 5.68880916 5.20970372 5.62635261 6.43852164\n",
      " 5.28123451 6.23422162 5.25388235 5.88008776 5.91955732 5.29712377\n",
      " 5.876057   5.96026743]\n",
      "\n",
      "What it should be:  [4.33333333 4.         5.33333333 6.16666667 6.16666667 5.33333333\n",
      " 5.33333333 6.16666667 6.5        6.83333333 5.33333333 6.83333333\n",
      " 6.33333333 6.5        6.5        4.66666667 5.83333333 7.\n",
      " 6.5        6.33333333 7.         4.         7.         5.66666667\n",
      " 4.83333333 7.         4.         6.         5.83333333 5.83333333\n",
      " 6.16666667 5.33333333 6.83333333 4.33333333 6.         6.66666667\n",
      " 4.66666667 6.         6.83333333 6.16666667 6.16666667 5.83333333\n",
      " 5.5        6.16666667 6.         5.83333333 3.33333333 6.83333333\n",
      " 6.5        6.33333333 6.16666667 5.         5.33333333 5.83333333\n",
      " 3.66666667 5.33333333 6.5        4.5        1.83333333 6.\n",
      " 5.         5.66666667 6.16666667 5.33333333 6.33333333 5.16666667\n",
      " 4.83333333 6.33333333 6.         6.83333333 7.         5.66666667\n",
      " 3.         6.5        5.5        5.33333333 4.5        5.\n",
      " 5.66666667 6.33333333 3.66666667 6.16666667 6.         5.\n",
      " 4.83333333 6.5        5.16666667 5.33333333 4.66666667 6.16666667\n",
      " 6.5        5.33333333 5.83333333 6.5        6.66666667 6.66666667\n",
      " 4.         5.16666667 5.83333333 6.33333333 6.         5.33333333\n",
      " 6.5        5.66666667 4.66666667 5.5        4.66666667 5.16666667\n",
      " 4.33333333 5.66666667]\n",
      "Correlation:  [[1.         0.10236238]\n",
      " [0.10236238 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.99992929 5.7139789  5.99635731 5.64498506 6.24643815 4.35742471\n",
      " 5.50606306 5.08721156 7.02340998 5.4752686  5.61042839 5.37218466\n",
      " 5.77009356 4.35143605 5.96965667 5.1256092  5.04292124 6.141077\n",
      " 5.07613087 5.69530529 5.79369319 6.26002631 5.13062081 4.77381079\n",
      " 5.68216521 5.48608828 5.37757223 5.54379422 5.10346191 5.73249889\n",
      " 6.51679486 5.89191422 4.96043499 6.4946797  5.71553102 4.96485298\n",
      " 4.36945525 5.84795145 5.15899316 5.52327958 5.33488924 5.17104916\n",
      " 6.35262007 6.29436635 5.89493406 5.05246    4.67153814 5.78030889\n",
      " 4.65942861 7.50046219 5.31227954 4.98714399 5.04032032 6.59755667\n",
      " 5.63533214 4.24135655 4.96973117 6.47869085 5.21737924 6.33497886\n",
      " 4.1418651  4.73484627 5.77475085 4.76811621 5.83633085 4.63593292\n",
      " 5.40762108 5.33595554 4.69124334 3.28269902 4.80997189 6.40759199\n",
      " 6.11221741 5.87198477 5.64279868 6.68820509 5.31685008 5.60787681\n",
      " 4.12346548 6.10936475 5.73963348 5.67987674 5.36822199 6.14017751\n",
      " 5.09378784 6.15914156 4.80621922 5.8155348  5.83528199 6.35084882\n",
      " 6.22969083 5.78519078 5.28838171 4.95350064 4.88298146 7.00389547\n",
      " 5.46178049 6.01079728 5.97125157 6.21536529 5.85028949 6.20920087\n",
      " 5.50781854 5.69828262 6.26362294 6.78469273 7.2660105  6.09176312\n",
      " 4.2888411  5.28646197]\n",
      "\n",
      "What it should be:  [5.83333333 5.33333333 6.5        5.66666667 7.         4.\n",
      " 4.16666667 6.83333333 6.16666667 6.16666667 6.16666667 4.83333333\n",
      " 6.         4.5        5.33333333 6.5        6.33333333 5.66666667\n",
      " 4.66666667 3.5        6.66666667 5.33333333 6.66666667 6.5\n",
      " 5.33333333 6.         4.83333333 4.         6.83333333 6.33333333\n",
      " 5.83333333 6.5        5.5        7.         5.83333333 6.5\n",
      " 6.         5.16666667 5.         5.83333333 5.5        4.\n",
      " 6.83333333 6.5        5.66666667 5.33333333 5.5        5.16666667\n",
      " 5.33333333 5.33333333 5.5        5.33333333 4.33333333 6.16666667\n",
      " 5.33333333 6.33333333 6.83333333 5.33333333 6.5        5.16666667\n",
      " 6.16666667 5.66666667 6.16666667 6.66666667 5.66666667 5.83333333\n",
      " 5.         6.         6.         6.5        4.33333333 5.33333333\n",
      " 5.66666667 5.66666667 6.         6.         6.33333333 3.\n",
      " 6.5        4.         4.83333333 6.16666667 6.83333333 6.83333333\n",
      " 5.         4.66666667 7.         5.16666667 6.         4.66666667\n",
      " 6.16666667 6.33333333 5.83333333 4.83333333 3.83333333 6.83333333\n",
      " 6.33333333 6.5        5.66666667 5.33333333 5.83333333 6.\n",
      " 6.16666667 6.16666667 4.5        4.5        6.5        4.83333333\n",
      " 5.         6.        ]\n",
      "Correlation:  [[1.         0.03228965]\n",
      " [0.03228965 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.65\n",
      "R2 score = -0.67\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.11534011 5.1127479  5.46179236 5.0616446  5.43295531 5.38150903\n",
      " 6.73399814 6.15523412 6.03443721 5.11881101 5.62561998 6.41511762\n",
      " 6.46047148 5.41175773 4.90727716 6.69411261 6.87493052 5.46072038\n",
      " 5.55578212 4.9424531  5.48146428 5.18540085 5.62330634 4.86365979\n",
      " 5.42659829 6.21875361 6.52316523 5.22319868 5.96634022 5.60864427\n",
      " 6.21085284 5.98405857 6.19514164 6.75393424 6.38944472 5.29394132\n",
      " 5.15022886 6.85286713 6.16348248 5.77551461 7.32831776 5.94669958\n",
      " 5.32703678 5.66703156 6.41172441 5.63477217 4.29405605 6.69146639\n",
      " 6.03052695 6.61330335 5.12144876 5.02275701 5.48029503 5.21221039\n",
      " 5.47407409 5.39619648 5.97766025 5.59793526 4.86342205 6.0812921\n",
      " 5.42687353 5.72831631 4.9595301  5.58373958 5.54818878 6.28849177\n",
      " 5.35572949 3.69081596 5.66245559 6.44474851 5.46943945 5.24148046\n",
      " 5.27161289 5.66790066 5.48281728 4.51761251 6.5636345  5.71269862\n",
      " 4.98086302 6.00438728 5.89214635 4.94665818 5.28082604 5.76104147\n",
      " 5.4230067  4.9315177  5.24594846 6.66212083 6.77001511 4.45587735\n",
      " 5.48453426 5.52328983 4.65515638 5.36360614 4.76569387 6.18100532\n",
      " 5.16207743 5.42726999 4.96793438 5.29958343 5.32835073 4.51452771\n",
      " 5.61410923 6.48258498 4.82728783 5.36858937 5.06236894 4.37579537\n",
      " 4.73975851 4.41888829]\n",
      "\n",
      "What it should be:  [5.66666667 3.66666667 6.33333333 6.16666667 5.33333333 5.16666667\n",
      " 7.         6.         4.5        6.66666667 6.         5.66666667\n",
      " 4.         3.83333333 7.         6.66666667 6.16666667 5.83333333\n",
      " 5.66666667 5.33333333 6.5        5.33333333 5.33333333 6.\n",
      " 6.         5.66666667 6.33333333 5.16666667 6.83333333 4.83333333\n",
      " 4.33333333 4.66666667 6.83333333 6.16666667 6.16666667 4.66666667\n",
      " 6.83333333 6.16666667 6.         4.16666667 7.         6.83333333\n",
      " 4.66666667 5.83333333 5.16666667 6.33333333 4.83333333 6.5\n",
      " 5.16666667 6.         4.5        3.66666667 4.83333333 4.\n",
      " 5.5        6.33333333 6.16666667 6.5        6.16666667 5.33333333\n",
      " 5.33333333 6.         5.5        5.16666667 5.33333333 7.\n",
      " 5.         4.5        4.83333333 5.16666667 5.         5.33333333\n",
      " 5.33333333 5.83333333 6.83333333 6.         6.66666667 5.16666667\n",
      " 6.16666667 4.66666667 4.66666667 5.66666667 5.66666667 6.83333333\n",
      " 4.66666667 5.         6.16666667 6.33333333 4.5        6.33333333\n",
      " 5.33333333 6.33333333 4.33333333 5.83333333 4.83333333 6.5\n",
      " 4.33333333 5.83333333 5.5        6.16666667 6.5        4.83333333\n",
      " 5.5        6.         5.83333333 6.16666667 5.5        4.66666667\n",
      " 4.66666667 6.33333333]\n",
      "Correlation:  [[1.        0.2808831]\n",
      " [0.2808831 1.       ]]\n",
      "Mean absolute error = 0.72\n",
      "Mean squared error = 0.81\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.43067001 4.19931687 5.95602671 6.48373228 5.11179726 5.00167222\n",
      " 5.00375374 5.99286536 6.47708297 5.81354566 5.38166007 5.71106288\n",
      " 5.06767343 5.41697199 4.38600989 4.80152667 4.7619883  6.19489163\n",
      " 5.66334253 5.39061696 4.59613697 6.18478691 5.19307675 5.73599161\n",
      " 5.67978971 6.29016272 5.79736154 6.31434312 6.68491255 4.77816525\n",
      " 5.83409428 5.27244981 4.84343673 6.53806669 4.50690059 5.51132901\n",
      " 4.81649931 5.364547   5.75258545 5.0934721  3.74570997 4.46868139\n",
      " 6.02626396 6.5018229  5.94195576 6.10718951 5.14112552 5.29330212\n",
      " 4.80347967 5.70313245 5.00566836 6.2232998  6.04539773 6.11250872\n",
      " 5.3701758  4.58166121 4.73690952 4.71238146 5.36038086 5.63635838\n",
      " 4.79584032 5.90562069 4.94337311 5.63247793 6.14431632 6.03129936\n",
      " 5.82203766 5.79042599 6.19450053 5.12181931 4.41416248 5.61734915\n",
      " 6.23146726 5.29027758 6.60842975 5.627713   4.91831244 5.2311877\n",
      " 5.0409699  5.72672665 4.72547829 4.91991677 4.83297969 4.71594917\n",
      " 5.12095303 5.29722886 5.7496911  6.08447719 5.41402767 5.24956081\n",
      " 4.69920575 6.34983181 5.46452105 6.10836907 4.3757351  6.75459451\n",
      " 6.499908   6.4594613  5.50483995 4.8126417  5.37663715 4.90503657\n",
      " 6.14346344 7.05971813 5.81074453 5.40710984 6.86785228 5.61705987\n",
      " 4.66347773 5.35488989]\n",
      "\n",
      "What it should be:  [6.         4.         6.5        6.16666667 6.16666667 3.83333333\n",
      " 5.83333333 6.33333333 6.5        4.5        3.66666667 5.5\n",
      " 6.16666667 6.         6.5        3.66666667 6.16666667 6.16666667\n",
      " 5.5        5.83333333 4.83333333 6.66666667 5.83333333 4.5\n",
      " 6.33333333 6.16666667 5.         4.5        5.16666667 5.83333333\n",
      " 6.16666667 5.83333333 6.66666667 6.16666667 6.         5.33333333\n",
      " 6.5        6.         6.5        3.5        6.33333333 6.\n",
      " 5.33333333 5.83333333 6.83333333 6.16666667 5.66666667 4.83333333\n",
      " 5.16666667 7.         5.5        5.66666667 6.33333333 6.66666667\n",
      " 6.83333333 5.66666667 6.         4.83333333 5.33333333 6.\n",
      " 5.16666667 6.16666667 6.83333333 6.         6.5        5.66666667\n",
      " 6.         5.33333333 6.66666667 5.33333333 6.33333333 4.\n",
      " 4.83333333 6.16666667 6.83333333 6.5        3.33333333 6.5\n",
      " 6.66666667 6.83333333 5.83333333 6.16666667 6.         5.83333333\n",
      " 4.66666667 3.66666667 5.66666667 6.33333333 5.33333333 5.66666667\n",
      " 4.83333333 6.         5.16666667 4.66666667 7.         5.66666667\n",
      " 6.16666667 7.         6.83333333 5.         5.33333333 4.33333333\n",
      " 4.5        3.         4.66666667 4.         5.33333333 6.5\n",
      " 6.33333333 5.        ]\n",
      "Correlation:  [[1.        0.0754855]\n",
      " [0.0754855 1.       ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.2\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.43\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.72794658 4.38407327 5.30445359 5.40989035 5.982644   5.54957526\n",
      " 6.17855637 5.4253644  5.64272948 5.5131675  5.62001592 4.84503109\n",
      " 5.61822633 5.72197615 5.52083689 5.28552353 5.75376319 6.03962621\n",
      " 6.1753695  5.64516543 5.39571547 5.84593636 5.58582297 5.45246609\n",
      " 6.43674964 6.06801028 5.59588112 5.45256659 5.0098679  6.44362913\n",
      " 5.27718453 5.45449949 5.12938233 5.56276106 5.7560464  6.0043669\n",
      " 6.76856029 5.69142152 6.09261377 6.11111833 5.53869611 5.86191807\n",
      " 5.07388301 5.44667079 5.98771501 6.0331811  6.15068081 5.61345889\n",
      " 5.29346442 5.18089848 5.56113697 5.41706941 4.40276799 4.88687558\n",
      " 6.63507143 5.05915999 5.10520793 5.67490221 6.24301206 6.00893908\n",
      " 5.87202404 5.25245374 5.1415703  5.38962287 5.26885974 5.829299\n",
      " 5.27717216 5.71549906 6.07123258 5.999679   5.8574874  6.10409449\n",
      " 5.57967515 5.44563099 6.14578724 6.39126678 5.50419595 5.12249488\n",
      " 5.33505661 6.29415556 5.88858964 5.56739687 5.19292146 6.01369662\n",
      " 5.98985499 5.05639494 5.67182016 6.12520518 6.00102952 5.45798578\n",
      " 5.2086077  5.7389623  5.99730956 5.49718494 6.96102262 5.1481708\n",
      " 6.80634343 6.07506318 5.31969283 5.8225451  4.85700971 6.10800025\n",
      " 5.36954972 5.38896229 5.48469488 5.49405312 4.98465434 5.87303583\n",
      " 5.51386856 5.9641047 ]\n",
      "\n",
      "What it should be:  [5.16666667 7.         1.83333333 4.         6.83333333 5.5\n",
      " 6.5        6.16666667 3.         6.16666667 6.83333333 6.83333333\n",
      " 5.33333333 5.66666667 6.5        5.83333333 5.33333333 5.66666667\n",
      " 6.33333333 5.33333333 4.66666667 5.16666667 3.66666667 6.\n",
      " 7.         5.83333333 6.83333333 6.         4.33333333 5.66666667\n",
      " 4.83333333 4.5        6.5        6.83333333 6.66666667 6.83333333\n",
      " 5.33333333 4.33333333 6.83333333 6.16666667 6.16666667 5.16666667\n",
      " 5.16666667 5.33333333 6.66666667 5.83333333 5.66666667 4.66666667\n",
      " 5.         5.66666667 6.16666667 6.16666667 6.33333333 5.83333333\n",
      " 6.5        6.16666667 5.5        6.5        4.66666667 4.83333333\n",
      " 6.66666667 5.33333333 4.83333333 5.66666667 6.33333333 7.\n",
      " 7.         6.33333333 5.5        4.33333333 4.5        5.66666667\n",
      " 5.16666667 6.         6.5        6.16666667 5.16666667 5.83333333\n",
      " 5.         6.16666667 5.         4.83333333 5.83333333 3.66666667\n",
      " 6.66666667 5.83333333 6.         6.16666667 5.5        6.83333333\n",
      " 5.5        6.66666667 6.5        5.83333333 5.66666667 6.83333333\n",
      " 5.83333333 5.33333333 6.5        6.33333333 5.33333333 6.16666667\n",
      " 5.         5.66666667 4.33333333 4.         4.66666667 4.83333333\n",
      " 4.5        5.83333333]\n",
      "Correlation:  [[1.         0.08463832]\n",
      " [0.08463832 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.16\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.96859236 5.58856991 5.38345689 5.36290216 4.55625522 5.61677348\n",
      " 6.50587612 5.27512629 7.04573655 5.73530245 6.18677841 6.39729552\n",
      " 5.39827519 5.75488108 5.26037691 4.92502722 6.25225119 5.55562735\n",
      " 5.93413588 6.44680907 6.6395254  5.687132   5.28077442 7.40838176\n",
      " 5.41603426 5.4117881  4.3925695  5.47613732 5.20212145 6.05310806\n",
      " 5.62232761 5.22963071 5.81473556 6.51345471 6.01766153 5.47001242\n",
      " 5.76939677 5.3554328  6.28108109 5.27774302 5.60691708 4.68270454\n",
      " 5.32560394 5.81811026 6.25076936 5.73858714 5.38082081 5.24215536\n",
      " 5.68191105 5.78591417 6.44943028 5.04976527 5.62083993 5.58350153\n",
      " 6.58506859 6.32428546 6.85700143 5.89597426 5.34575576 6.20388604\n",
      " 6.34765272 6.78955383 5.57903133 6.46705132 5.1390498  5.51373063\n",
      " 5.05872807 4.9642627  5.10782889 6.62223731 6.37029587 5.17208182\n",
      " 5.68750532 5.85991365 5.92093376 6.08566779 5.41821641 5.18083963\n",
      " 6.20516894 4.67032058 5.06010076 5.38749774 5.89035154 6.53341473\n",
      " 5.43708666 5.37422768 5.66595999 6.22499227 4.77299447 6.131977\n",
      " 6.16583826 5.3922213  5.16065712 5.56801004 5.36123715 6.24902316\n",
      " 6.16683467 5.92697674 5.60638021 4.27761302 5.60585825 5.47028166\n",
      " 6.50802074 4.8121676  4.92330765 5.75839402 6.05512324 6.01485939\n",
      " 5.45303917 4.82835997]\n",
      "\n",
      "What it should be:  [5.33333333 6.         4.83333333 4.         6.83333333 6.\n",
      " 5.66666667 6.5        6.66666667 7.         4.83333333 5.83333333\n",
      " 5.5        6.33333333 6.5        5.         6.16666667 4.5\n",
      " 6.33333333 6.33333333 6.5        7.         4.33333333 5.33333333\n",
      " 6.33333333 4.83333333 5.83333333 3.         4.66666667 6.16666667\n",
      " 5.83333333 5.5        5.83333333 5.16666667 5.33333333 6.33333333\n",
      " 5.66666667 6.16666667 6.16666667 6.         6.83333333 5.83333333\n",
      " 6.83333333 5.16666667 5.5        4.66666667 5.33333333 6.66666667\n",
      " 6.5        6.16666667 5.83333333 5.66666667 5.5        5.\n",
      " 5.83333333 6.         4.83333333 6.         5.33333333 5.66666667\n",
      " 6.         7.         4.         6.5        5.83333333 5.66666667\n",
      " 1.83333333 5.5        7.         5.33333333 5.16666667 4.66666667\n",
      " 5.83333333 7.         5.33333333 5.66666667 5.66666667 5.5\n",
      " 4.66666667 5.5        6.5        4.66666667 5.16666667 6.5\n",
      " 6.33333333 6.16666667 4.83333333 6.83333333 6.33333333 5.16666667\n",
      " 5.66666667 6.83333333 5.5        5.         4.5        6.5\n",
      " 5.66666667 6.83333333 4.5        7.         6.16666667 6.83333333\n",
      " 6.16666667 5.33333333 3.66666667 4.         5.16666667 4.83333333\n",
      " 6.         4.83333333]\n",
      "Correlation:  [[1.         0.10983548]\n",
      " [0.10983548 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.02\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.28\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.99307816 6.21046512 4.54816735 5.3079737  4.01136028 5.56868753\n",
      " 5.99424073 6.58217095 4.20237409 5.96939463 5.80863105 5.10850061\n",
      " 6.20440064 4.92993119 5.82095221 4.99361647 6.06032006 5.95274309\n",
      " 4.81079305 4.93734177 6.0928782  5.77876432 5.11673314 6.3889593\n",
      " 5.57220258 5.80849284 5.93536001 5.58874251 5.21463636 6.11441501\n",
      " 4.83280897 6.42092511 5.44432982 6.00225185 5.89671255 4.9453783\n",
      " 5.77401596 6.902143   5.52330602 5.69231365 5.02633191 5.12142113\n",
      " 6.15823276 5.96649897 5.64745511 5.89069205 4.66741869 5.54374896\n",
      " 5.5946088  5.55350568 6.06533994 6.13066621 5.92322822 6.30788767\n",
      " 6.30739233 5.21965763 5.62887692 5.47566737 6.06294576 4.93797283\n",
      " 6.01028246 5.51551478 5.43155294 5.91044233 5.59385559 5.3036889\n",
      " 5.65188944 5.70811291 5.80533483 5.81429014 6.23717967 5.98512923\n",
      " 5.72901779 5.77403826 6.32927373 4.93988343 4.52086114 6.19127967\n",
      " 5.1290132  6.26809871 5.8178164  5.68750634 6.21659235 6.09756694\n",
      " 5.9480713  5.52020546 4.90004387 5.26189341 5.35791536 6.54981591\n",
      " 6.16238435 5.70284036 5.75135226 5.39370605 6.58845398 6.12115393\n",
      " 6.14801163 5.97726268 6.30346967 5.64467581 5.88317903 5.35417093\n",
      " 5.527376   5.85217149 5.94669884 5.84228135 5.7470509  5.5697723\n",
      " 5.47334158 5.52343185]\n",
      "\n",
      "What it should be:  [6.5        6.         5.         5.33333333 6.33333333 5.83333333\n",
      " 5.66666667 7.         5.5        6.66666667 3.33333333 4.33333333\n",
      " 4.5        5.33333333 6.83333333 5.83333333 5.5        6.83333333\n",
      " 4.83333333 4.66666667 4.83333333 3.5        4.         6.83333333\n",
      " 5.83333333 4.83333333 6.16666667 3.66666667 5.5        4.33333333\n",
      " 7.         5.16666667 4.83333333 6.16666667 6.83333333 4.83333333\n",
      " 4.         5.83333333 4.83333333 6.66666667 6.83333333 6.5\n",
      " 7.         6.16666667 3.83333333 6.         4.5        6.5\n",
      " 5.5        5.16666667 6.83333333 4.16666667 6.33333333 5.5\n",
      " 6.66666667 6.16666667 1.83333333 5.         5.16666667 5.33333333\n",
      " 4.66666667 6.5        6.         6.5        6.5        5.33333333\n",
      " 6.16666667 6.83333333 4.33333333 6.83333333 6.83333333 6.5\n",
      " 6.66666667 6.33333333 4.83333333 5.33333333 6.83333333 6.33333333\n",
      " 6.         4.66666667 6.16666667 4.5        5.66666667 5.66666667\n",
      " 6.         6.5        6.66666667 5.16666667 6.66666667 5.83333333\n",
      " 6.16666667 4.5        6.33333333 5.16666667 6.33333333 6.33333333\n",
      " 6.16666667 5.33333333 4.         5.33333333 3.66666667 5.83333333\n",
      " 6.16666667 6.5        5.83333333 6.5        5.33333333 6.\n",
      " 4.66666667 5.83333333]\n",
      "Correlation:  [[1.         0.07660198]\n",
      " [0.07660198 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.19\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.71023102 5.38367485 6.48809785 6.1306749  5.30972092 5.89409087\n",
      " 6.11821743 5.06329092 5.07461148 6.97492765 5.42752441 5.27606042\n",
      " 5.06278889 4.82202689 4.66572013 5.48143845 6.42031529 6.14086438\n",
      " 5.63836235 5.70201048 5.07552002 5.79507739 5.99000925 6.3772673\n",
      " 5.61704807 5.29840613 6.29546545 6.18343008 4.85685063 5.76611559\n",
      " 6.75797941 5.24984561 5.41578393 5.65118449 5.46059672 5.82497859\n",
      " 5.28941193 5.48479574 5.98566704 5.3504692  5.70501536 5.59342882\n",
      " 5.68514971 6.04388023 5.65408647 6.28217827 5.80338588 6.20015729\n",
      " 5.09856413 5.75230884 5.94774968 5.23983168 5.05940587 6.59931859\n",
      " 6.12167752 6.1129771  5.17683342 4.49621733 6.26498766 5.7829029\n",
      " 5.10212304 4.60964705 4.82288168 5.28719868 6.06305265 6.39203866\n",
      " 4.82162221 5.15032824 4.57815459 6.46686291 5.44455818 6.09272621\n",
      " 6.54064172 5.0163207  4.54803586 6.32821487 5.43093055 6.20367988\n",
      " 5.91812524 5.45076838 4.89782872 5.04221547 5.22508552 6.0936127\n",
      " 4.84896343 5.39215607 5.32018226 5.80056142 4.68971978 6.31472081\n",
      " 4.93871859 5.64329428 5.71172729 5.35373746 4.78282785 5.63934495\n",
      " 5.1838254  5.38119519 5.3164147  6.35289143 5.3854365  5.55747635\n",
      " 5.67225806 5.29795292 5.5952548  5.56837373 6.09768625 6.76098581\n",
      " 6.31322492 5.50200787]\n",
      "\n",
      "What it should be:  [6.         3.         5.33333333 5.66666667 6.33333333 4.5\n",
      " 5.16666667 6.66666667 4.66666667 6.33333333 5.         4.\n",
      " 6.83333333 3.66666667 6.16666667 6.16666667 6.         4.83333333\n",
      " 6.16666667 4.         5.66666667 6.33333333 4.33333333 5.33333333\n",
      " 4.         6.16666667 6.16666667 5.16666667 5.33333333 6.33333333\n",
      " 5.66666667 5.5        4.83333333 5.66666667 6.5        4.33333333\n",
      " 4.66666667 6.16666667 6.83333333 4.5        6.16666667 3.5\n",
      " 6.16666667 6.33333333 5.         6.5        6.16666667 6.83333333\n",
      " 6.5        6.         5.33333333 5.66666667 6.83333333 5.5\n",
      " 5.66666667 7.         6.         6.5        4.16666667 5.33333333\n",
      " 5.83333333 5.66666667 6.16666667 4.83333333 6.         6.83333333\n",
      " 6.16666667 6.5        5.33333333 7.         6.         4.83333333\n",
      " 6.33333333 5.5        4.5        5.33333333 6.66666667 6.66666667\n",
      " 6.16666667 7.         1.83333333 6.5        6.33333333 5.\n",
      " 5.         5.16666667 7.         5.5        4.66666667 6.83333333\n",
      " 3.66666667 5.16666667 6.66666667 5.5        5.         6.33333333\n",
      " 5.83333333 5.33333333 5.66666667 5.5        5.83333333 6.5\n",
      " 5.33333333 6.         5.83333333 5.66666667 5.33333333 5.83333333\n",
      " 6.83333333 4.5       ]\n",
      "Correlation:  [[1.         0.17794799]\n",
      " [0.17794799 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.13\n",
      "R2 score = -0.13\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.54287729 4.97826537 6.51683751 4.91795866 5.09570157 4.76681134\n",
      " 4.92972035 5.85405538 6.01573711 6.25061643 5.17963173 5.42869391\n",
      " 5.0828952  5.34870505 7.06068624 5.34115413 6.01735435 5.41335627\n",
      " 5.93828561 5.93496136 6.1431762  5.62280508 6.03858215 6.00168035\n",
      " 6.51150459 5.2934881  4.66266422 5.28388252 4.42348982 5.8460859\n",
      " 5.2968347  5.69389631 4.98844002 5.55406123 6.04195687 6.14445801\n",
      " 6.31735097 5.21089082 5.17030827 5.39248252 5.60965109 6.32588715\n",
      " 5.99582369 5.63486662 6.34245727 5.40795059 6.38252426 6.04373037\n",
      " 5.50816591 6.13626941 5.75018774 5.90845322 4.90932637 5.72533524\n",
      " 5.97451527 5.28356828 5.76853718 5.08014388 5.82106127 6.07094472\n",
      " 5.84085244 6.15911726 5.60051277 4.78271998 5.8869644  6.33114815\n",
      " 5.97328649 4.76616578 4.51278332 4.47353673 6.12241741 5.88058823\n",
      " 6.01045401 6.07176147 5.54167516 5.99176773 5.92280422 5.24517609\n",
      " 5.31249563 4.78045242 6.21528487 6.54347204 5.62056496 4.76796762\n",
      " 6.31841619 5.28891941 6.07699783 5.79696393 5.32998558 5.36397619\n",
      " 6.5701757  6.13277308 6.10518146 5.16246194 5.67960598 5.64133599\n",
      " 5.56097641 6.00328867 6.2598585  5.93201772 6.1354872  5.14225534\n",
      " 5.58385036 5.02850719 5.14872245 5.71723908 5.15750055 5.94903775\n",
      " 6.06150262 5.53281791]\n",
      "\n",
      "What it should be:  [5.16666667 6.5        6.83333333 6.16666667 5.5        6.83333333\n",
      " 6.33333333 6.         3.83333333 6.66666667 3.66666667 6.16666667\n",
      " 6.         4.66666667 5.         6.16666667 6.16666667 5.66666667\n",
      " 5.16666667 5.83333333 6.33333333 4.5        4.         6.5\n",
      " 5.66666667 6.         6.16666667 7.         4.         6.16666667\n",
      " 3.33333333 7.         5.5        6.5        4.66666667 5.16666667\n",
      " 4.66666667 5.83333333 5.5        5.33333333 5.33333333 5.66666667\n",
      " 6.5        3.         6.16666667 5.83333333 6.16666667 6.16666667\n",
      " 5.5        5.33333333 6.66666667 6.16666667 4.83333333 5.33333333\n",
      " 4.83333333 4.5        6.         4.5        6.5        5.33333333\n",
      " 5.33333333 6.16666667 6.66666667 5.33333333 5.66666667 5.83333333\n",
      " 6.83333333 4.66666667 5.33333333 5.66666667 6.33333333 6.66666667\n",
      " 5.5        6.16666667 6.33333333 5.5        6.33333333 6.5\n",
      " 6.83333333 5.33333333 5.66666667 7.         5.33333333 6.16666667\n",
      " 5.16666667 6.66666667 5.83333333 6.         6.16666667 6.33333333\n",
      " 6.66666667 6.         5.66666667 4.         4.33333333 5.33333333\n",
      " 1.83333333 5.33333333 6.5        4.16666667 5.83333333 5.33333333\n",
      " 4.83333333 4.83333333 5.5        6.         6.5        6.16666667\n",
      " 6.83333333 7.        ]\n",
      "Correlation:  [[1.         0.14411498]\n",
      " [0.14411498 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.16\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.68426738 5.90824526 6.012304   6.40359948 5.81282338 7.58752243\n",
      " 5.84085202 6.62678643 5.63264341 5.96789962 6.27719769 5.89165905\n",
      " 6.03998329 4.50805139 5.88805545 5.83645039 5.51415584 5.5968238\n",
      " 6.17600284 6.25802825 6.12387391 5.42033333 5.89222704 5.95620606\n",
      " 5.91749238 5.594488   6.31609194 5.29217249 6.08685987 5.62666091\n",
      " 5.50912702 5.33500663 5.78117231 5.74583507 6.00708231 5.44412381\n",
      " 6.08906975 5.50356211 5.73297158 5.8700681  6.39084713 5.67196176\n",
      " 6.00733305 5.98325714 6.50326136 5.6427709  6.18775276 6.18849898\n",
      " 5.37138928 5.85657807 6.06508148 5.94096747 6.02870503 5.32772252\n",
      " 5.83342714 4.93457474 6.02986852 5.69112319 5.67234695 4.98768035\n",
      " 6.05759816 5.64751629 6.00456041 5.91533799 6.20213774 6.15348599\n",
      " 5.43348017 5.54392094 5.42132287 5.67211054 5.63305785 6.79477882\n",
      " 5.21061247 5.87984941 6.16952587 5.32186606 5.58343622 5.91176969\n",
      " 6.28497675 6.53545183 5.65522456 6.23384093 5.71304719 5.09727653\n",
      " 5.89656411 5.91781848 6.18175167 5.51202316 5.71923418 6.12179339\n",
      " 5.64021547 6.49498055 5.41674285 5.58011457 5.97158408 6.20765196\n",
      " 6.44272158 5.90186969 6.1336445  5.70632829 5.83893814 4.90916373\n",
      " 5.47374552 6.2261734  6.38986281 6.17203123 5.8271446  5.65398841\n",
      " 5.27257084 5.92807344]\n",
      "\n",
      "What it should be:  [6.16666667 5.5        6.5        6.83333333 5.         4.83333333\n",
      " 4.33333333 7.         4.83333333 5.33333333 6.         6.33333333\n",
      " 6.16666667 6.         6.16666667 3.66666667 6.5        5.16666667\n",
      " 6.33333333 5.66666667 4.16666667 6.16666667 5.16666667 5.33333333\n",
      " 6.33333333 4.5        6.5        5.5        5.5        5.83333333\n",
      " 6.5        6.16666667 6.83333333 6.5        5.66666667 5.66666667\n",
      " 6.         6.5        5.5        7.         6.16666667 6.33333333\n",
      " 5.83333333 4.         4.         4.66666667 6.33333333 4.83333333\n",
      " 5.33333333 6.16666667 5.16666667 4.83333333 4.33333333 5.83333333\n",
      " 6.         4.83333333 5.         6.33333333 6.         6.16666667\n",
      " 4.33333333 5.33333333 3.83333333 5.16666667 5.83333333 5.83333333\n",
      " 6.33333333 5.16666667 5.33333333 5.5        4.5        5.66666667\n",
      " 5.83333333 4.66666667 5.33333333 3.         5.66666667 6.66666667\n",
      " 5.5        3.66666667 6.         5.33333333 6.         3.33333333\n",
      " 4.83333333 6.83333333 5.33333333 5.83333333 6.16666667 4.66666667\n",
      " 4.5        5.66666667 5.83333333 5.         5.16666667 6.5\n",
      " 4.83333333 6.33333333 4.5        1.83333333 6.16666667 4.\n",
      " 6.33333333 6.16666667 6.         7.         6.66666667 6.\n",
      " 6.16666667 6.33333333]\n",
      "Correlation:  [[1.         0.02733167]\n",
      " [0.02733167 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.12\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.3\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.73516427 5.92738194 7.26183024 5.54747577 5.3277323  4.31697872\n",
      " 4.94006563 6.2702414  4.57368325 5.89122965 6.12244732 6.67207574\n",
      " 5.23156394 5.29462307 5.77792405 5.34172821 6.36971479 6.07949134\n",
      " 3.68291553 5.57614141 5.57574496 5.04966526 5.49177775 5.50730341\n",
      " 5.92854527 5.12709456 5.44337244 5.58675233 4.78578452 6.5546404\n",
      " 5.36965319 4.47036552 4.39334177 6.37011291 6.0688034  4.9832146\n",
      " 5.76723026 5.19109882 5.92474962 7.30094491 6.4089682  5.70398958\n",
      " 6.4189805  5.3472607  5.29325656 5.23718232 4.62088781 4.70283784\n",
      " 6.1061098  5.599093   5.52115865 5.85765769 4.76407632 4.69278668\n",
      " 5.6007011  6.49771217 4.55147438 5.63114608 4.96035488 5.25034685\n",
      " 5.68741231 5.50886306 5.43450037 6.5424019  5.49376791 6.44279716\n",
      " 6.11477596 5.36623264 7.27107496 5.49154513 5.44564812 4.92919926\n",
      " 2.63213227 5.99099284 5.80799995 5.46502786 5.53428683 4.86006244\n",
      " 5.29575653 5.14347502 5.46245139 6.24724711 5.72040449 4.17329701\n",
      " 4.99747036 5.86126432 4.75688698 5.02835139 5.02042429 5.92672919\n",
      " 6.42758192 5.10607033 5.41575031 5.28081395 5.58737531 6.34281864\n",
      " 5.23948002 6.49413433 6.45470368 5.28304972 5.18704251 5.60535671\n",
      " 3.42704093 6.92052584 6.25623017 5.85969788 5.37548224 5.81452696\n",
      " 4.6322236  5.07649866]\n",
      "\n",
      "What it should be:  [6.66666667 6.16666667 7.         4.66666667 4.66666667 6.33333333\n",
      " 4.5        6.         4.33333333 5.66666667 5.16666667 6.\n",
      " 6.33333333 6.5        6.5        5.33333333 6.66666667 6.5\n",
      " 4.83333333 5.         6.83333333 6.33333333 4.5        6.83333333\n",
      " 5.33333333 6.16666667 5.33333333 5.66666667 5.16666667 6.33333333\n",
      " 6.5        6.16666667 4.33333333 7.         6.         6.33333333\n",
      " 5.83333333 5.33333333 5.5        6.16666667 4.5        5.83333333\n",
      " 5.83333333 4.66666667 5.33333333 6.5        6.5        4.83333333\n",
      " 6.5        6.83333333 6.16666667 5.33333333 5.83333333 3.66666667\n",
      " 5.66666667 6.5        4.66666667 3.33333333 5.66666667 6.83333333\n",
      " 6.66666667 6.16666667 6.         6.16666667 5.         6.16666667\n",
      " 4.66666667 6.83333333 4.         5.66666667 5.83333333 5.5\n",
      " 5.5        5.83333333 6.83333333 5.66666667 6.5        5.33333333\n",
      " 5.5        4.33333333 6.16666667 5.5        6.66666667 3.66666667\n",
      " 3.83333333 6.66666667 6.5        7.         4.83333333 4.33333333\n",
      " 7.         5.33333333 6.         5.33333333 6.16666667 6.16666667\n",
      " 5.16666667 4.5        6.5        6.         5.5        4.\n",
      " 4.5        6.33333333 6.66666667 6.83333333 4.83333333 5.\n",
      " 5.16666667 6.33333333]\n",
      "Correlation:  [[1.         0.28692607]\n",
      " [0.28692607 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.82574568 5.17523105 6.19121739 6.36093623 4.53264995 5.0923556\n",
      " 5.78090611 5.71537293 6.08976487 6.28452607 5.54315677 4.8117331\n",
      " 5.84111784 5.03580716 5.54550962 5.76113217 5.4578478  4.88703297\n",
      " 5.48229636 5.31400713 5.96756601 6.05582144 5.38400813 5.78816665\n",
      " 5.25676161 5.83987285 5.03376003 5.38039995 5.88182792 5.0471926\n",
      " 6.04466338 5.08056511 5.12315624 5.29499345 4.17056013 5.76938815\n",
      " 6.05313832 6.13957365 4.65414226 5.19375996 5.47050618 5.03922487\n",
      " 5.91575677 6.03845656 5.01370536 5.63602776 5.98088534 5.77263112\n",
      " 6.40324411 5.39497214 5.5257184  5.39626807 6.07493692 5.49697427\n",
      " 4.98331897 4.95593719 5.76740488 5.0203872  6.14022611 5.47047537\n",
      " 5.95931803 5.46900493 5.24609213 5.1484477  6.19902087 6.19203594\n",
      " 6.29314267 5.34033175 5.54464429 4.88275867 5.63068574 4.96647523\n",
      " 6.26644371 5.86451842 5.28821476 6.14986975 5.65493362 5.99256265\n",
      " 5.18213535 6.99509304 5.94690436 6.08855087 5.08837983 4.94265559\n",
      " 5.18424508 5.19625692 4.51223071 5.73837836 5.89769495 5.7061459\n",
      " 6.14542683 5.5977247  6.27654475 4.97396078 6.12220375 5.1284858\n",
      " 4.7809715  5.98596026 5.92947558 5.33043903 5.68538908 5.09288452\n",
      " 5.33480613 5.16158755 4.84711885 5.484805   4.88560024 5.93149011\n",
      " 5.37341089 6.42692271]\n",
      "\n",
      "What it should be:  [4.5        4.33333333 6.5        5.83333333 6.         5.66666667\n",
      " 6.5        6.         6.83333333 6.5        4.66666667 6.16666667\n",
      " 6.5        7.         6.5        5.         6.16666667 3.66666667\n",
      " 5.16666667 5.33333333 5.33333333 5.16666667 5.83333333 5.16666667\n",
      " 4.33333333 5.         6.         6.16666667 6.16666667 1.83333333\n",
      " 4.83333333 5.16666667 4.33333333 6.66666667 6.33333333 5.33333333\n",
      " 6.16666667 7.         3.66666667 6.16666667 6.16666667 6.83333333\n",
      " 5.5        5.5        4.         6.33333333 5.33333333 6.\n",
      " 4.16666667 4.83333333 6.16666667 6.66666667 6.5        5.5\n",
      " 5.33333333 6.5        6.83333333 6.33333333 6.33333333 4.33333333\n",
      " 5.33333333 6.16666667 4.66666667 3.33333333 6.16666667 4.66666667\n",
      " 5.66666667 5.83333333 6.66666667 5.33333333 5.83333333 5.83333333\n",
      " 6.5        4.83333333 6.33333333 5.16666667 3.66666667 5.66666667\n",
      " 5.83333333 6.16666667 5.16666667 6.         5.33333333 5.66666667\n",
      " 6.16666667 4.5        6.83333333 6.33333333 6.         4.\n",
      " 5.16666667 4.83333333 5.33333333 6.83333333 6.83333333 5.66666667\n",
      " 5.5        6.         6.83333333 6.16666667 5.16666667 6.\n",
      " 6.         5.         5.33333333 6.16666667 5.         6.66666667\n",
      " 3.5        5.5       ]\n",
      "Correlation:  [[1.         0.12885904]\n",
      " [0.12885904 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.16\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.50467502 5.69629628 5.80152367 5.0520154  5.47847885 6.24670759\n",
      " 5.30543697 5.93471934 6.20767301 5.52773717 5.98495183 6.32318555\n",
      " 5.86527193 5.50820107 5.87966622 5.87945223 4.96573562 6.08278085\n",
      " 5.9724008  6.00289503 6.15738998 5.88838287 5.59567815 6.73493661\n",
      " 5.79867138 6.05632502 5.94080153 5.96035476 5.57589111 4.97920406\n",
      " 4.70760327 5.95317399 7.00684177 5.83450753 6.43840794 5.91406282\n",
      " 6.10442014 6.57390644 5.27009292 4.94969412 5.88220241 5.3657871\n",
      " 5.23631979 4.84287287 6.48905149 5.46500408 4.80324669 5.8854441\n",
      " 5.7209117  4.50013241 5.2607794  5.27258051 5.75600804 6.20790089\n",
      " 5.62446139 6.30678119 6.56015108 5.74626677 6.23313282 5.95363205\n",
      " 5.0241198  5.7955492  6.01626799 6.63474777 6.24727572 5.1948869\n",
      " 5.87326944 6.15095174 5.12795885 5.04601509 4.56898545 5.38185645\n",
      " 5.7501462  5.9016713  6.12503387 5.82591321 5.7725337  6.18273839\n",
      " 5.60630749 6.19233701 4.71716792 5.69336468 3.9706251  5.64915221\n",
      " 5.5099757  5.49899782 5.61914383 5.49471726 6.37011807 5.81263034\n",
      " 6.16018407 4.59255202 5.82945116 5.17553643 5.93912395 5.50722153\n",
      " 5.65222556 5.10216771 5.29645126 5.5132857  4.89438809 5.32778201\n",
      " 6.09013176 5.70067919 5.99053846 4.29112453 5.07919393 6.198689\n",
      " 5.75924301 6.3527631 ]\n",
      "\n",
      "What it should be:  [6.16666667 6.83333333 6.         5.83333333 4.         4.66666667\n",
      " 5.33333333 6.16666667 4.16666667 4.83333333 6.33333333 4.33333333\n",
      " 3.66666667 5.33333333 6.16666667 6.         5.33333333 6.5\n",
      " 6.16666667 5.66666667 5.16666667 6.16666667 6.83333333 5.83333333\n",
      " 5.16666667 4.66666667 6.16666667 5.5        4.33333333 6.16666667\n",
      " 4.5        6.66666667 5.5        4.5        6.33333333 6.83333333\n",
      " 5.83333333 6.16666667 5.66666667 3.66666667 6.16666667 4.5\n",
      " 6.         6.33333333 5.83333333 5.33333333 5.16666667 6.33333333\n",
      " 6.66666667 6.83333333 5.83333333 4.66666667 6.33333333 6.\n",
      " 5.33333333 6.66666667 3.33333333 6.5        6.5        6.5\n",
      " 6.5        5.16666667 5.16666667 6.16666667 5.66666667 5.66666667\n",
      " 6.         4.5        3.66666667 5.5        7.         5.\n",
      " 4.5        6.33333333 6.83333333 6.16666667 7.         6.83333333\n",
      " 3.5        6.83333333 1.83333333 5.83333333 5.         5.33333333\n",
      " 5.16666667 5.33333333 5.83333333 4.83333333 6.5        6.5\n",
      " 6.33333333 5.5        6.5        6.         4.33333333 5.83333333\n",
      " 5.83333333 6.33333333 5.66666667 4.         4.         5.\n",
      " 4.         6.16666667 6.83333333 6.66666667 6.5        6.16666667\n",
      " 5.5        4.66666667]\n",
      "Correlation:  [[1.         0.12809865]\n",
      " [0.12809865 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.51844773 5.17542802 4.99150102 5.58265448 6.95450202 5.57894251\n",
      " 5.70911649 6.72906841 5.93964008 5.96737531 6.21259697 2.85001588\n",
      " 4.25382177 5.48601431 5.86556374 5.47057364 5.13753559 5.7739037\n",
      " 5.64229094 5.2496334  6.56748414 5.62244395 4.09661607 4.97400469\n",
      " 5.4184989  6.17522849 5.09941833 6.66303761 6.1228473  6.51643539\n",
      " 6.34021144 5.12458136 5.28262266 4.63996933 5.76877827 4.31384114\n",
      " 5.90447934 5.75566617 4.14375919 5.64062859 5.15139452 4.67698991\n",
      " 4.54079933 5.73939024 5.77046878 5.66040402 3.17599928 5.93931958\n",
      " 6.69502489 5.33220398 4.08076501 5.85628112 5.73480367 5.61909131\n",
      " 4.3682403  5.33684578 6.52825466 6.47603632 5.24836215 5.24402677\n",
      " 5.23089331 5.82323196 5.82704542 5.22836167 5.90760606 6.55187904\n",
      " 5.09593911 5.55697803 5.18421182 6.16796242 5.6553269  5.41310934\n",
      " 4.18210026 5.97606216 5.2365282  6.37013421 5.38049176 5.92069288\n",
      " 5.97472226 6.1227142  4.26389485 5.91777687 5.16272424 5.9276602\n",
      " 5.54158738 6.41049525 6.43978346 4.99082001 5.45927296 5.46520759\n",
      " 5.74486353 5.28761006 5.05261867 5.06162436 5.6534815  6.57333047\n",
      " 4.47638619 6.08209314 5.53543947 6.86778638 6.3234625  5.67743667\n",
      " 3.76811343 5.34565074 4.28538001 4.87652458 4.9961774  5.61927448\n",
      " 4.53996925 5.76840045]\n",
      "\n",
      "What it should be:  [6.66666667 5.16666667 4.83333333 5.33333333 6.66666667 6.66666667\n",
      " 5.33333333 5.83333333 6.16666667 6.16666667 6.16666667 4.83333333\n",
      " 6.5        5.83333333 5.83333333 6.         6.5        4.83333333\n",
      " 4.33333333 6.5        5.66666667 6.83333333 6.         4.83333333\n",
      " 6.         7.         7.         5.         6.5        5.16666667\n",
      " 5.33333333 6.83333333 6.         3.66666667 5.83333333 5.5\n",
      " 5.16666667 6.66666667 4.5        5.33333333 6.16666667 6.\n",
      " 6.16666667 4.5        6.5        6.33333333 5.5        5.33333333\n",
      " 5.33333333 7.         6.5        6.16666667 4.5        6.5\n",
      " 4.33333333 5.66666667 5.33333333 6.16666667 6.16666667 3.33333333\n",
      " 7.         6.         5.66666667 4.         4.66666667 6.33333333\n",
      " 6.5        6.16666667 4.66666667 5.33333333 4.66666667 6.33333333\n",
      " 6.16666667 5.5        6.16666667 6.33333333 5.5        6.5\n",
      " 5.33333333 5.16666667 6.83333333 5.66666667 6.         6.83333333\n",
      " 4.33333333 6.5        6.16666667 5.5        4.83333333 4.\n",
      " 3.5        4.83333333 6.16666667 6.66666667 5.83333333 4.16666667\n",
      " 6.33333333 6.33333333 4.66666667 6.5        6.16666667 4.83333333\n",
      " 3.83333333 5.83333333 5.66666667 4.33333333 4.66666667 6.66666667\n",
      " 5.         6.83333333]\n",
      "Correlation:  [[1.         0.13128976]\n",
      " [0.13128976 1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.19\n",
      "Median absolute error = 0.86\n",
      "Explain variance score = -0.51\n",
      "R2 score = -0.56\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.44174472 5.76390987 6.10468998 5.6233494  5.15737935 5.64632484\n",
      " 5.45396248 5.00784892 5.69957722 5.45258317 4.98391746 5.79194708\n",
      " 6.40076659 5.44286049 6.74168272 5.09575122 5.98792401 5.12320613\n",
      " 5.09947721 5.73617947 5.91679967 5.31647581 4.90061413 6.31462623\n",
      " 6.39477738 5.96470625 5.53857919 5.47861668 6.54347205 6.01284357\n",
      " 5.16326764 6.04426955 5.97486867 5.20586252 5.68830181 5.93885976\n",
      " 4.74518926 6.43301913 5.53385902 5.80879884 5.18662256 6.18815045\n",
      " 5.3322646  5.8043175  5.48816216 5.24244851 5.91158837 4.78135492\n",
      " 5.48905529 4.98346659 6.04502999 4.65121658 6.16149971 5.41729872\n",
      " 4.96119766 4.81666654 5.71202088 4.61244037 4.64252673 5.77408008\n",
      " 5.94045376 6.47930623 6.37860421 6.15709735 6.09124197 5.40224161\n",
      " 5.3917944  5.42384821 5.07375145 5.21365661 5.49402166 5.89477869\n",
      " 6.20029876 5.69173853 5.49795322 5.92263405 4.83912502 5.51970098\n",
      " 5.4494326  6.2476845  6.70089743 5.90504185 4.63322924 5.61526411\n",
      " 6.24036854 5.22634138 4.80944087 5.60202033 5.39424661 5.83593738\n",
      " 4.95005105 5.5651112  5.41493909 5.85098643 5.06969242 5.71650947\n",
      " 5.59274295 6.14897186 5.72346142 5.35904435 5.46637413 5.25467123\n",
      " 5.98470376 6.37097321 5.77510305 6.05856775 4.30694913 6.16939556\n",
      " 6.61523664 6.71508664]\n",
      "\n",
      "What it should be:  [5.66666667 5.5        5.16666667 6.5        5.5        6.\n",
      " 3.66666667 6.5        4.83333333 4.         5.33333333 4.33333333\n",
      " 6.5        3.         6.66666667 5.         6.         5.5\n",
      " 5.         5.33333333 6.5        5.5        5.33333333 7.\n",
      " 6.16666667 5.83333333 1.83333333 6.         5.33333333 6.\n",
      " 7.         6.16666667 6.16666667 4.66666667 6.         5.33333333\n",
      " 4.33333333 5.83333333 6.33333333 6.83333333 4.83333333 5.33333333\n",
      " 5.16666667 5.83333333 4.66666667 5.66666667 6.         6.\n",
      " 4.83333333 3.66666667 5.5        5.83333333 4.83333333 6.66666667\n",
      " 6.5        6.5        6.5        4.         6.66666667 6.33333333\n",
      " 6.16666667 6.33333333 5.16666667 5.         6.16666667 5.33333333\n",
      " 6.66666667 4.33333333 5.33333333 4.83333333 6.83333333 5.33333333\n",
      " 5.83333333 6.83333333 5.33333333 6.16666667 5.5        6.\n",
      " 5.83333333 5.66666667 5.83333333 5.83333333 6.33333333 4.5\n",
      " 5.5        4.5        6.16666667 5.66666667 6.16666667 6.\n",
      " 5.5        4.66666667 4.83333333 5.83333333 4.66666667 5.33333333\n",
      " 5.5        5.66666667 4.66666667 4.16666667 6.83333333 5.83333333\n",
      " 3.33333333 5.16666667 6.66666667 5.16666667 3.66666667 4.5\n",
      " 6.16666667 6.16666667]\n",
      "Correlation:  [[1.         0.19451428]\n",
      " [0.19451428 1.        ]]\n",
      "Mean absolute error = 0.74\n",
      "Mean squared error = 0.93\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.11\n",
      "R2 score = -0.12\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.2315105  6.37263883 4.97207595 5.96031385 5.3179787  6.06061646\n",
      " 6.33370823 6.43214014 6.21511719 6.51491222 6.35148697 4.10091407\n",
      " 5.75250877 5.97561483 2.63968791 5.84438129 5.061584   6.08947283\n",
      " 5.81763001 5.73083548 6.25420014 6.34794301 6.97482761 5.56082159\n",
      " 6.42885033 6.24096881 6.22951482 5.90881303 5.93133375 5.0756045\n",
      " 5.54094978 6.85435606 6.16433714 5.93394451 6.02060487 5.60716193\n",
      " 5.72051298 6.21003844 5.76907902 6.00657874 5.76553859 5.79560618\n",
      " 5.66783873 6.37655659 6.11117154 6.92817123 6.07161608 5.03452838\n",
      " 4.95774258 6.26148796 5.95830464 5.30806622 5.37424711 5.41203725\n",
      " 5.20764196 6.0426109  4.97346709 5.5815763  5.18602754 5.21499562\n",
      " 5.35105837 5.81795817 6.44134974 6.06419749 6.53231907 6.37839895\n",
      " 4.81211165 5.81026769 6.41775837 6.04285984 5.17783072 5.99959843\n",
      " 5.76362352 5.5695274  6.77169804 6.84088944 5.80548044 6.02018805\n",
      " 6.10751333 5.47336075 5.84695184 5.36411541 5.18621623 5.66789725\n",
      " 5.73627196 6.13684531 5.87903535 6.46045671 5.31539379 5.02941448\n",
      " 4.91234202 5.1237541  4.71846008 6.25710307 6.76488152 4.97165822\n",
      " 5.78413069 6.97638661 5.90304051 5.38695116 5.370422   4.74017899\n",
      " 6.3278097  5.67023256 5.79124718 5.45347221 5.30898952 7.18640343\n",
      " 5.72350545 6.22471416]\n",
      "\n",
      "What it should be:  [5.33333333 6.83333333 6.33333333 5.66666667 6.33333333 6.\n",
      " 5.16666667 5.33333333 5.5        5.33333333 6.16666667 4.83333333\n",
      " 6.16666667 6.16666667 5.5        4.83333333 3.5        4.\n",
      " 5.33333333 7.         7.         6.83333333 5.16666667 5.16666667\n",
      " 5.16666667 6.         6.5        5.16666667 5.66666667 5.\n",
      " 4.66666667 6.83333333 6.5        6.         5.83333333 5.33333333\n",
      " 5.33333333 6.         6.66666667 5.33333333 5.66666667 6.33333333\n",
      " 6.66666667 6.33333333 4.         7.         5.         4.33333333\n",
      " 6.16666667 4.         6.66666667 6.33333333 6.16666667 5.5\n",
      " 7.         5.16666667 3.83333333 6.         5.83333333 5.83333333\n",
      " 6.5        4.66666667 6.5        6.83333333 6.5        4.66666667\n",
      " 4.         3.         5.         4.16666667 3.33333333 5.33333333\n",
      " 5.5        6.5        5.16666667 5.         5.66666667 5.83333333\n",
      " 6.83333333 3.66666667 5.         6.         6.16666667 4.66666667\n",
      " 5.33333333 6.33333333 3.66666667 4.33333333 6.83333333 6.83333333\n",
      " 6.16666667 4.66666667 5.66666667 4.66666667 6.         6.16666667\n",
      " 5.66666667 4.66666667 6.5        5.33333333 4.5        4.83333333\n",
      " 5.83333333 5.5        5.83333333 5.33333333 4.33333333 6.33333333\n",
      " 6.         6.16666667]\n",
      "Correlation:  [[1.         0.13044666]\n",
      " [0.13044666 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.47218259 5.08031514 5.68790311 5.64599791 5.46030043 5.50320769\n",
      " 4.80724697 6.21980656 5.98902475 6.51820019 5.20806026 5.78817821\n",
      " 5.58117815 6.22646311 5.95631472 7.18582006 5.80755163 5.24103931\n",
      " 6.88856985 5.23588732 6.55728023 3.63580449 6.21724018 4.52418835\n",
      " 5.03743557 6.16484308 5.0875545  5.50577438 5.78022621 5.3188051\n",
      " 5.43432774 4.9242679  5.79725573 5.51508116 6.74527606 6.75698853\n",
      " 6.06233654 6.23942707 6.25929404 5.94747633 5.31315212 5.30204595\n",
      " 6.03304683 6.04408011 5.62683748 7.10551373 5.49844614 5.62497357\n",
      " 5.45554613 5.5378839  6.61987639 4.91649219 5.67972298 5.90772607\n",
      " 6.43071505 5.85506864 6.36727823 4.88017675 5.51866066 6.39980188\n",
      " 5.92458182 6.52071465 5.37048608 6.6468098  5.83188235 6.0884566\n",
      " 4.98267977 5.6411837  5.57861192 5.62208981 5.93517024 5.19674034\n",
      " 4.37084414 7.33720493 5.2101829  5.67869994 5.50599464 6.92546477\n",
      " 5.03661096 5.18372455 5.02706547 5.00740738 5.71250168 5.55035158\n",
      " 5.29424844 6.15700479 5.72088255 5.16878305 6.00943189 5.99968201\n",
      " 5.85013086 5.47159667 5.61521039 5.49935423 5.23506458 5.14828258\n",
      " 6.83374972 5.41658568 5.88867486 4.11474095 5.85218404 5.35703047\n",
      " 5.57937408 6.70763058 6.16664871 4.90127211 5.74681312 5.80170689\n",
      " 4.52031835 4.96050844]\n",
      "\n",
      "What it should be:  [1.83333333 5.5        5.5        6.66666667 5.16666667 6.5\n",
      " 5.66666667 6.5        3.66666667 4.5        4.5        6.16666667\n",
      " 4.66666667 6.         5.66666667 5.33333333 5.         6.5\n",
      " 5.83333333 5.         6.         5.5        6.83333333 6.66666667\n",
      " 5.33333333 5.83333333 6.5        6.16666667 5.16666667 5.5\n",
      " 6.83333333 5.33333333 4.33333333 6.83333333 5.16666667 6.5\n",
      " 5.5        6.         5.66666667 6.16666667 4.         5.33333333\n",
      " 6.5        4.83333333 6.83333333 4.33333333 5.         6.16666667\n",
      " 5.         5.5        5.5        7.         6.16666667 6.\n",
      " 6.5        6.16666667 6.16666667 4.66666667 6.5        5.83333333\n",
      " 7.         6.33333333 5.66666667 6.66666667 4.83333333 4.\n",
      " 4.66666667 6.16666667 5.33333333 6.16666667 5.33333333 5.66666667\n",
      " 6.83333333 6.33333333 3.66666667 4.33333333 5.5        6.83333333\n",
      " 5.83333333 6.5        6.33333333 5.83333333 5.33333333 6.33333333\n",
      " 6.16666667 6.83333333 5.33333333 5.16666667 5.66666667 4.\n",
      " 4.83333333 4.33333333 4.         6.         6.         4.83333333\n",
      " 6.16666667 6.33333333 5.         5.83333333 5.33333333 5.66666667\n",
      " 6.         5.83333333 6.         6.66666667 5.66666667 4.83333333\n",
      " 6.5        6.66666667]\n",
      "Correlation:  [[1.        0.0110031]\n",
      " [0.0110031 1.       ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.51\n",
      "R2 score = -0.51\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.31069409 6.74572285 5.133842   6.03303177 7.06404979 5.67107531\n",
      " 5.80369667 5.01377786 4.7457843  6.12437885 5.55773749 6.2789987\n",
      " 6.7668114  5.35006441 5.27067367 6.40190595 5.48345634 5.31318593\n",
      " 5.55914169 4.69030736 6.29459071 6.22420441 5.05035048 6.2362756\n",
      " 5.53756333 4.27016465 5.26717972 5.80725223 6.36678518 4.07768938\n",
      " 5.30941892 4.66180687 4.77559283 5.72401367 6.25254495 4.47751145\n",
      " 5.00116515 6.28950486 5.79646138 5.4735472  5.20002408 6.09272462\n",
      " 4.96579102 4.8628601  5.84449392 4.35936366 5.03742565 5.61379377\n",
      " 5.10813307 5.39380763 5.22976996 6.04183468 6.19057231 5.96756753\n",
      " 4.60201258 5.94521923 4.88345775 4.27979712 5.94681525 5.24533829\n",
      " 5.73844609 4.99858845 5.29086865 6.99166979 5.62309286 5.19871932\n",
      " 6.04905528 5.12930128 5.26927566 6.13521628 5.30114203 4.32402375\n",
      " 5.85013065 6.09806675 5.4453844  6.18076784 4.76478228 7.41872438\n",
      " 5.49260794 5.58585406 6.39559432 5.49619367 5.47740726 5.82748713\n",
      " 3.87835338 4.93464537 5.70952798 5.36329622 5.60857469 6.105973\n",
      " 5.89605891 5.79787063 5.72861771 6.37037409 5.91496822 5.4648108\n",
      " 5.87221531 6.655019   4.59051413 5.00728103 5.66538009 4.79465436\n",
      " 6.37735502 5.33353882 5.57855801 6.11918627 5.71450674 5.36662842\n",
      " 4.88938257 5.99909225]\n",
      "\n",
      "What it should be:  [5.66666667 6.66666667 4.66666667 6.83333333 7.         6.5\n",
      " 6.5        4.66666667 6.5        5.16666667 5.83333333 5.33333333\n",
      " 6.33333333 4.83333333 6.83333333 6.33333333 5.83333333 6.66666667\n",
      " 6.33333333 6.83333333 6.16666667 7.         5.33333333 6.\n",
      " 4.5        5.5        3.83333333 5.33333333 6.16666667 6.\n",
      " 5.83333333 6.33333333 7.         6.83333333 5.83333333 5.\n",
      " 6.33333333 4.83333333 6.16666667 5.83333333 5.66666667 6.16666667\n",
      " 6.5        4.33333333 6.5        4.5        5.         5.16666667\n",
      " 6.5        6.66666667 6.33333333 6.5        4.66666667 4.83333333\n",
      " 5.16666667 6.         6.33333333 3.66666667 6.66666667 5.5\n",
      " 6.16666667 4.33333333 5.33333333 6.66666667 5.83333333 4.83333333\n",
      " 6.16666667 5.83333333 5.33333333 6.33333333 6.         4.83333333\n",
      " 6.         6.16666667 6.83333333 5.66666667 6.16666667 6.5\n",
      " 4.         5.         5.33333333 6.83333333 6.83333333 5.\n",
      " 6.33333333 4.         5.16666667 5.33333333 4.5        5.33333333\n",
      " 5.         5.33333333 6.83333333 4.5        5.83333333 5.83333333\n",
      " 5.66666667 4.         5.33333333 5.66666667 5.83333333 4.66666667\n",
      " 4.5        6.5        4.33333333 6.16666667 4.66666667 5.66666667\n",
      " 4.16666667 5.33333333]\n",
      "Correlation:  [[1.         0.19532191]\n",
      " [0.19532191 1.        ]]\n",
      "Mean absolute error = 0.77\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.3\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.44743578 5.3661109  6.0897115  5.78504037 5.85669973 5.84317981\n",
      " 6.33766452 6.14302847 5.49917488 5.94043957 5.4654095  4.76164618\n",
      " 5.69150127 6.29322177 5.35691459 6.35894581 5.34943724 5.31988952\n",
      " 6.25691506 6.31206561 4.822463   5.54470285 5.99671068 5.52043595\n",
      " 5.30149243 5.6253176  5.66287503 5.38490336 5.31648255 5.50213906\n",
      " 4.56785644 6.19748942 5.94547221 4.99834013 4.71590872 5.3877682\n",
      " 5.56750184 6.67641654 5.91791765 5.33516916 6.08105972 5.4346318\n",
      " 6.83392443 4.97889404 4.84277993 4.62795725 5.76878594 5.64961684\n",
      " 6.06166114 4.7520016  5.98053117 5.86619522 6.41144491 5.71433949\n",
      " 6.19539797 5.97202484 6.15724222 5.71363034 4.55630409 5.01691284\n",
      " 5.06401195 5.15844269 5.41301575 5.54933022 5.31851274 5.47230614\n",
      " 5.72886786 5.89198398 6.13925125 5.86770938 4.54945259 5.95863968\n",
      " 4.76887503 5.37375904 4.20991552 5.4942936  5.55203011 6.17782105\n",
      " 6.22969787 6.45494332 5.95012472 5.42839707 5.25745471 6.42122259\n",
      " 5.92694447 5.63634848 6.65872588 5.54815654 5.45553712 6.25891604\n",
      " 4.3184977  4.7075404  5.441505   4.3218818  5.90568911 5.96841546\n",
      " 7.06459069 4.736392   5.97496939 4.74007304 5.56360784 5.60904905\n",
      " 4.47897735 5.79370964 5.76894858 5.27354325 5.97700964 5.45537146\n",
      " 5.74815104 4.66846016]\n",
      "\n",
      "What it should be:  [6.33333333 5.         6.5        6.16666667 6.66666667 4.83333333\n",
      " 5.83333333 5.66666667 6.         6.33333333 5.83333333 5.5\n",
      " 5.66666667 6.83333333 6.16666667 5.5        4.         4.83333333\n",
      " 6.83333333 5.83333333 5.83333333 6.         7.         4.33333333\n",
      " 5.5        3.66666667 6.66666667 5.         5.83333333 3.5\n",
      " 3.66666667 6.16666667 6.33333333 5.66666667 7.         5.33333333\n",
      " 4.66666667 5.66666667 6.5        5.16666667 6.         6.\n",
      " 5.83333333 4.83333333 3.66666667 6.33333333 4.5        5.66666667\n",
      " 6.33333333 6.5        5.         6.16666667 6.         6.16666667\n",
      " 6.66666667 5.         4.66666667 5.         4.83333333 6.5\n",
      " 6.83333333 6.16666667 6.66666667 4.83333333 6.83333333 1.83333333\n",
      " 6.         6.16666667 6.         6.66666667 6.83333333 4.\n",
      " 5.33333333 6.66666667 4.5        6.83333333 5.33333333 6.33333333\n",
      " 5.83333333 3.33333333 6.83333333 5.33333333 5.66666667 5.66666667\n",
      " 5.66666667 4.66666667 6.16666667 6.         5.5        4.33333333\n",
      " 4.66666667 4.83333333 5.16666667 7.         5.5        6.33333333\n",
      " 6.5        4.5        4.         5.5        6.16666667 6.5\n",
      " 6.16666667 6.5        6.33333333 5.33333333 5.33333333 6.\n",
      " 6.5        6.16666667]\n",
      "Correlation:  [[1.        0.1171594]\n",
      " [0.1171594 1.       ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.58\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.24\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.79172122 5.45184819 7.36846307 5.36587163 6.26714697 5.75143262\n",
      " 6.09105351 5.52273143 6.06210678 6.07380213 2.63167744 5.24004708\n",
      " 5.50442368 5.26139225 6.25857139 6.01406615 6.75120405 6.26864859\n",
      " 6.39948068 5.35123067 5.87640024 6.94560052 5.41935363 6.13955427\n",
      " 5.89456974 4.90865246 6.43815489 6.66318665 5.06154873 6.18179001\n",
      " 4.81279803 4.82223149 5.15109864 6.75123495 6.8496788  5.01777534\n",
      " 6.32058009 5.8407931  5.48579997 6.54110688 5.09292461 3.47157284\n",
      " 5.55709974 7.29572458 6.28487784 6.3306258  5.09716561 5.16761837\n",
      " 6.31484027 6.16242461 5.33482166 5.82928981 5.24268185 4.24856279\n",
      " 4.98903396 6.9495803  4.5846631  4.98413328 5.84356345 6.59527424\n",
      " 6.34529871 4.59668454 5.60902814 6.50942926 6.50148609 4.95822661\n",
      " 5.69939223 5.56025892 7.38287523 5.60049115 5.00298935 6.17732245\n",
      " 5.52023971 6.71642844 6.54563391 5.6337693  6.27085195 5.10637993\n",
      " 5.55487286 5.15894367 5.88885439 7.29794078 4.69490925 5.7132001\n",
      " 6.54393057 5.83691384 6.25784732 5.50617284 4.87148374 4.91938449\n",
      " 5.45781061 6.50108219 5.86869099 5.37233596 5.82228101 5.71424939\n",
      " 6.62800083 6.48765192 6.03155111 5.58586818 6.84019051 6.0298965\n",
      " 6.32979784 5.45139118 6.13044673 4.7771863  7.06917108 6.1278562\n",
      " 5.44819883 5.9357499 ]\n",
      "\n",
      "What it should be:  [5.33333333 6.83333333 5.66666667 4.5        5.66666667 5.66666667\n",
      " 4.83333333 5.         5.16666667 5.16666667 4.83333333 6.16666667\n",
      " 5.33333333 5.5        5.33333333 5.83333333 4.5        5.\n",
      " 5.16666667 5.83333333 4.5        4.         6.66666667 5.33333333\n",
      " 3.5        3.66666667 6.         6.16666667 6.16666667 5.5\n",
      " 6.83333333 3.66666667 6.16666667 5.33333333 5.66666667 4.83333333\n",
      " 6.16666667 6.5        5.16666667 5.5        6.33333333 5.5\n",
      " 4.83333333 6.5        6.16666667 6.5        5.83333333 6.33333333\n",
      " 6.66666667 6.16666667 6.         5.33333333 5.33333333 6.5\n",
      " 6.5        6.66666667 5.83333333 6.16666667 5.33333333 6.16666667\n",
      " 6.16666667 3.83333333 6.33333333 7.         6.66666667 6.66666667\n",
      " 6.         6.         5.66666667 4.66666667 5.5        4.16666667\n",
      " 5.33333333 6.33333333 6.         5.         6.83333333 6.16666667\n",
      " 6.66666667 4.         5.16666667 3.         5.33333333 4.\n",
      " 6.16666667 6.         5.83333333 5.16666667 5.         6.\n",
      " 5.83333333 4.66666667 5.83333333 4.33333333 4.66666667 5.5\n",
      " 6.33333333 6.5        5.83333333 4.66666667 6.5        6.5\n",
      " 5.33333333 5.5        5.33333333 5.66666667 5.16666667 5.16666667\n",
      " 6.         7.        ]\n",
      "Correlation:  [[1.        0.0786918]\n",
      " [0.0786918 1.       ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.72\n",
      "R2 score = -0.78\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.91549318 5.93792408 5.50739602 5.20805027 5.98585351 5.39257143\n",
      " 5.75277882 5.91702586 5.98113454 6.07110718 5.57406478 5.30844741\n",
      " 6.42186801 5.42291679 6.58696169 5.04753858 6.41428355 5.69494542\n",
      " 5.38491042 6.01418161 6.17943709 5.86805789 5.1803584  5.62263259\n",
      " 5.44931085 5.73150991 7.09563958 5.13766939 5.37696042 6.33786105\n",
      " 3.94067021 5.26533831 6.26140218 5.94410437 5.1981602  5.20436522\n",
      " 5.38769913 5.50870378 6.12046037 5.14769795 4.19125602 5.59558586\n",
      " 5.10517236 6.55484725 6.53693736 6.58711403 5.86716532 6.82883349\n",
      " 5.00202436 6.56870041 5.62925474 5.55839533 4.29379947 6.53705235\n",
      " 4.91842034 4.20864804 5.72789121 5.63102506 5.3526689  6.00073919\n",
      " 5.30474656 5.57912357 3.93599755 6.46683683 5.88208198 5.03282143\n",
      " 6.29658009 5.41631824 6.21840554 6.3718678  4.53324009 5.1462415\n",
      " 6.62941432 4.74529402 4.79471206 5.17833802 5.76868441 5.70353113\n",
      " 5.93135905 6.27869442 6.34138217 7.04009156 5.69682084 6.02400912\n",
      " 5.49280058 6.25891008 6.72877228 5.80513618 5.51843124 6.17177545\n",
      " 5.98764033 5.92880465 5.97988576 5.95165087 5.70409299 6.52086401\n",
      " 4.7854814  5.06630458 6.41682536 6.05317706 6.1551977  5.82058358\n",
      " 6.18667893 4.98527063 5.21240303 4.58543911 6.10790015 6.65796943\n",
      " 4.73630312 5.95602442]\n",
      "\n",
      "What it should be:  [3.33333333 5.33333333 3.5        6.         6.         5.66666667\n",
      " 6.         6.         6.33333333 4.         5.33333333 6.5\n",
      " 6.5        5.33333333 4.         4.5        6.16666667 4.33333333\n",
      " 6.33333333 6.5        5.33333333 5.16666667 5.83333333 6.66666667\n",
      " 6.         5.33333333 5.16666667 5.16666667 5.66666667 6.\n",
      " 4.83333333 5.5        5.33333333 6.83333333 6.16666667 6.16666667\n",
      " 6.5        5.33333333 4.16666667 5.83333333 3.66666667 5.33333333\n",
      " 5.83333333 5.66666667 5.83333333 5.83333333 6.         4.66666667\n",
      " 4.66666667 6.16666667 5.33333333 5.83333333 4.33333333 6.16666667\n",
      " 7.         6.33333333 5.         6.16666667 4.33333333 6.33333333\n",
      " 4.33333333 4.5        5.83333333 6.16666667 3.66666667 3.66666667\n",
      " 6.33333333 5.83333333 5.5        6.5        6.         5.83333333\n",
      " 4.83333333 6.16666667 6.5        6.16666667 6.66666667 6.33333333\n",
      " 6.83333333 5.83333333 5.16666667 4.5        6.66666667 7.\n",
      " 5.16666667 6.83333333 7.         4.83333333 4.66666667 6.16666667\n",
      " 5.33333333 5.83333333 6.66666667 5.33333333 5.83333333 5.5\n",
      " 5.33333333 5.66666667 6.5        5.33333333 6.16666667 6.5\n",
      " 6.33333333 6.5        4.         6.33333333 6.83333333 5.16666667\n",
      " 6.         4.66666667]\n",
      "Correlation:  [[1.         0.07770388]\n",
      " [0.07770388 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.45\n",
      "R2 score = -0.46\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.06874086 5.5963417  5.70027868 5.69327257 6.599902   6.04198874\n",
      " 5.96625704 6.39130977 5.70122957 5.9094433  5.73694511 5.0190109\n",
      " 4.57515645 6.27532301 5.60474379 5.65430929 5.9380527  5.68470107\n",
      " 5.86654378 6.04615146 4.94599763 6.31820277 5.77988936 6.20889895\n",
      " 4.58539101 4.90173747 4.40373056 4.56944157 6.84560612 4.4773892\n",
      " 6.82932026 5.02749579 4.47459807 6.70773844 3.37922893 5.04250747\n",
      " 6.39145247 5.52791806 5.07676147 5.76168261 4.99838565 6.137863\n",
      " 6.47834982 5.43437446 5.26579953 4.72199462 6.23703796 4.78102171\n",
      " 6.1677256  5.71110393 5.04854316 5.10426866 6.40489836 6.12445264\n",
      " 5.40178623 4.87138501 6.69310513 5.17303383 6.54661882 6.32941903\n",
      " 5.00329865 6.02923007 5.47154284 5.64498596 6.30035559 5.30202906\n",
      " 6.30152234 5.24154315 5.53153629 6.00435039 4.97387502 5.05008483\n",
      " 5.60183343 4.39660553 5.66251014 6.44719236 6.32517266 6.18131005\n",
      " 5.60684362 5.34266309 5.759879   5.57003937 5.93176352 5.69704299\n",
      " 5.00017658 6.53996961 6.54926279 4.91997628 5.3344726  5.85495208\n",
      " 5.91803696 5.86609666 5.43056462 4.6865351  5.55310233 5.20800681\n",
      " 5.74886678 6.20202416 5.02551507 5.39868573 7.10501856 4.90431257\n",
      " 5.6816376  5.19037081 6.52733926 4.7135206  6.25972536 5.63575827\n",
      " 6.30423162 6.43168788]\n",
      "\n",
      "What it should be:  [5.66666667 6.5        4.83333333 5.33333333 6.16666667 6.16666667\n",
      " 6.66666667 5.33333333 6.83333333 5.33333333 6.16666667 5.33333333\n",
      " 6.         6.33333333 5.83333333 7.         4.5        5.66666667\n",
      " 3.5        5.83333333 6.66666667 7.         5.83333333 5.16666667\n",
      " 6.5        5.         5.5        6.33333333 6.33333333 5.16666667\n",
      " 6.33333333 6.         4.5        6.5        3.         6.5\n",
      " 6.16666667 6.66666667 1.83333333 6.33333333 7.         6.33333333\n",
      " 6.16666667 5.         4.         4.         5.66666667 5.83333333\n",
      " 5.16666667 4.5        6.16666667 5.83333333 5.83333333 6.16666667\n",
      " 4.83333333 6.5        5.83333333 6.66666667 6.5        6.\n",
      " 6.83333333 6.5        6.         6.16666667 5.16666667 6.\n",
      " 6.5        4.5        4.83333333 7.         5.33333333 4.66666667\n",
      " 3.66666667 6.16666667 6.         5.33333333 5.33333333 6.16666667\n",
      " 4.         5.5        6.         4.33333333 5.         5.16666667\n",
      " 6.5        6.         5.33333333 5.5        6.83333333 4.83333333\n",
      " 6.5        3.33333333 5.5        6.66666667 4.83333333 4.83333333\n",
      " 5.33333333 5.33333333 4.66666667 6.83333333 5.33333333 6.83333333\n",
      " 4.66666667 6.         6.16666667 4.66666667 6.83333333 4.5\n",
      " 5.66666667 5.66666667]\n",
      "Correlation:  [[1.         0.18983834]\n",
      " [0.18983834 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.16634864 5.96850644 5.8238212  5.19296006 5.65088327 6.20810938\n",
      " 5.72585179 4.8447012  5.53222553 5.62567106 5.93311436 6.08235109\n",
      " 5.45700085 5.81404977 6.23445569 6.2913933  6.55482228 6.2965154\n",
      " 6.36320665 5.45191655 6.09949484 6.7095503  5.56134567 6.31514235\n",
      " 4.57065883 5.49711295 6.06283023 6.11120531 5.98278723 5.21181704\n",
      " 5.1319108  5.77523756 5.62041079 6.59007458 6.48077747 4.42121204\n",
      " 5.17468902 5.99063009 5.74591571 5.79953603 6.43059474 6.02935349\n",
      " 5.27300547 6.04183328 5.24014845 6.18557496 4.68752984 6.5598531\n",
      " 6.33721267 6.38965975 5.81459006 4.59485042 6.04107363 6.37029407\n",
      " 6.77140305 5.11873977 5.70880761 5.39413393 6.8353827  5.70383042\n",
      " 5.28816084 6.71193861 4.62109649 4.58751717 6.05009932 4.94465249\n",
      " 4.97525696 5.79963326 6.19186977 6.42996171 5.45701216 6.31886949\n",
      " 6.27014528 6.28291538 5.78528883 6.00655037 5.70025198 6.94744644\n",
      " 5.35188765 6.31755734 4.67461957 6.23621138 6.37943309 4.92432857\n",
      " 5.88622222 5.27056809 6.30233095 6.66474493 5.84754418 6.91752978\n",
      " 6.71903226 5.44673331 5.69879455 5.7797486  5.78122907 5.45806473\n",
      " 7.35596205 5.56256125 5.93900691 5.76126739 5.40701849 6.23208516\n",
      " 4.51144494 5.9648666  5.9110576  5.46460002 5.12087199 5.76700663\n",
      " 5.20711441 4.32275692]\n",
      "\n",
      "What it should be:  [6.5        5.5        6.5        6.16666667 4.         4.5\n",
      " 5.33333333 6.16666667 6.66666667 6.33333333 5.16666667 4.66666667\n",
      " 6.         6.66666667 5.83333333 6.5        6.         6.16666667\n",
      " 7.         5.66666667 4.5        6.33333333 3.66666667 6.5\n",
      " 6.66666667 5.66666667 5.33333333 6.66666667 4.83333333 6.33333333\n",
      " 5.66666667 4.         5.         6.33333333 6.         6.33333333\n",
      " 5.         6.66666667 5.5        5.66666667 4.5        6.\n",
      " 6.         6.16666667 5.5        6.16666667 6.33333333 4.33333333\n",
      " 6.66666667 6.33333333 3.66666667 5.83333333 3.33333333 5.33333333\n",
      " 6.33333333 6.83333333 5.33333333 6.83333333 5.66666667 6.83333333\n",
      " 4.83333333 5.66666667 5.33333333 6.83333333 6.5        3.66666667\n",
      " 4.33333333 5.66666667 6.83333333 5.16666667 6.         4.66666667\n",
      " 5.33333333 6.         5.83333333 5.33333333 6.83333333 6.83333333\n",
      " 5.         5.5        6.5        6.5        6.5        5.83333333\n",
      " 6.         4.33333333 5.33333333 4.5        6.66666667 5.\n",
      " 5.16666667 5.5        6.33333333 5.33333333 6.83333333 6.66666667\n",
      " 3.         4.66666667 4.         6.5        6.16666667 6.33333333\n",
      " 5.83333333 5.33333333 5.16666667 4.66666667 5.         6.16666667\n",
      " 6.5        4.83333333]\n",
      "Correlation:  [[ 1.         -0.09520618]\n",
      " [-0.09520618  1.        ]]\n",
      "Mean absolute error = 0.9\n",
      "Mean squared error = 1.33\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.63\n",
      "R2 score = -0.65\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.85209547 5.33472198 6.30963487 5.2060718  5.84207722 6.33686495\n",
      " 6.02881043 5.42493296 5.54020012 5.18547649 5.01816582 5.42811838\n",
      " 5.33002002 5.62244937 4.90497105 6.28263942 5.67724634 5.41071418\n",
      " 5.0533373  6.42689106 5.58949676 5.7444065  4.66283059 6.13564644\n",
      " 6.80236093 5.68353178 5.30858305 5.08956535 5.39841603 5.0793363\n",
      " 5.4529267  5.90487196 4.10002948 5.48432126 4.40992881 6.03225678\n",
      " 6.33990136 5.98970209 5.87329317 5.31748334 6.51303019 5.42338804\n",
      " 4.88654081 5.15950351 5.86000452 5.96783844 6.01059092 5.95910033\n",
      " 4.36199819 5.39731917 6.25133949 5.98280183 5.0961151  6.21936783\n",
      " 5.58589158 5.63662269 4.08023057 6.43308467 5.69402695 6.38370712\n",
      " 5.80841831 4.88451908 5.63453505 5.84183768 5.75206047 6.01666185\n",
      " 5.75656794 6.24479281 5.59850198 6.00567474 5.53957596 5.89293019\n",
      " 5.96989091 5.75265973 4.99110552 5.88493251 5.68957353 5.03771914\n",
      " 5.59528676 6.33749748 5.5948069  5.66080777 5.46868146 5.04859322\n",
      " 5.36290382 6.07837351 4.37563963 4.88925878 5.60603083 5.10666334\n",
      " 5.94202031 4.7135055  6.47144486 5.78316779 5.09167282 4.56251746\n",
      " 5.84771961 4.65376118 4.78702878 6.04700838 6.44624114 5.38005593\n",
      " 5.40649442 4.96097334 6.06317196 6.22709271 5.00060805 6.36275179\n",
      " 5.78709337 6.00050821]\n",
      "\n",
      "What it should be:  [6.33333333 6.         6.         1.83333333 6.16666667 6.5\n",
      " 6.66666667 5.33333333 5.33333333 4.83333333 6.16666667 5.33333333\n",
      " 5.33333333 5.83333333 5.33333333 6.16666667 6.33333333 5.66666667\n",
      " 4.83333333 4.5        3.66666667 5.16666667 6.83333333 6.83333333\n",
      " 6.5        5.66666667 6.5        5.83333333 6.33333333 6.\n",
      " 6.83333333 5.83333333 4.         5.83333333 6.66666667 6.\n",
      " 3.83333333 5.83333333 5.66666667 5.33333333 4.         6.83333333\n",
      " 6.         6.16666667 6.5        5.83333333 6.33333333 6.16666667\n",
      " 5.         6.5        6.83333333 5.16666667 6.         5.66666667\n",
      " 4.5        5.16666667 5.5        6.16666667 6.16666667 5.33333333\n",
      " 6.16666667 4.83333333 6.66666667 6.16666667 6.16666667 6.83333333\n",
      " 5.5        4.33333333 5.         4.66666667 5.66666667 5.16666667\n",
      " 6.         6.33333333 3.66666667 6.5        6.5        6.33333333\n",
      " 6.5        6.33333333 5.16666667 6.16666667 7.         4.5\n",
      " 4.83333333 6.         6.66666667 5.83333333 5.16666667 5.5\n",
      " 5.66666667 5.16666667 5.83333333 5.         5.33333333 4.83333333\n",
      " 5.83333333 4.33333333 5.83333333 6.16666667 5.66666667 5.5\n",
      " 5.5        6.5        5.         6.16666667 4.66666667 3.\n",
      " 5.5        7.        ]\n",
      "Correlation:  [[1.         0.11650764]\n",
      " [0.11650764 1.        ]]\n",
      "Mean absolute error = 0.72\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.54\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.34338671 5.43700888 6.09126428 5.74929154 6.83781621 5.79978383\n",
      " 5.89806227 5.6484536  5.759517   5.99639961 5.52434948 6.55849079\n",
      " 5.82862999 6.74783034 6.08351663 6.15004458 6.74928688 6.0412326\n",
      " 6.49837973 5.93766535 6.69065925 5.35200881 6.73258059 5.24893647\n",
      " 6.08971206 6.27341671 4.66506458 5.13102702 6.8871633  5.98585982\n",
      " 5.86632851 5.46739878 5.36849691 5.92130693 5.43551454 6.30943244\n",
      " 6.35627984 6.2566491  5.52923468 6.12100793 5.97838457 4.99868022\n",
      " 6.93807247 5.73674258 5.91658435 6.62133975 4.56195574 5.87099224\n",
      " 6.19464636 5.49074799 6.57558542 6.2618812  5.55969586 5.6536152\n",
      " 5.97651675 5.97750444 6.08208012 5.94991835 5.52669316 5.90798749\n",
      " 5.58196803 5.2685038  6.03013564 6.53198621 6.51279522 5.69744216\n",
      " 5.23246653 6.33469479 5.529365   5.4171376  4.79754508 5.66564721\n",
      " 6.27317191 6.35269425 5.69445363 5.62129935 5.33211751 5.66321854\n",
      " 6.26129725 6.13893344 5.49230295 5.99140376 5.77539652 5.44241201\n",
      " 5.09687164 5.69121728 6.73669772 6.05576839 4.68055533 3.8600786\n",
      " 5.34500654 4.73535267 5.93928531 5.9888851  4.67853319 5.31972291\n",
      " 5.62443287 6.896692   6.93607601 5.78039341 5.93358593 6.13874713\n",
      " 5.92667184 6.11517427 5.33439726 5.79649378 7.0328436  5.12246546\n",
      " 6.56450594 6.43879095]\n",
      "\n",
      "What it should be:  [4.         6.33333333 5.33333333 4.33333333 6.33333333 5.66666667\n",
      " 5.83333333 3.66666667 5.         6.5        6.83333333 6.16666667\n",
      " 5.33333333 5.66666667 5.83333333 7.         4.66666667 3.66666667\n",
      " 3.83333333 6.5        5.66666667 5.33333333 6.16666667 6.16666667\n",
      " 6.16666667 6.         5.5        3.66666667 6.5        5.33333333\n",
      " 5.16666667 4.5        6.5        5.5        6.83333333 4.33333333\n",
      " 6.83333333 6.33333333 6.33333333 5.33333333 6.16666667 6.66666667\n",
      " 5.83333333 4.66666667 5.16666667 4.83333333 4.5        5.\n",
      " 5.5        6.         6.16666667 6.         3.5        6.16666667\n",
      " 5.16666667 6.5        5.66666667 5.         5.16666667 6.16666667\n",
      " 5.16666667 6.         6.5        6.5        4.83333333 4.83333333\n",
      " 4.83333333 6.5        5.83333333 4.5        4.         6.33333333\n",
      " 4.         6.         6.66666667 4.         6.16666667 4.66666667\n",
      " 5.66666667 1.83333333 4.83333333 6.16666667 6.16666667 6.5\n",
      " 5.5        4.16666667 6.         5.16666667 4.         3.\n",
      " 5.33333333 6.33333333 6.         5.         7.         4.5\n",
      " 6.66666667 6.33333333 7.         6.33333333 5.83333333 5.33333333\n",
      " 7.         6.66666667 6.16666667 5.83333333 6.83333333 6.66666667\n",
      " 5.33333333 5.66666667]\n",
      "Correlation:  [[1.         0.22464661]\n",
      " [0.22464661 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.15\n",
      "Median absolute error = 0.75\n",
      "Explain variance score = -0.08\n",
      "R2 score = -0.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.80688056 6.06259742 5.68911342 6.60481785 4.94705118 6.1807064\n",
      " 5.87800805 5.99121629 5.87243942 5.50620272 5.79495984 6.24669067\n",
      " 6.06015311 6.43773181 5.65615963 6.09627397 5.71388167 5.43219059\n",
      " 6.62909181 5.35093438 5.87753959 5.61861417 6.10897291 5.96861323\n",
      " 6.21572324 5.06615427 5.27724356 5.14577204 4.34456159 6.66133429\n",
      " 3.20055167 5.03657405 4.63549566 5.32898115 6.13644178 5.78503821\n",
      " 5.60478055 5.34262095 4.65148025 4.09345266 5.84503989 5.11840879\n",
      " 5.84271851 5.04729718 6.34344846 6.81630634 6.22411298 6.4657291\n",
      " 5.98988507 5.99071848 6.3331673  7.27487183 5.73955358 5.29628486\n",
      " 5.42252219 5.30418899 4.4212792  5.30885288 4.33335708 5.1811079\n",
      " 4.64330917 6.35038255 6.29102755 6.17606053 6.28764466 5.23640181\n",
      " 6.23643283 5.7830656  5.4263896  5.11597184 6.03994392 5.29339186\n",
      " 5.42211898 5.88373249 5.01604087 4.95516248 5.78535005 5.62307827\n",
      " 5.34439533 6.00594399 4.9593204  4.23971786 5.74751368 4.54699417\n",
      " 5.73768028 4.99630784 6.08003107 5.99654201 5.62696849 6.71866948\n",
      " 7.06001919 4.96227009 4.85443255 5.9343682  6.25739322 6.32951368\n",
      " 5.27963002 5.9415583  5.2518157  5.65550225 6.01407101 5.95770257\n",
      " 5.51900298 6.47733287 4.93452102 5.51982005 5.5452685  5.45729515\n",
      " 4.17168573 6.3521318 ]\n",
      "\n",
      "What it should be:  [5.33333333 4.5        5.5        6.         6.16666667 4.16666667\n",
      " 5.5        5.33333333 7.         5.66666667 5.33333333 5.83333333\n",
      " 6.33333333 6.66666667 6.16666667 5.16666667 5.33333333 6.5\n",
      " 6.16666667 6.66666667 6.66666667 5.66666667 6.83333333 5.83333333\n",
      " 7.         4.66666667 5.16666667 5.83333333 6.16666667 6.83333333\n",
      " 4.83333333 4.83333333 6.33333333 6.33333333 4.5        6.\n",
      " 4.66666667 6.16666667 6.16666667 5.83333333 4.         4.33333333\n",
      " 5.83333333 7.         4.         6.16666667 5.33333333 5.33333333\n",
      " 5.33333333 5.66666667 6.66666667 6.33333333 6.16666667 4.83333333\n",
      " 5.5        6.33333333 6.16666667 6.         5.5        5.66666667\n",
      " 4.83333333 6.83333333 6.33333333 6.33333333 5.33333333 5.\n",
      " 5.16666667 6.         6.         4.66666667 5.5        5.\n",
      " 6.83333333 5.83333333 6.16666667 6.16666667 5.66666667 4.66666667\n",
      " 5.33333333 6.83333333 4.83333333 3.83333333 6.         6.83333333\n",
      " 6.16666667 6.16666667 5.33333333 5.33333333 6.16666667 3.\n",
      " 5.16666667 5.83333333 4.83333333 5.66666667 6.5        4.66666667\n",
      " 6.16666667 7.         6.66666667 5.16666667 6.5        6.5\n",
      " 4.33333333 6.         6.5        5.33333333 6.33333333 5.5\n",
      " 6.5        6.16666667]\n",
      "Correlation:  [[1.         0.04641189]\n",
      " [0.04641189 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.05\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.63\n",
      "R2 score = -0.65\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.87538393 5.47433608 5.67898324 5.77961421 6.39350617 5.85876016\n",
      " 5.65334123 5.01847943 5.43576736 5.72071239 5.21100998 5.19151623\n",
      " 6.39069804 5.5214844  5.64134632 4.99592697 6.02733149 6.69330022\n",
      " 6.28880181 5.33329218 4.80066088 5.75100948 5.44393739 5.57262487\n",
      " 4.89086649 5.6440519  5.71397869 6.67980235 5.7644481  4.64775591\n",
      " 6.39285625 6.6927098  5.20603527 5.56137751 5.65917485 5.3565729\n",
      " 6.24820118 4.26523739 6.03613383 5.34246853 5.36398488 5.45072082\n",
      " 5.42581624 6.36322318 5.69323557 4.77171679 5.36798508 4.97681629\n",
      " 4.95445765 5.892555   5.80298089 5.11592137 5.62041485 4.42177932\n",
      " 6.1036263  5.53953055 5.35869155 5.35954667 6.56096169 5.32940651\n",
      " 5.42522019 4.76459202 6.33928983 6.0673208  6.03760327 6.46760668\n",
      " 6.04777433 4.67430259 6.04342401 6.45040835 6.04271733 5.74954777\n",
      " 6.29553227 3.98699479 5.32985535 6.46074388 4.81077732 5.32417547\n",
      " 5.61310925 7.58586454 7.21014083 6.01926805 5.11668071 6.18322601\n",
      " 5.61105558 5.40654022 5.84976529 5.39746838 5.37101124 5.31658554\n",
      " 6.63551527 5.47769801 5.41071189 5.46647387 5.98320314 6.18840712\n",
      " 5.86792071 6.50141593 5.95568612 4.57330674 5.58849239 5.6787928\n",
      " 5.04954253 6.26438957 6.35958521 5.81362038 5.47266516 5.75029758\n",
      " 5.18891553 5.50998105]\n",
      "\n",
      "What it should be:  [6.83333333 1.83333333 6.16666667 6.5        6.5        6.\n",
      " 3.33333333 6.         4.83333333 5.5        6.5        5.66666667\n",
      " 4.16666667 4.         5.83333333 4.         5.16666667 4.83333333\n",
      " 6.         4.33333333 5.83333333 5.66666667 3.         5.5\n",
      " 6.66666667 7.         4.83333333 6.16666667 6.         6.\n",
      " 5.66666667 5.16666667 6.16666667 5.16666667 6.33333333 5.83333333\n",
      " 6.33333333 4.83333333 6.16666667 5.66666667 4.33333333 5.83333333\n",
      " 6.66666667 5.66666667 6.5        3.66666667 5.83333333 6.83333333\n",
      " 6.33333333 5.66666667 6.5        5.33333333 6.33333333 6.16666667\n",
      " 5.83333333 4.66666667 6.5        4.83333333 6.5        5.\n",
      " 6.         6.5        6.16666667 5.83333333 4.66666667 5.33333333\n",
      " 5.33333333 5.33333333 5.33333333 5.83333333 6.83333333 5.83333333\n",
      " 5.5        5.5        5.33333333 6.16666667 6.33333333 7.\n",
      " 5.16666667 4.66666667 6.16666667 5.5        4.83333333 6.5\n",
      " 6.         5.66666667 6.5        5.16666667 5.83333333 5.83333333\n",
      " 7.         6.         5.5        4.66666667 4.66666667 6.16666667\n",
      " 5.         6.83333333 6.83333333 6.5        6.16666667 6.66666667\n",
      " 5.         5.33333333 6.33333333 6.16666667 6.16666667 4.66666667\n",
      " 4.83333333 3.5       ]\n",
      "Correlation:  [[1.         0.09296921]\n",
      " [0.09296921 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.64519385 5.98273457 5.87053808 6.31305102 5.30501731 6.16120013\n",
      " 6.63480164 4.03348397 5.75723845 4.41611614 4.74498684 4.90759161\n",
      " 6.32092488 4.898136   5.7099112  6.03179377 5.07101938 4.80418663\n",
      " 6.12863011 3.86182707 6.0157052  5.01316533 6.24338969 5.64568491\n",
      " 5.47781666 6.66139195 4.83853405 6.91491373 6.62200541 6.59000674\n",
      " 4.82941285 5.52744789 5.41100765 5.68319474 5.91198037 5.56743895\n",
      " 6.05057289 5.32913707 4.41527767 6.27697542 6.34279223 5.92429146\n",
      " 6.7955872  5.28548365 5.6586295  5.83358625 5.50717807 4.95135118\n",
      " 4.68913044 5.12870104 5.63500135 6.12107436 6.034496   5.1823333\n",
      " 5.54820803 7.23777396 5.50947881 6.02295605 5.01708825 6.21760543\n",
      " 5.50800209 6.32466848 5.47331573 5.14828908 5.32999412 5.37395464\n",
      " 5.72749925 6.34604589 6.45783897 6.64805646 4.62839835 6.05586039\n",
      " 5.84386631 5.59765461 5.43595644 6.61405372 4.40048098 5.77531764\n",
      " 4.21442917 6.27527509 5.92411426 4.70852584 6.03838098 5.5217781\n",
      " 6.41080259 7.9167598  6.67331149 6.57852993 5.31581564 6.29245562\n",
      " 4.45234469 4.95569906 4.58079641 5.78359925 5.37333622 5.77815815\n",
      " 4.41220543 5.43278327 4.86674497 5.19089534 6.5715997  5.63203584\n",
      " 5.45571964 4.7501197  4.35570683 6.17650829 5.71618382 5.11544338\n",
      " 6.72730538 4.86435559]\n",
      "\n",
      "What it should be:  [3.         5.16666667 4.5        6.83333333 5.5        4.16666667\n",
      " 6.5        6.83333333 5.66666667 6.33333333 6.16666667 6.16666667\n",
      " 5.5        5.         5.33333333 5.33333333 6.83333333 6.16666667\n",
      " 6.         4.83333333 5.83333333 5.5        6.         4.33333333\n",
      " 6.33333333 5.66666667 5.66666667 6.83333333 5.33333333 6.5\n",
      " 3.66666667 6.16666667 5.         6.66666667 5.5        4.83333333\n",
      " 6.16666667 5.83333333 6.         6.16666667 5.5        5.16666667\n",
      " 6.33333333 5.5        6.5        6.33333333 6.16666667 5.66666667\n",
      " 4.66666667 6.         5.66666667 6.         5.16666667 6.5\n",
      " 6.16666667 4.66666667 6.         5.5        5.33333333 6.33333333\n",
      " 5.66666667 3.33333333 5.66666667 6.16666667 5.83333333 6.66666667\n",
      " 6.33333333 5.83333333 6.5        5.16666667 5.83333333 6.16666667\n",
      " 4.         6.33333333 4.         5.33333333 3.66666667 6.66666667\n",
      " 4.83333333 5.66666667 6.5        5.33333333 6.         4.66666667\n",
      " 5.83333333 6.33333333 5.16666667 6.33333333 5.66666667 7.\n",
      " 5.16666667 5.33333333 6.         7.         4.         4.66666667\n",
      " 4.83333333 4.66666667 7.         6.5        5.33333333 6.66666667\n",
      " 4.5        5.33333333 6.33333333 4.66666667 6.5        5.83333333\n",
      " 6.5        5.83333333]\n",
      "Correlation:  [[1.         0.10393714]\n",
      " [0.10393714 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.12\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.59\n",
      "R2 score = -0.59\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.35639382 6.61666671 5.48850348 5.65217749 6.14276828 5.77397246\n",
      " 4.29981047 6.84736343 6.37127478 5.43802347 7.30355479 6.36003337\n",
      " 4.96907471 5.45554096 5.08592619 4.40706602 5.24705659 6.92654611\n",
      " 4.42718885 4.89958457 6.38555668 4.98520017 4.95127445 5.52161137\n",
      " 6.00271579 5.08549208 4.95051878 5.33576846 6.54403428 6.00986866\n",
      " 6.00041106 5.05696993 5.36876224 5.52658145 4.84374405 6.02610142\n",
      " 5.20292925 6.54972961 6.42557999 5.88932852 6.41602974 6.26738929\n",
      " 4.7319017  5.88899977 5.66821885 6.25080175 6.39469899 6.37771392\n",
      " 5.93460354 5.16154908 5.79450741 5.15511569 5.52907994 5.83857999\n",
      " 5.72723473 5.15074473 5.54686109 5.40099119 6.86341136 4.785774\n",
      " 5.44196781 5.21348009 5.26267662 6.0786235  6.58795995 5.4720952\n",
      " 6.03857973 5.33162928 5.42588155 5.27232598 5.61530501 5.34671471\n",
      " 6.22930501 5.82625761 5.70893925 5.69335744 5.21705952 6.25370302\n",
      " 6.84525995 5.85363801 5.86812451 5.15761956 4.53481808 5.62521037\n",
      " 6.24843391 5.93724409 5.96539042 6.30567875 5.11874728 5.37072665\n",
      " 4.4703224  5.7082714  6.47082595 7.52271055 5.53450667 5.44322087\n",
      " 4.63552361 5.49970913 5.09038159 3.55048781 5.67804479 5.2069902\n",
      " 6.25429803 4.36471203 5.78052755 6.1519418  5.6094736  6.62422815\n",
      " 6.19812974 6.32152202]\n",
      "\n",
      "What it should be:  [6.83333333 5.33333333 5.5        6.         6.33333333 6.5\n",
      " 4.         6.16666667 6.5        6.         6.         6.83333333\n",
      " 4.66666667 6.66666667 5.         4.5        6.33333333 4.83333333\n",
      " 5.66666667 6.33333333 4.66666667 6.         6.         6.16666667\n",
      " 4.66666667 4.         4.66666667 5.         5.66666667 3.66666667\n",
      " 5.83333333 4.33333333 5.5        6.5        5.33333333 6.5\n",
      " 6.16666667 6.83333333 6.66666667 6.16666667 6.33333333 4.\n",
      " 4.83333333 5.33333333 7.         5.16666667 6.5        5.33333333\n",
      " 5.83333333 6.         6.83333333 5.83333333 6.83333333 6.\n",
      " 6.5        5.33333333 4.33333333 4.66666667 5.16666667 4.5\n",
      " 5.66666667 5.33333333 3.5        6.16666667 5.16666667 6.\n",
      " 5.83333333 5.5        5.83333333 4.66666667 4.         5.83333333\n",
      " 6.16666667 6.16666667 6.16666667 5.83333333 4.33333333 7.\n",
      " 7.         5.83333333 6.33333333 5.5        5.16666667 4.5\n",
      " 5.33333333 4.83333333 5.83333333 5.66666667 6.16666667 6.16666667\n",
      " 6.16666667 6.16666667 5.33333333 6.33333333 6.83333333 4.83333333\n",
      " 6.5        6.5        5.5        5.5        7.         6.16666667\n",
      " 5.66666667 1.83333333 5.5        4.16666667 3.         5.83333333\n",
      " 6.5        6.33333333]\n",
      "Correlation:  [[1.        0.2840317]\n",
      " [0.2840317 1.       ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.12\n",
      "R2 score = -0.12\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.45739338 5.7304812  6.13573548 5.38416162 5.34767504 5.42339254\n",
      " 4.99582785 5.02119499 6.77742929 6.45998349 3.84878662 4.82237887\n",
      " 5.19647367 6.18176246 6.2251282  4.29498733 5.46675896 5.06563367\n",
      " 5.60905441 3.68331094 5.74075843 6.62783483 6.48231507 5.41556898\n",
      " 5.98913022 5.7281234  5.41883265 6.25798137 5.67245738 5.03696828\n",
      " 4.59837529 4.25661042 5.05909579 4.89744743 5.62562688 5.01604327\n",
      " 4.42724794 5.44368183 5.3722844  3.0675076  6.33279509 6.80701349\n",
      " 5.8642392  6.37767256 5.15217604 6.39339915 6.04507036 5.30543801\n",
      " 5.88586945 5.24295288 6.2207257  5.79271499 4.61069147 6.10969753\n",
      " 5.56035121 4.6160671  5.41417876 5.74514298 5.65474237 6.28374875\n",
      " 5.47156871 5.14215848 5.63684684 4.0951638  6.43872594 5.38827687\n",
      " 5.53215054 5.5561359  5.37647871 5.22930893 5.99368184 6.57158543\n",
      " 6.75026954 5.38415174 5.67995612 4.96266549 5.43428912 6.52486814\n",
      " 5.18194282 4.94011117 4.82739207 6.08669935 5.2238862  5.93132699\n",
      " 5.27486686 5.4548484  5.91564469 5.81859195 4.89021662 6.15322581\n",
      " 5.39138495 6.11570767 5.75881036 4.99786943 4.93021149 4.92882788\n",
      " 4.92459869 5.71904283 5.27255521 5.25096433 5.37340213 5.51842118\n",
      " 6.98533205 5.42129492 4.59380708 4.79710029 6.26899934 6.16778248\n",
      " 5.29233465 5.6086311 ]\n",
      "\n",
      "What it should be:  [5.5        7.         5.33333333 6.5        6.66666667 4.33333333\n",
      " 6.5        5.16666667 6.         4.83333333 7.         5.66666667\n",
      " 6.5        6.33333333 4.5        6.33333333 5.16666667 6.33333333\n",
      " 5.66666667 6.83333333 4.66666667 5.66666667 6.66666667 6.16666667\n",
      " 5.33333333 6.5        5.5        6.5        6.16666667 4.33333333\n",
      " 4.83333333 6.83333333 6.16666667 6.83333333 5.33333333 5.\n",
      " 4.66666667 5.33333333 6.83333333 6.16666667 5.33333333 5.16666667\n",
      " 6.66666667 6.83333333 5.83333333 5.66666667 4.5        6.\n",
      " 6.         4.66666667 6.66666667 6.5        6.16666667 4.\n",
      " 6.         4.         5.5        5.66666667 5.83333333 6.5\n",
      " 5.5        4.83333333 5.16666667 5.16666667 5.83333333 4.83333333\n",
      " 6.16666667 4.66666667 5.5        5.         6.33333333 6.33333333\n",
      " 6.16666667 7.         6.         4.         5.16666667 6.16666667\n",
      " 5.         3.5        6.         7.         5.         4.\n",
      " 5.83333333 6.83333333 4.83333333 5.83333333 5.83333333 5.83333333\n",
      " 6.33333333 6.5        5.83333333 4.83333333 5.         5.33333333\n",
      " 4.5        5.83333333 4.83333333 5.33333333 6.         5.83333333\n",
      " 5.66666667 4.5        4.5        3.66666667 4.66666667 5.33333333\n",
      " 5.33333333 4.33333333]\n",
      "Correlation:  [[1.       0.079471]\n",
      " [0.079471 1.      ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.55\n",
      "R2 score = -0.57\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.51681157 4.1279601  5.20183488 5.25328464 5.15764663 5.45500956\n",
      " 4.50672179 5.71215864 5.69003033 5.06596627 5.79904063 5.54240389\n",
      " 3.64958664 5.63930107 7.03490577 5.83434519 6.47240418 6.19080899\n",
      " 5.68740637 6.52803304 5.45952407 5.4113033  5.08666626 4.20877977\n",
      " 4.76943276 4.75138072 5.01977239 5.83520223 5.48970101 5.45865447\n",
      " 4.97569899 5.41943908 5.59627739 5.38405952 5.44974486 5.25357292\n",
      " 6.35261603 5.11539654 4.91276953 4.91673235 4.33178375 4.36097308\n",
      " 4.32390863 5.92221167 5.12109649 6.37136271 5.76285542 5.75778185\n",
      " 5.57102433 5.1357849  4.84815423 5.08123451 4.51392314 5.87603907\n",
      " 5.9978957  5.86854472 6.11435739 5.89588643 4.80509616 5.17104078\n",
      " 5.77718211 6.35809837 4.76918635 4.98461316 4.30899411 2.96706522\n",
      " 6.41881947 4.04408166 5.19567484 5.44682302 5.69992464 5.49359779\n",
      " 5.1631621  4.9786359  6.48241149 5.59676376 6.03179977 5.44525326\n",
      " 5.51666902 4.50647342 6.23535523 4.13341348 5.23340066 4.29667743\n",
      " 5.98993444 5.15077685 6.36752081 4.25823299 6.08251666 5.52147783\n",
      " 4.68459464 5.40010526 5.27300593 5.61878855 5.2032375  5.24143551\n",
      " 4.88682893 6.08832849 5.44381734 4.84292112 5.763839   4.78045735\n",
      " 4.77786175 5.66810112 4.77501714 5.11219717 5.67176161 6.25599695\n",
      " 5.35355659 5.74856571]\n",
      "\n",
      "What it should be:  [5.16666667 5.33333333 6.         3.         6.5        6.5\n",
      " 6.16666667 6.66666667 6.16666667 6.16666667 6.16666667 5.5\n",
      " 4.5        6.         6.83333333 4.83333333 6.33333333 5.16666667\n",
      " 6.66666667 5.66666667 4.5        6.33333333 5.16666667 4.66666667\n",
      " 5.16666667 4.33333333 6.66666667 6.5        5.16666667 5.33333333\n",
      " 4.5        6.         6.         7.         7.         6.83333333\n",
      " 5.         5.16666667 4.66666667 6.16666667 6.83333333 4.33333333\n",
      " 6.16666667 6.16666667 6.16666667 6.83333333 6.         6.5\n",
      " 5.5        5.66666667 5.66666667 5.33333333 6.         5.5\n",
      " 6.         5.66666667 5.83333333 6.5        5.33333333 6.16666667\n",
      " 6.         5.33333333 6.33333333 6.66666667 4.83333333 4.83333333\n",
      " 7.         6.5        6.33333333 5.33333333 5.16666667 6.\n",
      " 6.5        1.83333333 6.5        6.16666667 6.33333333 4.83333333\n",
      " 5.66666667 5.5        5.33333333 5.33333333 6.16666667 4.\n",
      " 5.83333333 5.83333333 4.66666667 6.33333333 6.83333333 5.83333333\n",
      " 3.66666667 6.         6.5        6.16666667 6.33333333 4.66666667\n",
      " 4.5        4.16666667 6.66666667 7.         5.66666667 6.66666667\n",
      " 4.83333333 5.66666667 5.         6.5        6.5        6.33333333\n",
      " 6.5        6.16666667]\n",
      "Correlation:  [[1.         0.25820922]\n",
      " [0.25820922 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.02133094 5.01231367 5.58745415 6.21099204 5.50357762 6.09175049\n",
      " 5.8215646  4.82234352 6.05677252 6.19437393 5.64035823 5.65459787\n",
      " 5.14642712 5.37916354 5.91196457 5.49796528 6.88751399 6.3384373\n",
      " 6.23391595 5.95922606 5.99395836 4.54095675 6.05058688 5.96191474\n",
      " 6.53691853 5.53552794 4.4867102  6.41687301 6.10219871 6.03652948\n",
      " 5.24168218 6.04379926 5.78078833 5.85792242 6.21907302 7.03494156\n",
      " 4.90783563 6.2705911  6.36640183 6.5373882  5.04761027 5.32330334\n",
      " 6.93482023 5.53398744 5.31105048 5.60993858 5.59840638 4.94522111\n",
      " 5.7478932  6.86810029 6.97929409 5.02255808 5.34531755 4.74079254\n",
      " 5.01832956 5.92046842 5.22065992 5.97274768 6.2629378  5.70011638\n",
      " 5.29674142 5.92231304 5.82085314 6.44633419 4.74917824 6.8119534\n",
      " 6.29082265 5.71362791 5.80687472 5.53416852 6.61216896 4.8178558\n",
      " 5.44399942 6.4478567  5.94128765 5.56377427 4.04964193 5.61439565\n",
      " 6.29967292 5.14852663 5.23320223 6.05130042 6.28905851 4.32988377\n",
      " 4.58411751 7.26122049 6.28456693 6.03640838 6.29880339 4.62254527\n",
      " 6.25589619 6.28172208 6.63286035 5.34540262 5.87018663 5.32389245\n",
      " 6.09465322 6.84810935 7.25905487 5.61650207 2.37519342 5.41877279\n",
      " 6.36761473 6.73006936 5.80011923 5.27022513 5.7288194  5.29964657\n",
      " 6.99372356 4.62487393]\n",
      "\n",
      "What it should be:  [6.         6.16666667 4.83333333 6.83333333 5.16666667 6.5\n",
      " 4.66666667 7.         6.5        6.16666667 5.5        5.33333333\n",
      " 5.83333333 5.33333333 5.         5.66666667 6.5        5.5\n",
      " 6.16666667 6.16666667 5.66666667 6.16666667 5.         5.16666667\n",
      " 7.         6.         4.66666667 4.83333333 5.33333333 5.33333333\n",
      " 5.66666667 5.83333333 6.         6.16666667 6.33333333 6.83333333\n",
      " 5.66666667 6.83333333 4.66666667 4.5        4.         6.83333333\n",
      " 6.16666667 6.33333333 4.33333333 4.33333333 6.66666667 5.83333333\n",
      " 6.66666667 7.         4.33333333 5.33333333 6.16666667 6.33333333\n",
      " 6.33333333 5.33333333 6.         5.83333333 5.66666667 5.16666667\n",
      " 5.16666667 5.33333333 5.83333333 5.66666667 3.66666667 6.33333333\n",
      " 6.16666667 6.5        5.33333333 3.         5.16666667 6.5\n",
      " 5.16666667 5.16666667 6.5        5.66666667 6.83333333 3.66666667\n",
      " 6.66666667 5.5        5.33333333 6.16666667 6.16666667 5.33333333\n",
      " 4.83333333 6.5        4.66666667 6.5        6.5        4.66666667\n",
      " 3.83333333 5.         6.83333333 5.5        5.16666667 4.\n",
      " 5.33333333 6.16666667 4.         5.83333333 5.5        6.16666667\n",
      " 6.16666667 6.83333333 4.5        4.         6.83333333 3.33333333\n",
      " 5.66666667 4.83333333]\n",
      "Correlation:  [[1.         0.16626965]\n",
      " [0.16626965 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.16\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.43\n",
      "R2 score = -0.47\n",
      " \n",
      " \n",
      "-------------- \n",
      "****************************************************\n",
      "0.7\n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.0628676  5.92164592 6.00862825 5.54008406 5.3239924  5.81415791\n",
      " 5.49207014 5.8697849  5.87022739 5.73888091 6.46220243 6.09929897\n",
      " 5.8174712  5.70829929 5.8411448  6.20277041 5.37430271 5.65879894\n",
      " 5.78793554 5.0696836  5.68837781 6.0832028  5.50576545 5.78347842\n",
      " 6.04636438 6.37527128 6.05447553 5.39354565 5.65423361 6.11583962\n",
      " 6.65545742 5.12389659 5.5860869  6.41656903 6.34300985 5.63526165\n",
      " 5.67988577 6.58089246 5.29728137 5.19444958 5.38364091 5.6835527\n",
      " 5.60687194 6.11890219 5.60957053 5.58921274 6.34132389 5.96982184\n",
      " 5.86516324 6.06020833 5.99064853 5.60234139 6.15806358 6.03157867\n",
      " 5.7597435  6.09219596 5.69797467 6.09276754 5.43749393 6.0689744\n",
      " 6.16138847 6.4652921  6.14049606 5.78016478 5.39214571 6.22974531\n",
      " 6.11676872 5.28026507 5.9042055  5.80061149 6.20012994 5.94805117\n",
      " 4.09847646 5.74645757 5.39217837 5.69479201 5.63244229 5.8519424\n",
      " 5.8784464  6.05349283 5.45037825 5.73723676 5.03313696 6.2954725\n",
      " 6.59464671 4.78255959 5.67484828 5.28265156 5.23915988 6.05301611\n",
      " 5.95659714 4.9827891  5.69878884 5.6772007  6.01475037 6.16906031\n",
      " 5.78020388 5.06828627 5.66017928 5.72526139 6.3559095  6.00715871\n",
      " 5.85411576 5.26221463 5.66475867 5.4959613  5.20976003 5.43721626\n",
      " 5.96547627 5.44191534 4.91395967 5.7873933  5.70300095 4.82131403\n",
      " 6.12945228 5.89436086 6.37745771 6.45415748 5.88300238 6.34735977\n",
      " 5.594166   6.41656395 5.64594979 5.26316873 5.22929703 6.52870203\n",
      " 6.19283169 6.30194095 6.12740653]\n",
      "\n",
      "What it should be:  [6.83333333 6.         6.83333333 6.83333333 4.83333333 3.33333333\n",
      " 6.5        6.         4.         4.83333333 6.16666667 6.16666667\n",
      " 5.5        4.33333333 6.16666667 4.5        6.66666667 6.33333333\n",
      " 4.33333333 6.         4.83333333 6.33333333 5.33333333 6.16666667\n",
      " 5.83333333 5.83333333 6.33333333 5.         3.5        6.\n",
      " 6.5        5.16666667 4.         5.16666667 6.16666667 4.66666667\n",
      " 6.16666667 4.83333333 6.         5.5        3.66666667 4.66666667\n",
      " 5.5        5.16666667 6.16666667 5.16666667 5.         4.66666667\n",
      " 5.83333333 5.33333333 5.66666667 4.33333333 6.5        6.83333333\n",
      " 6.33333333 5.83333333 6.         5.66666667 5.83333333 7.\n",
      " 6.         6.33333333 6.         5.33333333 6.         5.16666667\n",
      " 6.66666667 6.16666667 4.5        5.5        6.5        5.66666667\n",
      " 4.5        7.         6.16666667 6.33333333 5.33333333 6.33333333\n",
      " 5.33333333 5.33333333 5.66666667 6.66666667 6.33333333 5.66666667\n",
      " 4.         5.16666667 4.83333333 4.         5.33333333 5.5\n",
      " 6.16666667 5.66666667 5.5        5.         3.83333333 6.5\n",
      " 6.16666667 6.5        5.83333333 5.16666667 4.16666667 6.5\n",
      " 6.83333333 4.83333333 4.         5.33333333 6.16666667 6.66666667\n",
      " 5.33333333 3.66666667 4.66666667 6.         7.         5.33333333\n",
      " 6.16666667 6.66666667 5.83333333 5.66666667 5.66666667 5.66666667\n",
      " 6.         7.         6.5        5.33333333 6.16666667 6.\n",
      " 1.83333333 5.83333333 5.5       ]\n",
      "Correlation:  [[1.         0.08336615]\n",
      " [0.08336615 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.56\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.19\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.91238202 4.53873441 6.10708123 6.05049978 5.52370145 5.50678799\n",
      " 5.50866863 5.42442929 5.15138378 5.57748136 5.42287764 5.31906512\n",
      " 5.44955041 5.19207789 5.18003384 7.29848056 5.07207496 5.27828257\n",
      " 6.35065754 5.53502521 6.03486311 5.48726754 5.18058907 5.22978246\n",
      " 5.89868327 5.64213476 5.36880712 5.04549442 4.89586822 4.48394202\n",
      " 4.9075076  5.19717677 5.20553487 5.88170899 5.72047162 5.22758308\n",
      " 5.31814701 5.07571526 4.63121596 6.01404396 4.88286066 5.25519794\n",
      " 5.0626565  4.9841394  5.76594353 5.3962537  5.69086906 5.4719779\n",
      " 5.6147436  4.51650308 5.53749081 6.44929975 4.88967903 5.59499158\n",
      " 4.79400933 6.74039449 6.12847275 5.59447207 5.99371426 5.13921391\n",
      " 5.91258784 6.2729432  4.71181885 5.48771948 6.19362936 4.76326597\n",
      " 5.31013224 5.97334929 5.74423112 5.59144416 5.69973511 6.11987013\n",
      " 5.13882681 5.53887473 5.12983819 6.2237928  4.81961742 6.19676427\n",
      " 5.19581531 5.43102871 5.19167416 5.89699993 5.75057795 5.69421027\n",
      " 5.80925637 5.94450894 4.83365699 5.31253215 5.94805661 4.62812695\n",
      " 5.51801815 5.38349827 5.83417765 5.16761985 4.37677422 5.33644503\n",
      " 4.9379477  6.3315982  5.71622934 5.52370033 5.61525801 4.19973612\n",
      " 5.51409031 4.74689223 5.47426962 6.41930427 5.52984799 5.53565212\n",
      " 5.85444657 6.08527562 4.94129824 5.41816208 5.17329786 7.3234275\n",
      " 4.90569773 6.57961647 4.99308921 5.42917801 5.2717257  5.81996668\n",
      " 5.4902533  5.80508367 6.10420573 5.55702057 5.72222786 6.1266178\n",
      " 5.04992138 5.2699475  5.59291786]\n",
      "\n",
      "What it should be:  [5.16666667 6.66666667 5.83333333 6.         6.16666667 5.66666667\n",
      " 6.16666667 6.83333333 6.16666667 5.16666667 6.16666667 4.83333333\n",
      " 6.5        4.5        5.66666667 5.16666667 6.83333333 6.5\n",
      " 5.33333333 6.5        4.83333333 6.33333333 5.33333333 5.66666667\n",
      " 6.66666667 5.83333333 6.         6.33333333 6.66666667 6.\n",
      " 5.83333333 7.         5.33333333 6.16666667 6.16666667 4.\n",
      " 6.5        4.         5.5        7.         6.16666667 5.5\n",
      " 5.66666667 6.         5.         6.33333333 3.         5.16666667\n",
      " 5.33333333 5.33333333 5.66666667 6.16666667 5.         6.5\n",
      " 3.66666667 6.5        4.         5.5        6.         5.\n",
      " 4.66666667 5.83333333 3.5        5.         4.66666667 6.5\n",
      " 5.5        5.16666667 5.66666667 5.33333333 4.66666667 4.83333333\n",
      " 4.66666667 6.         6.         6.5        6.16666667 5.33333333\n",
      " 5.33333333 6.83333333 6.83333333 6.         4.66666667 6.66666667\n",
      " 6.16666667 4.33333333 6.16666667 4.83333333 6.5        6.33333333\n",
      " 6.33333333 5.66666667 7.         5.83333333 4.33333333 5.66666667\n",
      " 5.33333333 5.33333333 5.5        5.66666667 6.66666667 5.\n",
      " 6.66666667 4.83333333 4.5        6.16666667 4.83333333 6.16666667\n",
      " 6.5        6.33333333 5.83333333 6.66666667 5.83333333 6.83333333\n",
      " 5.16666667 3.66666667 4.66666667 5.33333333 6.16666667 1.83333333\n",
      " 6.16666667 3.83333333 5.83333333 6.16666667 6.83333333 5.33333333\n",
      " 5.16666667 6.83333333 6.66666667]\n",
      "Correlation:  [[1.         0.02609031]\n",
      " [0.02609031 1.        ]]\n",
      "Mean absolute error = 0.83\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.77\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.34\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.57220021 4.26389356 5.3269999  6.13168475 4.68353801 5.72480177\n",
      " 3.70203369 5.64927044 5.01023676 5.74810762 3.68416002 5.93395346\n",
      " 6.31770696 4.32274186 5.4736068  4.57408596 4.63883084 5.86640035\n",
      " 5.25900412 6.31616528 4.93827469 5.23932598 5.04311046 3.82487314\n",
      " 5.38472161 5.54826247 5.16594766 5.12500502 6.10277922 5.26641864\n",
      " 5.29001358 5.03762376 5.15777078 6.21433047 5.82717761 5.20079755\n",
      " 6.04283723 5.8172689  4.6560428  4.88044407 3.84697579 5.44431554\n",
      " 5.92953661 4.73723159 5.52655265 6.20362654 5.08478551 5.45156369\n",
      " 5.24005293 5.74572785 5.37793144 4.98591961 5.76844513 5.93185601\n",
      " 6.02191534 4.1710435  5.33331934 6.29127032 5.51479237 5.99954268\n",
      " 5.53098522 5.01311334 4.45771797 4.73460625 6.03870795 5.17893613\n",
      " 6.51355314 5.69922331 5.14084552 6.10018601 4.76832645 5.01931704\n",
      " 4.99886932 6.50971946 3.64422243 4.97209925 5.3306692  4.04870304\n",
      " 5.86651355 4.76078908 5.43803536 4.93715604 5.17202428 6.1523522\n",
      " 5.09834767 6.11057593 6.17344034 5.46255212 6.10094412 3.89597339\n",
      " 4.70775496 4.87796805 4.86619481 5.89422246 5.29638722 5.68453714\n",
      " 4.52044515 4.84481237 5.54135385 6.15130311 5.34379426 5.99393943\n",
      " 5.45380672 5.8285953  5.20525379 5.8025425  5.69376976 5.88126113\n",
      " 6.40278892 6.19918929 6.03143494 5.21067527 4.87933659 5.73040742\n",
      " 5.20042119 5.65640448 5.82932802 4.83262896 5.80131995 4.72334321\n",
      " 5.6991754  5.23191855 6.6208784  3.69829049 6.10278735 5.19536165\n",
      " 5.66390479 4.49494028 5.56090035]\n",
      "\n",
      "What it should be:  [6.66666667 3.66666667 6.33333333 5.33333333 5.5        4.\n",
      " 6.5        5.5        6.         4.83333333 6.83333333 5.83333333\n",
      " 5.66666667 3.66666667 7.         5.66666667 5.5        6.16666667\n",
      " 5.5        4.83333333 6.5        4.66666667 6.5        7.\n",
      " 5.66666667 6.         5.5        7.         5.33333333 6.16666667\n",
      " 5.         6.5        5.66666667 6.16666667 6.         6.\n",
      " 6.16666667 5.16666667 6.33333333 6.5        6.16666667 6.16666667\n",
      " 5.83333333 5.         6.         5.83333333 4.33333333 6.16666667\n",
      " 6.66666667 6.16666667 4.83333333 5.83333333 6.5        6.16666667\n",
      " 5.66666667 3.83333333 6.66666667 6.         5.16666667 5.66666667\n",
      " 5.83333333 6.         4.83333333 4.66666667 5.33333333 1.83333333\n",
      " 5.83333333 6.16666667 4.66666667 4.83333333 5.33333333 6.66666667\n",
      " 5.         5.33333333 4.5        6.5        6.33333333 4.5\n",
      " 4.5        6.83333333 7.         4.83333333 6.16666667 6.33333333\n",
      " 6.33333333 6.         6.83333333 4.         4.5        5.16666667\n",
      " 5.83333333 4.66666667 3.66666667 5.66666667 6.16666667 5.16666667\n",
      " 6.16666667 6.33333333 6.16666667 6.83333333 6.16666667 6.66666667\n",
      " 5.5        6.83333333 7.         5.83333333 5.5        5.66666667\n",
      " 6.16666667 7.         5.33333333 6.         5.16666667 6.33333333\n",
      " 5.66666667 6.66666667 6.83333333 6.         5.16666667 4.66666667\n",
      " 5.16666667 4.         6.66666667 4.83333333 5.16666667 4.33333333\n",
      " 5.         4.         6.83333333]\n",
      "Correlation:  [[1.         0.18024028]\n",
      " [0.18024028 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.27\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.96724211 5.48866551 5.86751369 5.05301463 5.80499629 5.05544\n",
      " 6.36332254 5.87610095 6.32075779 6.02474543 6.11806948 6.12785699\n",
      " 5.64296464 6.08815222 5.38718683 6.93784882 5.63497456 5.92172867\n",
      " 5.96434572 5.93968629 6.33178757 5.2899653  5.67725839 5.63029239\n",
      " 5.61449439 5.37022115 5.30569187 5.54597309 5.58592686 6.27621065\n",
      " 6.51966196 5.24604317 5.52040117 5.83633535 6.01217602 5.72614787\n",
      " 5.67282311 6.38144408 5.08063435 5.5360426  5.42180137 5.4031922\n",
      " 5.65980144 5.53188567 6.20755271 5.27025274 5.44916715 5.56765984\n",
      " 6.7040607  4.82260755 6.67674877 5.97379018 5.41824819 6.09302345\n",
      " 5.43426831 5.59182415 5.1922356  5.91837434 4.77227718 5.86462042\n",
      " 5.99736074 6.04241357 5.8157803  5.26232275 7.32083904 5.71466827\n",
      " 5.68094922 5.39171418 6.41384777 5.68802388 5.18865256 5.60889237\n",
      " 5.46386351 4.89308602 4.75682801 5.230337   4.66203147 5.41793805\n",
      " 5.88911147 5.84736693 5.44028388 6.37983058 6.08002749 5.44743939\n",
      " 5.82523467 5.51592558 4.97870454 6.04983049 5.72715273 6.02217616\n",
      " 5.2209408  5.80972472 5.96071576 5.32067778 5.83013795 6.20885845\n",
      " 4.93720593 4.68639475 5.87763002 5.15540915 6.11761373 5.44302652\n",
      " 5.93862045 6.09790939 6.00400489 5.24930967 5.84735508 5.71870766\n",
      " 5.03973224 6.90458486 6.6685762  5.29538959 5.64988918 5.67660334\n",
      " 6.81812103 5.03436303 5.57777489 5.49653901 5.15323084 4.34970808\n",
      " 5.55740328 5.60417314 5.91240911 6.36800557 4.3178944  6.22535093\n",
      " 5.33677899 5.55986389 6.45872493]\n",
      "\n",
      "What it should be:  [4.83333333 5.83333333 5.83333333 5.66666667 5.83333333 5.5\n",
      " 5.83333333 6.16666667 4.         6.         6.         5.66666667\n",
      " 6.33333333 4.66666667 6.5        6.         5.66666667 5.5\n",
      " 4.66666667 5.16666667 5.33333333 4.         5.83333333 4.66666667\n",
      " 6.16666667 5.83333333 5.         6.83333333 5.         5.16666667\n",
      " 6.66666667 6.33333333 6.5        6.5        6.66666667 3.\n",
      " 6.83333333 6.16666667 4.83333333 6.83333333 5.66666667 6.\n",
      " 5.83333333 4.66666667 6.16666667 6.83333333 5.         5.83333333\n",
      " 4.16666667 6.33333333 6.16666667 5.33333333 6.16666667 5.66666667\n",
      " 5.66666667 4.33333333 6.5        5.33333333 7.         6.33333333\n",
      " 3.83333333 6.16666667 5.5        5.83333333 6.83333333 5.33333333\n",
      " 6.66666667 6.83333333 6.         6.5        6.16666667 7.\n",
      " 6.         5.33333333 5.33333333 6.         4.83333333 5.66666667\n",
      " 5.33333333 4.5        5.66666667 6.16666667 4.5        6.5\n",
      " 4.83333333 7.         6.         5.33333333 6.16666667 6.5\n",
      " 3.66666667 6.16666667 6.33333333 3.33333333 6.83333333 6.83333333\n",
      " 6.5        5.33333333 5.5        3.66666667 6.83333333 4.66666667\n",
      " 1.83333333 5.16666667 5.66666667 4.33333333 5.5        4.\n",
      " 4.5        5.33333333 5.16666667 3.5        6.         5.\n",
      " 4.83333333 6.         6.         5.33333333 4.66666667 6.16666667\n",
      " 5.5        6.5        5.16666667 6.5        5.16666667 6.5\n",
      " 5.         6.66666667 5.83333333]\n",
      "Correlation:  [[1.         0.06095075]\n",
      " [0.06095075 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.43340993 4.9768058  5.11220475 6.30926865 7.52214331 5.93074106\n",
      " 5.22592966 5.64560501 6.97349197 4.87117751 5.82473038 6.52845189\n",
      " 6.36234572 5.86104031 5.20819984 6.01587807 5.10886072 6.58701533\n",
      " 6.46168587 7.07376743 6.579985   5.11065611 5.77562354 5.11673792\n",
      " 7.01051015 6.50665725 4.89377111 5.03892431 5.14096708 5.52059418\n",
      " 6.95003563 5.70024296 6.00415574 6.1510677  6.54090327 4.89268841\n",
      " 5.20303799 5.21233545 6.53949608 5.27079323 5.11959297 5.74781994\n",
      " 4.14285047 4.99454651 4.1872219  5.4161613  5.05785084 6.36034879\n",
      " 5.9616997  6.97110563 4.70960547 5.06714066 6.60155734 7.45838174\n",
      " 5.33546579 5.75909327 5.32566796 6.06160881 6.66302417 6.00803679\n",
      " 6.13890149 6.65318867 6.88503498 5.38054189 4.60958001 5.29275643\n",
      " 5.06772916 5.43639532 5.53822205 4.23130156 6.41876981 6.23009297\n",
      " 5.99346215 6.00446771 5.06373578 5.68912478 5.71582942 3.66304902\n",
      " 5.73588295 5.3316788  6.42232113 6.63980467 6.03380741 5.20869696\n",
      " 6.69432057 5.40839043 6.16612944 5.29845858 5.82052953 5.93474844\n",
      " 5.34103072 6.0556171  6.11414597 6.55672668 6.06947639 5.68900955\n",
      " 6.76215612 5.09751492 5.64352321 7.01744068 6.32532076 5.5464467\n",
      " 5.75918779 6.28498827 5.93776668 4.3601983  5.64317579 5.87618079\n",
      " 6.70442874 5.97996676 6.07981157 6.92051097 5.66023543 5.40405174\n",
      " 6.10958096 6.46707831 5.55597073 5.26795435 6.32400935 4.65019851\n",
      " 6.48888499 6.57854008 6.73499618 6.00111214 5.76453958 5.30076479\n",
      " 5.93120095 7.81151176 6.89084737]\n",
      "\n",
      "What it should be:  [5.16666667 4.66666667 5.33333333 5.5        4.5        5.33333333\n",
      " 4.83333333 4.66666667 6.16666667 3.66666667 5.66666667 4.5\n",
      " 5.66666667 5.33333333 5.33333333 3.66666667 6.33333333 5.33333333\n",
      " 5.66666667 4.5        6.66666667 5.83333333 4.16666667 5.83333333\n",
      " 3.         5.5        5.         6.         6.5        6.16666667\n",
      " 7.         5.66666667 6.66666667 6.33333333 6.83333333 6.\n",
      " 6.16666667 5.         6.66666667 6.5        5.33333333 6.16666667\n",
      " 4.         6.5        6.         6.5        5.33333333 6.5\n",
      " 5.83333333 6.66666667 6.33333333 5.83333333 5.66666667 4.\n",
      " 4.33333333 4.83333333 6.16666667 5.83333333 6.16666667 6.83333333\n",
      " 6.33333333 4.66666667 7.         5.83333333 6.5        6.\n",
      " 6.33333333 6.66666667 5.83333333 6.33333333 7.         6.66666667\n",
      " 6.83333333 5.33333333 6.83333333 4.         5.66666667 5.5\n",
      " 4.         5.         4.5        5.33333333 4.66666667 6.5\n",
      " 6.5        5.83333333 5.83333333 6.         3.33333333 6.16666667\n",
      " 4.66666667 5.83333333 5.16666667 5.33333333 6.16666667 6.83333333\n",
      " 4.66666667 4.83333333 6.5        6.         4.33333333 5.\n",
      " 5.16666667 6.16666667 5.83333333 6.16666667 6.16666667 6.5\n",
      " 5.5        4.         5.16666667 4.5        6.         6.\n",
      " 6.         6.16666667 4.33333333 5.5        5.66666667 4.33333333\n",
      " 5.16666667 6.16666667 5.5        6.         6.33333333 6.5\n",
      " 6.16666667 4.83333333 5.66666667]\n",
      "Correlation:  [[ 1.         -0.05950151]\n",
      " [-0.05950151  1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.43\n",
      "Median absolute error = 0.72\n",
      "Explain variance score = -0.84\n",
      "R2 score = -0.9\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [3.62920129 5.97785266 6.67258825 5.03477924 4.28216722 5.58309261\n",
      " 5.61099587 6.13591825 5.60979736 5.9263577  5.89186326 5.84384428\n",
      " 5.17073164 6.86459172 5.03957975 4.39321121 5.98658159 5.29125118\n",
      " 5.65623716 5.67680004 6.94014287 6.12425614 5.89183865 4.93457945\n",
      " 4.48114489 5.90675177 6.37863444 5.44447063 5.92140587 5.84282338\n",
      " 5.01360497 5.61655575 5.50986994 5.89500751 5.02928933 6.42995566\n",
      " 5.88737861 5.56284726 5.67981658 5.11373153 5.47889723 4.40614744\n",
      " 5.64669571 5.19969009 5.0393718  5.23901973 5.70443531 5.54504918\n",
      " 6.30966454 5.0917724  5.99278902 5.40410301 6.27543706 6.18215503\n",
      " 5.09502158 5.61087935 5.36443554 5.37891377 5.28282721 6.00387081\n",
      " 5.53710346 4.64673472 5.05666503 6.12407841 5.57512224 4.9476099\n",
      " 5.83729183 6.58180493 6.18950359 6.54203174 5.20496774 5.18968696\n",
      " 5.24203908 5.19038818 6.00232736 3.8803799  6.46004453 5.52721346\n",
      " 4.82906287 4.23811801 6.00539154 3.66835837 5.46892979 6.31980966\n",
      " 5.94399567 4.24749047 5.972796   6.17467436 5.55334166 4.41940379\n",
      " 5.95341082 4.19137435 5.17965635 5.27518207 5.5411457  6.07815799\n",
      " 5.9908676  5.14736803 5.67824592 4.13858079 6.26877236 4.87620332\n",
      " 5.8841733  5.52911334 6.44706538 5.0669026  6.90705982 5.97185382\n",
      " 6.32310984 5.58397635 5.80717138 4.85567357 4.98419256 5.46049062\n",
      " 6.10938785 5.40503719 5.36914291 4.78065334 5.01160616 5.36962419\n",
      " 5.95798949 6.07243152 4.90475352 5.40706927 5.93234958 5.96890274\n",
      " 5.63158546 5.70840012 3.84536159]\n",
      "\n",
      "What it should be:  [6.5        6.66666667 6.83333333 6.83333333 6.33333333 5.16666667\n",
      " 4.66666667 5.16666667 5.83333333 6.5        6.16666667 5.83333333\n",
      " 6.16666667 5.66666667 6.66666667 3.66666667 5.83333333 6.16666667\n",
      " 5.66666667 6.         4.         6.16666667 5.33333333 4.\n",
      " 6.16666667 5.83333333 6.         6.16666667 6.83333333 4.66666667\n",
      " 4.83333333 4.83333333 6.16666667 5.5        5.5        6.\n",
      " 4.16666667 6.5        6.5        5.         5.83333333 4.\n",
      " 6.5        6.16666667 5.83333333 6.33333333 6.16666667 5.83333333\n",
      " 5.33333333 6.         4.83333333 4.66666667 6.33333333 4.66666667\n",
      " 5.66666667 3.66666667 6.16666667 4.83333333 6.66666667 6.83333333\n",
      " 6.83333333 5.33333333 4.         6.16666667 4.83333333 5.\n",
      " 5.16666667 6.         6.16666667 5.33333333 6.83333333 5.5\n",
      " 6.33333333 6.5        6.         4.83333333 6.5        4.33333333\n",
      " 6.16666667 5.33333333 6.5        5.5        6.         6.66666667\n",
      " 4.66666667 5.5        7.         6.83333333 6.16666667 1.83333333\n",
      " 6.5        6.         3.5        4.83333333 6.83333333 5.66666667\n",
      " 6.66666667 5.5        5.33333333 6.5        5.16666667 6.\n",
      " 5.16666667 4.66666667 5.33333333 4.5        5.66666667 4.5\n",
      " 5.         5.16666667 6.16666667 4.         6.66666667 5.33333333\n",
      " 7.         6.33333333 6.5        5.33333333 5.33333333 5.\n",
      " 5.66666667 6.33333333 6.33333333 5.83333333 6.16666667 5.66666667\n",
      " 6.66666667 3.         6.16666667]\n",
      "Correlation:  [[1.         0.13432576]\n",
      " [0.13432576 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.33\n",
      "R2 score = -0.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.71850495 4.91231334 5.49909828 5.41362171 5.86407245 5.78648045\n",
      " 6.52818733 5.21498596 4.66596669 5.55074508 5.3302978  5.37781433\n",
      " 5.39322017 4.61698308 6.00194945 4.37064448 5.45237716 5.61649466\n",
      " 4.98826396 6.0901172  5.80659307 5.22501293 5.07734987 5.42738832\n",
      " 4.72031036 5.86693043 4.82907544 6.00392892 5.97899021 5.21323723\n",
      " 5.70873907 4.77329899 5.3393236  5.05077625 5.5286233  5.03362248\n",
      " 6.01980093 5.65423616 6.61488116 6.21716795 4.97784754 4.06502854\n",
      " 4.89195179 4.92087444 5.33991295 5.08358657 5.72153732 4.89667993\n",
      " 5.39212287 6.51748176 5.73894175 6.29417852 5.66110142 5.57879328\n",
      " 5.71246309 3.80453116 5.10908494 5.65381103 4.49755163 5.28250133\n",
      " 5.68842918 5.26752599 5.1761938  6.01399414 6.08189168 5.66815936\n",
      " 5.09636648 5.60229217 5.93354268 4.90974942 6.51331464 5.38227117\n",
      " 5.58576895 4.37119302 5.94289078 5.13921466 5.61990665 5.20247073\n",
      " 4.76455769 5.67109878 5.08145144 4.60037361 5.20655724 5.23397336\n",
      " 5.19806157 5.54544164 4.51567852 4.72147597 5.39868267 4.95060151\n",
      " 6.05305709 5.48933685 5.91140069 5.49976964 4.81693953 5.29519413\n",
      " 4.75922522 6.44979982 5.5434545  5.75210508 6.42915942 5.88198905\n",
      " 5.476933   5.25572637 5.90735761 5.27329721 5.63937108 5.68184386\n",
      " 5.72669765 5.09532215 6.02744294 4.98079239 5.36532999 4.22001084\n",
      " 5.61621595 5.83726115 7.0173712  4.73868724 5.4667443  4.85114474\n",
      " 4.56513077 5.51275042 5.10027661 4.87178819 5.11769135 5.8335024\n",
      " 5.45584383 5.99860507 4.54494012]\n",
      "\n",
      "What it should be:  [5.33333333 6.5        4.33333333 5.66666667 4.83333333 6.5\n",
      " 5.83333333 5.33333333 6.         6.16666667 6.5        6.33333333\n",
      " 5.66666667 4.83333333 6.16666667 6.5        4.         5.16666667\n",
      " 5.33333333 5.16666667 6.5        6.83333333 6.16666667 7.\n",
      " 6.5        6.5        5.         6.83333333 5.16666667 4.66666667\n",
      " 6.66666667 5.5        6.16666667 6.66666667 4.83333333 5.83333333\n",
      " 6.         5.66666667 4.66666667 5.83333333 6.33333333 6.\n",
      " 6.83333333 6.33333333 6.16666667 6.5        6.16666667 6.66666667\n",
      " 3.66666667 6.33333333 5.5        6.66666667 5.         3.\n",
      " 7.         5.5        6.16666667 6.16666667 5.83333333 6.\n",
      " 5.33333333 6.16666667 4.5        5.33333333 6.5        4.5\n",
      " 4.66666667 5.16666667 5.33333333 5.33333333 5.33333333 5.83333333\n",
      " 6.16666667 7.         5.16666667 5.         6.16666667 5.33333333\n",
      " 3.66666667 5.66666667 5.33333333 7.         5.5        6.5\n",
      " 3.66666667 5.16666667 5.5        5.83333333 6.66666667 4.83333333\n",
      " 4.33333333 5.66666667 6.66666667 5.         5.5        4.\n",
      " 4.66666667 4.66666667 5.16666667 5.83333333 6.5        6.\n",
      " 6.83333333 7.         4.66666667 6.16666667 6.33333333 5.66666667\n",
      " 6.16666667 5.83333333 5.33333333 6.         6.33333333 6.83333333\n",
      " 4.         6.33333333 6.33333333 4.5        5.66666667 6.\n",
      " 6.33333333 4.83333333 6.83333333 6.33333333 6.16666667 4.33333333\n",
      " 6.83333333 6.5        4.83333333]\n",
      "Correlation:  [[ 1.         -0.05368313]\n",
      " [-0.05368313  1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.17\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.62\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.83194745 4.00828937 5.39019899 5.72499587 5.98685415 6.10822631\n",
      " 5.09739844 5.64253162 6.80155944 5.34093238 5.42348534 4.46578423\n",
      " 4.69662807 5.40884702 5.26604856 6.53822055 6.51329088 5.91542638\n",
      " 5.60258767 5.35643857 5.01520459 5.34472555 5.59532546 6.17281915\n",
      " 5.41369908 4.42469843 5.45849378 6.4954954  5.24791249 5.41319769\n",
      " 4.80874196 4.8402064  5.25735763 6.22209967 3.96105231 5.55022239\n",
      " 4.43325687 5.06471747 5.07656321 6.01663214 5.55936131 5.65010458\n",
      " 6.50945151 5.65250501 6.2622686  4.8800172  5.24148502 5.59063102\n",
      " 4.57162114 4.75726857 6.36014775 5.33772809 5.28152777 5.19339637\n",
      " 5.47293823 5.67786959 6.97149848 5.22763747 6.47983572 6.03232188\n",
      " 5.29208456 2.71179676 4.94335481 6.11360952 5.12615022 6.43645053\n",
      " 5.57573488 6.77061565 5.00425225 5.19256982 5.80337113 6.15933007\n",
      " 3.75944054 6.19782831 4.60466321 6.75808424 5.29899325 5.5504181\n",
      " 6.45869037 5.90222556 5.94509535 6.94369616 5.68782118 5.75366183\n",
      " 4.94504951 6.19240416 5.64664214 5.81225991 5.1433046  6.4905905\n",
      " 5.95886362 5.61454748 6.21389268 4.52111356 5.49919501 6.27992823\n",
      " 5.67688291 6.3408425  6.09553886 5.56128887 5.10592509 5.72437986\n",
      " 6.84998657 4.92223722 5.95326542 6.12697422 7.17031886 4.72547454\n",
      " 7.47328642 5.21163849 3.95773246 5.71047883 5.28205121 6.25319723\n",
      " 6.63735201 5.20733255 6.51689296 5.80758452 5.76731774 4.68503282\n",
      " 5.2738044  5.74649152 5.33536897 4.6910564  4.679225   6.18770594\n",
      " 4.92019175 4.93550868 5.67060198]\n",
      "\n",
      "What it should be:  [5.83333333 6.83333333 6.5        6.83333333 5.16666667 6.33333333\n",
      " 5.66666667 5.83333333 5.33333333 6.5        6.5        5.5\n",
      " 6.66666667 5.33333333 4.66666667 6.16666667 6.83333333 6.16666667\n",
      " 4.83333333 6.66666667 1.83333333 6.66666667 5.16666667 6.33333333\n",
      " 4.66666667 6.33333333 4.5        7.         5.5        6.\n",
      " 5.5        5.5        6.66666667 6.         4.5        6.16666667\n",
      " 4.5        6.         6.33333333 5.66666667 6.         4.\n",
      " 6.83333333 5.5        5.33333333 3.66666667 5.66666667 6.16666667\n",
      " 6.33333333 6.66666667 5.83333333 4.83333333 5.83333333 6.16666667\n",
      " 5.16666667 3.33333333 6.5        5.         5.66666667 5.66666667\n",
      " 5.         4.83333333 4.83333333 6.83333333 5.33333333 7.\n",
      " 6.16666667 6.         5.66666667 4.66666667 5.5        6.5\n",
      " 7.         6.         4.         6.16666667 6.         5.33333333\n",
      " 6.16666667 5.83333333 5.83333333 4.66666667 5.33333333 5.16666667\n",
      " 6.16666667 6.5        6.         4.83333333 5.16666667 5.33333333\n",
      " 5.33333333 5.83333333 5.16666667 5.33333333 6.         5.33333333\n",
      " 6.5        6.5        5.33333333 5.66666667 3.66666667 5.5\n",
      " 6.5        6.83333333 6.83333333 6.66666667 7.         3.5\n",
      " 6.33333333 6.16666667 6.5        6.         6.66666667 5.66666667\n",
      " 6.16666667 5.         5.66666667 6.16666667 4.83333333 4.66666667\n",
      " 5.         4.66666667 5.83333333 6.33333333 6.16666667 5.33333333\n",
      " 5.66666667 6.5        5.5       ]\n",
      "Correlation:  [[1.         0.21240946]\n",
      " [0.21240946 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.04\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.4\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.93294015 5.29261057 4.80914522 5.59529097 5.54596403 6.02354451\n",
      " 5.74291775 5.96300457 6.56124399 6.1378376  5.29291851 5.63120305\n",
      " 5.25653626 5.23863154 6.00778168 5.40231279 6.25054609 5.11792785\n",
      " 4.83757127 5.84129435 5.80390319 7.35769921 6.75789976 6.47894245\n",
      " 5.88107516 4.68187949 5.73322677 5.95454205 3.78571153 6.73989937\n",
      " 5.53537112 6.22357189 5.97714934 6.06468167 5.44180773 5.57900214\n",
      " 5.53201284 5.57228941 5.86632511 6.87390887 4.24370739 6.41313436\n",
      " 4.7784397  7.16627373 5.64972005 5.9958147  5.03273788 5.6400914\n",
      " 6.30026155 6.43400781 5.48500864 5.86585861 5.59283699 5.44802817\n",
      " 6.2484601  5.9181631  5.27677538 5.76953221 5.32130424 5.9648247\n",
      " 6.14490598 6.47497012 5.37163641 5.32905573 6.09551457 5.91022299\n",
      " 5.61065404 6.4348888  6.17267769 5.07060527 6.71102231 5.6934653\n",
      " 5.58031934 6.10458889 4.6109577  5.73544068 6.03589368 5.43704588\n",
      " 4.65944533 5.1252895  5.31683528 4.51131626 6.00241347 5.15419122\n",
      " 6.03100118 5.51090852 6.27825373 5.62070959 5.6396643  6.66558887\n",
      " 6.72407338 7.09612199 5.55460132 5.60634042 5.74431333 5.89834776\n",
      " 5.24144692 5.35406345 6.21305958 5.1815847  4.69108581 6.28212501\n",
      " 5.63401825 5.60693585 5.84657416 5.29308262 6.09592277 6.22536823\n",
      " 6.19986756 6.01325254 5.87081547 6.89493879 6.16050587 5.63021604\n",
      " 6.51648958 5.74283059 5.87835151 5.79673691 5.90709422 5.65763561\n",
      " 5.38002241 5.14309663 5.65813158 5.29441171 5.79015008 5.8658966\n",
      " 6.00877017 6.29515383 5.38287214]\n",
      "\n",
      "What it should be:  [6.83333333 4.83333333 5.33333333 4.16666667 6.16666667 5.66666667\n",
      " 6.         5.5        5.33333333 5.16666667 4.         6.66666667\n",
      " 6.         6.83333333 5.33333333 5.66666667 5.33333333 6.5\n",
      " 6.5        5.5        5.66666667 6.66666667 7.         6.66666667\n",
      " 6.16666667 4.33333333 6.16666667 6.16666667 6.33333333 7.\n",
      " 5.83333333 5.         4.5        5.16666667 5.33333333 6.5\n",
      " 5.33333333 6.5        6.         4.83333333 4.83333333 6.16666667\n",
      " 4.         6.5        5.16666667 5.83333333 5.33333333 6.5\n",
      " 5.16666667 6.83333333 4.33333333 5.33333333 6.16666667 4.\n",
      " 4.         6.16666667 5.16666667 3.66666667 4.83333333 6.5\n",
      " 4.66666667 6.16666667 6.16666667 6.16666667 6.         5.33333333\n",
      " 5.83333333 5.33333333 6.33333333 6.         6.         5.66666667\n",
      " 5.         5.83333333 6.33333333 3.66666667 5.5        5.16666667\n",
      " 6.33333333 5.5        6.83333333 5.         6.         5.66666667\n",
      " 6.         5.33333333 4.33333333 6.83333333 5.83333333 6.66666667\n",
      " 6.16666667 4.5        6.5        5.66666667 5.5        6.16666667\n",
      " 4.83333333 4.83333333 6.5        5.33333333 3.33333333 6.66666667\n",
      " 5.16666667 4.66666667 6.16666667 5.83333333 6.83333333 5.83333333\n",
      " 6.66666667 7.         6.33333333 4.66666667 4.66666667 6.16666667\n",
      " 6.         5.         6.5        6.66666667 6.33333333 3.83333333\n",
      " 5.5        5.83333333 4.         6.5        5.66666667 6.33333333\n",
      " 5.33333333 5.16666667 7.        ]\n",
      "Correlation:  [[1.         0.16147188]\n",
      " [0.16147188 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.91\n",
      "Median absolute error = 0.54\n",
      "Explain variance score = -0.25\n",
      "R2 score = -0.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.41230082 3.62761915 5.35448685 4.52342482 4.85516197 6.18524643\n",
      " 5.8487318  6.00297101 5.91376594 4.94393691 5.76998369 6.11598456\n",
      " 3.28498897 5.65421743 5.65277613 5.33201185 6.21577236 5.42660206\n",
      " 5.15153299 5.3630994  5.57888176 5.67810892 7.11613596 6.31339415\n",
      " 5.12615767 6.51159569 5.69722906 7.54237821 5.99012908 4.52871207\n",
      " 6.19213781 5.63490023 5.12827506 6.721128   5.79396903 6.25234286\n",
      " 5.23500503 6.49586608 5.73149852 6.72722397 5.08956613 5.65716988\n",
      " 5.2735509  5.28475553 5.71897081 6.28081312 5.43850488 4.49083001\n",
      " 5.43859447 4.40535275 6.55409819 6.46865699 5.33649307 6.21128152\n",
      " 6.21906897 5.78987105 6.01340129 5.24869637 5.31727297 6.03518102\n",
      " 5.6256557  5.66691514 6.28808651 6.31527608 5.89833781 6.45947386\n",
      " 5.50571009 7.26126568 6.03672803 6.4036516  5.54498932 5.95499552\n",
      " 5.32211931 5.38737565 4.05259677 5.16099864 5.18574787 5.98959767\n",
      " 6.17974776 5.95271442 5.50373933 6.49820062 5.87259537 6.7119833\n",
      " 5.45175262 5.51586346 5.53627857 6.12355907 5.77211236 5.68520586\n",
      " 5.47069909 6.06656697 5.80611227 5.70603802 6.16580294 4.84443663\n",
      " 6.4205681  4.59723903 5.648572   5.80856058 6.06923921 5.4977269\n",
      " 5.54006307 5.540414   5.52368651 7.49189056 3.99317411 6.33253413\n",
      " 4.6474136  5.02049112 4.90809122 5.12931789 6.05632532 5.89676786\n",
      " 6.08997749 6.06356092 6.11392794 4.83148912 4.38802568 5.49572027\n",
      " 5.83293829 7.81794637 5.56596369 5.1212518  5.6628098  4.19492311\n",
      " 6.51086659 6.29991047 6.21631746]\n",
      "\n",
      "What it should be:  [5.33333333 6.16666667 6.5        6.83333333 5.33333333 6.33333333\n",
      " 5.66666667 4.83333333 6.33333333 5.83333333 6.66666667 5.33333333\n",
      " 4.83333333 5.33333333 5.5        6.16666667 6.66666667 6.33333333\n",
      " 5.5        6.33333333 6.33333333 4.33333333 6.5        6.16666667\n",
      " 3.83333333 6.66666667 6.         6.16666667 5.83333333 4.33333333\n",
      " 5.83333333 4.         6.66666667 6.5        5.5        6.66666667\n",
      " 4.83333333 5.66666667 5.16666667 5.33333333 6.5        6.\n",
      " 5.83333333 5.16666667 6.5        6.5        5.83333333 4.83333333\n",
      " 6.5        4.83333333 4.5        5.33333333 4.33333333 6.33333333\n",
      " 5.33333333 6.5        6.83333333 4.         4.         6.83333333\n",
      " 6.16666667 5.33333333 7.         5.33333333 4.66666667 6.\n",
      " 5.5        5.5        5.33333333 6.5        6.16666667 7.\n",
      " 3.5        6.83333333 6.83333333 6.         4.         5.\n",
      " 5.83333333 4.66666667 6.         6.16666667 7.         7.\n",
      " 6.         5.         6.         5.83333333 4.66666667 5.\n",
      " 3.         5.33333333 6.16666667 5.66666667 4.66666667 4.83333333\n",
      " 6.83333333 6.5        5.66666667 5.66666667 5.33333333 5.16666667\n",
      " 5.16666667 5.16666667 5.83333333 5.66666667 7.         5.\n",
      " 6.33333333 4.83333333 5.         6.33333333 6.16666667 4.66666667\n",
      " 4.66666667 6.         6.         4.83333333 5.16666667 5.33333333\n",
      " 4.66666667 6.16666667 3.33333333 6.16666667 4.         3.66666667\n",
      " 6.16666667 6.16666667 5.33333333]\n",
      "Correlation:  [[1.         0.19035881]\n",
      " [0.19035881 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.38\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.16029454 4.17107508 5.04727291 5.18948964 4.89994819 6.06998066\n",
      " 6.10444834 5.98951543 4.83252647 6.39417608 5.48014931 5.288363\n",
      " 6.63972583 6.13128432 4.96390057 5.37416687 5.5382603  6.23552962\n",
      " 5.4893063  5.55762316 5.1131193  5.74165963 5.21312343 5.87078972\n",
      " 4.29592771 5.235018   5.64862883 5.67791418 5.14465043 5.99555879\n",
      " 5.76562771 5.85700546 5.20529383 5.28665615 4.52819094 4.78660524\n",
      " 5.55140492 3.97787079 4.81853212 4.53399113 5.99754146 5.53629726\n",
      " 6.81555296 5.94736842 5.20530304 5.50475741 4.73806932 4.60304841\n",
      " 5.71975106 5.44283492 5.73825096 5.5870159  5.70744612 4.95021686\n",
      " 5.7178082  5.8498239  5.55047817 5.29235733 6.19691226 5.5522442\n",
      " 6.41017676 5.16560359 4.96435061 6.44061462 6.10762646 5.81230369\n",
      " 5.8927699  6.13543287 5.40193557 5.3602714  6.39126152 5.76295726\n",
      " 7.26920325 5.36484484 5.41401972 6.01667103 5.84994867 6.34389348\n",
      " 5.65518618 6.67736972 5.59899817 4.28130542 5.42209477 6.21211071\n",
      " 5.81630661 5.24803067 5.75869613 4.7307612  5.34797556 5.3311157\n",
      " 5.00385925 4.49276356 5.08208673 5.11409584 6.32917023 5.34667588\n",
      " 6.40104779 5.87289811 6.49973121 5.33845735 5.42654856 5.15844741\n",
      " 5.8252626  5.79327759 5.9870412  6.42948334 5.7650931  4.78247971\n",
      " 5.84695948 5.66309351 5.36109238 5.48636124 6.34105362 5.30379638\n",
      " 6.48731146 5.17562943 5.26858317 5.55989081 5.99902801 5.47163654\n",
      " 6.33034103 5.32262914 6.32102531 5.41557413 5.39287293 6.17112163\n",
      " 5.90515502 5.0335865  3.65272868]\n",
      "\n",
      "What it should be:  [6.33333333 5.33333333 6.5        5.66666667 5.66666667 6.5\n",
      " 6.16666667 6.16666667 5.83333333 7.         6.33333333 6.5\n",
      " 5.66666667 5.83333333 4.5        5.5        5.33333333 6.5\n",
      " 4.         4.83333333 3.5        6.16666667 4.         5.83333333\n",
      " 1.83333333 6.         6.         6.33333333 7.         5.83333333\n",
      " 5.83333333 5.         5.83333333 4.83333333 6.         5.\n",
      " 6.16666667 4.83333333 5.83333333 4.33333333 5.16666667 6.5\n",
      " 6.16666667 4.5        5.66666667 5.         5.5        5.16666667\n",
      " 4.         6.5        6.16666667 6.33333333 5.16666667 7.\n",
      " 6.66666667 6.33333333 5.16666667 5.33333333 6.         5.33333333\n",
      " 4.66666667 6.5        6.83333333 5.33333333 6.66666667 4.5\n",
      " 6.         6.         5.5        5.5        5.83333333 6.66666667\n",
      " 6.16666667 6.5        6.83333333 5.16666667 5.16666667 6.83333333\n",
      " 5.5        6.16666667 6.         7.         5.5        5.33333333\n",
      " 6.66666667 6.83333333 6.         4.83333333 4.33333333 5.66666667\n",
      " 6.33333333 6.5        6.         4.66666667 6.16666667 6.83333333\n",
      " 5.33333333 6.33333333 4.66666667 5.66666667 5.33333333 5.16666667\n",
      " 5.83333333 5.33333333 5.83333333 5.66666667 5.5        6.83333333\n",
      " 6.66666667 3.         6.16666667 6.         6.16666667 6.16666667\n",
      " 4.66666667 5.83333333 4.         5.         5.16666667 6.16666667\n",
      " 5.33333333 5.83333333 6.5        4.5        6.83333333 6.5\n",
      " 5.5        4.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.12510769]\n",
      " [0.12510769 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = -0.31\n",
      "R2 score = -0.33\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.16075291 5.64641934 5.19707044 6.14308082 5.33372577 4.92632795\n",
      " 5.40286156 5.64852743 6.06592532 5.06611993 6.1847701  5.45570004\n",
      " 5.48102959 5.85392605 5.27495675 5.70764805 5.86159821 5.19685758\n",
      " 5.91240627 5.47573148 6.33360946 5.50045504 5.65219282 5.38047916\n",
      " 6.00711691 6.1069996  5.73655081 5.53815443 5.78381284 5.17075044\n",
      " 5.3871446  5.18199438 6.0179756  5.44140629 5.55600312 5.52178095\n",
      " 5.60142884 5.76389346 6.09006457 5.84409848 5.56951356 5.39867329\n",
      " 6.00140728 5.60654542 5.9873897  5.52314791 5.75187227 5.21393753\n",
      " 6.08617206 5.4951818  5.69035376 6.29666068 4.88570868 5.8978705\n",
      " 6.03309794 6.30665165 5.60722347 5.64959206 5.18664931 6.21590992\n",
      " 5.10499639 6.38897478 5.47952331 4.88760106 6.060105   5.42725898\n",
      " 5.03209509 5.65537652 6.02983049 5.78652691 5.38088097 5.65594208\n",
      " 4.72224792 5.9716652  4.98564066 5.83947219 5.50769838 4.08940884\n",
      " 6.25952757 6.07307434 5.45768335 5.60646092 5.54145384 4.88018817\n",
      " 5.11235527 5.61893512 5.66405367 5.39405244 6.2446866  6.26223817\n",
      " 5.89265946 5.67332569 6.01022351 5.63797551 5.23775883 5.87178489\n",
      " 5.62996424 5.54549558 6.00654545 5.54347544 5.15853965 5.93405109\n",
      " 6.0676445  5.6913876  5.39859013 5.77531093 5.95060108 5.97366266\n",
      " 6.1479489  4.94402417 5.61754198 5.51987655 5.16477108 5.59032324\n",
      " 5.41146765 5.60470139 5.36963243 5.27518446 6.18996992 5.96151288\n",
      " 5.23759744 6.10106304 5.87858503 5.48751338 5.55687897 6.44017706\n",
      " 5.50476415 5.74669279 5.10105469]\n",
      "\n",
      "What it should be:  [6.         5.33333333 5.83333333 6.83333333 6.66666667 5.66666667\n",
      " 6.5        6.83333333 5.33333333 4.33333333 4.         4.33333333\n",
      " 5.33333333 4.66666667 6.66666667 5.         7.         3.5\n",
      " 6.33333333 5.83333333 4.83333333 6.5        5.83333333 6.33333333\n",
      " 5.66666667 6.16666667 3.66666667 6.         6.66666667 6.66666667\n",
      " 3.33333333 6.66666667 5.33333333 5.33333333 5.33333333 5.33333333\n",
      " 6.         6.83333333 4.83333333 3.66666667 5.33333333 6.\n",
      " 6.5        6.33333333 7.         4.33333333 7.         6.66666667\n",
      " 4.33333333 4.5        6.83333333 5.83333333 6.5        5.5\n",
      " 5.         6.16666667 6.16666667 4.66666667 4.         6.16666667\n",
      " 5.16666667 3.83333333 5.16666667 6.83333333 6.16666667 6.\n",
      " 6.16666667 5.66666667 7.         5.83333333 6.66666667 5.66666667\n",
      " 4.66666667 6.16666667 4.5        5.66666667 6.16666667 4.\n",
      " 6.33333333 5.66666667 6.5        5.66666667 6.5        6.33333333\n",
      " 6.5        6.33333333 6.83333333 5.33333333 6.16666667 6.5\n",
      " 4.83333333 6.16666667 4.5        5.16666667 6.         6.5\n",
      " 4.5        6.         4.83333333 4.83333333 6.5        6.16666667\n",
      " 6.         5.         5.16666667 5.83333333 5.83333333 6.33333333\n",
      " 6.16666667 4.83333333 6.16666667 5.         6.5        6.83333333\n",
      " 6.83333333 4.5        5.5        6.83333333 5.83333333 1.83333333\n",
      " 4.83333333 6.33333333 5.5        5.5        6.16666667 6.16666667\n",
      " 3.         5.33333333 5.83333333]\n",
      "Correlation:  [[1.         0.03604651]\n",
      " [0.03604651 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.14\n",
      "R2 score = -0.14\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.60271065 5.61553756 4.50411529 5.04910244 5.563382   5.84494812\n",
      " 5.15389054 6.25075821 5.28837858 5.75497941 5.22043258 5.913462\n",
      " 5.60443034 6.24529877 5.7866181  5.30847942 4.88909583 5.24287755\n",
      " 5.72577481 5.27597284 5.43075069 6.19854928 5.77013613 5.58311979\n",
      " 6.1581931  4.86145288 6.33497493 6.54395102 5.05925939 5.61139318\n",
      " 5.17097032 5.6660711  6.2023474  6.08120666 5.74169722 5.93096222\n",
      " 5.32350084 4.7884336  5.13732316 5.33145623 5.59755072 5.89038698\n",
      " 4.96918125 5.96812148 4.60617994 5.77084756 5.77401445 5.63496201\n",
      " 5.04855799 4.9516292  6.40915267 6.05949287 5.65696747 6.19290651\n",
      " 5.38248868 5.85528852 6.48936803 5.54132815 6.37080109 6.34069616\n",
      " 5.43304013 6.24912789 5.29630222 4.6993584  5.64847002 5.14957379\n",
      " 5.50319381 5.91933666 5.44548997 5.92315571 5.92388407 6.24546903\n",
      " 5.18367208 4.85394545 5.73364376 6.05487808 4.46077586 5.33493627\n",
      " 6.75316914 5.25514017 5.52408851 5.37524351 6.14576793 4.85881838\n",
      " 5.8788114  5.7549463  5.93485604 5.76772783 4.68754439 5.94659757\n",
      " 3.9995978  6.07739592 5.29379656 6.0264978  6.24010746 5.30323161\n",
      " 4.92784567 6.27572507 5.42130809 5.36472822 5.64206941 6.03115517\n",
      " 5.81110158 6.20199069 5.7764137  5.39016886 5.60465392 5.94429521\n",
      " 5.72658629 6.45608562 5.41603914 5.42799442 5.26495697 6.17885858\n",
      " 5.89337002 5.21700405 6.1883737  6.06391121 5.43409461 5.5339183\n",
      " 6.09543919 5.31290486 6.39987004 5.15084512 5.88734033 6.16820947\n",
      " 5.89004878 5.50042265 5.26800169]\n",
      "\n",
      "What it should be:  [6.         6.16666667 5.66666667 5.33333333 6.5        5.33333333\n",
      " 5.5        5.16666667 5.83333333 3.33333333 5.66666667 5.5\n",
      " 6.16666667 4.16666667 5.5        5.66666667 6.         4.83333333\n",
      " 5.66666667 6.66666667 6.16666667 3.66666667 4.         3.5\n",
      " 6.83333333 5.83333333 6.66666667 5.33333333 5.33333333 6.16666667\n",
      " 4.33333333 5.5        4.5        6.83333333 6.5        6.\n",
      " 6.16666667 5.33333333 6.         5.33333333 6.         5.83333333\n",
      " 7.         5.66666667 6.33333333 6.5        4.66666667 6.16666667\n",
      " 6.33333333 4.5        6.         7.         4.         5.83333333\n",
      " 4.33333333 5.33333333 4.33333333 4.66666667 6.83333333 5.16666667\n",
      " 6.5        5.83333333 4.66666667 1.83333333 4.83333333 5.\n",
      " 5.66666667 4.66666667 5.5        5.83333333 6.         5.83333333\n",
      " 5.33333333 6.33333333 6.5        6.83333333 5.66666667 6.33333333\n",
      " 6.5        5.16666667 6.16666667 5.         6.16666667 4.83333333\n",
      " 6.5        6.5        6.83333333 5.         6.16666667 6.66666667\n",
      " 5.5        6.16666667 6.16666667 7.         5.83333333 5.\n",
      " 6.5        4.83333333 6.16666667 3.66666667 6.66666667 6.16666667\n",
      " 4.         4.66666667 4.83333333 5.33333333 5.83333333 6.5\n",
      " 7.         6.5        5.16666667 6.66666667 4.83333333 6.16666667\n",
      " 5.16666667 6.16666667 6.         6.16666667 6.83333333 6.33333333\n",
      " 6.33333333 5.83333333 6.16666667 6.83333333 4.5        6.5\n",
      " 6.16666667 4.66666667 5.33333333]\n",
      "Correlation:  [[1.         0.11178749]\n",
      " [0.11178749 1.        ]]\n",
      "Mean absolute error = 0.78\n",
      "Mean squared error = 0.97\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.00753491 5.40686391 6.79964963 5.74349349 4.81758522 4.87543286\n",
      " 5.74470998 5.50238428 5.23980808 5.45196195 5.91406185 5.72670559\n",
      " 5.82012262 4.5195796  5.66382519 6.28258494 3.08617516 5.92722453\n",
      " 6.23488094 5.47257346 5.85356515 5.59069975 4.69286947 5.27119642\n",
      " 5.73102201 5.95021741 5.30486621 6.17572334 5.16205399 5.77608378\n",
      " 4.47232908 5.46067846 6.1423253  6.08815179 5.14589373 5.52505635\n",
      " 5.75377629 5.27137788 6.25388714 5.05078046 4.68710104 4.20847891\n",
      " 5.2920052  5.09412649 5.85525849 5.14489648 5.30550859 6.24736447\n",
      " 6.66187734 5.43774933 5.66992114 6.41446415 6.04847201 5.88588888\n",
      " 5.29846977 4.89691384 4.8066317  5.34884476 5.01113235 5.99686955\n",
      " 5.65425801 5.74663615 6.65293447 5.32467751 6.17002856 5.78445868\n",
      " 6.27459406 5.51505495 5.44158411 5.19805127 5.11186429 4.41296339\n",
      " 6.37007648 5.85859863 5.19665582 5.9153493  5.067504   4.72024362\n",
      " 4.80162827 5.83943154 5.00542513 6.37040776 5.70398153 5.83878505\n",
      " 4.80694478 6.31365535 6.05764966 5.67171778 3.83939301 6.74827046\n",
      " 4.85026894 4.56834753 5.44312165 5.91055297 4.09541288 5.44378196\n",
      " 5.78653249 5.83905264 4.43844597 6.29609624 5.37157336 5.20282831\n",
      " 6.75591385 4.94811708 6.15255323 6.33537346 5.73566388 5.19827484\n",
      " 5.59465507 4.97298808 5.67284408 5.34340369 5.89086821 5.94850519\n",
      " 7.68303517 5.72285201 6.0033161  5.8661149  5.95311099 6.78104135\n",
      " 6.25335549 4.71328823 6.35779892 4.82827896 5.99314433 5.47521347\n",
      " 5.59853955 5.65590194 6.00667458]\n",
      "\n",
      "What it should be:  [4.         6.         4.66666667 7.         6.         3.66666667\n",
      " 6.5        6.         5.83333333 3.33333333 5.         6.83333333\n",
      " 5.33333333 5.83333333 6.         4.66666667 5.5        5.16666667\n",
      " 6.5        6.         5.66666667 6.16666667 6.16666667 5.33333333\n",
      " 6.5        6.83333333 4.33333333 5.33333333 4.66666667 6.\n",
      " 6.33333333 6.         6.66666667 6.33333333 6.16666667 4.33333333\n",
      " 5.         4.         5.83333333 6.83333333 5.66666667 6.5\n",
      " 6.33333333 6.66666667 6.33333333 5.         5.33333333 4.5\n",
      " 6.33333333 5.33333333 6.83333333 5.83333333 6.16666667 6.66666667\n",
      " 5.33333333 5.83333333 6.16666667 5.83333333 6.5        4.5\n",
      " 5.66666667 3.66666667 4.83333333 6.5        5.5        5.16666667\n",
      " 6.66666667 4.         5.33333333 6.33333333 6.16666667 6.33333333\n",
      " 5.66666667 6.5        6.5        5.66666667 6.16666667 6.66666667\n",
      " 4.33333333 6.16666667 6.16666667 6.33333333 7.         6.\n",
      " 4.         4.66666667 6.83333333 5.33333333 5.83333333 6.\n",
      " 3.83333333 4.83333333 6.66666667 6.16666667 4.83333333 5.5\n",
      " 5.16666667 5.5        6.         4.         5.33333333 5.83333333\n",
      " 4.5        4.83333333 6.         4.66666667 5.83333333 4.16666667\n",
      " 5.16666667 4.66666667 4.83333333 5.16666667 6.66666667 6.83333333\n",
      " 3.         5.66666667 6.5        5.5        5.33333333 5.66666667\n",
      " 6.5        6.33333333 6.5        5.33333333 6.16666667 5.33333333\n",
      " 3.66666667 5.5        4.33333333]\n",
      "Correlation:  [[ 1.         -0.06281538]\n",
      " [-0.06281538  1.        ]]\n",
      "Mean absolute error = 0.89\n",
      "Mean squared error = 1.3\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.63\n",
      "R2 score = -0.64\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.31269689 5.90716562 5.79232614 6.06001549 5.88328451 5.80819245\n",
      " 5.85680874 5.52976907 5.94201454 5.55437071 5.11218605 5.87177267\n",
      " 5.07039931 5.70357278 5.06347966 5.17201989 5.57499017 4.98995254\n",
      " 5.55341124 5.72965465 5.82016086 5.33640572 7.06624725 4.9909442\n",
      " 6.17706913 6.00970742 5.59936749 5.47719293 5.66106345 6.56200433\n",
      " 5.93144834 5.64900041 6.25628336 6.36872157 6.14970061 6.11953551\n",
      " 6.31463947 5.77685312 6.24697347 5.99348509 5.59987081 5.75693623\n",
      " 5.68943096 5.61135468 5.23399592 5.87866489 5.93536525 5.55801442\n",
      " 5.88878915 5.521405   5.87796554 5.37429652 5.40455702 5.74768274\n",
      " 6.79932808 6.29322731 6.15732821 6.15717596 6.59682022 5.8272578\n",
      " 6.55660338 4.80147337 5.29017784 5.83046006 5.74528592 5.40270601\n",
      " 5.93882199 5.75428762 5.59565908 5.75602303 5.76209336 5.97660316\n",
      " 6.08023522 5.27316886 5.57732555 5.9005173  5.89035383 6.29228017\n",
      " 5.38515268 5.88592286 5.20017179 6.09913756 6.55022321 5.5580595\n",
      " 6.27706247 5.51008866 6.53173821 5.00456117 5.79753062 5.74849414\n",
      " 6.18674661 5.1876582  5.55191639 6.10579012 5.74019252 5.67053027\n",
      " 6.10273172 6.13657734 6.4641197  6.01336725 5.36878716 5.58463733\n",
      " 5.31075529 5.82509587 4.53719411 5.67905959 5.63352071 5.46493629\n",
      " 5.3713584  5.32970471 5.38740647 6.29053218 5.74566544 5.87915991\n",
      " 5.94641384 5.46464288 5.69341442 5.74036574 5.8481265  6.02525893\n",
      " 5.76248046 5.64556922 5.89557884 5.65232614 5.35104227 5.29315499\n",
      " 5.57607177 6.21308329 5.5886604 ]\n",
      "\n",
      "What it should be:  [4.83333333 6.5        5.5        6.16666667 5.66666667 6.16666667\n",
      " 4.83333333 5.33333333 5.33333333 6.5        3.66666667 6.33333333\n",
      " 5.16666667 4.         6.33333333 4.5        4.16666667 6.83333333\n",
      " 6.         4.5        6.33333333 5.66666667 5.83333333 4.66666667\n",
      " 5.83333333 6.         6.5        5.83333333 4.33333333 5.5\n",
      " 5.66666667 6.5        4.66666667 6.33333333 5.         5.66666667\n",
      " 5.33333333 5.33333333 5.66666667 4.66666667 6.5        5.33333333\n",
      " 4.         5.16666667 5.66666667 7.         4.83333333 5.\n",
      " 6.16666667 5.33333333 5.5        6.66666667 6.66666667 6.16666667\n",
      " 6.33333333 5.         6.         4.         6.83333333 5.33333333\n",
      " 6.33333333 5.5        6.         6.         4.83333333 6.66666667\n",
      " 6.83333333 4.         4.83333333 6.         6.5        3.66666667\n",
      " 6.16666667 4.33333333 6.5        3.83333333 4.5        5.16666667\n",
      " 7.         6.5        4.5        5.33333333 4.         6.16666667\n",
      " 4.33333333 5.83333333 7.         4.33333333 5.83333333 6.66666667\n",
      " 5.66666667 5.5        5.83333333 5.5        6.5        6.83333333\n",
      " 1.83333333 5.83333333 6.83333333 6.5        6.33333333 6.16666667\n",
      " 5.33333333 5.33333333 3.         6.16666667 6.66666667 5.66666667\n",
      " 5.         6.16666667 6.16666667 6.         5.83333333 5.33333333\n",
      " 6.66666667 5.5        5.16666667 6.66666667 6.33333333 5.33333333\n",
      " 6.16666667 6.16666667 6.16666667 6.16666667 6.16666667 4.66666667\n",
      " 3.5        3.33333333 6.5       ]\n",
      "Correlation:  [[1.         0.09106518]\n",
      " [0.09106518 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.04\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.11\n",
      "R2 score = -0.14\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.07003937 5.89572572 5.53858888 4.74112253 5.70130095 5.66479118\n",
      " 5.31583416 5.39132557 6.24083853 4.48253425 5.29020714 6.02396806\n",
      " 5.55972364 4.70326534 5.28215449 5.04872015 5.26435131 5.65190607\n",
      " 5.1316677  5.20548526 5.38203668 5.72238948 5.55624063 4.90022516\n",
      " 5.86864999 5.86214516 4.63560707 6.39921837 4.68381134 5.70929798\n",
      " 6.21619395 5.07133979 5.88731319 5.52046925 5.24874257 5.14982185\n",
      " 5.4148141  5.89711704 5.1916832  5.93702669 5.63083558 5.61564239\n",
      " 6.2013384  5.59218419 5.80680312 6.09386416 5.44498973 5.70406445\n",
      " 6.24447044 5.11307165 4.82549383 6.20780705 5.71555244 5.77277504\n",
      " 4.70647002 5.58469522 5.39822996 4.70279697 6.14346367 5.87333427\n",
      " 5.81010413 4.66338296 5.54319664 5.41886988 5.51152289 4.72677667\n",
      " 4.12407109 5.50714647 5.99208644 6.026527   6.09262268 5.17463394\n",
      " 5.23132687 4.78367579 5.36434994 5.46706051 5.33918016 5.79142222\n",
      " 5.73576132 6.33594189 5.67609382 5.80820948 5.70781076 5.49147305\n",
      " 5.79404331 5.02558232 5.82429246 5.73215759 6.1942299  5.69416616\n",
      " 5.89238301 5.1092529  4.43837886 5.68020003 6.45638272 6.15786697\n",
      " 5.69014466 6.15160403 5.91883496 4.80517778 5.62459135 4.88505436\n",
      " 5.3327887  5.67274033 5.66802784 5.7462165  4.75747463 5.61514126\n",
      " 5.86984701 5.689009   4.74678008 5.56021425 5.32926013 5.28011622\n",
      " 5.6785217  4.88883158 5.05519466 5.7056473  4.53785317 5.48091808\n",
      " 4.8279455  5.66318103 5.97453292 5.61227571 6.2830577  5.0822066\n",
      " 5.95007204 5.50922777 4.96303302]\n",
      "\n",
      "What it should be:  [6.16666667 6.33333333 5.83333333 4.83333333 5.66666667 4.5\n",
      " 5.83333333 4.66666667 6.33333333 3.         5.83333333 6.5\n",
      " 6.83333333 6.83333333 6.         5.5        5.66666667 6.16666667\n",
      " 6.5        5.33333333 5.83333333 6.16666667 3.33333333 7.\n",
      " 5.66666667 6.33333333 4.83333333 7.         3.66666667 6.66666667\n",
      " 6.5        6.5        6.5        6.83333333 5.33333333 3.5\n",
      " 5.83333333 4.66666667 6.16666667 6.33333333 4.         6.5\n",
      " 5.5        6.         4.83333333 6.16666667 5.33333333 6.66666667\n",
      " 5.83333333 6.16666667 7.         5.33333333 5.16666667 4.83333333\n",
      " 3.66666667 6.5        5.         5.5        4.5        6.16666667\n",
      " 6.5        6.5        6.66666667 5.         6.33333333 6.83333333\n",
      " 5.5        4.83333333 5.33333333 6.         5.83333333 6.33333333\n",
      " 4.66666667 3.66666667 5.83333333 4.33333333 5.16666667 5.16666667\n",
      " 6.         6.5        6.33333333 6.83333333 5.66666667 6.66666667\n",
      " 5.66666667 5.         5.5        5.33333333 6.16666667 5.33333333\n",
      " 5.66666667 6.         4.5        6.         5.33333333 5.66666667\n",
      " 6.         5.66666667 6.66666667 6.5        6.         4.5\n",
      " 5.16666667 6.83333333 5.5        4.66666667 4.33333333 6.66666667\n",
      " 6.66666667 4.16666667 5.66666667 6.66666667 6.16666667 5.\n",
      " 6.         6.33333333 4.83333333 7.         1.83333333 5.16666667\n",
      " 6.16666667 5.16666667 4.66666667 6.83333333 6.33333333 6.33333333\n",
      " 6.83333333 6.16666667 5.83333333]\n",
      "Correlation:  [[1.         0.28206777]\n",
      " [0.28206777 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.89\n",
      "Median absolute error = 0.66\n",
      "Explain variance score = 0.03\n",
      "R2 score = -0.01\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.634182   5.2109527  5.45051424 6.01663015 5.6238263  5.6046152\n",
      " 4.88678147 5.27959318 5.30860437 5.38933496 6.12135395 5.93353161\n",
      " 6.00409363 5.77416334 5.77480722 6.05630305 5.68663637 5.33213249\n",
      " 5.98416314 5.35501544 5.70552005 4.86739007 5.85028539 5.8616255\n",
      " 5.41475103 6.29860906 5.30523904 6.10606964 6.50289514 5.95133126\n",
      " 5.65494546 6.37453076 5.40764706 6.20527439 6.07821827 6.24475643\n",
      " 5.64830543 5.78340478 5.7502171  5.53211517 6.85026942 6.78958681\n",
      " 5.57030154 5.81125181 4.81613027 6.8134011  6.34192867 5.87223375\n",
      " 5.10265255 5.848119   6.32926418 6.49334206 5.75240587 5.54589328\n",
      " 6.13362695 5.59355697 6.1520353  5.42858757 5.82573603 6.00757306\n",
      " 5.88713832 5.56640532 5.79663763 5.88820666 5.59524924 6.12483904\n",
      " 5.96045696 5.98429689 5.62966762 6.52318188 5.32139906 6.39188155\n",
      " 5.95770541 4.85035515 6.25864924 6.2353103  5.74532915 5.89677704\n",
      " 6.29099934 5.98078678 5.8859615  6.03703278 5.90805299 5.97914487\n",
      " 5.69334022 6.56861688 6.00376612 5.42400387 5.52167984 5.6948371\n",
      " 5.71708268 5.10576812 5.78285823 6.0634496  5.71067574 6.50593846\n",
      " 5.90352907 5.51859662 6.03965161 5.98077976 5.73684408 6.16844864\n",
      " 5.50235254 6.25418995 5.51160477 5.68628728 5.30262222 5.34613844\n",
      " 6.30700753 5.98818378 5.63171614 5.34859371 5.96047964 5.01832048\n",
      " 6.27138967 6.3878827  5.94096828 5.29087803 6.192494   5.56587701\n",
      " 5.93059683 5.54342931 5.62139724 6.22297745 5.51504605 6.16018223\n",
      " 6.19332824 5.17677708 4.99533271]\n",
      "\n",
      "What it should be:  [5.33333333 6.66666667 6.5        6.16666667 5.16666667 5.5\n",
      " 4.33333333 6.83333333 5.33333333 6.         4.5        6.83333333\n",
      " 6.66666667 6.16666667 6.16666667 6.66666667 5.5        5.16666667\n",
      " 5.5        5.5        7.         6.         6.5        6.5\n",
      " 5.5        4.66666667 4.5        4.66666667 6.5        6.33333333\n",
      " 7.         6.16666667 4.         5.16666667 6.33333333 6.16666667\n",
      " 3.66666667 5.16666667 3.33333333 6.5        5.         5.33333333\n",
      " 4.66666667 5.83333333 4.5        4.33333333 6.5        4.83333333\n",
      " 4.66666667 7.         6.         5.33333333 6.33333333 6.16666667\n",
      " 4.33333333 6.83333333 4.         4.83333333 5.66666667 6.66666667\n",
      " 3.         4.83333333 7.         6.66666667 5.5        5.33333333\n",
      " 6.16666667 3.66666667 5.33333333 6.         5.16666667 5.83333333\n",
      " 6.16666667 6.5        4.83333333 5.5        5.66666667 6.16666667\n",
      " 4.66666667 6.16666667 5.16666667 4.         5.         4.83333333\n",
      " 5.         5.83333333 6.5        4.66666667 5.83333333 6.5\n",
      " 6.33333333 6.5        4.66666667 7.         6.5        5.33333333\n",
      " 5.83333333 6.33333333 6.66666667 4.         5.16666667 5.83333333\n",
      " 5.83333333 4.33333333 5.66666667 6.         6.16666667 5.66666667\n",
      " 6.         4.83333333 6.66666667 5.33333333 6.33333333 5.66666667\n",
      " 1.83333333 6.33333333 5.66666667 5.16666667 6.5        4.83333333\n",
      " 3.83333333 5.5        5.33333333 5.66666667 5.33333333 6.83333333\n",
      " 5.83333333 4.         5.83333333]\n",
      "Correlation:  [[ 1.        -0.0169498]\n",
      " [-0.0169498  1.       ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.21\n",
      "R2 score = -0.28\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.68971992 5.59993811 5.72725475 6.07757913 4.69006455 6.41559663\n",
      " 4.86844015 6.39940721 5.87725706 4.48533116 4.82031548 6.32296588\n",
      " 5.18807941 3.95369815 6.3453193  5.67129268 6.45197765 5.94790644\n",
      " 5.0779335  5.95113569 5.562326   5.7545214  5.52775232 6.24961034\n",
      " 4.59841226 4.52159956 6.18598945 6.25914146 4.75753996 5.08753426\n",
      " 5.34582061 4.85754761 5.17579106 5.67792055 6.73768526 5.34990688\n",
      " 5.0154631  5.72859778 5.81867235 5.29771061 5.09997696 5.3520993\n",
      " 5.42242405 5.47938784 5.91307688 5.01963555 4.04646486 5.75503324\n",
      " 5.79933968 5.41102295 4.79029356 5.36316827 5.64742313 6.31021543\n",
      " 5.70365952 5.30235289 5.38028466 4.89481225 6.06992202 5.53876382\n",
      " 6.12909232 5.7209858  5.21517352 5.65407505 5.03169881 5.23727695\n",
      " 5.04004552 3.02902898 6.0357704  4.89721464 5.33344312 6.53917467\n",
      " 5.64981178 5.51783119 6.28021372 4.46233552 4.39162941 5.84844241\n",
      " 5.70956424 5.34946288 5.53645133 5.14409505 5.5633745  5.3979424\n",
      " 5.70124078 5.24448117 4.911392   6.30620007 6.24166391 5.72839414\n",
      " 5.74424944 7.04275528 3.71389322 6.08562916 6.11920288 5.88426385\n",
      " 5.64161841 6.34799103 6.25525782 5.35351454 5.8221693  5.88496198\n",
      " 5.58625852 4.38497253 5.76857516 4.93491891 6.09733914 5.37669917\n",
      " 6.53952105 5.86971166 5.4660632  5.1331748  6.13935283 5.4770301\n",
      " 4.61386775 5.21241437 6.72478236 5.83824062 6.54539244 5.48141872\n",
      " 6.48231668 5.57294163 5.49954532 5.4773334  5.05583979 5.23889069\n",
      " 5.42214902 6.19704838 4.75110035]\n",
      "\n",
      "What it should be:  [6.83333333 3.         4.33333333 7.         5.66666667 5.83333333\n",
      " 6.66666667 4.5        4.66666667 6.         6.5        6.16666667\n",
      " 6.         5.16666667 5.16666667 6.5        6.5        6.5\n",
      " 4.83333333 5.16666667 5.33333333 6.33333333 6.16666667 5.66666667\n",
      " 3.83333333 6.33333333 4.66666667 5.33333333 5.83333333 3.66666667\n",
      " 4.66666667 5.         6.16666667 5.66666667 4.83333333 4.\n",
      " 6.33333333 5.16666667 5.16666667 6.66666667 5.5        6.5\n",
      " 6.66666667 5.5        6.         6.16666667 4.33333333 6.\n",
      " 5.16666667 6.33333333 6.33333333 6.16666667 4.83333333 4.5\n",
      " 3.5        6.5        7.         5.33333333 5.66666667 5.5\n",
      " 5.16666667 6.33333333 6.66666667 5.83333333 5.33333333 4.33333333\n",
      " 6.5        5.5        6.         7.         5.83333333 6.83333333\n",
      " 5.66666667 6.66666667 5.66666667 6.         6.5        6.5\n",
      " 6.66666667 5.         6.83333333 6.16666667 4.5        5.66666667\n",
      " 5.66666667 5.         4.83333333 6.5        6.5        6.66666667\n",
      " 5.5        6.5        6.5        4.         5.66666667 4.66666667\n",
      " 6.16666667 4.16666667 6.33333333 4.5        4.83333333 6.83333333\n",
      " 6.16666667 6.16666667 6.16666667 4.66666667 5.83333333 5.83333333\n",
      " 5.16666667 6.16666667 6.         6.16666667 5.83333333 5.66666667\n",
      " 5.5        4.5        7.         5.5        5.16666667 6.16666667\n",
      " 5.66666667 6.33333333 5.         5.33333333 3.66666667 5.5\n",
      " 6.         6.83333333 6.83333333]\n",
      "Correlation:  [[ 1.00000000e+00 -1.42397469e-04]\n",
      " [-1.42397469e-04  1.00000000e+00]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.78\n",
      "Explain variance score = -0.56\n",
      "R2 score = -0.6\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.22636966 5.81889083 5.45938599 5.95997734 5.56419026 5.20272916\n",
      " 5.2751759  5.59403941 5.58091003 5.284309   5.61203782 5.89206083\n",
      " 5.30836859 5.65402983 6.53621288 5.43471616 4.6913004  5.9991648\n",
      " 5.24646011 5.32311197 6.16982188 5.5978304  5.6567992  5.46297535\n",
      " 5.43978479 5.16316271 5.80819745 5.60516174 5.80389725 5.31352255\n",
      " 5.52946203 6.17041916 5.25254185 5.99103975 5.39937463 5.51591026\n",
      " 5.2374277  5.80990051 5.52819914 5.45673778 6.60963116 5.70993871\n",
      " 6.30836011 5.35188086 6.16122457 5.69790591 5.62252492 5.49444205\n",
      " 5.42495001 6.58527817 5.65881528 5.21960697 5.62391878 5.47555605\n",
      " 5.46816544 6.37294969 5.22536885 5.28098755 5.27979069 5.35899099\n",
      " 6.05839669 5.63721382 6.04520671 5.18811432 6.64925849 5.10714491\n",
      " 5.34322168 5.94401274 5.46234842 5.32124044 5.91372044 5.8209891\n",
      " 5.81885218 6.24798753 5.64497762 5.30012774 5.73492997 6.03756236\n",
      " 5.71968793 5.76599221 5.7570362  6.07367132 5.01116572 6.24724852\n",
      " 6.73750228 5.1454457  6.3087899  5.60308156 5.87406438 5.06926746\n",
      " 5.28571829 6.26866193 7.02980081 6.49053441 6.34756655 6.41562194\n",
      " 5.73442598 5.60408261 5.4896789  5.90739888 5.98718041 5.58282667\n",
      " 5.04296689 5.97306969 4.90503378 6.23166745 5.32741007 5.58150736\n",
      " 5.9959246  5.19276236 4.83711409 4.76557465 5.83446863 6.01704582\n",
      " 6.13605514 5.48911035 5.56243403 5.78590793 6.73062277 5.18264669\n",
      " 5.47824395 6.18973678 5.10308607 5.28568639 5.76497538 6.01246065\n",
      " 5.8540717  6.15987997 6.06046566]\n",
      "\n",
      "What it should be:  [5.66666667 5.83333333 6.83333333 6.5        3.83333333 5.\n",
      " 6.16666667 5.66666667 6.33333333 4.5        6.66666667 5.66666667\n",
      " 5.16666667 6.16666667 7.         6.66666667 5.33333333 5.\n",
      " 5.66666667 4.66666667 6.         5.83333333 6.83333333 4.83333333\n",
      " 3.5        5.5        5.66666667 6.         5.66666667 5.\n",
      " 6.83333333 6.83333333 6.16666667 6.5        5.5        4.5\n",
      " 5.33333333 7.         3.66666667 7.         5.83333333 4.\n",
      " 5.5        5.83333333 6.33333333 6.5        6.33333333 6.\n",
      " 6.         5.16666667 6.33333333 4.66666667 4.         5.\n",
      " 5.16666667 6.16666667 3.66666667 4.5        6.33333333 6.16666667\n",
      " 4.66666667 6.16666667 6.66666667 5.83333333 6.66666667 4.83333333\n",
      " 5.5        5.16666667 4.83333333 4.         6.5        4.83333333\n",
      " 4.33333333 6.16666667 6.         6.16666667 5.16666667 6.16666667\n",
      " 6.16666667 5.16666667 5.33333333 5.33333333 6.16666667 5.16666667\n",
      " 6.5        5.83333333 6.         4.66666667 6.16666667 3.66666667\n",
      " 6.         6.83333333 3.         7.         4.66666667 5.66666667\n",
      " 5.16666667 6.         6.66666667 5.33333333 6.16666667 6.66666667\n",
      " 6.5        6.         4.83333333 4.16666667 1.83333333 6.16666667\n",
      " 5.16666667 6.5        4.83333333 4.66666667 6.16666667 6.83333333\n",
      " 6.         6.5        6.66666667 6.16666667 4.66666667 4.\n",
      " 5.66666667 5.66666667 5.5        5.83333333 7.         6.83333333\n",
      " 6.16666667 5.33333333 6.33333333]\n",
      "Correlation:  [[1.         0.17606764]\n",
      " [0.17606764 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.63\n",
      "Explain variance score = -0.06\n",
      "R2 score = -0.06\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.92255592 5.53508489 5.7077136  6.14115638 4.87522573 5.66939221\n",
      " 4.83051015 5.64819485 4.94876542 5.71141569 4.53192389 6.00421367\n",
      " 4.5725598  4.96121717 6.21194223 5.57284501 4.42359331 5.35270924\n",
      " 5.82177993 5.5521765  5.91524807 5.70999595 4.31234504 6.00765123\n",
      " 5.35880367 6.30153499 4.56016081 5.58430694 5.93836651 6.15075626\n",
      " 5.78334372 5.84018945 7.24247332 5.67163235 4.73308375 5.41067857\n",
      " 4.97595522 4.96518399 6.10393448 5.68037244 5.90809597 5.14723257\n",
      " 4.97294563 4.93909934 6.08122229 5.42020569 6.06420769 4.60477176\n",
      " 5.81496276 5.84282083 6.51334219 5.26515086 5.59902657 5.79528572\n",
      " 4.82095899 4.80301364 5.64021799 4.4000474  5.73245366 5.95759326\n",
      " 5.73844321 4.93223846 5.55027892 4.74210096 6.52453865 5.17457641\n",
      " 5.94758745 6.43455164 4.92472502 5.84119396 5.81663449 5.59160907\n",
      " 5.42792459 4.7377623  5.81788438 5.19328293 5.37671672 4.9979326\n",
      " 4.89549596 5.01347714 5.36662908 5.44330633 4.84763879 5.62947287\n",
      " 6.03922099 5.48850736 4.99743493 6.41500569 5.48560734 6.27390421\n",
      " 5.04033285 5.52471931 6.53168727 6.10328858 4.83719635 6.19808601\n",
      " 5.54825515 5.31629694 4.57195466 6.13851743 6.81952601 6.02011656\n",
      " 5.24240394 4.68008617 5.31398206 5.47849595 6.70799516 5.14139356\n",
      " 6.7748702  5.84839782 3.93707542 5.62639225 4.7027964  5.52383222\n",
      " 6.19435178 6.38335036 3.72048131 5.92474153 5.15978121 6.2006042\n",
      " 6.7844918  6.27633374 5.78868189 6.40503395 4.9979755  6.38422342\n",
      " 4.66914647 6.12707488 5.86923123]\n",
      "\n",
      "What it should be:  [5.33333333 3.66666667 5.16666667 6.66666667 5.83333333 4.5\n",
      " 6.66666667 5.66666667 4.         6.5        3.66666667 6.83333333\n",
      " 6.         4.83333333 7.         5.         5.         6.33333333\n",
      " 6.         6.16666667 5.33333333 6.33333333 6.83333333 5.16666667\n",
      " 6.16666667 7.         6.16666667 5.83333333 6.83333333 5.16666667\n",
      " 5.33333333 5.         6.16666667 6.66666667 6.         5.16666667\n",
      " 5.5        6.         4.83333333 6.         4.33333333 4.\n",
      " 3.         5.16666667 6.33333333 5.5        4.5        7.\n",
      " 5.         5.33333333 6.16666667 6.33333333 3.33333333 6.5\n",
      " 6.5        7.         4.83333333 4.83333333 5.83333333 6.66666667\n",
      " 4.5        5.5        6.33333333 6.16666667 6.16666667 4.\n",
      " 5.66666667 5.33333333 5.66666667 5.33333333 6.5        5.83333333\n",
      " 6.83333333 5.83333333 5.83333333 6.         6.5        6.33333333\n",
      " 6.66666667 5.66666667 5.66666667 3.66666667 6.83333333 5.33333333\n",
      " 6.16666667 4.66666667 6.33333333 5.33333333 4.83333333 5.83333333\n",
      " 5.         5.66666667 5.66666667 5.33333333 6.5        6.83333333\n",
      " 6.5        5.33333333 6.33333333 6.66666667 6.5        5.16666667\n",
      " 5.83333333 4.33333333 3.5        5.83333333 4.66666667 6.66666667\n",
      " 6.16666667 5.83333333 7.         5.5        5.83333333 5.66666667\n",
      " 4.5        6.16666667 5.5        6.33333333 6.5        6.66666667\n",
      " 5.66666667 7.         5.5        6.         5.16666667 5.33333333\n",
      " 6.5        6.83333333 6.16666667]\n",
      "Correlation:  [[1.         0.05589267]\n",
      " [0.05589267 1.        ]]\n",
      "Mean absolute error = 0.88\n",
      "Mean squared error = 1.15\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.48\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.19925972 5.13576835 5.47267688 5.96360469 5.75707073 5.27829467\n",
      " 5.19940588 6.6080961  5.17192548 4.94705309 5.9541348  5.45486217\n",
      " 5.8465181  5.6276717  6.6084621  5.6561875  5.44804174 6.29174412\n",
      " 5.78756278 5.98913744 6.17457725 6.15417173 5.66422536 4.62904943\n",
      " 5.61806347 5.89690846 5.26504672 5.73398722 6.6093708  5.31045865\n",
      " 6.16294013 6.58476857 4.74526156 5.34639851 4.52910893 5.31124914\n",
      " 5.53622145 5.73634932 5.59848794 6.14190027 5.30928969 6.22545226\n",
      " 4.87030854 5.56801592 5.90248214 6.21140355 5.96631643 5.56807057\n",
      " 5.73789227 5.02417449 5.56911022 5.36635914 5.69023666 4.6273497\n",
      " 5.22470498 5.7942965  5.72564118 6.68784248 6.28032223 5.74500008\n",
      " 5.51060374 5.67129725 5.58856162 5.4534806  6.07415651 5.3675367\n",
      " 6.17937202 5.55200194 5.05686548 6.31097552 6.02080166 6.01716298\n",
      " 5.73077239 5.89922335 6.35237122 5.27949099 6.14507579 5.99132698\n",
      " 5.32999882 5.40384535 5.69083284 6.89534082 5.06636443 5.39705303\n",
      " 6.81552384 6.28387165 5.26145449 4.90292705 5.6290193  6.3538414\n",
      " 5.81557128 5.21915991 5.94683131 6.4162035  5.1146021  6.19830936\n",
      " 6.23188063 5.71940512 4.00687354 5.37314089 6.12605481 6.26764063\n",
      " 6.10076659 5.55101284 5.74907801 5.42992943 5.70188666 5.04310805\n",
      " 5.42716228 5.72228543 5.55558639 5.84987787 4.44958464 5.60543321\n",
      " 5.10204384 6.00249113 5.92413578 5.77282754 5.56846131 5.20860446\n",
      " 5.78241275 5.18058925 5.13145729 5.72545173 6.19346604 5.63916573\n",
      " 4.93138932 6.49274591 5.41332627]\n",
      "\n",
      "What it should be:  [5.66666667 4.83333333 5.16666667 5.83333333 6.5        6.66666667\n",
      " 6.16666667 6.5        6.83333333 6.33333333 6.16666667 5.33333333\n",
      " 6.5        5.16666667 6.83333333 6.66666667 4.66666667 6.16666667\n",
      " 6.83333333 6.16666667 6.83333333 4.66666667 5.5        6.\n",
      " 4.5        7.         6.5        6.         7.         6.\n",
      " 5.33333333 6.66666667 5.83333333 6.33333333 5.5        6.16666667\n",
      " 4.33333333 5.16666667 6.5        5.16666667 6.66666667 5.16666667\n",
      " 4.         4.66666667 4.66666667 6.5        6.5        6.\n",
      " 6.         4.66666667 4.66666667 7.         5.33333333 5.16666667\n",
      " 5.33333333 6.         6.16666667 6.16666667 5.33333333 5.\n",
      " 5.16666667 4.66666667 6.83333333 6.83333333 5.5        4.83333333\n",
      " 6.16666667 4.66666667 3.66666667 6.5        6.33333333 5.5\n",
      " 6.         5.5        6.33333333 4.83333333 5.66666667 6.16666667\n",
      " 6.5        4.         5.66666667 6.5        4.83333333 5.83333333\n",
      " 6.33333333 6.         6.         5.83333333 7.         5.83333333\n",
      " 6.16666667 5.5        5.5        6.66666667 5.66666667 5.33333333\n",
      " 6.5        6.66666667 6.83333333 5.33333333 7.         6.16666667\n",
      " 5.66666667 5.         4.16666667 6.33333333 5.66666667 5.33333333\n",
      " 5.33333333 5.33333333 5.66666667 4.83333333 6.5        4.5\n",
      " 5.83333333 5.83333333 4.         7.         1.83333333 6.16666667\n",
      " 3.83333333 5.         5.         5.16666667 4.         3.33333333\n",
      " 6.5        4.33333333 4.83333333]\n",
      "Correlation:  [[1.         0.14353034]\n",
      " [0.14353034 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.57\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.15\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.71466013 6.32375581 5.71997841 5.72307754 5.70195522 5.40571944\n",
      " 4.92315562 5.98642462 5.97022754 5.58171458 6.08755573 5.78260581\n",
      " 6.32512168 5.81535715 5.61958248 5.50700659 4.87765623 5.93574713\n",
      " 5.37492717 6.679835   5.56668149 6.06740324 6.29793296 5.4350503\n",
      " 5.21483886 6.83766619 5.89376269 6.40857323 5.24573778 5.57270049\n",
      " 5.27403153 5.90055641 6.14635552 6.15092863 5.64631718 5.57788349\n",
      " 5.97441726 5.79443329 6.42724419 5.51290475 5.99577901 5.6787227\n",
      " 5.89981729 5.53602163 5.3429209  5.75771242 4.9664165  4.50847859\n",
      " 6.05205723 5.76230046 6.41431561 5.47736592 5.24902513 6.66115538\n",
      " 5.74908865 5.91718168 6.38840055 5.17986177 5.34757221 5.73762952\n",
      " 5.49715445 5.6685126  6.33691813 5.13473775 6.12733582 6.10311567\n",
      " 5.22341692 6.52663903 5.5238111  5.76296843 6.23399035 5.59239187\n",
      " 5.88052552 5.68185652 5.57791834 4.819003   6.08658268 5.97366085\n",
      " 5.35512971 5.67705396 6.53100727 5.35593235 5.69290056 5.21361929\n",
      " 5.46600135 5.92438472 5.65482087 5.68379328 5.50770611 6.10686603\n",
      " 6.27175076 5.51566997 5.52128083 5.5535397  5.52323941 6.3619618\n",
      " 5.38965817 4.97627334 5.9368452  5.80687436 6.39745691 5.7353877\n",
      " 5.37365518 7.26154457 5.61634487 6.22165692 6.11616502 5.4737999\n",
      " 6.1319299  5.31505201 5.79865454 5.55314724 6.30052584 6.20837505\n",
      " 5.60489567 5.05153518 5.8984236  5.62950547 6.05533481 5.7143808\n",
      " 4.95597273 5.62932675 4.91438775 5.0304866  5.42325153 5.85721018\n",
      " 6.52541574 5.75000023 5.84601361]\n",
      "\n",
      "What it should be:  [6.         6.16666667 5.33333333 6.83333333 6.         6.5\n",
      " 6.33333333 6.33333333 5.83333333 4.83333333 5.33333333 4.66666667\n",
      " 7.         6.         6.66666667 5.16666667 5.16666667 6.16666667\n",
      " 6.16666667 7.         6.         4.16666667 6.16666667 5.\n",
      " 6.16666667 5.33333333 4.         5.33333333 5.5        5.\n",
      " 4.83333333 5.83333333 5.33333333 5.16666667 4.66666667 7.\n",
      " 5.33333333 6.16666667 6.83333333 3.66666667 6.5        6.83333333\n",
      " 4.66666667 5.33333333 3.5        6.5        5.66666667 4.\n",
      " 5.16666667 5.5        6.83333333 3.66666667 1.83333333 5.33333333\n",
      " 5.66666667 6.66666667 5.83333333 5.33333333 4.         6.\n",
      " 5.83333333 4.5        5.33333333 6.5        5.66666667 6.83333333\n",
      " 6.33333333 6.16666667 6.66666667 6.33333333 6.66666667 5.83333333\n",
      " 5.5        6.66666667 4.5        4.33333333 4.5        6.33333333\n",
      " 5.33333333 5.66666667 4.5        6.16666667 6.         6.\n",
      " 5.16666667 5.83333333 5.66666667 5.83333333 5.83333333 6.5\n",
      " 6.5        5.5        4.66666667 6.5        4.83333333 6.83333333\n",
      " 5.33333333 5.16666667 5.66666667 7.         6.66666667 5.33333333\n",
      " 6.5        6.         6.5        4.66666667 6.5        3.33333333\n",
      " 5.5        6.83333333 6.5        6.         6.33333333 6.33333333\n",
      " 5.         3.         6.5        3.83333333 5.66666667 5.5\n",
      " 5.33333333 5.83333333 6.66666667 4.83333333 5.         4.33333333\n",
      " 6.16666667 4.         4.83333333]\n",
      "Correlation:  [[1.         0.27834951]\n",
      " [0.27834951 1.        ]]\n",
      "Mean absolute error = 0.74\n",
      "Mean squared error = 0.9\n",
      "Median absolute error = 0.57\n",
      "Explain variance score = 0.04\n",
      "R2 score = 0.01\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.7371885  4.79906447 5.42770734 5.1934617  5.77964723 5.30771859\n",
      " 5.37273259 5.54673327 4.77726625 5.3751639  6.23714089 5.53087029\n",
      " 5.9480182  5.80440965 5.20090805 5.99674014 5.93344973 4.34451476\n",
      " 5.7067868  5.01646326 6.13795292 5.2754898  5.6265144  6.18089254\n",
      " 5.71839392 5.80005418 6.19281131 5.6513146  5.70969977 5.67129418\n",
      " 6.08126248 5.13715396 6.47580089 5.78097651 5.78073534 6.06105214\n",
      " 5.44175973 5.90112764 5.54612332 5.803731   6.11329039 5.31794132\n",
      " 6.47841053 4.77726666 5.26879203 5.67694472 5.56643496 4.98110486\n",
      " 5.7793433  5.87757029 6.19616635 5.12412436 6.07498458 5.65973144\n",
      " 6.00367352 5.64764971 5.69742009 5.55269641 5.63331311 5.77892507\n",
      " 5.08405715 6.33376786 5.64940199 5.23838932 5.86533027 6.05148519\n",
      " 5.78622858 5.45687269 5.97830288 5.22073679 4.72293616 5.69970752\n",
      " 5.85964517 5.08582163 5.82441392 5.15275497 6.18639936 5.66546018\n",
      " 5.77912325 5.44374012 5.78705505 5.39754778 5.13692051 5.70987177\n",
      " 5.41088435 5.17920976 5.71050025 5.16009695 5.65433472 5.3484469\n",
      " 5.88102175 5.53153558 5.65322622 6.10247379 5.47510227 6.4918414\n",
      " 5.72358389 6.63855247 5.70387748 4.81509055 5.31254645 5.29365222\n",
      " 5.78431362 5.01858582 5.58388638 5.92802441 5.00530716 5.2134693\n",
      " 4.45096277 5.07069327 5.15565388 5.98616922 6.28314016 5.10296002\n",
      " 4.94015227 5.46317475 5.57707563 4.93595075 5.77757316 5.40182822\n",
      " 5.74677131 5.56591338 5.09513617 5.65426384 5.48105096 5.35142651\n",
      " 4.66210269 5.46325663 6.21806256]\n",
      "\n",
      "What it should be:  [4.         5.5        1.83333333 6.33333333 6.83333333 5.5\n",
      " 5.33333333 5.83333333 3.66666667 6.83333333 4.66666667 6.\n",
      " 6.         5.33333333 6.         5.16666667 5.         6.5\n",
      " 5.5        5.         6.5        6.66666667 6.83333333 6.33333333\n",
      " 6.16666667 6.5        5.33333333 6.16666667 6.66666667 6.5\n",
      " 6.33333333 6.66666667 3.66666667 7.         6.33333333 4.66666667\n",
      " 3.5        6.83333333 6.5        6.5        6.83333333 6.\n",
      " 6.16666667 6.16666667 6.         6.33333333 6.33333333 3.\n",
      " 4.83333333 5.16666667 6.16666667 6.16666667 4.5        4.83333333\n",
      " 4.16666667 6.16666667 6.         6.5        3.66666667 4.66666667\n",
      " 6.16666667 6.         6.5        4.33333333 5.66666667 5.83333333\n",
      " 5.33333333 5.66666667 5.16666667 6.16666667 6.66666667 6.66666667\n",
      " 5.66666667 6.5        6.         4.         5.16666667 5.83333333\n",
      " 5.66666667 6.66666667 5.33333333 5.33333333 4.         5.16666667\n",
      " 6.5        4.83333333 5.33333333 6.         5.66666667 4.\n",
      " 6.83333333 5.16666667 3.33333333 6.         6.16666667 6.16666667\n",
      " 6.5        5.83333333 4.83333333 5.66666667 5.5        6.\n",
      " 4.33333333 7.         6.5        4.83333333 6.33333333 6.16666667\n",
      " 4.66666667 5.33333333 6.83333333 5.83333333 7.         6.16666667\n",
      " 5.         4.5        5.5        6.         4.83333333 5.83333333\n",
      " 4.33333333 5.66666667 4.66666667 6.16666667 5.16666667 5.66666667\n",
      " 5.33333333 6.66666667 5.5       ]\n",
      "Correlation:  [[1.         0.00255948]\n",
      " [0.00255948 1.        ]]\n",
      "Mean absolute error = 0.85\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.81\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.65603063 5.77204189 5.43798072 5.79108507 5.99810383 5.3588319\n",
      " 5.59085943 5.79586808 5.66261258 5.45388307 5.59165706 5.28084248\n",
      " 6.55820415 6.47252491 5.04199649 4.95917187 4.53538376 5.09308694\n",
      " 5.74815252 6.27215006 5.83118224 6.1211461  5.33604293 5.36113315\n",
      " 5.6808877  5.38523955 6.07045892 5.67785279 4.61973343 5.98659602\n",
      " 5.81559389 5.09636891 5.54053239 5.15444529 5.89214082 6.20288213\n",
      " 6.07481777 5.35789648 4.59758226 5.64416715 5.51710339 5.27965203\n",
      " 6.11690732 5.73081411 5.64470532 5.57215904 6.65741148 5.78448561\n",
      " 5.11854879 5.87827707 5.99074718 4.28147536 5.31201547 4.30453741\n",
      " 5.5544266  5.23456747 6.39272045 6.6435689  5.29468544 5.42846625\n",
      " 5.84545113 5.48127851 6.47480232 5.45354595 5.99890426 5.57080651\n",
      " 5.3277653  6.23485226 6.07059102 5.89804988 4.63882496 6.25880461\n",
      " 5.43367529 5.13830008 5.62383591 5.29976688 6.16938844 4.90058225\n",
      " 5.71475355 6.0085176  5.82375225 6.14646778 6.30858137 4.57489769\n",
      " 5.21674175 5.56740394 5.6525     4.8656949  6.23474024 6.52446191\n",
      " 6.41799663 4.54323155 6.46999731 4.60994226 5.2268885  6.22926341\n",
      " 5.22551216 5.30519221 5.40754985 6.42441391 5.10905739 5.07701502\n",
      " 5.53746333 5.18730149 5.43270237 5.79827914 5.79315152 5.81346541\n",
      " 5.22695255 5.91992568 5.9147887  5.81348448 5.11962342 5.95009661\n",
      " 4.6158385  6.08689316 5.15172334 4.89222563 5.39661993 6.68109578\n",
      " 6.54717329 5.53169091 5.8229774  5.94335286 5.9705126  5.06485386\n",
      " 5.21604648 5.23658265 6.47446773]\n",
      "\n",
      "What it should be:  [5.16666667 6.         1.83333333 5.16666667 5.33333333 5.33333333\n",
      " 6.66666667 5.66666667 4.         5.83333333 6.83333333 4.83333333\n",
      " 4.33333333 6.16666667 4.5        4.66666667 6.16666667 5.5\n",
      " 6.         6.16666667 6.16666667 6.5        4.66666667 5.\n",
      " 5.33333333 5.33333333 5.33333333 6.5        4.83333333 6.5\n",
      " 6.33333333 5.83333333 6.         6.5        6.5        6.5\n",
      " 5.         6.16666667 4.83333333 6.33333333 5.5        7.\n",
      " 6.16666667 5.16666667 6.         5.83333333 5.83333333 5.66666667\n",
      " 6.66666667 3.33333333 6.83333333 3.         6.16666667 4.66666667\n",
      " 6.16666667 6.16666667 6.83333333 6.83333333 5.5        4.83333333\n",
      " 4.         5.33333333 5.33333333 5.16666667 6.5        6.83333333\n",
      " 6.16666667 6.33333333 6.5        6.66666667 6.33333333 7.\n",
      " 5.16666667 5.33333333 7.         5.33333333 6.16666667 4.33333333\n",
      " 5.83333333 6.         6.16666667 6.         6.16666667 4.5\n",
      " 6.5        4.83333333 6.66666667 5.66666667 6.5        6.16666667\n",
      " 6.83333333 4.33333333 5.66666667 5.5        6.66666667 6.33333333\n",
      " 4.66666667 6.5        3.83333333 3.66666667 6.16666667 6.\n",
      " 4.83333333 6.         5.33333333 6.83333333 5.16666667 6.\n",
      " 5.33333333 5.33333333 5.66666667 6.66666667 3.5        5.5\n",
      " 5.5        5.66666667 6.33333333 5.83333333 5.83333333 4.66666667\n",
      " 6.16666667 5.         6.         4.         5.33333333 7.\n",
      " 5.66666667 6.33333333 5.5       ]\n",
      "Correlation:  [[1.         0.23899914]\n",
      " [0.23899914 1.        ]]\n",
      "Mean absolute error = 0.72\n",
      "Mean squared error = 0.89\n",
      "Median absolute error = 0.56\n",
      "Explain variance score = -0.06\n",
      "R2 score = -0.06\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.56016131 5.61494736 4.83587332 5.99569393 5.26653243 6.25577725\n",
      " 6.28834346 6.62943001 5.9812873  5.93664908 6.15709167 6.80754982\n",
      " 6.15365429 5.63432233 5.63727725 5.76840186 5.56394733 5.19667607\n",
      " 7.11188428 5.70042416 5.22390782 5.78839102 5.46084495 5.64187255\n",
      " 6.30276249 6.70277565 5.27158405 6.4519454  5.45358653 6.0372085\n",
      " 6.75715163 6.62958514 5.49041016 5.56039134 5.98877879 6.32904059\n",
      " 5.94142051 5.53869694 5.89265954 5.26029845 6.08272538 6.10460628\n",
      " 6.0459558  5.66263466 5.32963222 5.72370733 5.40783163 5.72376568\n",
      " 5.90483141 4.90451041 5.61079876 5.43212322 6.31954866 5.77472283\n",
      " 5.60356328 6.31058491 5.29357979 5.60975967 5.2855175  5.9384189\n",
      " 5.82708345 6.87688381 5.40258643 5.85101824 6.29991519 5.90757143\n",
      " 6.05028258 6.31495161 5.90438672 6.00026152 6.81812801 5.02206268\n",
      " 5.98115274 6.10730133 5.25058245 5.57893848 5.44643157 5.60833638\n",
      " 5.76250689 5.16646838 4.86155471 5.05436294 5.91985853 4.96321658\n",
      " 6.10546093 5.34816509 6.28431122 5.88905513 5.52600609 4.8109152\n",
      " 5.85222928 5.00436625 5.48356797 5.8329615  5.8513374  5.97928201\n",
      " 6.29001072 6.04960872 5.51408781 5.83144994 5.0499003  6.26349044\n",
      " 5.95928328 5.56733195 5.02160869 6.51429999 5.99239988 5.6313049\n",
      " 5.55937123 5.67143774 4.83974523 6.19520361 5.95316361 6.0449703\n",
      " 5.23184579 5.89959552 5.57084639 5.97509571 6.50883209 5.03537852\n",
      " 5.82286092 5.88294662 5.66493002 5.33381872 5.84592668 5.77946959\n",
      " 5.64690611 5.96040359 5.74263553]\n",
      "\n",
      "What it should be:  [5.16666667 6.         6.         6.33333333 4.33333333 6.5\n",
      " 6.16666667 4.83333333 6.16666667 6.         5.66666667 7.\n",
      " 6.5        7.         4.5        5.66666667 6.5        6.16666667\n",
      " 4.83333333 6.83333333 6.83333333 4.5        6.16666667 5.83333333\n",
      " 4.33333333 6.83333333 6.66666667 7.         5.16666667 3.\n",
      " 4.66666667 3.83333333 6.5        5.66666667 6.5        5.66666667\n",
      " 5.83333333 3.66666667 4.83333333 7.         5.66666667 5.66666667\n",
      " 6.5        4.16666667 5.5        5.         6.33333333 6.16666667\n",
      " 4.33333333 3.5        6.33333333 6.5        5.16666667 3.66666667\n",
      " 6.16666667 5.66666667 4.         5.66666667 6.16666667 3.66666667\n",
      " 4.83333333 4.5        6.83333333 5.83333333 4.66666667 5.16666667\n",
      " 6.33333333 6.16666667 6.33333333 6.         5.83333333 6.\n",
      " 5.16666667 5.         5.83333333 6.83333333 6.16666667 4.66666667\n",
      " 6.5        6.66666667 4.         6.66666667 6.16666667 4.\n",
      " 5.33333333 5.5        1.83333333 4.83333333 5.5        6.66666667\n",
      " 5.16666667 5.33333333 6.66666667 6.83333333 4.5        4.\n",
      " 6.33333333 7.         5.83333333 5.5        6.16666667 4.\n",
      " 5.33333333 5.66666667 3.33333333 5.33333333 5.83333333 5.16666667\n",
      " 6.66666667 6.16666667 6.5        4.83333333 6.16666667 4.83333333\n",
      " 6.83333333 5.         6.5        5.83333333 5.16666667 6.33333333\n",
      " 5.33333333 4.66666667 5.16666667 5.83333333 6.         5.83333333\n",
      " 6.66666667 6.33333333 5.5       ]\n",
      "Correlation:  [[ 1.         -0.13290448]\n",
      " [-0.13290448  1.        ]]\n",
      "Mean absolute error = 0.92\n",
      "Mean squared error = 1.36\n",
      "Median absolute error = 0.88\n",
      "Explain variance score = -0.35\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.06977179 6.22142963 6.29310533 5.0045711  5.23804991 5.66545261\n",
      " 5.53980406 5.69497861 5.64139218 5.13338006 5.96683712 5.59738383\n",
      " 6.27630527 5.58094641 4.95292608 6.49104919 5.80229991 5.85063511\n",
      " 6.56057619 6.10308072 5.40926007 5.91391102 6.10359565 5.68353588\n",
      " 6.21882542 5.77995299 6.22935419 5.30067199 6.52109806 5.91945843\n",
      " 5.88695186 5.1653998  6.1228224  5.89072934 5.42615885 6.02324193\n",
      " 5.92474371 5.98414587 5.64509241 6.00720531 5.92552458 6.00619526\n",
      " 6.09221427 5.57507184 5.90126081 5.5665181  4.43833266 5.33201629\n",
      " 6.36240118 5.72941975 6.13079393 5.56599329 5.48755444 5.96153723\n",
      " 6.27743463 6.62463106 6.32863612 5.66664841 6.47663994 6.03483151\n",
      " 5.56974202 6.44455582 5.77486103 6.232581   5.33152268 5.3289697\n",
      " 5.54551748 5.45210429 5.86138325 5.63367934 5.56473992 5.76251246\n",
      " 5.35619471 5.97389113 6.13191953 6.17889199 6.55388618 5.25497031\n",
      " 7.29040715 5.90641623 5.91024586 5.04853533 5.89908514 5.86405577\n",
      " 5.840874   5.62358478 6.04051443 6.73783049 6.23755047 6.1835978\n",
      " 6.070007   6.62923052 7.23641058 5.74722551 4.93946183 5.74043156\n",
      " 6.44270166 5.839535   5.6184194  6.12408963 6.1988191  5.5286576\n",
      " 5.86070142 5.58953586 4.87718191 6.07549338 5.49525471 5.43250384\n",
      " 5.83129848 5.66368155 6.08185286 5.82474414 5.86374141 6.62587611\n",
      " 5.98024539 5.69063528 5.40609164 6.3329054  5.73669252 6.31622922\n",
      " 5.7636162  5.452834   5.89424935 4.69752251 5.71407488 5.00791008\n",
      " 5.18603846 6.001147   6.12563868]\n",
      "\n",
      "What it should be:  [5.16666667 7.         6.         6.33333333 4.5        6.16666667\n",
      " 5.66666667 5.66666667 5.         6.         6.66666667 6.5\n",
      " 1.83333333 4.83333333 4.33333333 5.66666667 5.83333333 6.33333333\n",
      " 4.66666667 6.33333333 6.5        6.16666667 6.16666667 6.\n",
      " 5.66666667 5.83333333 5.33333333 4.         6.33333333 6.66666667\n",
      " 6.16666667 5.5        6.83333333 6.83333333 6.5        6.16666667\n",
      " 6.66666667 5.33333333 4.66666667 4.83333333 6.         3.66666667\n",
      " 6.16666667 4.         6.16666667 5.66666667 6.16666667 6.\n",
      " 5.83333333 5.66666667 6.66666667 6.         5.16666667 3.66666667\n",
      " 6.16666667 5.16666667 7.         5.66666667 6.         5.66666667\n",
      " 6.16666667 7.         4.33333333 6.16666667 4.66666667 5.33333333\n",
      " 4.5        6.83333333 6.         6.83333333 4.         4.83333333\n",
      " 6.5        5.         4.66666667 6.         5.16666667 5.33333333\n",
      " 6.33333333 3.83333333 5.         6.16666667 6.5        5.33333333\n",
      " 6.66666667 4.16666667 6.16666667 6.16666667 4.33333333 6.\n",
      " 5.83333333 6.5        4.66666667 6.5        5.5        6.\n",
      " 5.83333333 5.33333333 5.33333333 6.16666667 6.5        4.\n",
      " 5.16666667 5.83333333 5.33333333 5.83333333 5.83333333 4.83333333\n",
      " 5.16666667 5.83333333 5.33333333 4.83333333 5.16666667 5.5\n",
      " 5.33333333 5.66666667 5.         5.5        6.66666667 6.5\n",
      " 3.33333333 3.66666667 6.16666667 5.66666667 5.83333333 6.16666667\n",
      " 6.33333333 4.66666667 6.5       ]\n",
      "Correlation:  [[1.        0.0888586]\n",
      " [0.0888586 1.       ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.99\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.17\n",
      "R2 score = -0.24\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.31635446 5.88633321 4.65329427 6.0587854  5.45291001 6.29723068\n",
      " 6.56134936 5.8280811  5.39464069 6.03997599 5.37251316 5.1805262\n",
      " 5.65637751 5.75215136 5.92949218 4.9201875  5.70617076 6.70972755\n",
      " 5.52340384 5.66929944 5.4219734  6.27334265 5.814519   5.71609093\n",
      " 5.10436806 5.86844886 5.78761714 5.70299715 5.46706112 5.45566142\n",
      " 5.74276922 5.90377968 5.71328298 6.44262459 6.11033528 6.16245564\n",
      " 5.19491199 5.4167672  5.76015019 5.10006441 5.13308153 5.27793707\n",
      " 6.43607845 6.87103588 4.95112247 5.13751661 5.58894584 5.82617514\n",
      " 5.66657263 5.45338236 5.33710336 6.15185514 5.92600793 5.60112283\n",
      " 5.80783465 6.04259522 4.64326311 6.26255712 5.92063704 5.96277584\n",
      " 6.07356922 6.21339364 5.86474491 5.47386624 5.46901027 5.8803415\n",
      " 4.73909024 6.47544344 5.34846924 5.12294084 6.16270509 5.91350777\n",
      " 6.17131081 6.06685737 5.91952417 4.9331593  5.86912032 5.94016918\n",
      " 5.51205253 5.53918843 5.8380786  6.33962927 6.33342113 5.22618218\n",
      " 5.13558254 6.83568733 6.05816022 5.29685934 5.862408   6.13581227\n",
      " 4.74821713 5.98654453 5.65850781 5.94683313 5.36150849 6.08061248\n",
      " 5.76909883 6.35952969 5.93851713 6.21436641 5.72241116 5.99929868\n",
      " 5.17322118 5.65241565 5.73088758 5.78109618 4.92859351 6.14171261\n",
      " 6.01285066 6.19668511 5.48817456 5.98084569 5.66144785 5.80685558\n",
      " 6.86319453 6.12961726 5.13355484 5.92849897 5.35116505 5.57758773\n",
      " 5.64994317 5.9899226  5.92537887 5.26065363 5.24488662 5.55087476\n",
      " 5.23137943 5.47737667 5.46089491]\n",
      "\n",
      "What it should be:  [6.         5.5        5.5        6.         6.5        6.5\n",
      " 5.83333333 4.83333333 7.         5.33333333 4.83333333 5.16666667\n",
      " 6.16666667 6.         5.16666667 6.66666667 6.16666667 6.\n",
      " 6.83333333 4.83333333 5.5        4.66666667 6.66666667 5.16666667\n",
      " 3.66666667 1.83333333 5.5        5.5        5.33333333 4.\n",
      " 5.83333333 4.66666667 6.83333333 6.66666667 5.33333333 5.83333333\n",
      " 4.33333333 6.         5.16666667 5.66666667 6.16666667 6.16666667\n",
      " 5.16666667 6.33333333 4.5        6.33333333 5.66666667 5.33333333\n",
      " 6.33333333 7.         5.33333333 4.         5.83333333 6.33333333\n",
      " 4.33333333 6.5        4.33333333 6.5        6.66666667 5.33333333\n",
      " 6.5        6.5        6.16666667 5.         3.33333333 5.33333333\n",
      " 3.66666667 5.83333333 3.66666667 6.         5.66666667 6.5\n",
      " 5.33333333 6.16666667 6.33333333 6.83333333 7.         4.33333333\n",
      " 6.16666667 6.         7.         3.83333333 5.33333333 4.66666667\n",
      " 5.16666667 6.33333333 6.         5.66666667 6.66666667 5.\n",
      " 5.66666667 4.16666667 6.16666667 6.16666667 5.5        6.\n",
      " 6.16666667 7.         3.         6.83333333 6.33333333 6.\n",
      " 6.16666667 5.33333333 6.16666667 6.16666667 4.66666667 5.66666667\n",
      " 6.33333333 4.66666667 5.83333333 5.66666667 5.83333333 6.16666667\n",
      " 7.         5.66666667 6.83333333 5.         4.         4.66666667\n",
      " 5.         5.83333333 6.33333333 6.5        5.83333333 6.16666667\n",
      " 5.5        4.83333333 6.66666667]\n",
      "Correlation:  [[1.         0.16200018]\n",
      " [0.16200018 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.59\n",
      "Explain variance score = -0.08\n",
      "R2 score = -0.09\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.59088958 5.96159188 5.11641477 5.11382833 6.38752688 5.84731803\n",
      " 5.82093822 5.77226207 4.30563863 4.97858503 5.56889949 5.70833665\n",
      " 5.20180084 5.24420836 5.66508062 5.41769687 5.70152361 5.87222283\n",
      " 4.87463008 5.35588026 5.21801571 5.88681583 5.46398114 6.28228656\n",
      " 6.04179159 5.24333991 5.08231282 5.64182912 4.8969051  5.37968218\n",
      " 5.57004647 5.40436666 6.44830144 5.88655298 5.61744039 5.69812741\n",
      " 5.48628444 5.56768565 5.78542002 5.55623038 5.24151891 5.67079954\n",
      " 5.00894858 6.00690178 5.15803182 4.3014231  5.23442367 5.83387898\n",
      " 5.50421773 5.99549801 5.29992568 5.36455954 4.64632224 4.92304635\n",
      " 5.9630074  4.98080413 5.33962175 5.59389955 6.1335952  5.11773993\n",
      " 5.96070224 4.97554936 5.53241031 5.77924785 5.3099054  4.29731058\n",
      " 6.28051725 5.21009113 5.75861265 4.51481394 5.64183731 4.80873351\n",
      " 5.47350422 5.63106165 4.61042104 6.75108793 4.65072185 4.72274636\n",
      " 5.84149263 4.91491648 5.86686176 4.8985859  5.82569313 4.49603363\n",
      " 4.29936966 5.77731441 5.97875581 5.16108391 3.9413107  5.62269714\n",
      " 5.65974243 5.8665807  5.24263453 5.55747655 4.42070958 3.84019759\n",
      " 6.01025781 5.57834925 4.01116083 5.97729654 5.95467638 5.44329362\n",
      " 5.30474494 6.31384329 6.82723149 5.67623673 5.52659379 5.60022844\n",
      " 5.92173275 5.33310326 5.76469554 6.42322928 6.33786814 6.1547387\n",
      " 6.14428434 5.67308656 5.55945727 5.79663084 5.3055197  5.4771498\n",
      " 4.87993362 5.59014766 5.37700123 4.96098746 6.18040515 5.57111572\n",
      " 5.73312013 5.96198882 6.06491975]\n",
      "\n",
      "What it should be:  [6.66666667 5.33333333 4.66666667 6.83333333 5.66666667 5.33333333\n",
      " 6.16666667 6.16666667 6.5        5.5        6.16666667 6.66666667\n",
      " 4.66666667 6.         4.5        4.33333333 5.83333333 6.\n",
      " 3.66666667 5.66666667 4.33333333 6.         4.33333333 6.5\n",
      " 5.83333333 5.         5.         6.5        4.83333333 6.\n",
      " 5.33333333 4.66666667 6.33333333 6.16666667 5.5        5.16666667\n",
      " 6.33333333 5.33333333 6.83333333 6.66666667 6.         4.\n",
      " 5.83333333 6.83333333 5.83333333 4.83333333 7.         5.83333333\n",
      " 5.66666667 7.         3.5        5.         6.16666667 6.33333333\n",
      " 5.66666667 5.66666667 5.66666667 6.16666667 6.66666667 6.5\n",
      " 6.         4.5        5.33333333 4.         4.5        4.33333333\n",
      " 5.83333333 4.83333333 6.16666667 6.33333333 6.16666667 5.16666667\n",
      " 6.16666667 5.33333333 5.5        6.5        4.66666667 3.66666667\n",
      " 4.66666667 6.5        3.33333333 6.33333333 5.83333333 6.83333333\n",
      " 6.5        4.66666667 7.         6.83333333 4.83333333 5.16666667\n",
      " 5.66666667 5.33333333 6.         3.         6.5        5.5\n",
      " 6.         5.83333333 5.83333333 4.5        5.66666667 5.5\n",
      " 6.66666667 3.66666667 6.         6.         6.83333333 6.83333333\n",
      " 6.83333333 6.83333333 5.83333333 6.16666667 6.33333333 6.33333333\n",
      " 5.83333333 6.5        5.16666667 6.66666667 6.66666667 6.\n",
      " 4.         5.16666667 6.33333333 4.         4.5        6.16666667\n",
      " 6.66666667 6.33333333 6.16666667]\n",
      "Correlation:  [[1.         0.13601899]\n",
      " [0.13601899 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.04\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.26\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.8565648  5.59976695 4.40551405 4.62054105 5.39536607 4.50959552\n",
      " 5.16463675 4.83783926 5.13302236 4.6354411  6.250819   5.07787088\n",
      " 3.49439199 5.98088731 5.42678422 5.84038636 4.59679929 5.11318188\n",
      " 6.33352005 4.87238658 3.69112691 5.51222507 5.77994605 5.20826467\n",
      " 6.31722952 4.28383385 4.64736026 6.17025549 5.32160551 5.57085019\n",
      " 5.63823829 6.44257997 5.54120118 6.25694859 5.9923052  4.95339916\n",
      " 6.12287753 5.98386684 5.23497632 6.93072694 4.40070487 5.04344282\n",
      " 6.23657439 6.31256173 6.44127964 5.52979837 6.41190583 5.74394295\n",
      " 5.93564588 4.92383937 5.23139334 5.5160716  6.16865218 5.66669372\n",
      " 6.67449499 5.98198668 5.42714229 4.5302723  5.52474912 5.18508861\n",
      " 5.22411587 6.08101881 6.06863492 6.46838501 5.38935049 6.38732061\n",
      " 5.85145927 6.12492503 5.20229187 5.41572473 5.87027966 5.1978633\n",
      " 5.85075082 5.832826   6.1659584  5.2920984  4.02979813 4.88450437\n",
      " 5.62570106 5.18329407 5.08415069 6.41453322 4.05270116 5.82536579\n",
      " 6.25802359 5.91779426 5.71333115 5.38140952 5.51397629 6.2525628\n",
      " 4.77573329 6.35230916 5.55330966 5.82684538 5.12696008 6.10286025\n",
      " 4.86329534 5.97558978 4.90939748 5.44049845 5.95338185 5.4457961\n",
      " 5.23374106 5.2314125  5.94179824 4.8540533  5.15011185 4.76868347\n",
      " 5.61573284 5.87045274 6.09930216 3.91630032 5.83349703 3.97835635\n",
      " 5.55545726 6.46758652 5.91002653 5.11401939 5.48026328 4.55349261\n",
      " 5.04887476 4.95332097 5.49860315 4.67959229 4.72192667 5.95218122\n",
      " 5.8333368  4.91783321 5.70356985]\n",
      "\n",
      "What it should be:  [7.         5.33333333 5.16666667 6.5        6.5        4.5\n",
      " 5.83333333 6.5        4.         5.66666667 6.66666667 4.66666667\n",
      " 6.83333333 7.         5.83333333 5.66666667 4.5        4.\n",
      " 6.16666667 6.         6.5        6.33333333 5.5        5.\n",
      " 6.5        6.5        4.66666667 5.5        6.         4.66666667\n",
      " 6.33333333 5.16666667 5.5        6.16666667 6.16666667 3.66666667\n",
      " 6.5        3.33333333 6.66666667 6.33333333 6.66666667 6.\n",
      " 6.         7.         4.83333333 7.         5.33333333 6.16666667\n",
      " 6.66666667 5.33333333 6.33333333 6.83333333 6.66666667 6.83333333\n",
      " 5.33333333 6.16666667 5.83333333 5.16666667 5.66666667 1.83333333\n",
      " 5.5        4.5        5.16666667 5.66666667 6.         6.33333333\n",
      " 6.5        5.33333333 4.33333333 5.66666667 5.83333333 5.83333333\n",
      " 6.83333333 4.         6.         5.5        6.83333333 4.66666667\n",
      " 6.83333333 5.33333333 6.16666667 6.33333333 6.16666667 4.33333333\n",
      " 6.16666667 5.33333333 4.66666667 5.66666667 6.33333333 6.66666667\n",
      " 4.66666667 6.5        5.5        6.16666667 4.66666667 6.16666667\n",
      " 6.33333333 5.5        5.         4.33333333 6.5        5.66666667\n",
      " 5.83333333 4.5        4.5        6.16666667 5.5        5.83333333\n",
      " 5.33333333 5.         5.83333333 4.83333333 6.16666667 7.\n",
      " 5.16666667 5.33333333 5.66666667 4.83333333 4.83333333 5.83333333\n",
      " 5.16666667 6.83333333 6.         6.33333333 5.16666667 5.33333333\n",
      " 6.16666667 5.5        6.66666667]\n",
      "Correlation:  [[1.         0.07153333]\n",
      " [0.07153333 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.18\n",
      "Median absolute error = 0.65\n",
      "Explain variance score = -0.47\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.06692569 6.68358307 6.00235427 5.46238875 4.84541653 5.44903136\n",
      " 5.6165006  6.0537128  5.37415081 4.84760371 6.03322354 5.72480325\n",
      " 6.75377731 5.8817586  4.02307135 6.38780845 4.85490372 5.56395824\n",
      " 6.23590512 5.67129117 6.09423885 5.50309037 6.22150978 6.17859027\n",
      " 5.6256258  4.76739891 5.76508041 4.92630195 5.93714171 5.49898532\n",
      " 5.19965891 6.34016437 5.57860172 5.41157317 5.93623572 6.03486464\n",
      " 5.97298669 5.22350973 5.4380181  4.83014184 5.72517648 5.10347921\n",
      " 5.68589683 5.86904319 5.98862524 5.72556834 5.27623883 5.88316651\n",
      " 5.89232437 6.35043253 5.46919697 5.97090931 5.93077918 5.49591579\n",
      " 5.38585956 5.50655037 6.1290579  5.30359499 5.83592424 5.88684119\n",
      " 5.10717008 6.23487048 5.24533946 6.38365827 5.43988326 6.27574531\n",
      " 5.80532268 4.19877065 6.76071455 5.30586479 6.13281906 5.58228764\n",
      " 5.14843196 6.65076703 5.93181313 5.06152147 5.56292173 5.37571578\n",
      " 5.19293471 5.68304716 5.83851642 5.53315961 5.47231869 5.54165328\n",
      " 4.52878744 5.72953563 4.54849204 5.31309044 6.1787722  5.61040344\n",
      " 5.02301519 6.23301432 5.92466802 4.47984234 5.79833899 3.91730206\n",
      " 5.61187073 5.98982691 5.43233925 5.64820574 5.55275168 5.73712664\n",
      " 6.46080214 6.55224817 5.62372111 5.61958837 5.82658592 5.64582027\n",
      " 4.85026609 5.98246775 6.06087752 5.96829735 5.3571689  5.15876211\n",
      " 5.57169453 5.6976863  5.80962763 5.52076802 5.31481242 5.28999368\n",
      " 6.21150051 5.80807177 5.80365079 5.48734785 4.83317431 5.03023198\n",
      " 4.6139749  4.8647213  5.79057137]\n",
      "\n",
      "What it should be:  [6.         5.66666667 5.66666667 4.83333333 4.33333333 6.16666667\n",
      " 6.66666667 6.66666667 4.83333333 5.33333333 5.16666667 6.16666667\n",
      " 4.83333333 6.83333333 4.         5.16666667 6.83333333 6.5\n",
      " 6.66666667 5.83333333 6.5        1.83333333 5.16666667 4.16666667\n",
      " 5.66666667 6.         4.66666667 4.33333333 5.83333333 3.5\n",
      " 6.83333333 4.83333333 4.         6.         5.33333333 6.16666667\n",
      " 6.         5.5        6.5        5.5        5.5        5.33333333\n",
      " 5.83333333 6.16666667 6.83333333 6.         5.5        6.16666667\n",
      " 3.33333333 7.         6.33333333 6.66666667 6.33333333 6.16666667\n",
      " 5.         3.83333333 6.66666667 4.33333333 6.33333333 5.83333333\n",
      " 6.16666667 6.83333333 4.         7.         6.         4.66666667\n",
      " 6.33333333 5.33333333 6.16666667 5.66666667 5.66666667 5.33333333\n",
      " 5.5        5.33333333 6.16666667 6.5        5.33333333 6.5\n",
      " 6.16666667 5.33333333 6.33333333 6.33333333 5.66666667 5.83333333\n",
      " 4.83333333 5.66666667 6.5        5.33333333 6.5        6.\n",
      " 5.         5.16666667 6.5        3.         6.83333333 5.16666667\n",
      " 6.16666667 5.16666667 5.33333333 3.66666667 5.83333333 6.33333333\n",
      " 5.83333333 6.83333333 6.         5.83333333 4.5        5.5\n",
      " 5.         5.83333333 4.5        5.16666667 4.5        4.83333333\n",
      " 6.16666667 5.         6.16666667 4.66666667 5.83333333 6.66666667\n",
      " 4.5        6.66666667 6.5        6.33333333 6.         4.5\n",
      " 6.33333333 6.16666667 5.66666667]\n",
      "Correlation:  [[1.         0.19758606]\n",
      " [0.19758606 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.93\n",
      "Median absolute error = 0.6\n",
      "Explain variance score = -0.11\n",
      "R2 score = -0.11\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.97887326 6.02528404 5.05601124 5.38462719 6.44970286 4.93945808\n",
      " 5.27482138 5.03775205 6.46826861 4.95829664 5.73675661 6.29297925\n",
      " 5.63772662 5.75040396 5.50207922 5.33396109 4.83703695 6.47257018\n",
      " 4.48626801 6.20264871 6.02786665 5.52925716 5.76640832 5.79673537\n",
      " 6.05031476 4.81710074 4.70374352 6.63246764 5.47744888 5.7554725\n",
      " 5.8819303  5.98726282 5.18924188 5.79717032 6.26950405 5.68509216\n",
      " 5.47555867 4.75064194 4.90259197 5.40082663 6.36569737 5.24838693\n",
      " 6.59801924 5.50325654 6.43903413 6.24449135 6.05979346 6.0827856\n",
      " 5.56998513 6.50784338 5.53497412 5.37795025 6.82111318 4.05862096\n",
      " 6.00742833 6.11715164 5.81979627 6.17832612 7.14905538 5.43772466\n",
      " 5.6446875  6.22235909 5.77358474 6.24880109 6.17154426 5.25078651\n",
      " 5.54979341 5.7358162  4.78853886 3.53821499 7.10614626 6.24852031\n",
      " 6.02112986 5.11454199 5.63427257 7.17484168 6.50159452 4.84787371\n",
      " 6.44731907 5.10002466 6.2624391  5.54346305 5.45201292 5.92965686\n",
      " 6.56135167 5.95998852 5.48302114 4.65027714 5.15033314 6.26662909\n",
      " 6.39069929 5.44860724 2.67738241 6.09331824 5.53204842 5.81411501\n",
      " 5.51347215 6.19344708 5.12707793 5.06032901 5.72376327 6.02580571\n",
      " 5.4056382  6.8505332  6.10075681 5.59515416 6.01277831 6.1477419\n",
      " 6.25832456 6.18838761 5.37978327 5.92749333 5.92276127 6.12549709\n",
      " 6.40080142 6.18031052 4.91690515 4.78068156 6.02109897 5.26274788\n",
      " 5.78935775 5.34054332 5.43251531 6.54471493 6.47035557 5.54691976\n",
      " 4.84876557 6.67600616 6.18901356]\n",
      "\n",
      "What it should be:  [6.16666667 4.5        6.5        5.83333333 6.16666667 6.5\n",
      " 6.33333333 4.83333333 6.33333333 6.5        6.16666667 6.16666667\n",
      " 4.33333333 4.33333333 6.66666667 6.83333333 6.83333333 5.66666667\n",
      " 6.5        6.16666667 6.66666667 5.33333333 5.33333333 5.5\n",
      " 5.83333333 6.16666667 4.         5.16666667 6.66666667 4.66666667\n",
      " 5.         4.         5.66666667 4.33333333 5.33333333 6.16666667\n",
      " 4.83333333 5.83333333 5.33333333 5.66666667 6.33333333 4.\n",
      " 3.33333333 6.16666667 6.66666667 5.33333333 5.33333333 5.83333333\n",
      " 4.83333333 6.66666667 5.66666667 5.83333333 4.66666667 6.33333333\n",
      " 5.33333333 5.66666667 4.83333333 6.16666667 6.83333333 5.\n",
      " 5.33333333 5.16666667 5.         5.66666667 5.16666667 6.\n",
      " 6.83333333 5.5        6.33333333 4.83333333 6.5        6.5\n",
      " 5.16666667 5.16666667 5.         4.83333333 7.         5.66666667\n",
      " 6.33333333 3.66666667 6.83333333 3.         7.         6.\n",
      " 6.66666667 4.5        5.         4.66666667 3.66666667 4.5\n",
      " 4.66666667 5.83333333 5.5        6.16666667 6.83333333 5.33333333\n",
      " 4.83333333 3.66666667 5.83333333 5.83333333 6.66666667 5.33333333\n",
      " 4.         5.16666667 6.16666667 5.33333333 6.         4.16666667\n",
      " 5.5        6.33333333 7.         6.5        5.33333333 5.83333333\n",
      " 5.66666667 3.5        4.33333333 4.83333333 6.5        4.66666667\n",
      " 6.16666667 6.5        4.66666667 6.5        6.16666667 5.16666667\n",
      " 6.16666667 7.         6.        ]\n",
      "Correlation:  [[1.         0.07893778]\n",
      " [0.07893778 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.21\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.47\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.16970318 5.46799427 5.71326942 4.18230734 6.10890854 6.47932419\n",
      " 6.01308761 6.46978004 5.35951342 6.28195268 4.96434462 5.81701047\n",
      " 5.43370799 6.84684473 5.6162466  4.97435882 5.97549767 5.74284972\n",
      " 4.78399516 5.95050142 6.76693602 6.1550539  5.99759828 5.63642154\n",
      " 5.88195461 6.11838227 4.99604931 6.22539869 4.94729008 4.87214957\n",
      " 6.41893023 5.40944686 5.78642141 6.77303316 6.36257316 5.39782503\n",
      " 6.09165192 6.00566537 5.4209696  6.09355615 6.52399026 6.17057409\n",
      " 7.11862588 6.81330585 5.09845297 6.95190064 5.48067413 6.20970414\n",
      " 5.82496632 6.90198488 5.38343467 6.08739916 5.03681291 6.2954022\n",
      " 5.55243962 5.89264797 7.29237237 5.88266468 5.68301564 5.87974917\n",
      " 5.95080621 5.77379846 5.40621748 5.8094794  5.28418297 5.47463006\n",
      " 7.15714365 5.36948237 5.09495118 6.27064808 6.51396682 5.38184541\n",
      " 5.67610392 5.37494128 5.52865537 6.2217762  6.14139289 5.29023881\n",
      " 5.21775456 5.96975531 7.22801027 5.84807531 5.32894363 5.3008653\n",
      " 5.5529409  6.58332387 7.2539262  7.03277694 7.39344058 5.14732432\n",
      " 6.38676978 6.09282183 5.48255307 6.50239651 6.34551833 5.54744759\n",
      " 5.70923568 5.06184951 5.89313449 5.06164682 5.7110933  5.57262594\n",
      " 6.30403011 6.05651489 5.00481519 5.54067241 6.12944793 5.33281219\n",
      " 4.79918778 5.70987787 6.43781406 5.86209785 6.07717859 6.03375155\n",
      " 6.00777157 6.49570643 7.06811737 5.76005429 5.36023417 5.23279015\n",
      " 6.10613031 5.90948084 5.35598942 5.27905365 5.25814873 5.81573682\n",
      " 6.1200359  4.80481783 6.73279707]\n",
      "\n",
      "What it should be:  [5.5        6.83333333 5.33333333 1.83333333 4.66666667 5.5\n",
      " 5.         4.16666667 5.83333333 6.5        5.66666667 6.5\n",
      " 3.5        5.5        6.16666667 6.5        6.5        5.\n",
      " 6.33333333 6.16666667 4.66666667 6.         5.83333333 5.5\n",
      " 4.         6.33333333 4.33333333 6.83333333 6.16666667 5.33333333\n",
      " 6.16666667 6.         5.83333333 6.16666667 5.66666667 5.66666667\n",
      " 6.16666667 5.66666667 5.83333333 5.16666667 6.5        5.66666667\n",
      " 4.66666667 4.5        6.33333333 6.16666667 4.33333333 5.16666667\n",
      " 6.16666667 5.16666667 5.16666667 6.33333333 6.         6.66666667\n",
      " 5.16666667 5.83333333 4.5        3.         5.66666667 5.83333333\n",
      " 4.66666667 6.16666667 4.66666667 4.83333333 5.83333333 5.66666667\n",
      " 6.33333333 5.33333333 7.         6.5        3.33333333 6.83333333\n",
      " 5.33333333 4.83333333 4.         6.5        5.33333333 4.66666667\n",
      " 5.33333333 6.16666667 5.16666667 5.16666667 6.66666667 4.83333333\n",
      " 5.         6.16666667 4.66666667 4.83333333 6.16666667 6.33333333\n",
      " 6.83333333 6.5        5.66666667 6.5        5.33333333 5.33333333\n",
      " 3.66666667 3.66666667 6.83333333 6.         6.33333333 5.5\n",
      " 4.5        5.83333333 5.         4.         6.16666667 5.33333333\n",
      " 5.         6.83333333 5.5        5.5        6.5        6.\n",
      " 6.33333333 5.83333333 4.5        6.33333333 5.66666667 4.83333333\n",
      " 6.66666667 4.         6.         5.83333333 6.16666667 5.5\n",
      " 6.5        5.33333333 5.83333333]\n",
      "Correlation:  [[1.         0.07077395]\n",
      " [0.07077395 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.24\n",
      "Median absolute error = 0.61\n",
      "Explain variance score = -0.4\n",
      "R2 score = -0.52\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.61817587 6.07724986 6.1015327  6.12808172 4.70536166 5.18583452\n",
      " 6.01777564 5.96012968 5.18382298 5.38497575 6.41735468 5.57379091\n",
      " 5.97940193 5.64297901 6.50596574 5.90248773 6.00197678 6.41203957\n",
      " 6.37239602 6.33439293 5.43400872 4.85395763 5.42073947 5.00857203\n",
      " 6.53928048 5.81898502 6.71431341 6.09513388 4.83771255 5.63605421\n",
      " 5.85537311 5.84620103 5.18635667 6.03897005 4.69695381 7.19072063\n",
      " 5.65124529 5.72953903 6.79742143 6.13006851 5.55232711 6.25731053\n",
      " 5.60622803 4.64135794 4.72698728 5.64410484 6.25208741 5.3958694\n",
      " 6.72366111 6.36073442 5.97718229 5.52010302 5.23992905 5.30495935\n",
      " 5.4050885  5.92647588 5.00242359 5.55103705 5.05307451 5.59705051\n",
      " 5.75095199 6.14267137 5.42822447 5.51014965 5.54829796 7.26273005\n",
      " 5.99662601 5.85172254 6.52758483 6.37141531 6.24335226 4.57963406\n",
      " 5.18303045 5.51400755 5.74507856 6.53453248 6.00905991 6.38173264\n",
      " 5.1669634  5.93200465 6.90873727 5.87178568 4.60333332 6.39657239\n",
      " 6.13369881 4.9874223  5.36943533 5.62247907 5.30250468 4.94935874\n",
      " 4.37099255 5.79997622 6.15938637 6.63899749 5.5151861  6.35161476\n",
      " 6.75485278 6.07990984 5.01614966 5.9018264  6.11592164 6.26897503\n",
      " 4.97047712 5.77673893 4.35449623 5.41371415 5.56379647 5.46616918\n",
      " 5.86483884 4.22409511 6.27756895 5.2171023  5.28945618 5.8341756\n",
      " 5.62454566 6.56213314 6.79063742 6.22044005 5.67832214 5.21281995\n",
      " 4.41140718 6.07705342 6.23744535 5.15907449 6.19216787 5.88235648\n",
      " 6.00067223 4.81144347 5.84661577]\n",
      "\n",
      "What it should be:  [6.         4.         6.33333333 6.66666667 5.5        4.66666667\n",
      " 5.83333333 5.16666667 4.83333333 5.         6.5        5.83333333\n",
      " 5.5        5.33333333 6.66666667 5.16666667 6.         5.66666667\n",
      " 6.5        3.5        5.66666667 5.83333333 4.         5.33333333\n",
      " 6.16666667 6.83333333 5.33333333 5.16666667 4.5        6.33333333\n",
      " 6.16666667 6.83333333 6.         6.5        7.         4.5\n",
      " 6.16666667 7.         5.16666667 6.16666667 5.33333333 6.5\n",
      " 5.66666667 5.16666667 3.83333333 6.16666667 4.16666667 5.5\n",
      " 6.66666667 5.33333333 5.16666667 5.33333333 5.33333333 5.\n",
      " 5.33333333 4.83333333 5.5        5.         5.66666667 5.83333333\n",
      " 6.33333333 5.83333333 5.         6.16666667 6.33333333 6.16666667\n",
      " 6.         4.83333333 6.33333333 7.         4.5        5.5\n",
      " 6.33333333 6.         4.5        5.16666667 6.83333333 5.5\n",
      " 6.16666667 7.         5.83333333 4.66666667 3.33333333 4.66666667\n",
      " 3.66666667 6.         6.66666667 6.83333333 6.66666667 4.83333333\n",
      " 4.66666667 6.5        7.         5.66666667 4.33333333 5.16666667\n",
      " 6.         6.         3.66666667 5.         5.66666667 6.16666667\n",
      " 4.33333333 5.66666667 6.33333333 4.33333333 6.16666667 6.5\n",
      " 4.66666667 6.5        6.         4.83333333 5.5        5.66666667\n",
      " 6.5        4.66666667 6.83333333 6.5        5.33333333 6.\n",
      " 4.         6.         6.83333333 6.5        5.83333333 6.83333333\n",
      " 6.16666667 6.16666667 6.        ]\n",
      "Correlation:  [[1.         0.17695243]\n",
      " [0.17695243 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.94\n",
      "Median absolute error = 0.64\n",
      "Explain variance score = -0.26\n",
      "R2 score = -0.27\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.18008515 5.45424945 5.23458469 5.93625053 5.67129437 5.84637189\n",
      " 5.37251044 5.88063855 5.92170879 6.21359228 4.77160175 4.3919336\n",
      " 4.91164076 6.91298369 5.036553   5.71295395 5.52377475 5.32800713\n",
      " 6.46362442 4.75304337 5.06743574 6.20081267 5.90520709 5.5352265\n",
      " 5.74125876 5.15558117 5.07590188 6.51758778 5.67449602 5.48062989\n",
      " 4.36078755 6.20720805 5.43822069 5.9160946  5.37041207 4.92856472\n",
      " 5.70811323 5.37513279 5.82784574 5.3300599  6.27553788 5.44912238\n",
      " 4.96622927 5.09997205 5.87884606 4.91742809 4.96539346 5.49926866\n",
      " 5.49019992 5.57137022 6.63914119 4.72743755 5.67767621 6.87688284\n",
      " 4.43540706 6.00787363 6.40804063 5.61338071 6.00263919 5.11366705\n",
      " 6.26205708 5.4646288  5.40567221 5.31180915 4.92162573 5.89648659\n",
      " 5.61583477 4.5377601  5.68662798 5.73909319 5.71296219 5.66914314\n",
      " 5.08620256 5.95275861 6.08931575 6.10348298 4.65545998 5.07937073\n",
      " 6.04342827 5.90096972 5.26386943 4.87617673 5.97088671 5.1933438\n",
      " 4.90078572 6.06076834 4.83972086 4.41005305 5.73427507 5.44301044\n",
      " 5.67184483 5.13313244 5.80309378 5.25867001 6.32921709 5.41806997\n",
      " 4.81645471 5.6732312  5.47156459 6.15037185 5.73590249 6.04263141\n",
      " 6.42731419 4.98595837 4.83152732 4.56530857 5.23689509 6.56875365\n",
      " 5.65241267 6.07311407 5.89427445 5.40279422 5.83201755 6.25846171\n",
      " 5.25100242 4.46528938 5.53257088 6.06635867 5.03537603 5.59465313\n",
      " 6.03370808 6.16677292 5.76115552 5.28039088 6.31541472 5.97131289\n",
      " 5.32601569 5.62698363 5.93495585]\n",
      "\n",
      "What it should be:  [6.         5.83333333 5.5        6.33333333 4.         5.66666667\n",
      " 5.16666667 6.16666667 6.83333333 5.83333333 5.66666667 7.\n",
      " 6.33333333 5.16666667 6.66666667 5.5        6.         5.16666667\n",
      " 6.33333333 5.         4.5        6.5        6.16666667 6.16666667\n",
      " 4.83333333 4.5        5.33333333 6.16666667 4.         6.5\n",
      " 7.         5.16666667 4.66666667 5.5        5.83333333 3.66666667\n",
      " 5.33333333 6.83333333 6.33333333 4.66666667 6.16666667 5.66666667\n",
      " 1.83333333 5.83333333 4.83333333 4.66666667 6.83333333 5.33333333\n",
      " 3.5        5.66666667 6.5        4.5        5.83333333 4.83333333\n",
      " 6.5        5.16666667 6.16666667 6.83333333 4.66666667 6.5\n",
      " 3.66666667 6.         5.83333333 6.16666667 4.         6.16666667\n",
      " 4.66666667 6.33333333 5.33333333 6.5        6.         6.66666667\n",
      " 5.33333333 5.         5.83333333 6.         5.5        5.33333333\n",
      " 6.         5.16666667 5.5        6.66666667 5.33333333 6.83333333\n",
      " 6.33333333 6.5        6.16666667 5.5        4.5        5.16666667\n",
      " 5.66666667 4.83333333 5.66666667 4.33333333 6.33333333 5.\n",
      " 6.         5.83333333 4.33333333 7.         4.66666667 5.66666667\n",
      " 7.         6.5        6.83333333 5.66666667 6.         6.5\n",
      " 6.33333333 6.16666667 6.83333333 6.83333333 6.16666667 4.66666667\n",
      " 6.83333333 3.66666667 6.66666667 5.33333333 6.66666667 6.83333333\n",
      " 6.5        5.33333333 5.83333333 5.33333333 6.16666667 6.16666667\n",
      " 6.16666667 5.66666667 4.33333333]\n",
      "Correlation:  [[1.         0.06168206]\n",
      " [0.06168206 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.07\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.29\n",
      "R2 score = -0.31\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.54132283 4.98908791 6.52285836 5.80168818 6.22839086 5.81114033\n",
      " 6.33986785 6.43166812 4.64144001 5.89663295 6.20029702 5.34603642\n",
      " 5.66545349 5.6221649  6.16240705 5.34948037 5.9923063  5.69406078\n",
      " 5.38626721 6.12411219 6.29662593 4.62521766 6.59772815 6.59030511\n",
      " 6.42324004 5.815426   5.04019115 5.44542879 4.93605561 5.7008261\n",
      " 5.21978459 5.88046879 6.38678213 6.05626747 6.62073188 6.65035752\n",
      " 4.88292454 4.5110565  5.73817653 5.41248268 5.46760919 4.7225285\n",
      " 5.26284558 5.84831038 4.79269131 4.71775073 4.68645931 5.19017895\n",
      " 5.838529   6.03950601 5.52349373 5.45526462 6.12709752 5.59056275\n",
      " 6.4606762  5.82069722 5.96900468 6.09918225 6.06438069 5.35226835\n",
      " 6.57346895 5.75188803 5.30616759 6.05647446 6.03947719 6.04270581\n",
      " 5.26689108 5.478378   7.20236975 6.01228584 5.70390966 5.11456671\n",
      " 5.27241691 5.70729748 4.7724812  5.85048033 5.63376658 6.91566185\n",
      " 6.6637732  5.44694787 5.47000077 6.05601471 5.63321071 4.99748264\n",
      " 5.20378983 5.09995749 4.5772633  5.49373945 5.90509775 5.97775299\n",
      " 5.07081988 5.98254841 5.00462412 5.35742592 4.54922368 5.46526402\n",
      " 5.68290219 5.49433654 6.03954035 5.98198696 5.60071291 6.53835465\n",
      " 5.71967031 5.24907425 6.04248563 4.65699023 6.39010796 6.30843018\n",
      " 5.86060448 5.13727528 5.80834129 6.32903396 4.87374903 5.30403778\n",
      " 5.40704516 5.65174059 5.61202036 5.41679487 5.01812691 6.69557076\n",
      " 5.62357706 5.78241642 5.2550788  4.57767242 4.96528776 5.57481931\n",
      " 5.40821411 5.38205866 5.72229896]\n",
      "\n",
      "What it should be:  [5.66666667 5.5        4.5        6.         4.16666667 6.\n",
      " 6.16666667 6.83333333 5.83333333 4.5        5.5        6.5\n",
      " 4.83333333 5.         5.33333333 6.5        5.33333333 3.83333333\n",
      " 6.16666667 5.16666667 4.83333333 5.5        6.33333333 5.33333333\n",
      " 5.83333333 6.16666667 6.66666667 6.33333333 4.33333333 5.83333333\n",
      " 5.83333333 6.5        6.66666667 5.66666667 6.5        5.66666667\n",
      " 6.         6.16666667 6.5        6.5        6.83333333 6.16666667\n",
      " 6.16666667 4.         4.83333333 6.5        6.         5.66666667\n",
      " 4.66666667 4.5        4.66666667 5.33333333 6.16666667 1.83333333\n",
      " 5.33333333 6.33333333 6.16666667 6.83333333 6.16666667 5.83333333\n",
      " 6.33333333 6.66666667 5.33333333 4.         6.16666667 6.83333333\n",
      " 3.5        6.66666667 6.83333333 6.66666667 6.5        7.\n",
      " 6.33333333 5.5        3.         6.5        6.         5.66666667\n",
      " 7.         4.83333333 5.83333333 5.83333333 5.5        4.33333333\n",
      " 5.         7.         5.16666667 7.         5.16666667 4.5\n",
      " 5.66666667 6.16666667 6.33333333 5.33333333 4.         5.16666667\n",
      " 6.5        6.16666667 4.66666667 4.         5.66666667 5.5\n",
      " 5.33333333 5.5        5.16666667 4.33333333 6.66666667 3.33333333\n",
      " 5.83333333 5.         5.5        5.33333333 6.         6.83333333\n",
      " 5.16666667 4.33333333 5.83333333 6.33333333 6.33333333 6.66666667\n",
      " 6.83333333 4.66666667 6.         4.5        4.83333333 5.66666667\n",
      " 4.66666667 5.16666667 6.5       ]\n",
      "Correlation:  [[1.         0.11758523]\n",
      " [0.11758523 1.        ]]\n",
      "Mean absolute error = 0.82\n",
      "Mean squared error = 1.08\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.22\n",
      "R2 score = -0.22\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.76153229 6.02003663 5.43169324 6.40348469 5.01470664 4.76061874\n",
      " 4.92304776 6.03273876 5.90226064 5.59985281 4.69086363 6.34475242\n",
      " 4.77096541 6.16031476 6.741967   4.34506368 6.65567535 6.72325576\n",
      " 6.0697569  4.70519696 6.91499897 6.58465519 5.12366906 5.21133081\n",
      " 5.04471844 5.46006065 2.79820826 6.62161374 5.94234087 5.22358584\n",
      " 5.82996882 5.99014143 5.35809901 3.94413991 4.9391283  5.70769891\n",
      " 5.8886835  6.14656595 6.2940122  6.03088916 4.92139942 4.69587726\n",
      " 5.89685266 5.16139461 6.34070156 5.53840542 6.14524254 5.16172338\n",
      " 5.18017159 6.49644334 5.35936008 6.42946052 4.98660851 5.84816885\n",
      " 5.63515889 5.82032767 4.58241408 5.17936713 5.45007578 5.76235119\n",
      " 5.95835541 6.14015784 5.91422805 5.45816215 5.24358295 4.71193829\n",
      " 5.47174215 6.18765676 6.00901758 5.52159111 6.33543163 4.76052632\n",
      " 5.72192691 5.92723728 5.64038307 5.38409085 5.72986831 6.00577411\n",
      " 5.47652257 5.95814006 5.61560246 6.64677225 5.24538328 5.62952849\n",
      " 5.51577395 5.36124354 6.24698744 5.6600024  5.14268287 4.4728924\n",
      " 6.59448633 5.11511249 5.68025196 5.4067981  5.23105961 6.11590702\n",
      " 6.25258786 5.22165208 6.01726005 6.58093279 5.5629641  5.48455382\n",
      " 5.70998342 5.26759469 5.67215108 5.37731219 5.31039071 6.05257769\n",
      " 6.30932987 6.7787085  6.39938788 5.95164606 4.56033945 5.66730496\n",
      " 5.55808747 7.3479245  6.13443895 5.23509476 5.84479943 5.81656833\n",
      " 4.95680745 5.57271959 5.89159556 5.34099171 5.33888969 6.32639833\n",
      " 5.48518428 5.02319995 5.33515697]\n",
      "\n",
      "What it should be:  [5.83333333 5.5        6.16666667 6.16666667 4.83333333 6.83333333\n",
      " 7.         5.         5.66666667 5.16666667 6.5        5.83333333\n",
      " 3.83333333 6.5        4.5        6.33333333 6.16666667 5.66666667\n",
      " 5.33333333 5.         6.16666667 7.         4.83333333 5.66666667\n",
      " 6.33333333 6.83333333 4.83333333 5.66666667 5.66666667 5.\n",
      " 3.66666667 5.66666667 4.66666667 7.         3.         6.66666667\n",
      " 5.33333333 6.16666667 5.33333333 6.33333333 6.16666667 6.5\n",
      " 6.5        5.33333333 5.83333333 4.83333333 6.16666667 5.33333333\n",
      " 6.         6.83333333 6.83333333 5.5        5.83333333 6.\n",
      " 3.66666667 6.5        5.5        5.83333333 6.16666667 4.66666667\n",
      " 5.83333333 5.16666667 4.83333333 4.33333333 6.16666667 6.83333333\n",
      " 5.         6.16666667 4.         6.         5.83333333 5.5\n",
      " 6.66666667 5.33333333 5.33333333 4.         5.33333333 4.5\n",
      " 6.         5.16666667 6.83333333 4.66666667 5.33333333 6.16666667\n",
      " 5.16666667 5.33333333 6.66666667 6.66666667 5.83333333 6.66666667\n",
      " 5.33333333 4.         6.33333333 4.33333333 6.33333333 5.16666667\n",
      " 5.83333333 5.83333333 6.83333333 6.83333333 4.33333333 6.83333333\n",
      " 5.66666667 4.66666667 6.33333333 6.16666667 4.5        6.16666667\n",
      " 6.         4.83333333 5.16666667 6.         6.5        5.33333333\n",
      " 6.16666667 6.16666667 5.16666667 5.5        5.16666667 6.66666667\n",
      " 6.         4.66666667 6.5        6.33333333 5.83333333 6.\n",
      " 5.66666667 3.66666667 3.5       ]\n",
      "Correlation:  [[1.         0.04798903]\n",
      " [0.04798903 1.        ]]\n",
      "Mean absolute error = 0.86\n",
      "Mean squared error = 1.11\n",
      "Median absolute error = 0.73\n",
      "Explain variance score = -0.49\n",
      "R2 score = -0.49\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [7.16218088 5.52310725 5.81751767 5.54223948 4.94597595 5.26069853\n",
      " 6.3059941  5.43367717 5.02158727 5.63201196 6.12044937 5.06616212\n",
      " 5.47724463 5.85519937 4.6068277  5.27743161 5.55944551 6.36611035\n",
      " 6.22540434 5.55186794 4.89443443 5.09164783 5.7678417  5.88019535\n",
      " 4.34404964 5.6494151  6.28376838 5.307408   5.55035307 5.17225801\n",
      " 4.61202063 5.80270311 5.53318156 5.84484795 6.02676027 5.0620084\n",
      " 5.54660465 5.68803395 5.9048744  5.32772785 6.27067013 6.1115825\n",
      " 5.57447717 4.89588611 6.20863908 4.64817388 5.81666868 5.7698569\n",
      " 5.94806168 5.26924371 5.85153523 5.06762427 5.75748698 5.91690907\n",
      " 5.58458634 5.64035301 6.08708791 6.63190022 6.09088586 6.56022831\n",
      " 6.04411942 5.60312247 5.6349051  5.82140099 5.59789923 4.96596329\n",
      " 5.38149436 5.88988764 5.39123139 6.09778541 4.43491599 5.14948826\n",
      " 6.20453548 6.15769223 5.76703041 5.58849401 5.85276994 6.2568299\n",
      " 6.39827998 5.29563981 6.51743191 5.77319893 5.65580258 5.83560095\n",
      " 6.61160876 6.02242655 4.71187925 6.31639322 5.28484454 5.00784139\n",
      " 5.29454552 6.75176397 5.56441168 5.32761928 5.79983758 5.47561189\n",
      " 6.41373843 4.31028974 5.76541494 5.48969252 4.5816346  5.88586212\n",
      " 6.24511641 6.16350376 5.32643351 6.00929047 6.11005238 5.94167712\n",
      " 6.03237044 6.11084245 5.61962523 5.29516146 5.06969166 6.28579596\n",
      " 5.84248067 4.86612684 6.15803973 6.04580096 6.53740453 5.30829753\n",
      " 5.87449504 7.06282518 6.217153   6.78548647 5.59414489 5.35520232\n",
      " 5.60634707 5.6936069  5.59717714]\n",
      "\n",
      "What it should be:  [5.33333333 5.5        6.5        6.         5.5        5.66666667\n",
      " 6.5        4.16666667 5.5        4.         6.5        6.33333333\n",
      " 6.33333333 4.5        5.33333333 4.         5.16666667 5.66666667\n",
      " 5.66666667 4.5        5.83333333 1.83333333 5.5        4.83333333\n",
      " 4.         5.66666667 5.33333333 6.         4.         4.83333333\n",
      " 6.33333333 6.16666667 4.5        5.83333333 5.33333333 6.16666667\n",
      " 4.66666667 5.33333333 5.33333333 5.66666667 5.83333333 6.\n",
      " 6.16666667 5.83333333 6.83333333 7.         5.33333333 4.66666667\n",
      " 6.33333333 6.66666667 5.16666667 6.66666667 6.33333333 6.83333333\n",
      " 4.66666667 6.33333333 6.5        5.33333333 6.16666667 4.66666667\n",
      " 6.66666667 5.83333333 3.33333333 4.83333333 5.         6.\n",
      " 5.33333333 6.83333333 6.83333333 6.16666667 3.         6.\n",
      " 6.83333333 6.83333333 5.83333333 5.66666667 6.16666667 6.5\n",
      " 5.66666667 3.66666667 5.83333333 6.         6.16666667 5.33333333\n",
      " 6.33333333 4.66666667 5.         6.         3.66666667 4.\n",
      " 6.16666667 6.16666667 3.5        6.5        6.16666667 6.5\n",
      " 7.         4.83333333 6.83333333 6.5        6.5        5.5\n",
      " 5.83333333 5.5        5.83333333 5.16666667 7.         5.5\n",
      " 6.66666667 5.16666667 3.66666667 6.         5.         6.16666667\n",
      " 6.16666667 6.5        4.83333333 6.66666667 6.         6.33333333\n",
      " 5.5        6.16666667 5.83333333 5.16666667 6.16666667 6.\n",
      " 4.83333333 6.16666667 6.33333333]\n",
      "Correlation:  [[1.         0.21998776]\n",
      " [0.21998776 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 0.95\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.08\n",
      "R2 score = -0.09\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.81328842 6.49635556 6.3364662  5.95326411 6.32566351 6.32400643\n",
      " 5.71555205 5.24424254 4.90280278 5.24124089 5.70655162 5.78806808\n",
      " 6.37314909 6.19139232 6.16423897 5.87726225 5.52672766 6.3384942\n",
      " 5.8273682  5.85999236 5.53038175 5.89902295 5.45283617 5.9035571\n",
      " 6.50104107 5.74878801 5.7880144  5.6709501  5.34413257 6.19401885\n",
      " 6.37639088 5.03515555 5.60941802 5.65834521 5.3164483  5.83942118\n",
      " 5.85670539 6.21172162 5.49486148 5.34326998 4.94756597 5.82761969\n",
      " 5.65018122 5.83570306 5.40175689 5.7646627  5.28338932 5.63043253\n",
      " 6.1974492  5.33228248 5.52469275 5.41013738 6.19338824 5.6352673\n",
      " 6.05594885 6.01401038 6.63822804 5.81402328 5.89251744 6.44059566\n",
      " 6.28855864 5.11357773 5.89802587 5.43309524 5.9111003  5.05355905\n",
      " 5.88647615 5.7875764  6.51884973 6.36719889 5.61735123 4.8966024\n",
      " 5.53015797 4.83936898 5.59771233 5.65797836 5.89386582 5.52309517\n",
      " 5.84192737 5.60674932 5.67897947 5.73604347 6.11370459 5.75513379\n",
      " 5.18284749 5.90671127 7.06902484 6.01291714 6.69798668 6.1993038\n",
      " 6.06828157 5.24875762 5.66653919 5.79958664 5.52944702 5.56504819\n",
      " 5.82964615 5.3926796  5.52212061 5.77523641 5.80267609 5.13130222\n",
      " 5.51864946 5.67407887 5.47223767 5.60965026 5.7377896  6.05980015\n",
      " 5.95339172 5.4118496  5.3111726  5.63417567 5.3652267  5.76676866\n",
      " 6.30690885 6.11638697 5.92416207 5.65622427 6.71584837 5.36320647\n",
      " 5.73224105 5.96266832 5.6777996  5.66319184 5.79231837 5.53371831\n",
      " 5.82268398 5.49357087 6.13633725]\n",
      "\n",
      "What it should be:  [4.83333333 6.16666667 6.16666667 4.66666667 6.66666667 5.83333333\n",
      " 7.         6.         7.         5.83333333 4.33333333 6.16666667\n",
      " 5.33333333 5.16666667 6.         4.83333333 3.66666667 5.83333333\n",
      " 5.5        4.66666667 4.66666667 6.83333333 6.16666667 5.\n",
      " 6.16666667 4.5        5.66666667 6.33333333 5.33333333 5.33333333\n",
      " 6.5        6.33333333 5.83333333 6.         5.33333333 4.66666667\n",
      " 6.66666667 4.66666667 4.         6.16666667 3.66666667 4.66666667\n",
      " 5.33333333 4.33333333 4.33333333 6.         5.16666667 6.16666667\n",
      " 6.66666667 3.33333333 6.5        3.5        6.         5.83333333\n",
      " 4.66666667 6.33333333 5.66666667 5.16666667 5.83333333 6.\n",
      " 5.5        6.5        6.83333333 6.33333333 5.16666667 4.5\n",
      " 6.         6.33333333 6.33333333 6.83333333 5.33333333 4.83333333\n",
      " 6.16666667 5.16666667 5.66666667 5.5        6.83333333 6.5\n",
      " 1.83333333 4.83333333 6.16666667 5.5        6.83333333 6.\n",
      " 4.5        5.5        6.16666667 6.5        6.16666667 5.33333333\n",
      " 4.         6.83333333 7.         5.66666667 6.16666667 6.33333333\n",
      " 5.5        3.66666667 6.66666667 5.5        5.16666667 6.16666667\n",
      " 5.33333333 5.         6.66666667 6.66666667 5.66666667 6.83333333\n",
      " 5.66666667 6.33333333 4.         5.33333333 3.83333333 5.83333333\n",
      " 5.33333333 4.33333333 6.         6.5        5.33333333 5.66666667\n",
      " 6.83333333 5.16666667 7.         6.16666667 6.5        5.66666667\n",
      " 5.         3.         5.33333333]\n",
      "Correlation:  [[1.         0.16834564]\n",
      " [0.16834564 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 0.98\n",
      "Median absolute error = 0.74\n",
      "Explain variance score = -0.04\n",
      "R2 score = -0.08\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [4.03217309 5.93524157 4.9476656  5.38608475 5.78005868 5.02196999\n",
      " 6.10604414 5.50201654 6.24988969 5.79191296 4.43403835 5.58356356\n",
      " 4.58767334 6.03187721 4.83748596 5.52455088 5.09943231 5.81979463\n",
      " 6.00265913 5.31308274 5.14061557 6.42557408 6.46250146 6.76145036\n",
      " 6.38489081 5.2279196  5.5458588  6.0514269  4.93631205 4.68061066\n",
      " 5.293793   5.4986336  4.83472249 6.12970434 5.38444506 5.46314627\n",
      " 4.24159821 5.86422223 6.50660858 5.94777502 5.31951688 5.15705176\n",
      " 4.62480031 5.99483934 4.88902087 5.90066814 5.32582129 4.89852358\n",
      " 5.20417135 4.61405862 6.12357221 5.51292417 5.35307869 5.2532674\n",
      " 4.16660385 6.07439699 5.63693    4.68576343 6.52889781 6.37858999\n",
      " 6.66314074 5.86719894 4.74404531 5.09504637 5.72175559 5.13477898\n",
      " 4.42563487 5.68466427 6.51244888 4.67541906 5.80621404 5.23325773\n",
      " 3.76484676 5.56772766 5.4451249  5.96811045 5.42985374 5.23440325\n",
      " 6.37028323 5.29938945 6.34310897 5.39896222 4.37480209 5.22231097\n",
      " 4.95323476 5.12412705 5.66784288 6.18105382 5.40399726 6.52130019\n",
      " 5.53960297 6.03274537 5.21193928 4.68103807 5.58249228 5.10086589\n",
      " 5.76587869 5.13609043 5.83239853 5.21770353 6.16280522 4.17980336\n",
      " 6.18133222 5.83618373 5.36116805 4.87980911 5.54063881 5.16579269\n",
      " 5.84786518 6.06003522 4.76499978 5.82184753 5.56274346 6.08468631\n",
      " 5.94774768 5.38531236 5.90394101 5.29525527 4.49288737 5.95595075\n",
      " 5.08410634 6.20655449 6.38999954 5.72598684 5.46525398 5.77023262\n",
      " 5.33097234 4.83544571 5.82001391]\n",
      "\n",
      "What it should be:  [4.83333333 7.         4.5        6.66666667 6.16666667 6.16666667\n",
      " 4.83333333 5.66666667 4.         4.66666667 6.5        5.16666667\n",
      " 7.         6.16666667 5.16666667 4.83333333 5.33333333 6.16666667\n",
      " 5.16666667 4.83333333 6.16666667 6.16666667 5.33333333 6.33333333\n",
      " 4.33333333 5.5        6.66666667 6.         6.83333333 5.\n",
      " 6.33333333 6.         6.5        3.5        5.33333333 6.33333333\n",
      " 4.83333333 6.33333333 6.5        5.66666667 6.33333333 5.33333333\n",
      " 6.33333333 6.16666667 6.16666667 5.66666667 6.83333333 6.5\n",
      " 4.         7.         3.66666667 5.33333333 4.66666667 5.33333333\n",
      " 3.83333333 5.33333333 5.83333333 6.5        6.66666667 7.\n",
      " 6.5        5.66666667 5.5        5.33333333 6.         4.66666667\n",
      " 4.         5.83333333 4.66666667 5.16666667 5.33333333 6.66666667\n",
      " 5.5        6.83333333 5.33333333 6.16666667 5.16666667 4.66666667\n",
      " 5.         6.33333333 6.         5.83333333 6.5        5.83333333\n",
      " 6.83333333 4.83333333 6.66666667 6.5        6.         6.5\n",
      " 5.66666667 6.5        6.33333333 6.83333333 5.5        4.\n",
      " 4.66666667 6.83333333 6.5        5.66666667 6.16666667 5.33333333\n",
      " 6.33333333 5.33333333 7.         6.5        6.         6.\n",
      " 5.16666667 4.5        6.66666667 5.16666667 3.66666667 5.83333333\n",
      " 6.         5.83333333 6.16666667 6.66666667 4.66666667 6.\n",
      " 5.5        6.         6.5        6.16666667 4.16666667 5.83333333\n",
      " 6.83333333 4.83333333 5.5       ]\n",
      "Correlation:  [[1.         0.05557241]\n",
      " [0.05557241 1.        ]]\n",
      "Mean absolute error = 0.8\n",
      "Mean squared error = 1.09\n",
      "Median absolute error = 0.5\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.52\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.60369764 6.17642482 4.67360429 6.50329598 6.05760051 5.47609048\n",
      " 5.30403339 5.7663285  5.52520524 4.42768076 5.03111469 5.40090397\n",
      " 5.42068868 5.80163277 4.87019787 4.9666897  5.31907356 5.93338367\n",
      " 5.7273235  6.49096788 5.95781904 4.34190233 5.54754741 6.17361472\n",
      " 5.31678536 5.99861307 6.62470494 5.13667777 5.44628045 5.89247828\n",
      " 5.36165778 5.28595809 6.37059629 4.83157824 6.65162779 5.32465862\n",
      " 5.22527454 6.06546357 5.52358858 5.39577577 6.16058285 5.91071632\n",
      " 5.72844375 5.53651075 4.7832547  6.2187455  5.33110625 5.34253203\n",
      " 5.09404085 5.56790261 5.58107415 6.12732192 6.16474004 4.57304597\n",
      " 5.85052436 5.40754486 6.0750473  5.60248322 5.74725979 5.31574192\n",
      " 5.68401008 4.64333042 5.63933814 5.42559821 4.47461899 3.99455952\n",
      " 6.08047323 5.05237529 5.14991081 5.27834304 5.19900092 6.48000302\n",
      " 5.98908805 4.31570205 4.56305736 4.66123884 5.72095824 5.46159626\n",
      " 6.37211799 6.0623224  5.37946298 5.55917857 6.20288881 6.3794499\n",
      " 5.8212324  5.71428827 5.9731906  5.08506814 5.68430256 5.92459586\n",
      " 6.09643417 5.77680685 5.19090134 5.14115648 5.02843421 4.21449148\n",
      " 5.3247323  5.86786421 5.35835715 5.64691103 6.09083676 5.82784443\n",
      " 4.97601325 5.89041188 4.72665013 4.59135336 6.03546664 6.12100526\n",
      " 5.81677899 5.71422821 5.59094566 5.95032226 5.96051475 5.20454685\n",
      " 6.22737404 5.14728367 7.01927065 5.39750762 5.76897286 5.65035728\n",
      " 5.50489214 5.28368254 5.88098725 5.37005879 5.31843577 6.20398743\n",
      " 5.23455734 5.28281459 5.39747184]\n",
      "\n",
      "What it should be:  [6.5        7.         5.83333333 6.83333333 6.16666667 6.\n",
      " 6.16666667 5.16666667 6.16666667 5.33333333 6.         4.\n",
      " 5.16666667 5.83333333 6.16666667 5.83333333 5.83333333 5.66666667\n",
      " 6.33333333 6.33333333 6.5        4.5        5.33333333 6.5\n",
      " 6.5        5.66666667 6.5        5.33333333 5.16666667 5.33333333\n",
      " 6.5        6.         3.83333333 5.5        1.83333333 6.16666667\n",
      " 5.5        6.33333333 6.66666667 5.16666667 7.         4.83333333\n",
      " 5.66666667 6.         5.5        6.66666667 5.83333333 6.83333333\n",
      " 5.         6.5        5.5        4.83333333 4.33333333 5.\n",
      " 4.83333333 6.66666667 5.33333333 6.83333333 5.66666667 6.33333333\n",
      " 5.83333333 5.66666667 6.         4.5        5.83333333 7.\n",
      " 6.83333333 6.         3.66666667 6.83333333 5.5        7.\n",
      " 5.83333333 7.         6.         6.33333333 6.5        5.33333333\n",
      " 6.16666667 5.83333333 4.33333333 6.16666667 6.16666667 4.66666667\n",
      " 5.83333333 5.33333333 5.33333333 5.66666667 6.5        6.5\n",
      " 6.83333333 5.33333333 5.16666667 3.         6.33333333 4.\n",
      " 3.5        6.16666667 4.66666667 3.66666667 6.16666667 4.16666667\n",
      " 6.16666667 5.33333333 4.83333333 6.33333333 6.83333333 5.66666667\n",
      " 6.16666667 4.66666667 7.         4.83333333 5.         5.83333333\n",
      " 5.83333333 4.83333333 4.83333333 6.83333333 6.         6.\n",
      " 5.66666667 6.5        4.66666667 6.5        6.33333333 5.83333333\n",
      " 6.         5.16666667 6.16666667]\n",
      "Correlation:  [[1.         0.01102143]\n",
      " [0.01102143 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.14\n",
      "Median absolute error = 0.69\n",
      "Explain variance score = -0.36\n",
      "R2 score = -0.39\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.24186622 4.44929894 4.92451047 5.9707933  5.61829833 5.3639648\n",
      " 6.08437069 5.46838334 6.00895288 5.60628164 5.25847304 5.64853304\n",
      " 7.11325344 5.43370543 5.86458278 5.81551963 6.47368207 5.75566209\n",
      " 5.75340485 5.29012913 5.80686116 4.92135805 6.28208174 6.32082596\n",
      " 5.51939327 5.10005278 5.71046132 5.62451653 6.33201785 4.81088232\n",
      " 5.89035718 7.27735317 5.19394784 7.12739806 5.82806546 5.8526733\n",
      " 6.19443204 5.81696139 5.97452623 5.68168586 6.71464897 5.74067623\n",
      " 5.78840958 5.86568691 5.37821849 6.07873446 5.65098204 5.67420154\n",
      " 5.6026347  5.4593855  5.44853443 5.45086345 5.79991171 6.32904002\n",
      " 5.27756081 6.31335466 5.7269839  5.29733441 6.11339902 6.5405836\n",
      " 5.06742451 5.98993693 6.09737005 6.04409169 5.30856401 6.88470521\n",
      " 5.75995775 6.11805841 4.30583424 6.35022771 5.48874938 6.51309658\n",
      " 4.87503405 5.064393   5.20556835 5.1757745  5.40133615 4.50360617\n",
      " 6.0172249  5.89903027 6.00408244 4.5897772  6.08887687 4.95404486\n",
      " 5.53104504 5.38372057 5.58338167 5.6515235  6.23637847 4.95823838\n",
      " 5.58633642 6.06545387 5.63039132 5.85778575 5.15855487 5.95845744\n",
      " 5.52458329 4.86523283 6.24713267 5.46030829 5.07923526 5.49187853\n",
      " 5.90845473 4.78879571 6.07642723 5.86627627 5.14817146 6.34986889\n",
      " 5.70215797 4.5958615  5.27282653 5.88026386 5.84138998 5.23406069\n",
      " 5.33091736 5.54428357 5.62510892 6.02969555 5.29865414 5.29395187\n",
      " 5.42279016 5.47198034 5.4821514  5.20481377 6.14946497 5.0627115\n",
      " 5.86860273 5.84768338 4.92609252]\n",
      "\n",
      "What it should be:  [6.         6.83333333 3.66666667 6.83333333 6.16666667 6.\n",
      " 5.33333333 6.16666667 6.83333333 6.16666667 6.66666667 5.16666667\n",
      " 5.83333333 5.83333333 4.83333333 1.83333333 5.33333333 5.66666667\n",
      " 6.16666667 5.66666667 5.         6.33333333 6.         6.66666667\n",
      " 6.5        4.         3.5        6.5        6.         5.5\n",
      " 4.         6.16666667 3.83333333 7.         5.16666667 4.16666667\n",
      " 4.33333333 6.16666667 6.         5.33333333 7.         6.\n",
      " 5.16666667 5.5        5.83333333 6.5        6.5        4.83333333\n",
      " 4.66666667 5.83333333 5.83333333 5.66666667 6.33333333 6.\n",
      " 5.         5.83333333 6.66666667 4.66666667 5.66666667 5.66666667\n",
      " 5.83333333 5.16666667 6.5        5.83333333 6.16666667 5.66666667\n",
      " 6.5        4.66666667 5.5        6.5        6.5        5.33333333\n",
      " 4.83333333 6.16666667 3.33333333 4.66666667 6.66666667 7.\n",
      " 4.83333333 6.83333333 6.83333333 5.66666667 6.33333333 5.\n",
      " 6.16666667 6.         5.33333333 6.5        6.33333333 6.83333333\n",
      " 6.         5.66666667 5.33333333 6.16666667 6.         5.5\n",
      " 3.66666667 5.33333333 5.33333333 6.66666667 4.5        5.5\n",
      " 5.33333333 7.         5.33333333 6.33333333 5.16666667 6.33333333\n",
      " 4.83333333 4.5        4.83333333 6.16666667 4.5        6.5\n",
      " 5.         4.         6.83333333 5.16666667 6.66666667 4.5\n",
      " 6.66666667 4.5        5.5        5.         6.5        4.33333333\n",
      " 5.66666667 6.16666667 6.33333333]\n",
      "Correlation:  [[1.         0.13811372]\n",
      " [0.13811372 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.18\n",
      "R2 score = -0.18\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.90862669 5.82156845 6.23974497 5.57849095 5.45617281 5.79527827\n",
      " 5.2421421  5.75841522 5.54113779 5.73083909 5.41375483 5.17694706\n",
      " 5.80036745 5.69847805 5.41860196 5.90609107 5.96272174 6.09820431\n",
      " 5.65640267 6.03382203 4.91421834 4.83337975 5.5165236  5.8543585\n",
      " 5.70240162 5.79530728 6.04701801 4.73216193 5.79519291 5.99128424\n",
      " 6.15673271 5.76476838 5.76069702 5.14153878 5.41880752 5.26504496\n",
      " 5.65435533 6.00804314 5.83314944 5.23973049 5.92566335 5.74312479\n",
      " 5.34714489 5.34509356 5.04651335 5.84151716 5.09553553 6.21356701\n",
      " 5.11106846 5.10497422 5.57843652 5.21239138 6.19206881 5.02133108\n",
      " 5.31619459 5.77450513 4.68517473 4.85475062 5.58591359 5.37447014\n",
      " 5.56549932 5.76813729 5.6385258  5.51429828 4.1667133  5.95822439\n",
      " 5.84308561 5.22341659 6.23430387 5.57905074 5.63071831 5.5649098\n",
      " 5.31966344 5.73794872 5.82182666 4.54630517 6.15196544 4.85411947\n",
      " 5.75322812 5.33987091 5.77615201 5.24503258 4.88823201 5.25062826\n",
      " 5.53990809 6.07317467 5.16773864 5.05865175 5.03998143 5.54122173\n",
      " 5.31684416 4.94381146 4.99046335 5.72503186 5.96635834 5.28504667\n",
      " 6.00972111 5.76425938 5.98832151 5.50425974 5.5521375  5.99347045\n",
      " 5.34820801 5.33244396 5.62935254 6.00930602 5.980392   5.24234922\n",
      " 5.27744029 6.13649331 5.20827669 5.36765448 6.15092377 4.76709641\n",
      " 4.83516372 5.94240637 4.80197526 5.15183288 5.79745327 4.83499093\n",
      " 5.50691507 5.96874293 6.46337142 5.78558813 5.85667604 5.6413779\n",
      " 5.51823639 5.4734795  5.51148389]\n",
      "\n",
      "What it should be:  [6.16666667 5.33333333 5.33333333 5.66666667 6.66666667 6.66666667\n",
      " 5.83333333 6.5        5.33333333 6.66666667 6.5        3.5\n",
      " 4.66666667 5.5        7.         5.66666667 5.83333333 6.\n",
      " 6.5        5.83333333 6.5        5.16666667 6.         3.66666667\n",
      " 4.83333333 6.16666667 7.         3.83333333 6.         6.16666667\n",
      " 6.         6.33333333 5.66666667 4.33333333 4.5        6.5\n",
      " 6.         4.         6.83333333 5.33333333 6.83333333 6.33333333\n",
      " 5.16666667 5.33333333 1.83333333 5.33333333 4.66666667 7.\n",
      " 6.66666667 5.5        4.         5.83333333 5.33333333 6.66666667\n",
      " 6.         6.83333333 5.5        5.66666667 6.16666667 6.66666667\n",
      " 6.66666667 5.83333333 6.33333333 6.5        4.83333333 5.66666667\n",
      " 6.16666667 6.83333333 5.83333333 6.         5.16666667 5.5\n",
      " 5.83333333 6.5        5.83333333 6.16666667 5.83333333 4.83333333\n",
      " 6.5        6.16666667 6.         6.         6.         6.5\n",
      " 6.         5.5        6.33333333 5.5        4.66666667 4.\n",
      " 5.33333333 3.66666667 5.33333333 4.66666667 6.83333333 6.33333333\n",
      " 5.33333333 5.83333333 6.83333333 6.83333333 5.33333333 5.66666667\n",
      " 7.         6.5        6.16666667 6.16666667 5.66666667 5.83333333\n",
      " 5.         6.33333333 6.         6.5        5.33333333 3.\n",
      " 4.66666667 6.16666667 6.33333333 4.5        4.83333333 6.5\n",
      " 4.83333333 5.66666667 6.16666667 4.5        5.16666667 3.33333333\n",
      " 5.5        4.5        4.16666667]\n",
      "Correlation:  [[1.         0.22394668]\n",
      " [0.22394668 1.        ]]\n",
      "Mean absolute error = 0.76\n",
      "Mean squared error = 0.89\n",
      "Median absolute error = 0.68\n",
      "Explain variance score = -0.0\n",
      "R2 score = -0.02\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.19773965 5.56138462 5.38249592 5.81288183 5.72833013 6.14214391\n",
      " 5.83793907 5.21758054 6.48964665 4.50636333 4.89431242 4.48759897\n",
      " 6.04841136 4.71581551 4.56877155 5.08034269 6.02861333 6.41100464\n",
      " 5.90733121 5.4214232  5.28494685 5.07518676 5.57909494 4.80065952\n",
      " 4.44900431 4.78527416 5.65342051 4.318931   4.63424054 6.18653162\n",
      " 4.33892229 5.72444072 5.25481893 6.31251454 5.69102733 5.67475383\n",
      " 5.01587538 4.74588715 4.85973705 5.02727122 5.70239491 5.02649363\n",
      " 5.59213751 5.22564254 5.45170607 4.80514829 4.75821199 6.10016971\n",
      " 5.90722501 6.28110488 6.30848933 5.61334119 5.65255701 5.63557688\n",
      " 5.78873505 4.81623686 5.04303013 6.03480858 5.97611399 5.78772777\n",
      " 5.00316528 4.66876315 6.10287223 4.91173371 5.5993339  4.34453423\n",
      " 6.05711624 4.84760012 5.32101414 4.87171923 5.42898527 6.51294748\n",
      " 4.82708056 5.89617664 5.63770026 5.93819638 5.57462834 5.17334164\n",
      " 5.33839218 5.47197545 5.53739034 5.03494989 5.12631259 5.40469305\n",
      " 4.815012   5.82817625 5.81478436 5.21533903 4.50103943 6.0085768\n",
      " 5.50639188 4.37366583 5.7135273  5.1486668  5.77206118 5.36523808\n",
      " 7.04595077 5.6494403  5.96662638 5.36633223 5.53467436 6.05301416\n",
      " 6.8428053  6.09988971 5.78624914 6.89383326 5.07838085 6.14661962\n",
      " 5.46830466 6.79013218 4.74448683 5.46191979 5.23368878 4.24663432\n",
      " 5.18627394 4.47177599 5.95236125 5.12691668 4.80485922 5.34115864\n",
      " 5.925344   4.48111967 5.26738705 5.92527362 5.58654866 5.09294788\n",
      " 5.38397669 5.61016849 4.80652613]\n",
      "\n",
      "What it should be:  [5.33333333 6.16666667 5.83333333 6.83333333 6.16666667 6.5\n",
      " 6.5        5.33333333 6.33333333 6.83333333 5.5        7.\n",
      " 6.16666667 5.16666667 4.66666667 6.33333333 4.5        6.5\n",
      " 6.83333333 5.66666667 6.5        6.         6.16666667 5.83333333\n",
      " 3.83333333 5.         6.33333333 5.83333333 6.5        6.66666667\n",
      " 7.         5.33333333 6.66666667 5.33333333 6.16666667 5.16666667\n",
      " 7.         6.83333333 3.5        4.83333333 5.         5.33333333\n",
      " 5.83333333 6.         4.         4.83333333 6.66666667 5.16666667\n",
      " 6.16666667 6.33333333 4.66666667 5.83333333 6.66666667 6.16666667\n",
      " 6.33333333 4.66666667 5.5        5.         3.         6.16666667\n",
      " 6.16666667 3.66666667 5.66666667 6.33333333 4.5        4.83333333\n",
      " 6.83333333 6.16666667 4.33333333 5.83333333 6.83333333 4.66666667\n",
      " 5.5        6.         5.5        6.16666667 6.5        6.\n",
      " 4.33333333 4.66666667 5.33333333 6.16666667 5.66666667 6.83333333\n",
      " 4.83333333 5.33333333 5.33333333 4.5        6.16666667 5.16666667\n",
      " 6.66666667 5.66666667 4.16666667 5.5        6.5        5.83333333\n",
      " 6.33333333 6.16666667 5.5        6.         6.5        5.66666667\n",
      " 7.         5.83333333 6.         5.83333333 4.83333333 7.\n",
      " 5.66666667 6.83333333 6.16666667 4.5        5.16666667 6.33333333\n",
      " 5.16666667 5.33333333 5.66666667 5.66666667 4.         4.33333333\n",
      " 6.16666667 4.83333333 6.16666667 5.33333333 5.66666667 3.33333333\n",
      " 6.33333333 4.5        6.83333333]\n",
      "Correlation:  [[1.         0.14162899]\n",
      " [0.14162899 1.        ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.03\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.28\n",
      "R2 score = -0.35\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.2330201  4.95956984 4.6584299  5.23781419 5.16718466 6.00322091\n",
      " 5.64857441 5.28752833 5.71959292 4.58089594 5.97774848 5.46550688\n",
      " 5.23308927 5.5157155  4.9279116  5.01642321 6.17159175 5.37797749\n",
      " 5.37607311 5.40248702 6.56090922 5.29934627 4.87592712 6.00049827\n",
      " 5.45310125 5.62719286 5.80253377 5.74271632 6.11707942 3.87327436\n",
      " 5.80350297 5.36700568 5.34136494 4.53088129 5.65904132 5.94367884\n",
      " 5.51229238 5.9090186  5.33720069 5.5473785  5.59214626 5.78376953\n",
      " 6.06596067 5.10506011 5.73006996 6.14345616 5.57723418 5.81785333\n",
      " 6.18719687 5.74385468 5.63357299 5.9326056  5.14324775 5.05512991\n",
      " 5.91152611 5.28720695 5.95881194 4.52542946 5.20057744 5.39089787\n",
      " 5.63251284 5.24341658 5.06145206 4.9741125  5.32143961 5.07875652\n",
      " 5.30076212 5.40057922 5.25332651 5.78943097 5.50128358 5.24117546\n",
      " 5.92102712 6.12642364 5.51644789 5.11631417 4.88986163 4.90756458\n",
      " 5.544505   5.88525074 5.55476003 5.97402418 5.13279864 5.91823607\n",
      " 5.43014548 5.12217774 5.3357423  6.05909284 5.61360437 6.0800458\n",
      " 5.38141529 5.2360581  5.63550274 5.67433023 5.13646754 5.66534789\n",
      " 4.43325145 6.02201763 5.42285441 5.19286225 5.78174085 5.04373049\n",
      " 5.88096089 4.25146099 5.22004286 5.98827698 5.34641956 4.38104147\n",
      " 4.28693096 5.91704061 6.04708036 5.60104423 5.88079863 5.32850248\n",
      " 4.32367885 5.84049503 5.11188238 5.81418792 5.53423728 5.0046191\n",
      " 4.83506965 5.94927378 5.6367396  5.58200821 5.94915137 5.71432395\n",
      " 6.49112197 5.76851762 5.5699812 ]\n",
      "\n",
      "What it should be:  [7.         6.33333333 6.         4.33333333 6.66666667 6.\n",
      " 4.5        6.33333333 6.16666667 4.5        6.33333333 5.\n",
      " 6.16666667 7.         5.33333333 6.66666667 6.5        6.33333333\n",
      " 6.16666667 6.83333333 6.16666667 5.33333333 6.33333333 6.33333333\n",
      " 6.83333333 1.83333333 4.5        6.5        6.5        6.\n",
      " 4.83333333 4.66666667 5.5        4.33333333 6.33333333 5.66666667\n",
      " 5.33333333 6.16666667 6.         5.83333333 6.33333333 5.66666667\n",
      " 7.         4.5        4.83333333 6.5        6.83333333 3.66666667\n",
      " 6.5        5.33333333 5.66666667 5.33333333 6.5        4.66666667\n",
      " 4.66666667 5.         4.83333333 3.5        4.5        5.16666667\n",
      " 5.33333333 6.66666667 6.16666667 5.66666667 5.83333333 4.66666667\n",
      " 4.66666667 5.66666667 5.5        6.16666667 6.         4.83333333\n",
      " 6.66666667 5.33333333 5.83333333 4.83333333 6.         5.5\n",
      " 5.5        6.83333333 6.5        6.16666667 4.83333333 3.83333333\n",
      " 6.66666667 5.33333333 5.66666667 6.33333333 6.         5.83333333\n",
      " 6.         6.16666667 6.83333333 6.16666667 6.83333333 5.66666667\n",
      " 4.         4.         4.         6.16666667 5.83333333 6.33333333\n",
      " 6.16666667 6.33333333 6.16666667 5.66666667 5.16666667 5.5\n",
      " 4.33333333 6.66666667 5.33333333 5.33333333 6.83333333 6.5\n",
      " 6.16666667 5.16666667 3.66666667 5.66666667 6.83333333 6.66666667\n",
      " 5.33333333 5.5        5.83333333 3.         7.         5.\n",
      " 6.5        5.33333333 6.5       ]\n",
      "Correlation:  [[1.         0.16299662]\n",
      " [0.16299662 1.        ]]\n",
      "Mean absolute error = 0.79\n",
      "Mean squared error = 1.0\n",
      "Median absolute error = 0.67\n",
      "Explain variance score = -0.09\n",
      "R2 score = -0.14\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.24625018 6.65792089 6.12282051 6.24919668 6.61468012 5.24524857\n",
      " 6.22385338 5.32516954 5.1918756  5.76250491 5.69616625 6.80133929\n",
      " 6.44653764 6.11628783 4.75031388 5.99591177 5.76251983 5.242999\n",
      " 6.55201766 6.07022394 5.13914578 5.52258918 5.85456634 4.82381948\n",
      " 5.99800946 5.91758251 5.40831778 6.07285929 6.52719215 6.20588963\n",
      " 6.18221359 5.63470007 5.86827217 5.07306532 6.08197876 5.77111456\n",
      " 5.02752982 5.88916107 7.1050908  4.85038347 6.21576501 6.2753984\n",
      " 3.61293644 6.15917588 5.53496072 5.60412039 5.64931557 4.69406896\n",
      " 6.1169234  6.53607523 5.48484665 5.18761189 6.04510516 5.11704259\n",
      " 5.68501843 5.58933192 6.53383489 7.84254484 6.06513438 4.76454048\n",
      " 5.02213236 5.96071783 4.83807163 5.72087907 6.04350886 6.38716089\n",
      " 4.7406953  4.40771711 5.15549545 6.16912858 6.58117239 5.75461221\n",
      " 5.21284212 6.37770613 6.16174641 4.77191914 6.96040403 5.58381267\n",
      " 6.99620337 4.95648891 5.86548662 5.49417509 5.70097228 5.79247626\n",
      " 6.40526176 6.14396523 6.24505633 5.52092981 6.46565427 6.38943249\n",
      " 5.59056211 5.80088883 6.64111212 5.81771457 5.51946289 6.30772259\n",
      " 6.07320233 7.01003682 5.67851937 5.30910242 5.42169715 6.77021699\n",
      " 6.31063105 4.74406456 4.50809678 6.23942945 6.2936406  5.24912948\n",
      " 5.7140579  5.77545394 6.69073352 3.94769215 5.4351094  5.51717696\n",
      " 5.13568691 6.48578205 6.33582912 5.37572524 6.44563235 6.27489515\n",
      " 6.9432794  4.89961756 6.11210819 5.84744513 6.02671816 5.62898871\n",
      " 7.35030082 6.31185884 5.19147162]\n",
      "\n",
      "What it should be:  [4.66666667 6.5        5.         4.5        7.         6.66666667\n",
      " 6.         5.66666667 5.5        5.33333333 5.33333333 6.16666667\n",
      " 5.66666667 6.5        6.83333333 5.16666667 6.5        6.\n",
      " 6.16666667 3.33333333 5.66666667 5.5        5.5        4.83333333\n",
      " 6.83333333 5.83333333 4.33333333 6.33333333 5.33333333 6.16666667\n",
      " 4.66666667 5.83333333 6.16666667 4.66666667 5.16666667 6.66666667\n",
      " 5.66666667 6.         6.33333333 6.16666667 4.33333333 6.5\n",
      " 4.83333333 4.5        6.66666667 5.83333333 4.         3.66666667\n",
      " 4.         6.16666667 3.66666667 4.66666667 5.16666667 6.16666667\n",
      " 3.5        5.         5.33333333 6.5        6.33333333 7.\n",
      " 5.83333333 6.33333333 5.83333333 6.33333333 7.         6.83333333\n",
      " 6.5        5.83333333 5.33333333 5.66666667 4.         4.33333333\n",
      " 6.33333333 6.83333333 4.66666667 6.         6.66666667 5.33333333\n",
      " 6.16666667 4.83333333 6.         6.16666667 5.33333333 5.33333333\n",
      " 5.16666667 4.5        6.5        4.83333333 5.83333333 5.33333333\n",
      " 6.5        5.5        6.5        5.83333333 3.66666667 6.\n",
      " 5.16666667 6.16666667 5.83333333 7.         5.33333333 3.\n",
      " 5.33333333 4.5        5.83333333 6.83333333 7.         6.16666667\n",
      " 6.16666667 5.         5.66666667 4.83333333 4.83333333 5.\n",
      " 5.66666667 5.66666667 5.33333333 5.66666667 6.83333333 4.66666667\n",
      " 6.         4.33333333 6.5        6.66666667 6.         6.66666667\n",
      " 5.66666667 6.83333333 4.5       ]\n",
      "Correlation:  [[1.         0.17045405]\n",
      " [0.17045405 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.1\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.32\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.51519362 5.9994501  5.7398793  5.87461685 6.2708232  5.04792298\n",
      " 5.68536696 6.81747148 5.17534765 4.97291124 5.58113518 5.58564839\n",
      " 5.95953336 5.54070006 5.31565273 4.78796644 5.63884187 5.78264011\n",
      " 5.38201816 5.38727543 5.1689831  5.99937165 5.85667667 4.71717777\n",
      " 6.05979628 6.12440093 5.2958657  5.48121755 5.50112372 4.61337307\n",
      " 5.40382693 5.09201988 5.96227858 4.56387223 6.10390637 6.19718607\n",
      " 4.73988192 5.36648258 5.77179509 5.82309541 3.24003233 6.31381931\n",
      " 2.51856842 6.13432289 5.46390911 5.45102447 4.94003484 6.16233797\n",
      " 4.5109438  6.52827023 5.1245054  6.3111719  5.15818531 5.2382186\n",
      " 5.17437098 5.20874595 6.44505429 5.17025293 6.34180248 5.64813413\n",
      " 5.36766966 5.00018098 4.27520998 5.72630181 6.56601986 5.94814997\n",
      " 6.50597272 5.88392355 4.83620026 5.12816783 4.98203768 4.09931324\n",
      " 5.86361531 4.70443077 6.26919608 5.61531742 6.23716604 6.97185743\n",
      " 6.21379728 5.62466281 4.40660903 4.37060932 4.70587614 5.78745795\n",
      " 5.33878446 4.7478575  4.4499723  6.439165   4.93522387 6.28645303\n",
      " 6.18876944 5.45736849 4.86389678 5.54916473 6.03989737 4.98517371\n",
      " 5.76951921 4.7678069  4.49585977 5.57537455 5.44905986 5.22120471\n",
      " 5.81121619 5.50115187 5.76355411 6.01053758 5.3032931  4.55061572\n",
      " 5.5445232  6.58822126 6.55295763 4.0985341  5.88802757 5.94700291\n",
      " 5.30817325 5.0339101  5.68293647 6.05249712 4.29506727 4.94341285\n",
      " 5.41849699 4.63863897 6.64689065 6.26084035 4.45776086 5.88373372\n",
      " 4.60940979 5.79127358 5.1741876 ]\n",
      "\n",
      "What it should be:  [6.16666667 5.33333333 4.5        5.5        6.16666667 7.\n",
      " 4.83333333 6.83333333 3.66666667 4.83333333 6.         6.\n",
      " 6.16666667 5.66666667 4.66666667 5.66666667 6.         4.83333333\n",
      " 6.5        5.5        5.         6.5        6.83333333 4.5\n",
      " 5.33333333 6.5        6.33333333 6.5        5.5        3.33333333\n",
      " 6.16666667 5.83333333 6.66666667 5.83333333 6.83333333 5.33333333\n",
      " 5.33333333 5.83333333 5.16666667 5.33333333 5.5        6.5\n",
      " 4.83333333 5.16666667 6.5        5.33333333 6.5        6.16666667\n",
      " 6.         6.33333333 5.66666667 5.16666667 5.33333333 6.33333333\n",
      " 6.16666667 4.83333333 4.83333333 6.5        7.         4.5\n",
      " 6.66666667 4.66666667 6.83333333 5.83333333 5.33333333 5.66666667\n",
      " 7.         5.5        5.83333333 5.83333333 5.         4.83333333\n",
      " 5.66666667 6.83333333 5.66666667 4.         6.66666667 5.66666667\n",
      " 6.16666667 6.         6.16666667 5.83333333 4.83333333 5.16666667\n",
      " 5.83333333 6.5        6.         6.83333333 6.33333333 7.\n",
      " 5.33333333 5.66666667 6.16666667 7.         6.5        7.\n",
      " 4.16666667 6.66666667 6.5        6.66666667 5.83333333 4.66666667\n",
      " 6.16666667 4.5        6.5        6.16666667 6.83333333 5.\n",
      " 6.16666667 5.66666667 5.33333333 3.66666667 6.33333333 6.\n",
      " 6.16666667 6.16666667 5.83333333 6.16666667 4.33333333 5.16666667\n",
      " 5.16666667 5.5        3.         5.5        5.83333333 4.66666667\n",
      " 4.66666667 6.         4.66666667]\n",
      "Correlation:  [[1.        0.1705902]\n",
      " [0.1705902 1.       ]]\n",
      "Mean absolute error = 0.81\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.7\n",
      "Explain variance score = -0.44\n",
      "R2 score = -0.53\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.67161324 4.89188333 5.63766518 6.92321776 6.37816475 6.82431716\n",
      " 5.83986915 4.81490384 5.95350592 6.49990791 5.42415434 4.92296811\n",
      " 4.33662532 5.36927872 4.61315631 5.77242443 5.55951763 5.52945987\n",
      " 5.96824335 6.15520965 5.510069   6.27711079 6.24582697 4.87024011\n",
      " 6.20205213 6.49433092 5.74291588 5.55410564 5.52759991 4.7729074\n",
      " 5.5669818  5.91543707 6.8003286  4.93720246 5.83621324 6.46932696\n",
      " 5.47392735 4.88921371 6.02790386 4.2410845  5.51741756 5.93043084\n",
      " 5.55297491 4.20416541 4.83817689 4.9272349  6.09626675 5.710936\n",
      " 6.03199156 5.23490667 5.01787393 5.53495313 4.63737371 5.61751217\n",
      " 5.53522699 6.05457687 5.25762848 5.27077678 6.38765767 5.53072606\n",
      " 6.13146906 5.58934754 5.56466338 6.17390749 5.10881222 5.62610555\n",
      " 4.02494755 4.2749782  6.16058091 5.6186152  5.07535035 6.12573676\n",
      " 5.83609755 5.1400305  5.8227037  5.73235372 5.47942616 6.20953405\n",
      " 5.59740118 5.186152   6.46238271 3.15537832 6.86591973 6.51238382\n",
      " 5.09816608 5.45197001 5.90917524 4.7992643  5.14722957 5.21082952\n",
      " 5.84616408 5.02003035 5.08764638 7.07670738 5.75279276 5.74923475\n",
      " 6.20822725 5.60939805 5.23578979 5.38949277 5.36443949 6.30031351\n",
      " 6.30500643 5.92114028 6.20836608 5.93527918 4.92747847 6.25008262\n",
      " 4.39630945 5.58715245 5.70944966 6.26269362 5.6284121  6.88585291\n",
      " 5.9038211  5.88749555 6.30444504 6.43121799 6.00962022 6.74157946\n",
      " 5.29890713 5.87608591 5.42857328 6.44780742 5.83907385 4.85062319\n",
      " 5.8864976  6.17200583 5.20356813]\n",
      "\n",
      "What it should be:  [5.33333333 3.83333333 6.5        6.66666667 6.         6.5\n",
      " 6.16666667 5.16666667 5.33333333 5.66666667 5.83333333 6.16666667\n",
      " 4.83333333 5.83333333 4.83333333 4.66666667 6.66666667 7.\n",
      " 5.16666667 5.66666667 5.         4.         3.33333333 4.66666667\n",
      " 4.5        6.16666667 6.5        5.33333333 6.5        4.\n",
      " 4.5        5.5        6.         6.         7.         5.\n",
      " 6.83333333 6.66666667 6.16666667 5.33333333 6.         4.33333333\n",
      " 5.83333333 6.33333333 5.83333333 6.5        5.16666667 3.5\n",
      " 6.66666667 6.33333333 6.16666667 5.16666667 6.5        6.33333333\n",
      " 6.         5.83333333 3.         4.         6.         6.33333333\n",
      " 7.         7.         5.83333333 5.5        4.83333333 5.66666667\n",
      " 5.83333333 6.83333333 6.5        5.16666667 6.16666667 6.83333333\n",
      " 6.         5.66666667 4.83333333 6.66666667 6.66666667 7.\n",
      " 5.66666667 5.16666667 6.         5.5        6.5        5.33333333\n",
      " 6.16666667 4.66666667 6.16666667 5.66666667 6.5        3.66666667\n",
      " 5.16666667 6.         6.16666667 6.33333333 5.83333333 4.\n",
      " 6.         6.83333333 6.16666667 4.83333333 4.5        6.16666667\n",
      " 4.5        4.66666667 5.33333333 6.16666667 6.5        5.66666667\n",
      " 3.66666667 5.33333333 6.66666667 4.33333333 4.16666667 6.5\n",
      " 4.66666667 4.66666667 7.         6.33333333 4.         5.5\n",
      " 4.83333333 5.33333333 5.5        5.33333333 6.16666667 4.83333333\n",
      " 5.33333333 6.16666667 5.83333333]\n",
      "Correlation:  [[1.         0.10962928]\n",
      " [0.10962928 1.        ]]\n",
      "Mean absolute error = 0.87\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.79\n",
      "Explain variance score = -0.37\n",
      "R2 score = -0.37\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.67476603 6.07524166 5.38069724 5.35874006 5.70263825 5.1437857\n",
      " 5.91416472 5.29633004 5.90907702 5.75865964 4.3983654  5.9319365\n",
      " 5.59587517 5.69638557 6.17456633 5.49608441 5.00262665 6.48547366\n",
      " 5.87446348 6.43815873 5.04649994 5.5490566  5.31655603 5.71686489\n",
      " 5.35771351 5.24961131 4.90548    5.39647993 5.732109   5.0624706\n",
      " 5.63677269 5.29838678 5.28002766 6.24828568 5.62956374 5.27629065\n",
      " 5.75289484 5.68840153 5.32585117 5.74679784 5.59750181 6.0525233\n",
      " 5.41050471 4.94625052 5.79444284 5.40437209 5.85589584 5.69368582\n",
      " 5.8687058  5.7377408  5.08013862 5.30474959 6.60684136 5.83801325\n",
      " 5.19087792 5.07638267 5.83868367 6.19195981 5.63985511 5.04945133\n",
      " 5.77087344 6.31473373 5.70607247 5.75980075 6.07502373 5.26409043\n",
      " 4.943297   5.61335291 5.18001543 5.60744018 4.53506713 5.40677366\n",
      " 5.65730245 5.50823218 5.11730088 5.38504213 4.18363998 6.15790717\n",
      " 5.62798406 4.82244022 5.55712719 6.15815561 5.45939947 5.80024274\n",
      " 5.78391973 5.26448467 5.93304158 5.32288859 6.23694008 5.78863003\n",
      " 5.61118761 6.03873782 6.50987945 6.19070471 5.52021464 5.5424014\n",
      " 5.67647492 5.56106259 5.17747583 5.8197714  6.02341249 5.80899264\n",
      " 4.82406777 5.56120397 5.4934733  4.61934743 5.65326432 5.40208552\n",
      " 5.59970231 6.57350743 5.96263416 5.4536391  5.54211722 5.61997232\n",
      " 5.72163755 5.63892361 4.95873652 6.16256092 5.79328621 5.9135175\n",
      " 4.70893833 5.16683037 5.4710632  5.80683679 5.95370146 5.82273075\n",
      " 5.3137733  5.89715179 5.20548156]\n",
      "\n",
      "What it should be:  [6.66666667 6.         4.5        5.33333333 5.5        4.33333333\n",
      " 4.5        6.         5.33333333 6.83333333 5.83333333 4.5\n",
      " 5.33333333 6.33333333 5.83333333 5.5        3.5        6.16666667\n",
      " 5.16666667 4.83333333 6.83333333 5.66666667 7.         5.16666667\n",
      " 6.16666667 5.16666667 4.16666667 6.66666667 5.33333333 6.33333333\n",
      " 5.5        6.         6.33333333 5.66666667 4.5        5.\n",
      " 5.16666667 6.33333333 6.         6.5        7.         5.66666667\n",
      " 4.         6.5        6.5        6.16666667 5.83333333 6.\n",
      " 5.66666667 6.16666667 6.83333333 4.83333333 3.66666667 5.83333333\n",
      " 4.66666667 5.83333333 5.66666667 6.16666667 6.66666667 6.33333333\n",
      " 6.         5.83333333 6.5        6.83333333 4.         5.16666667\n",
      " 5.         6.16666667 5.33333333 6.5        6.         6.\n",
      " 4.66666667 6.5        6.66666667 6.16666667 4.         6.33333333\n",
      " 6.33333333 6.66666667 3.66666667 3.         5.33333333 6.16666667\n",
      " 6.         7.         6.33333333 6.5        6.66666667 5.33333333\n",
      " 6.83333333 6.         6.83333333 5.66666667 6.33333333 6.83333333\n",
      " 6.16666667 6.16666667 6.16666667 7.         5.16666667 6.83333333\n",
      " 6.5        5.16666667 1.83333333 6.16666667 6.16666667 4.83333333\n",
      " 5.66666667 5.33333333 6.16666667 3.33333333 4.33333333 5.5\n",
      " 4.66666667 6.5        3.83333333 4.         6.16666667 4.33333333\n",
      " 5.5        6.66666667 5.83333333 4.83333333 6.83333333 6.16666667\n",
      " 5.5        6.83333333 4.66666667]\n",
      "Correlation:  [[1.         0.00572275]\n",
      " [0.00572275 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.13\n",
      "Median absolute error = 0.71\n",
      "Explain variance score = -0.2\n",
      "R2 score = -0.21\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [6.23171779 5.52602619 5.25469013 5.86940378 5.65951597 6.11337797\n",
      " 6.01807172 5.78674351 5.15335995 3.67709084 5.60315735 5.14622384\n",
      " 5.93389459 5.82625141 5.89952627 4.67271777 5.68714813 5.22724892\n",
      " 4.69859992 5.8997216  6.14548145 5.67666288 4.97319979 6.51635724\n",
      " 5.63506445 5.42175342 5.12164015 5.95700521 5.82981211 5.82679266\n",
      " 6.10613436 6.2885871  6.05640785 5.87430829 5.34244331 6.18991905\n",
      " 5.62956187 5.09681901 6.29320868 6.67192358 6.08609977 5.28233825\n",
      " 5.90650948 6.14293067 5.16751243 4.59407574 5.56890984 5.86887235\n",
      " 5.96183477 5.25153906 5.91599624 4.955552   6.47014603 5.61223759\n",
      " 4.81418023 5.52763584 6.0477874  6.5325889  5.83945263 5.56446369\n",
      " 5.72676749 5.8807908  5.49365229 6.23538657 6.82565744 5.23459316\n",
      " 5.24433162 6.33834439 6.46649834 6.39369516 6.00655546 5.68224105\n",
      " 6.22828088 5.70931829 6.43373964 4.85312444 5.00820709 5.46818568\n",
      " 6.53875264 5.50754243 4.26171623 5.28043292 4.79114687 5.98296119\n",
      " 6.14265355 5.46825337 5.6002707  5.80368048 6.31748658 5.28020842\n",
      " 4.15717592 5.09216915 5.74448338 5.90848317 6.68381722 5.00770189\n",
      " 6.14900861 5.13780419 6.06750005 5.26516833 4.68178789 4.31792709\n",
      " 6.08183084 6.14715584 6.12610573 5.68199339 5.87328132 5.77011757\n",
      " 5.86781696 5.33307617 5.92230218 5.63270272 6.43399538 5.64185887\n",
      " 6.26578987 5.49370297 6.15977669 5.82814625 6.27110555 4.75585814\n",
      " 6.09466517 4.31525719 5.66643834 6.3143088  6.33763221 4.69053998\n",
      " 4.23789659 5.32353547 5.88232132]\n",
      "\n",
      "What it should be:  [5.83333333 3.66666667 4.33333333 5.66666667 6.16666667 6.33333333\n",
      " 7.         5.         5.16666667 4.83333333 4.5        6.16666667\n",
      " 5.5        6.83333333 3.         5.83333333 5.16666667 6.33333333\n",
      " 6.16666667 6.         6.5        6.         6.33333333 6.33333333\n",
      " 5.66666667 4.         6.33333333 6.5        4.5        7.\n",
      " 6.66666667 4.16666667 6.         5.33333333 6.66666667 6.5\n",
      " 4.66666667 6.16666667 4.33333333 6.16666667 6.83333333 6.5\n",
      " 6.83333333 6.5        5.83333333 5.66666667 5.5        6.16666667\n",
      " 6.5        5.66666667 4.66666667 4.83333333 6.66666667 4.83333333\n",
      " 5.         5.33333333 4.66666667 5.5        6.66666667 6.5\n",
      " 6.16666667 5.33333333 6.33333333 6.         6.33333333 6.83333333\n",
      " 5.66666667 5.16666667 5.33333333 5.83333333 5.33333333 4.\n",
      " 5.16666667 5.33333333 3.33333333 3.5        6.         6.5\n",
      " 6.16666667 6.         6.5        5.83333333 5.83333333 4.5\n",
      " 6.66666667 4.         6.66666667 6.         5.66666667 6.16666667\n",
      " 5.5        4.33333333 3.66666667 4.83333333 5.83333333 6.5\n",
      " 6.5        4.83333333 6.66666667 5.16666667 5.83333333 3.83333333\n",
      " 4.66666667 5.66666667 6.         5.33333333 4.5        6.16666667\n",
      " 5.5        6.16666667 4.66666667 4.83333333 6.5        5.33333333\n",
      " 6.83333333 6.83333333 6.33333333 6.         5.83333333 7.\n",
      " 6.83333333 4.66666667 4.5        5.66666667 6.66666667 5.83333333\n",
      " 1.83333333 6.5        5.83333333]\n",
      "Correlation:  [[1.         0.18682116]\n",
      " [0.18682116 1.        ]]\n",
      "Mean absolute error = 0.84\n",
      "Mean squared error = 1.06\n",
      "Median absolute error = 0.76\n",
      "Explain variance score = -0.15\n",
      "R2 score = -0.15\n",
      " \n",
      " \n",
      "-------------- \n",
      "     ****************************************************\n",
      "LinearRegression()\n",
      "Predictet: [5.64223533 6.31799002 6.15924707 6.22721271 5.83408426 5.18925638\n",
      " 6.331707   6.00190558 5.65449797 6.12631288 6.10184855 5.37911814\n",
      " 5.5850814  5.69015775 6.33303481 6.27139564 5.55825232 5.96435441\n",
      " 5.48419521 6.26376647 6.2301445  5.2350001  5.51256894 6.46465716\n",
      " 5.66606379 5.85055664 6.1501248  5.77198669 6.113516   5.95832706\n",
      " 6.01288714 6.18373059 5.68275489 4.63786724 5.75354874 6.21098201\n",
      " 6.45139285 5.60829397 5.50320447 4.75579368 6.53684187 6.00473182\n",
      " 6.0249276  5.62169278 5.1976075  5.71483149 5.8618925  5.79038533\n",
      " 5.27221125 5.51949434 6.25921025 6.20250261 6.56096431 6.09717322\n",
      " 5.97095349 7.11766244 5.49718802 5.18850732 6.45906394 5.67191042\n",
      " 5.7048166  5.395457   5.54980388 6.08441702 5.43243463 5.86053508\n",
      " 5.9282373  6.1245469  5.67590303 6.58046833 5.47986247 5.63789153\n",
      " 6.76935018 6.21755713 4.69409373 5.30595691 5.96177743 6.10964458\n",
      " 5.46659623 5.12516368 5.92243188 6.27058072 6.29154564 6.14813214\n",
      " 5.85896216 5.98966602 5.29065827 5.82865671 5.68746395 6.17056472\n",
      " 6.46978592 6.32449372 7.05723091 5.29709858 5.96341744 5.47598722\n",
      " 4.73492009 5.04739925 5.06494791 6.09786653 5.31863151 5.85867697\n",
      " 5.0036769  5.46295974 5.88013213 5.74523757 5.0701105  5.70983019\n",
      " 5.3400676  5.51985772 5.87174871 6.64794733 5.76103058 5.82711962\n",
      " 6.55278768 6.05584269 5.68369609 5.95195761 5.9578716  5.37823857\n",
      " 4.86486956 5.3593929  5.99202934 6.59029218 5.61598846 6.50549239\n",
      " 5.15481261 5.15665927 5.44219261]\n",
      "\n",
      "What it should be:  [5.16666667 1.83333333 6.83333333 5.33333333 5.66666667 4.5\n",
      " 6.33333333 6.16666667 5.33333333 5.         4.         7.\n",
      " 5.33333333 5.5        6.16666667 6.5        6.16666667 6.5\n",
      " 5.66666667 4.66666667 5.16666667 5.33333333 4.83333333 5.33333333\n",
      " 5.16666667 5.66666667 6.         6.66666667 5.16666667 3.66666667\n",
      " 6.83333333 6.83333333 4.66666667 4.33333333 6.16666667 6.5\n",
      " 5.83333333 6.66666667 6.         4.66666667 5.33333333 6.5\n",
      " 6.16666667 5.16666667 5.16666667 6.66666667 6.83333333 6.16666667\n",
      " 6.66666667 6.16666667 6.5        5.66666667 7.         3.83333333\n",
      " 6.5        5.16666667 6.5        6.         4.33333333 5.33333333\n",
      " 5.83333333 5.66666667 6.33333333 5.83333333 6.83333333 6.5\n",
      " 5.         5.83333333 3.         5.5        5.5        4.66666667\n",
      " 6.5        4.66666667 6.16666667 5.66666667 6.16666667 5.\n",
      " 4.83333333 5.83333333 5.33333333 4.33333333 6.         5.5\n",
      " 4.66666667 4.83333333 6.33333333 5.16666667 6.66666667 5.83333333\n",
      " 6.33333333 6.         4.83333333 4.         6.16666667 6.16666667\n",
      " 5.5        5.         6.         6.         6.16666667 5.33333333\n",
      " 5.5        6.         5.16666667 7.         4.83333333 5.83333333\n",
      " 3.5        5.5        6.         7.         5.66666667 4.33333333\n",
      " 4.16666667 6.         4.         5.33333333 6.         5.\n",
      " 5.66666667 6.         5.83333333 6.5        5.33333333 5.83333333\n",
      " 4.5        6.         5.5       ]\n",
      "Correlation:  [[1.         0.06069328]\n",
      " [0.06069328 1.        ]]\n",
      "Mean absolute error = 0.75\n",
      "Mean squared error = 1.01\n",
      "Median absolute error = 0.62\n",
      "Explain variance score = -0.23\n",
      "R2 score = -0.29\n",
      " \n",
      " \n",
      "-------------- \n"
     ]
    }
   ],
   "source": [
    "save_meanabsoluteerror = []\n",
    "save_correlation = []\n",
    "for i in range(1,8):\n",
    "    print(\"****************************************************\")\n",
    "    print('0.'+str(i))\n",
    "    numpase = 0\n",
    "    for t in range(0,50):\n",
    "\n",
    "        print(\"     ****************************************************\")\n",
    "        c = list(zip(X, xCorr))\n",
    "        accur = []\n",
    "        random.shuffle(c)\n",
    "\n",
    "        DX, DY = zip(*c)\n",
    "        DX = np.array(DX)\n",
    "        DY = np.array(DY)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(DX, DY, test_size=float('0.'+str(i)))\n",
    "        # Create an object, or instance, of the class.\n",
    "        meanXpatient = []\n",
    "        X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "        X_test = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "\n",
    "        clf = linear_model.LinearRegression()\n",
    "        # Train it\n",
    "        #fitting (learning) the parameters of a model in sklearn is fit(X, y).\n",
    "        print(clf.fit(X_train, y_train))\n",
    "        clf.coef_\n",
    "        clf.intercept_\n",
    "        clf.score(X_train, y_train)\n",
    "        #predict the class of the test data\n",
    "        #sklearn is predict(X)\n",
    "        prediction = (clf.predict(X_test))\n",
    "        print('Predictet: {}\\n'.format(prediction) )\n",
    "        print('What it should be: ', y_test)\n",
    "        print('Correlation: ', np.corrcoef(y_test, prediction))\n",
    "        corre = np.corrcoef(y_test, prediction)\n",
    "        save_correlation.append(corre[0][1])\n",
    "        # Then, compute the classification accuracy obtained.\n",
    "        print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test, prediction), 2)) \n",
    "        print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, prediction), 2)) \n",
    "        save_meanabsoluteerror.append(round(sm.mean_absolute_error(y_test, prediction), 2))\n",
    "        print(\"Median absolute error =\", round(sm.median_absolute_error(y_test, prediction), 2)) \n",
    "        print(\"Explain variance score =\", round(sm.explained_variance_score(y_test, prediction), 2)) \n",
    "        print(\"R2 score =\", round(sm.r2_score(y_test, prediction), 2))\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        print('-------------- ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nan\nnan\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(save_meanabsoluteerror))\n",
    "print(np.mean(save_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lavels2 = []\n",
    "for i  in xCorr:\n",
    "    if i>5.0:\n",
    "        Lavels2.append(int(0))\n",
    "    if i<=5.0:\n",
    "        Lavels2.append(int(1))\n",
    "\n",
    "Y = np.array(Lavels2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************** 0.1\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.4\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.7368421052631579\n",
      "     Roc:  0.6323529411764706\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.4\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.5795454545454545\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7368421052631579\n",
      "     Roc:  0.5729166666666666\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.6346153846153846\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.5448717948717949\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.525\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.375\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.4285714285714286\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.7368421052631579\n",
      "     Roc:  0.6323529411764706\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.6166666666666667\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.5512820512820512\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.5285714285714286\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.3611111111111111\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.7368421052631579\n",
      "     Roc:  0.6500000000000001\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.8421052631578947\n",
      "     Roc:  0.6911764705882353\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.631578947368421\n",
      "     Roc:  0.3529411764705882\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.5928571428571427\n",
      "     Recall:  0.4\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.5416666666666666\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.7894736842105263\n",
      "     Roc:  0.4166666666666667\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.43333333333333335\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6842105263157895\n",
      "     Roc:  0.5416666666666666\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  23\n",
      "**************************************************** 0.2\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.48655913978494625\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.47629310344827586\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.5402097902097902\n",
      "     Recall:  0.2727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.5444444444444444\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.5786713286713286\n",
      "     Recall:  0.2727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.6190476190476191\n",
      "     Recall:  0.5714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.5203703703703704\n",
      "     Recall:  0.3\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.5416666666666666\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.4418103448275862\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.5850000000000001\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.5043103448275862\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7297297297297297\n",
      "     Roc:  0.5575396825396826\n",
      "     Recall:  0.2222222222222222\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.521505376344086\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.7297297297297297\n",
      "     Roc:  0.590625\n",
      "     Recall:  0.4\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.521505376344086\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.5976190476190476\n",
      "     Recall:  0.42857142857142855\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.4685314685314685\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.44841269841269843\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.513986013986014\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.36363636363636365\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.5176282051282051\n",
      "     Recall:  0.07692307692307693\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.43103448275862066\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.5203703703703704\n",
      "     Recall:  0.3\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.575925925925926\n",
      "     Recall:  0.3\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.6120689655172414\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.47043010752688175\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.490625\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7297297297297297\n",
      "     Roc:  0.50625\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.4685314685314685\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.6190476190476191\n",
      "     Recall:  0.5714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.513986013986014\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  31\n",
      "**************************************************** 0.3\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.48863636363636365\n",
      "     Recall:  0.2727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.7454545454545455\n",
      "     Roc:  0.6411149825783972\n",
      "     Recall:  0.42857142857142855\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4616724738675958\n",
      "     Recall:  0.14285714285714285\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.5917874396135265\n",
      "     Recall:  0.4444444444444444\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1]\n",
      "     El q ha de ser:  [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.48863636363636365\n",
      "     Recall:  0.2727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5253623188405797\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.7090909090909091\n",
      "     Roc:  0.6742021276595744\n",
      "     Recall:  0.625\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.45772946859903385\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5503875968992248\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.5319767441860466\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4844322344322345\n",
      "     Recall:  0.23076923076923078\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5467032967032966\n",
      "     Recall:  0.3076923076923077\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.4772727272727273\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.53397212543554\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5224458204334366\n",
      "     Recall:  0.17647058823529413\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5347985347985348\n",
      "     Recall:  0.3076923076923077\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6363636363636364\n",
      "     Roc:  0.46590909090909094\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4875\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7090909090909091\n",
      "     Roc:  0.5461672473867595\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.4903100775193798\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5074404761904762\n",
      "     Recall:  0.2857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5497076023391813\n",
      "     Recall:  0.21052631578947367\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.5166666666666667\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "     Accuracy:  0.6363636363636364\n",
      "     Roc:  0.4432234432234432\n",
      "     Recall:  0.07692307692307693\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4666666666666667\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5387596899224806\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5041666666666667\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4616724738675958\n",
      "     Recall:  0.14285714285714285\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "     El q ha de ser:  [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6363636363636364\n",
      "     Roc:  0.4973867595818815\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  29\n",
      "**************************************************** 0.4\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.47214734950584014\n",
      "     Recall:  0.09523809523809523\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.4354066985645933\n",
      "     Recall:  0.05263157894736842\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.4105603448275862\n",
      "     Recall:  0.0625\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6621621621621622\n",
      "     Roc:  0.5143540669856459\n",
      "     Recall:  0.21052631578947367\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.605296343001261\n",
      "     Recall:  0.5384615384615384\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.43890386343216536\n",
      "     Recall:  0.047619047619047616\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6621621621621622\n",
      "     Roc:  0.5178571428571428\n",
      "     Recall:  0.2857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.42063492063492064\n",
      "     Recall:  0.05555555555555555\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.439484126984127\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.7027027027027027\n",
      "     Roc:  0.5649717514124294\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.44011544011544007\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.4865229110512129\n",
      "     Recall:  0.14285714285714285\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.46726190476190477\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.47380952380952385\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.4981481481481481\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.5225988700564972\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.5107816711590296\n",
      "     Recall:  0.2857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.5574074074074075\n",
      "     Recall:  0.3\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.43163841807909603\n",
      "     Recall:  0.06666666666666667\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.5052631578947369\n",
      "     Recall:  0.21052631578947367\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6621621621621622\n",
      "     Roc:  0.47519841269841273\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "     El q ha de ser:  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.5668103448275862\n",
      "     Recall:  0.375\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6891891891891891\n",
      "     Roc:  0.4849137931034483\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.4789473684210527\n",
      "     Recall:  0.15789473684210525\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.5285714285714286\n",
      "     Recall:  0.35714285714285715\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.41964285714285715\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6486486486486487\n",
      "     Roc:  0.49166666666666664\n",
      "     Recall:  0.15\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6891891891891891\n",
      "     Roc:  0.5307539682539684\n",
      "     Recall:  0.2222222222222222\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.5043062200956937\n",
      "     Recall:  0.2631578947368421\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6621621621621622\n",
      "     Roc:  0.4083333333333333\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6891891891891891\n",
      "     Roc:  0.5067796610169492\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6756756756756757\n",
      "     Roc:  0.47629310344827586\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.7432432432432432\n",
      "     Roc:  0.6377990430622009\n",
      "     Recall:  0.42105263157894735\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6081081081081081\n",
      "     Roc:  0.44354066985645935\n",
      "     Recall:  0.10526315789473684\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.5174825174825175\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.41468926553672314\n",
      "     Recall:  0.06666666666666667\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6891891891891891\n",
      "     Roc:  0.5316384180790961\n",
      "     Recall:  0.26666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.5225988700564972\n",
      "     Recall:  0.3333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6216216216216216\n",
      "     Roc:  0.44841269841269843\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "     Accuracy:  0.6621621621621622\n",
      "     Roc:  0.5146892655367231\n",
      "     Recall:  0.26666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6351351351351351\n",
      "     Roc:  0.44802259887005647\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  41\n",
      "**************************************************** 0.5\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6086956521739131\n",
      "     Roc:  0.46376811594202894\n",
      "     Recall:  0.17391304347826086\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6304347826086957\n",
      "     Roc:  0.4704477611940299\n",
      "     Recall:  0.12\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6739130434782609\n",
      "     Roc:  0.5219899062725306\n",
      "     Recall:  0.2631578947368421\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.4852448021462106\n",
      "     Recall:  0.23809523809523808\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "     Accuracy:  0.6086956521739131\n",
      "     Roc:  0.43478260869565216\n",
      "     Recall:  0.08695652173913043\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7065217391304348\n",
      "     Roc:  0.5422077922077922\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.48550724637681164\n",
      "     Recall:  0.21739130434782608\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7065217391304348\n",
      "     Roc:  0.5415828303152247\n",
      "     Recall:  0.23809523809523808\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.45974025974025967\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6304347826086957\n",
      "     Roc:  0.44545454545454544\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7065217391304348\n",
      "     Roc:  0.5144927536231884\n",
      "     Recall:  0.13043478260869565\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.5072463768115942\n",
      "     Recall:  0.21739130434782608\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.575974025974026\n",
      "     Recall:  0.4090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6304347826086957\n",
      "     Roc:  0.475\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6847826086956522\n",
      "     Roc:  0.4967532467532467\n",
      "     Recall:  0.13636363636363635\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.5064935064935066\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.43831168831168826\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6413043478260869\n",
      "     Roc:  0.47791044776119407\n",
      "     Recall:  0.12\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6847826086956522\n",
      "     Roc:  0.5077611940298509\n",
      "     Recall:  0.12\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6956521739130435\n",
      "     Roc:  0.5507246376811594\n",
      "     Recall:  0.2608695652173913\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.44415584415584414\n",
      "     Recall:  0.045454545454545456\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.48550724637681153\n",
      "     Recall:  0.13043478260869565\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6413043478260869\n",
      "     Roc:  0.5147058823529411\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.44744744744744747\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.49283582089552247\n",
      "     Recall:  0.12\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.7065217391304348\n",
      "     Roc:  0.5183823529411764\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.4850649350649351\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.43791044776119403\n",
      "     Recall:  0.04\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.4966465459423206\n",
      "     Recall:  0.19047619047619047\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6739130434782609\n",
      "     Roc:  0.5128358208955224\n",
      "     Recall:  0.16\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.44415584415584414\n",
      "     Recall:  0.045454545454545456\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6195652173913043\n",
      "     Roc:  0.4680555555555556\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.517910447761194\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6413043478260869\n",
      "     Roc:  0.4819444444444444\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6086956521739131\n",
      "     Roc:  0.47792207792207797\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6304347826086957\n",
      "     Roc:  0.45495495495495497\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.525\n",
      "     Recall:  0.3\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6521739130434783\n",
      "     Roc:  0.5945945945945946\n",
      "     Recall:  0.5\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6956521739130435\n",
      "     Roc:  0.5708333333333334\n",
      "     Recall:  0.35\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6739130434782609\n",
      "     Roc:  0.5072463768115941\n",
      "     Recall:  0.17391304347826086\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6630434782608695\n",
      "     Roc:  0.517910447761194\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6086956521739131\n",
      "     Roc:  0.4623376623376624\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  42\n",
      "**************************************************** 0.6\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.4786821705426356\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6363636363636364\n",
      "     Roc:  0.4632034632034632\n",
      "     Recall:  0.030303030303030304\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6454545454545455\n",
      "     Roc:  0.46434294871794873\n",
      "     Recall:  0.03125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6454545454545455\n",
      "     Roc:  0.5270034843205574\n",
      "     Recall:  0.2857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      "     El q ha de ser:  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "     Accuracy:  0.6818181818181818\n",
      "     Roc:  0.5278745644599303\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6636363636363637\n",
      "     Roc:  0.5272199910754127\n",
      "     Recall:  0.25925925925925924\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7090909090909091\n",
      "     Roc:  0.5284090909090909\n",
      "     Recall:  0.22727272727272727\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5364705882352941\n",
      "     Recall:  0.32\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.47430313588850176\n",
      "     Recall:  0.10714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n",
      "     Accuracy:  0.7\n",
      "     Roc:  0.5229166666666667\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6090909090909091\n",
      "     Roc:  0.46041666666666664\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.5255427841634738\n",
      "     Recall:  0.3103448275862069\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.49127906976744184\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5100174216027875\n",
      "     Recall:  0.17857142857142858\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7090909090909091\n",
      "     Roc:  0.4991289198606272\n",
      "     Recall:  0.07142857142857142\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7181818181818181\n",
      "     Roc:  0.5432692307692307\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6454545454545455\n",
      "     Roc:  0.489010989010989\n",
      "     Recall:  0.19230769230769232\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "     Accuracy:  0.6636363636363637\n",
      "     Roc:  0.4686411149825784\n",
      "     Recall:  0.07142857142857142\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     Accuracy:  0.6090909090909091\n",
      "     Roc:  0.5449775112443778\n",
      "     Recall:  0.43478260869565216\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6363636363636364\n",
      "     Roc:  0.48421615837346177\n",
      "     Recall:  0.23809523809523808\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6454545454545455\n",
      "     Roc:  0.44917582417582413\n",
      "     Recall:  0.07692307692307693\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.4793793385055125\n",
      "     Recall:  0.16129032258064516\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.6126936531734133\n",
      "     Recall:  0.4782608695652174\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.4764705882352941\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.5068681318681318\n",
      "     Recall:  0.19230769230769232\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6636363636363637\n",
      "     Roc:  0.45764705882352946\n",
      "     Recall:  0.08\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.7\n",
      "     Roc:  0.5047909407665505\n",
      "     Recall:  0.10714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.4986933797909408\n",
      "     Recall:  0.10714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1\n",
      " 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.508495752123938\n",
      "     Recall:  0.30434782608695654\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.45314591700133866\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.509581881533101\n",
      "     Recall:  0.21428571428571427\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6636363636363637\n",
      "     Roc:  0.5039198606271776\n",
      "     Recall:  0.17857142857142858\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.47076461769115446\n",
      "     Recall:  0.21739130434782608\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.4712182061579652\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6272727272727273\n",
      "     Roc:  0.45601045296167253\n",
      "     Recall:  0.10714285714285714\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6909090909090909\n",
      "     Roc:  0.5325077399380805\n",
      "     Recall:  0.11764705882352941\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5213414634146342\n",
      "     Recall:  0.25\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6181818181818182\n",
      "     Roc:  0.44712182061579653\n",
      "     Recall:  0.1111111111111111\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.4903100775193798\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6454545454545455\n",
      "     Roc:  0.5151717983043285\n",
      "     Recall:  0.25925925925925924\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6545454545454545\n",
      "     Roc:  0.5087014725568942\n",
      "     Recall:  0.2222222222222222\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6090909090909091\n",
      "     Roc:  0.4929411764705882\n",
      "     Recall:  0.28\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6727272727272727\n",
      "     Roc:  0.534269902085994\n",
      "     Recall:  0.2413793103448276\n",
      " \n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  43\n",
      "**************************************************** 0.7\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "     Accuracy:  0.6589147286821705\n",
      "     Roc:  0.48620689655172417\n",
      "     Recall:  0.1724137931034483\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6976744186046512\n",
      "     Roc:  0.5143186306780777\n",
      "     Recall:  0.16129032258064516\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6124031007751938\n",
      "     Roc:  0.4338383838383839\n",
      "     Recall:  0.1\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.47678018575851394\n",
      "     Recall:  0.058823529411764705\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.4673374613003096\n",
      "     Recall:  0.029411764705882353\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.689922480620155\n",
      "     Roc:  0.5132575757575758\n",
      "     Recall:  0.15151515151515152\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6511627906976745\n",
      "     Roc:  0.4557750759878419\n",
      "     Recall:  0.02857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.47939068100358423\n",
      "     Recall:  0.05555555555555555\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.48622291021671826\n",
      "     Recall:  0.08823529411764706\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.5217461340206185\n",
      "     Recall:  0.21875\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6046511627906976\n",
      "     Roc:  0.44040404040404035\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.47695852534562216\n",
      "     Recall:  0.0967741935483871\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6356589147286822\n",
      "     Roc:  0.4722222222222222\n",
      "     Recall:  0.16666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.7131782945736435\n",
      "     Roc:  0.5161082474226804\n",
      "     Recall:  0.125\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6976744186046512\n",
      "     Roc:  0.5479310344827587\n",
      "     Recall:  0.27586206896551724\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.7286821705426356\n",
      "     Roc:  0.5492424242424242\n",
      "     Recall:  0.18181818181818182\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1\n",
      " 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.5548090523338047\n",
      "     Recall:  0.35714285714285715\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "     El q ha de ser:  [1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.5156565656565657\n",
      "     Recall:  0.23333333333333334\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1\n",
      " 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1\n",
      " 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6124031007751938\n",
      "     Roc:  0.5072489391796322\n",
      "     Recall:  0.32142857142857145\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "     Accuracy:  0.6589147286821705\n",
      "     Roc:  0.4790273556231003\n",
      "     Recall:  0.08571428571428572\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.689922480620155\n",
      "     Roc:  0.518448275862069\n",
      "     Recall:  0.20689655172413793\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6434108527131783\n",
      "     Roc:  0.5251724137931034\n",
      "     Recall:  0.3103448275862069\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.4718564845292955\n",
      "     Recall:  0.0967741935483871\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.4294827586206897\n",
      "     Recall:  0.06896551724137931\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.47844827586206895\n",
      "     Recall:  0.20689655172413793\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6434108527131783\n",
      "     Roc:  0.5813461538461538\n",
      "     Recall:  0.48\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "     Accuracy:  0.6356589147286822\n",
      "     Roc:  0.422680412371134\n",
      "     Recall:  0.0\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.502020202020202\n",
      "     Recall:  0.26666666666666666\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.4777462121212121\n",
      "     Recall:  0.09090909090909091\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "     Accuracy:  0.689922480620155\n",
      "     Roc:  0.4939655172413793\n",
      "     Recall:  0.13793103448275862\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.504040404040404\n",
      "     Recall:  0.2\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6589147286821705\n",
      "     Roc:  0.4757575757575757\n",
      "     Recall:  0.13333333333333333\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6821705426356589\n",
      "     Roc:  0.49148606811145507\n",
      "     Recall:  0.08823529411764706\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6666666666666666\n",
      "     Roc:  0.4715170278637771\n",
      "     Recall:  0.058823529411764705\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.49081829896907214\n",
      "     Recall:  0.21875\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "     Accuracy:  0.6976744186046512\n",
      "     Roc:  0.48768996960486316\n",
      "     Recall:  0.02857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6511627906976745\n",
      "     Roc:  0.44747474747474747\n",
      "     Recall:  0.06666666666666667\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Bad accu\n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.6511627906976745\n",
      "     Roc:  0.4567241379310345\n",
      "     Recall:  0.10344827586206896\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "     Accuracy:  0.6976744186046512\n",
      "     Roc:  0.4867241379310345\n",
      "     Recall:  0.10344827586206896\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.500805412371134\n",
      "     Recall:  0.15625\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1]\n",
      "     El q ha de ser:  [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.43500000000000005\n",
      "     Recall:  0.12\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.4945533769063181\n",
      "     Recall:  0.18518518518518517\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1]\n",
      "     El q ha de ser:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "     Accuracy:  0.627906976744186\n",
      "     Roc:  0.5042432814710042\n",
      "     Recall:  0.2857142857142857\n",
      " \n",
      "     --\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "     Predictet: [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     El q ha de ser:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "     Accuracy:  0.6744186046511628\n",
      "     Roc:  0.49327956989247307\n",
      "     Recall:  0.08333333333333333\n",
      " \n",
      "************************************************ The half of the iterations dont past the .6 accur\n",
      "Num de acc que pasa de 0.5:  44\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "for i in range(1,8):\n",
    "    print(\"**************************************************** 0.\"+str(i))\n",
    "    numpase = 0\n",
    "    accur = []\n",
    "    xin = []\n",
    "    for t in range(0,50):\n",
    "\n",
    "        print(\"     --\")\n",
    "        c = list(zip(X, Y))\n",
    "\n",
    "        random.shuffle(c)\n",
    "\n",
    "        DX, DY = zip(*c)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(DX, DY, test_size=float('0.'+str(i)))\n",
    "        X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "        X_test = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "\n",
    "        # Create an object, or instance, of the class.\n",
    "        # Train it\n",
    "        # Adjust the parameters so it can predict the correct class as accurately.\n",
    "        clf = LinearSVC(penalty='l2', multi_class='crammer_singer',)\n",
    "        #fitting (learning) the parameters of a model in sklearn is fit(X, y).\n",
    "        print(clf.fit(X_train, y_train))\n",
    "        clf.coef_\n",
    "        clf.intercept_\n",
    "        clf.score(X_train, y_train)\n",
    "        #predict the class of the test data\n",
    "        #sklearn is predict(X)\n",
    "        prediction = (clf.predict(X_test))\n",
    "        try:\n",
    "            if float(accuracy_score(y_test, prediction))>0.6:\n",
    "                print('     Predictet: {}'.format(prediction) )\n",
    "                print('     El q ha de ser: ',y_test)\n",
    "                # Then, compute the classification accuracy obtained.\n",
    "                print('     Accuracy: ', accuracy_score(y_test, prediction))\n",
    "\n",
    "                print('     Roc: ',roc_auc_score(y_test, prediction))\n",
    "\n",
    "                print('     Recall: ',recall_score(y_test, prediction))\n",
    "                print(' ')\n",
    "                numpase=numpase+1\n",
    "                accur.append(float(accuracy_score(y_test, prediction)))\n",
    "                xin.append(str(t))\n",
    "            else:\n",
    "                print('     Bad accu')\n",
    "    \n",
    "        except:\n",
    "            print('ERROR')\n",
    "    if numpase>25:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_axes([0,0,1,1])\n",
    "        ax.bar(xin,accur)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('************************************************ The half of the iterations dont past the .6 accur')\n",
    "    print('Num de acc que pasa de 0.5: ',numpase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}